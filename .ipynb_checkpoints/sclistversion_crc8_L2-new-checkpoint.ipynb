{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8752b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc45a",
   "metadata": {},
   "source": [
    "# Configuration variables (previously args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b957ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # Block length\n",
    "K = 37   # Message size\n",
    "kernel_size = 16  # Kernel size (ell)\n",
    "rate_profile = 'polar'  # Rate profiling; choices=['RM', 'polar', 'sorted', 'last', 'rev_polar', 'custom']\n",
    "infty = 1000.  # Infinity value for frozen position LLR in polar dec\n",
    "lse = 'minsum'  # LSE function; choices=['minsum', 'lse']\n",
    "hard_decision = False  # Polar code sc decoding hard decision?\n",
    "\n",
    "# DeepPolar parameters\n",
    "encoder_type = 'KO'  # Type of encoding; choices=['KO', 'scaled', 'polar']\n",
    "decoder_type = 'KO'  # Type of decoding; choices=['KO', 'SC', 'KO_parallel', 'KO_last_parallel']\n",
    "enc_activation = 'selu'  # Activation function\n",
    "dec_activation = 'selu'  # Activation function\n",
    "dropout_p = 0.\n",
    "dec_hidden_size = 128  # Neural network size\n",
    "enc_hidden_size = 64   # Neural network size\n",
    "f_depth = 3  # Decoder neural network depth\n",
    "g_depth = 3  # Encoder neural network depth\n",
    "g_skip_depth = 1  # Encoder neural network skip depth\n",
    "g_skip_layer = 1  # Encoder neural network skip layer\n",
    "onehot = False  # Use onehot representation of prev_decoded_bits\n",
    "shared = False  # Share weights across depth\n",
    "use_skip = True  # Use skip connections\n",
    "use_norm = False  # Use normalization\n",
    "binary = False  # Use binary quantization\n",
    "\n",
    "# Infrastructure parameters\n",
    "id = None  # Optional ID for multiple runs\n",
    "test = False  # Testing mode flag\n",
    "pairwise = False  # Plot codeword pairwise distances\n",
    "epos = False  # Plot error positions\n",
    "seed = None  # Random seed\n",
    "anomaly = False  # Enable anomaly detection\n",
    "dataparallel = False  # Use dataparallel\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture parameters\n",
    "polar_depths = []  # List of depths to use polar encoding/decoding\n",
    "last_ell = None  # Use kernel last_ell last layer\n",
    "\n",
    "\n",
    "# Channel parameters\n",
    "radar_power = None  # Radar power parameter\n",
    "radar_prob = 0.1  # Radar probability parameter\n",
    "\n",
    "# Training parameters\n",
    "full_iters = 500  # Full iterations\n",
    "enc_train_iters = 30  # Encoder iterations\n",
    "dec_train_iters = 300  # Decoder iterations\n",
    "enc_train_snr = 0.  # SNR at which encoder is trained\n",
    "dec_train_snr = -2.  # SNR at which decoder is trained\n",
    "weight_decay = 0.0\n",
    "dec_lr = 0.001  # Decoder Learning rate\n",
    "enc_lr = 0.001  # Encoder Learning rate\n",
    "batch_size = 20000  # Size of batches\n",
    "small_batch_size = 5000  # Size of small batches\n",
    "noise_type = 'awgn'  # Noise type; choices=['fading', 'awgn', 'radar']\n",
    "regularizer = None  # Regularizer type; choices=['std', 'max_deviation','polar']\n",
    "regularizer_weight = 0.001\n",
    "loss_type = 'BCE' # loss function; choices=['MSE', 'BCE', 'BCE_reg', 'L1', 'huber', 'focal', 'BCE_bler']\n",
    "initialization = 'random'  # Initialization type; choices=['random', 'zeros']\n",
    "optim_name = 'Adam'  # Optimizer type; choices=['Adam', 'RMS', 'SGD', 'AdamW']\n",
    "\n",
    "# Testing parameters\n",
    "test_batch_size = 2000  # Size of test batches\n",
    "num_errors = 100  # Test until _ block errors\n",
    "test_snr_start = -5.  # Testing SNR start\n",
    "test_snr_end = -1.   # Testing SNR end\n",
    "snr_points = 5       # Testing SNR num points\n",
    "\n",
    "\n",
    "\n",
    "# Model saving/loading parameters\n",
    "model_save_per = 100  # Model save frequency\n",
    "model_iters = None  # Option to load specific model iteration\n",
    "test_load_path = None  # Path to load test model\n",
    "\n",
    "load_path = None  # Load path \n",
    "kernel_load_path = 'Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new'   # Kernel load path\n",
    "no_fig = False  # Plot figure option\n",
    "\n",
    "\n",
    "# Scheduler parameters\n",
    "scheduler = 'cosine' # choices = ['reduce', '1cycle', 'cosine']\n",
    "scheduler_patience = None  # Scheduler patience\n",
    "batch_schedule = False  # Use batch scheduler\n",
    "batch_patience = 50  # Batch scheduler patience \n",
    "batch_factor = 2  # Batch multiplication factor\n",
    "min_batch_size = 500  # Minimum batch size\n",
    "max_batch_size = 50000  # Maximum batch size\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117821f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab1d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "crc_len = 3  # CRC length \n",
    "# Initialize CRC\n",
    "crc_poly = [1, 0, 1, 1]  # CRC polynomial\n",
    "L=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc384a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_original_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}/{encoder_type}__{enc_train_snr}_Encoder_{decoder_type}_{dec_train_snr}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e40922",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}_SClist_L_{L}_crc_{crc_poly}/{encoder_type}_Encoder_{decoder_type}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0c3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path +'/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e521",
   "metadata": {},
   "source": [
    "# Part 1: Core Utilities and Model Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_db2sigma(train_snr):\n",
    "    return 10**(-train_snr*1.0/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a23a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2bb73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a smoother version using product of bit probabilities\n",
    "def soft_bler_loss(logits, targets):\n",
    "    bit_probs = torch.sigmoid(logits)  # For correct bits\n",
    "    bit_probs = torch.where(targets == 1., bit_probs, 1 - bit_probs)\n",
    "    block_probs = torch.prod(bit_probs, dim=1)  # Probability of whole block being correct\n",
    "    return -torch.mean(torch.log(block_probs + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b989d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_ber(y_true, y_pred, mask=None):\n",
    "    if mask == None:\n",
    "        mask=torch.ones(y_true.size(),device=y_true.device)\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "    mask = mask.view(mask.shape[0], -1, 1)\n",
    "    myOtherTensor = (mask*torch.ne(torch.round(y_true), torch.round(y_pred))).float()\n",
    "    res = sum(sum(myOtherTensor))/(torch.sum(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_bler(y_true, y_pred, get_pos = False):\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "\n",
    "    decoded_bits = torch.round(y_pred).cpu()\n",
    "    X_test = torch.round(y_true).cpu()\n",
    "    tp0 = (abs(decoded_bits-X_test)).view([X_test.shape[0],X_test.shape[1]])\n",
    "    tp0 = tp0.detach().cpu().numpy()\n",
    "    bler_err_rate = sum(np.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
    "\n",
    "    if not get_pos:\n",
    "        return bler_err_rate\n",
    "    else:\n",
    "        err_pos = list(np.nonzero((np.sum(tp0,axis=1)>0).astype(int))[0])\n",
    "        return bler_err_rate, err_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92df8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_signal(input_signal, sigma = 1.0, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 0.05):\n",
    "    data_shape = input_signal.shape\n",
    "    device = input_signal.device\n",
    "    if noise_type == 'awgn':\n",
    "        dist = torch.distributions.Normal(torch.tensor([0.0], device=device), torch.tensor([sigma], device=device))\n",
    "        noise = dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 'fading':\n",
    "        fading_h = torch.sqrt(torch.randn_like(input_signal)**2 + torch.randn_like(input_signal)**2)/np.sqrt(3.14/2.0)\n",
    "        noise = sigma * torch.randn_like(input_signal)\n",
    "        corrupted_signal = fading_h *(input_signal) + noise\n",
    "\n",
    "    elif noise_type == 'radar':\n",
    "        add_pos = np.random.choice([0.0, 1.0], data_shape, p=[1 - radar_prob, radar_prob])\n",
    "        corrupted_signal = radar_power* np.random.standard_normal(size=data_shape) * add_pos\n",
    "        noise = sigma * torch.randn_like(input_signal) +\\\n",
    "                    torch.from_numpy(corrupted_signal).float().to(input_signal.device)\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 't-dist':\n",
    "        dist = torch.distributions.StudentT(torch.tensor([vv], device=device))\n",
    "        noise = sigma* dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    return corrupted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e97bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp(x, y):\n",
    "    log_sum_ms = torch.min(torch.abs(x), torch.abs(y))*torch.sign(x)*torch.sign(y)\n",
    "    return log_sum_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5937279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp_4(x_1, x_2, x_3, x_4):\n",
    "    return min_sum_log_sum_exp(min_sum_log_sum_exp(x_1, x_2), min_sum_log_sum_exp(x_3, x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c239bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, y):\n",
    "    def log_sum_exp_(LLR_vector):\n",
    "        sum_vector = LLR_vector.sum(dim=1, keepdim=True)\n",
    "        sum_concat = torch.cat([sum_vector, torch.zeros_like(sum_vector)], dim=1)\n",
    "        return torch.logsumexp(sum_concat, dim=1)- torch.logsumexp(LLR_vector, dim=1) \n",
    "\n",
    "    Lv = log_sum_exp_(torch.cat([x.unsqueeze(2), y.unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "    return Lv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655fe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bitarray(in_number, bit_width):\n",
    "    binary_string = bin(in_number)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(bit_width, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[bit_width-i-1] = int(binary_string[length-i-1])\n",
    "    return bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a081f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSetBits(n):\n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, enc_quantize_level = 2, enc_value_limit = 1.0, enc_grad_limit = 0.01, enc_clipping = 'both'):\n",
    "        ctx.save_for_backward(inputs)\n",
    "        assert enc_clipping in ['both', 'inputs']\n",
    "        ctx.enc_clipping = enc_clipping\n",
    "        ctx.enc_value_limit = enc_value_limit\n",
    "        ctx.enc_quantize_level = enc_quantize_level\n",
    "        ctx.enc_grad_limit = enc_grad_limit\n",
    "\n",
    "        x_lim_abs = enc_value_limit\n",
    "        x_lim_range = 2.0 * x_lim_abs\n",
    "        x_input_norm = torch.clamp(inputs, -x_lim_abs, x_lim_abs)\n",
    "\n",
    "        if enc_quantize_level == 2:\n",
    "            outputs_int = torch.sign(x_input_norm)\n",
    "        else:\n",
    "            outputs_int = torch.round((x_input_norm +x_lim_abs) * ((enc_quantize_level - 1.0)/x_lim_range)) * x_lim_range/(enc_quantize_level - 1.0) - x_lim_abs\n",
    "\n",
    "        return outputs_int\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.enc_clipping in ['inputs', 'both']:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input>ctx.enc_value_limit]=0\n",
    "            grad_output[input<-ctx.enc_value_limit]=0\n",
    "\n",
    "        if ctx.enc_clipping in ['gradient', 'both']:\n",
    "            grad_output = torch.clamp(grad_output, -ctx.enc_grad_limit, ctx.enc_grad_limit)\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d695a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'tanh':\n",
    "        return F.tanh\n",
    "    elif activation == 'elu':\n",
    "        return F.elu\n",
    "    elif activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'selu':\n",
    "        return F.selu\n",
    "    elif activation == 'sigmoid':\n",
    "        return F.sigmoid\n",
    "    elif activation == 'gelu':\n",
    "        return F.gelu\n",
    "    elif activation == 'silu':\n",
    "        return F.silu\n",
    "    elif activation == 'mish':\n",
    "        return F.mish\n",
    "    elif activation == 'linear':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Activation function {activation} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth=3, skip_depth=1, skip_layer=1, ell=2, activation='selu', use_skip=False, augment=False):\n",
    "        super(g_Full, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.ell = ell\n",
    "        self.ell_input_size = input_size//self.ell\n",
    "        self.augment = augment\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "        self.skip_depth = skip_depth\n",
    "        self.skip_layer = skip_layer\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        if self.use_skip:\n",
    "            self.skip = nn.ModuleList([nn.Linear(self.input_size + self.output_size, self.hidden_size, bias=True)])\n",
    "            self.skip.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.skip_depth)])\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        self.linears.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.depth)])\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_augment(msg, ell):\n",
    "        u = msg.clone()\n",
    "        n = int(np.log2(ell))\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, ell, 2*num_bits):\n",
    "                if len(u.shape) == 2:\n",
    "                    u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                elif len(u.shape) == 3:\n",
    "                    u = torch.cat((u[:, :, :i], u[:, :, i:i+num_bits].clone() * u[:, :, i+num_bits: i+2*num_bits], u[:, :, i+num_bits:]), dim=2)\n",
    "\n",
    "        if len(u.shape) == 3:\n",
    "            return u[:, :, :-1]\n",
    "        elif len(u.shape) == 2:\n",
    "            return u[:, :-1]\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y.clone()\n",
    "        for ii, layer in enumerate(self.linears):\n",
    "            if ii != self.depth:\n",
    "                x = self.activation_fn(layer(x))\n",
    "                if self.use_skip and ii == self.skip_layer:\n",
    "                    if len(x.shape) == 3:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=2)\n",
    "                    elif len(x.shape) == 2:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=1)\n",
    "                    for jj, skip_layer in enumerate(self.skip):\n",
    "                        skip_input = self.activation_fn(skip_layer(skip_input))\n",
    "                    x = x + skip_input\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if self.augment:\n",
    "                    x = x + g_Full.get_augment(y, self.ell)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d72065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape should be: (batch_size, seq_len, hidden_dim)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class f_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0., activation='selu', depth=3, use_norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.use_norm = use_norm\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "\n",
    "        # Initial layers same as original f_Full\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        if self.use_norm:\n",
    "            self.norms = nn.ModuleList([nn.LayerNorm(self.hidden_size)])\n",
    "        \n",
    "        # Attention layer after first linear\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,  # Reduced number of heads\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Remaining layers same as original\n",
    "        for ii in range(1, self.depth):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size, bias=True))\n",
    "            if self.use_norm:\n",
    "                self.norms.append(nn.LayerNorm(self.hidden_size))\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    def forward(self, y, aug=None):\n",
    "        x = y.clone()\n",
    "        \n",
    "        # First linear layer\n",
    "        x = self.linears[0](x)\n",
    "        if self.use_norm:\n",
    "            x = self.norms[0](x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        # Reshape for attention: [batch, seq_len, hidden]\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = attn_out if len(y.shape) == 3 else attn_out.squeeze(1)\n",
    "        \n",
    "        # Remaining layers\n",
    "        for ii in range(1, len(self.linears)):\n",
    "            if ii != self.depth:\n",
    "                x = self.linears[ii](x)\n",
    "                if self.use_norm:\n",
    "                    x = self.norms[ii](x)\n",
    "                x = self.activation_fn(x)\n",
    "            else:\n",
    "                x = self.linears[ii](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10845154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        try:\n",
    "            m.bias.data.fill_(0.)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e38e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(actions):\n",
    "    inds = (0.5 + 0.5*actions).long()\n",
    "    return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594f46",
   "metadata": {},
   "source": [
    "# Part 2: Core PolarCode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarCode:\n",
    "\n",
    "    def __init__(self, n, K, Fr = None, rs = None, use_cuda = True, infty = 1000., hard_decision = False, lse = 'lse'):\n",
    "\n",
    "        assert n>=1\n",
    "        self.n = n\n",
    "        self.N = 2**n\n",
    "        self.K = K\n",
    "        self.G2 = np.array([[1,1],[0,1]])\n",
    "        self.G = np.array([1])\n",
    "        for i in range(n):\n",
    "            self.G = np.kron(self.G, self.G2)\n",
    "        self.G = torch.from_numpy(self.G).float()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.infty = infty\n",
    "        self.hard_decision = hard_decision\n",
    "        self.lse = lse\n",
    "\n",
    "        if Fr is not None:\n",
    "            assert len(Fr) == self.N - self.K\n",
    "            self.frozen_positions = Fr\n",
    "            self.unsorted_frozen_positions = self.frozen_positions\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "            self.info_positions = np.array(list(set(self.frozen_positions) ^ set(np.arange(self.N))))\n",
    "            self.unsorted_info_positions = self.info_positions\n",
    "            self.info_positions.sort()\n",
    "            \n",
    "        else:\n",
    "            if rs is None:\n",
    "                # in increasing order of reliability\n",
    "                self.reliability_seq = np.arange(1023, -1, -1)\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "            else:\n",
    "                self.reliability_seq = rs\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "\n",
    "                assert len(self.rs) == self.N\n",
    "            # best K bits\n",
    "            self.info_positions = self.rs[:self.K]\n",
    "            self.unsorted_info_positions = self.reliability_seq[self.reliability_seq<self.N][:self.K]\n",
    "            self.info_positions.sort()\n",
    "            self.unsorted_info_positions=np.flip(self.unsorted_info_positions)\n",
    "            # worst N-K bits\n",
    "            self.frozen_positions = self.rs[self.K:]\n",
    "            self.unsorted_frozen_positions = self.rs[self.K:]\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "\n",
    "            self.CRC_polynomials = {\n",
    "            3: torch.Tensor([1, 0, 1, 1]).int(),\n",
    "            8: torch.Tensor([1, 1, 1, 0, 1, 0, 1, 0, 1]).int(),\n",
    "            16: torch.Tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]).int(),\n",
    "                                    }\n",
    "\n",
    "    def get_G(self, ell):\n",
    "        n = int(np.log2(ell))\n",
    "        G = np.array([1])\n",
    "        for i in range(n):\n",
    "            G = np.kron(G, self.G2)\n",
    "        return G\n",
    "\n",
    "    def encode_plotkin(self, message, scaling = None, custom_info_positions = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "        if custom_info_positions is not None:\n",
    "            info_positions = custom_info_positions\n",
    "        else:\n",
    "            info_positions = self.info_positions\n",
    "        u = torch.ones(message.shape[0], self.N, dtype=torch.float).to(message.device)\n",
    "        u[:, info_positions] = message\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                # u[:, i:i+num_bits] = u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits].clone\n",
    "        if scaling is not None:\n",
    "            u = (scaling * np.sqrt(self.N)*u)/torch.norm(scaling)\n",
    "        return u\n",
    "    \n",
    "    def channel(self, code, snr, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 5e-2):\n",
    "        if noise_type != \"bsc\":\n",
    "            sigma = snr_db2sigma(snr)\n",
    "        else:\n",
    "            sigma = snr\n",
    "\n",
    "        r = corrupt_signal(code, sigma, noise_type, vv, radar_power, radar_prob)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def define_partial_arrays(self, llrs):\n",
    "        # Initialize arrays to store llrs and partial_sums useful to compute the partial successive cancellation process.\n",
    "        llr_array = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        llr_array[:, self.n] = llrs\n",
    "        partial_sums = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        return llr_array, partial_sums\n",
    "\n",
    "\n",
    "    def updateLLR(self, leaf_position, llrs, partial_llrs = None, prior = None):\n",
    "\n",
    "        #START\n",
    "        depth = self.n\n",
    "        decoded_bits = partial_llrs[:,0].clone()\n",
    "        if prior is None:\n",
    "            prior = torch.zeros(self.N) #priors\n",
    "        llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth, 0, leaf_position, prior, decoded_bits)\n",
    "        return llrs, decoded_bits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def partial_decode(self, llrs, partial_llrs, depth, bit_position, leaf_position, prior, decoded_bits=None):\n",
    "        # Function to call recursively, for partial SC decoder.\n",
    "        # We are assuming that u_0, u_1, .... , u_{leaf_position -1} bits are known.\n",
    "        # Partial sums computes the sums got through Plotkin encoding operations of known bits, to avoid recomputation.\n",
    "        # this function is implemented for rate 1 (not accounting for frozen bits in polar SC decoding)\n",
    "\n",
    "        # print(\"DEPTH = {}, bit_position = {}\".format(depth, bit_position))\n",
    "        half_index = 2 ** (depth - 1)\n",
    "        leaf_position_at_depth = leaf_position // 2**(depth-1) # will tell us whether left_child or right_child\n",
    "\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            # Left child\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position:left_bit_position+1]\n",
    "            elif leaf_position_at_depth == left_bit_position:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                elif self.lse == 'lse':\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                #print(Lu.device, prior.device, torch.ones_like(Lu).device)\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu + prior[left_bit_position]*torch.ones_like(Lu)\n",
    "                if self.hard_decision:\n",
    "                    u_hat = torch.sign(Lu)\n",
    "                else:\n",
    "                    u_hat = torch.tanh(Lu/2)\n",
    "\n",
    "                decoded_bits[:, left_bit_position] = u_hat.squeeze(1)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # Right child\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "            if leaf_position_at_depth > right_bit_position:\n",
    "                pass\n",
    "            elif leaf_position_at_depth == right_bit_position:\n",
    "                Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "                llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv + prior[right_bit_position] * torch.ones_like(Lv)\n",
    "                if self.hard_decision:\n",
    "                    v_hat = torch.sign(Lv)\n",
    "                else:\n",
    "                    v_hat = torch.tanh(Lv/2)\n",
    "                decoded_bits[:, right_bit_position] = v_hat.squeeze(1)\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            # LEFT CHILD\n",
    "            # Find likelihood of (u xor v) xor (v) = u\n",
    "            # Lu = log_sum_exp(torch.cat([llrs[:, :half_index].unsqueeze(2), llrs[:, half_index:].unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                Lu = llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "            else:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                elif self.lse == 'lse':\n",
    "                    # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu\n",
    "                llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, left_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # RIGHT CHILD\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "\n",
    "            Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "            llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv\n",
    "            llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, right_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "            return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "    def updatePartialSums(self, leaf_position, decoded_bits, partial_llrs):\n",
    "\n",
    "        u = decoded_bits.clone()\n",
    "        u[:, leaf_position+1:] = 0\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            partial_llrs[:, d] = u\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        partial_llrs[:, self.n] = u\n",
    "        return partial_llrs\n",
    "\n",
    "    def sc_decode_new(self, corrupted_codewords, snr, use_gt = None, channel = 'awgn'):\n",
    "\n",
    "        assert channel in ['awgn', 'bsc']\n",
    "\n",
    "        if channel == 'awgn':\n",
    "            noise_sigma = snr_db2sigma(snr)\n",
    "            llrs = (2/noise_sigma**2)*corrupted_codewords\n",
    "        elif channel == 'bsc':\n",
    "            # snr refers to transition prob\n",
    "            p = (torch.ones(1)*(snr + 1e-9)).to(corrupted_codewords.device)\n",
    "            llrs = (torch.clip(torch.log((1 - p) / p), -10000, 10000) * (corrupted_codewords + 1) - torch.clip(torch.log(p / (1-p)), -10000, 10000) * (corrupted_codewords - 1))/2\n",
    "\n",
    "        # step-wise implementation using updateLLR and updatePartialSums\n",
    "\n",
    "        priors = torch.zeros(self.N)\n",
    "        priors[self.frozen_positions] = self.infty\n",
    "\n",
    "        u_hat = torch.zeros(corrupted_codewords.shape[0], self.N, device=corrupted_codewords.device)\n",
    "        llr_array, partial_llrs = self.define_partial_arrays(llrs)\n",
    "        for ii in range(self.N):\n",
    "            #start = time.time()\n",
    "            llr_array , decoded_bits = self.updateLLR(ii, llr_array.clone(), partial_llrs, priors)\n",
    "            #print('SC update : {}'.format(time.time() - start), corrupted_codewords.shape[0])\n",
    "            if use_gt is None:\n",
    "                u_hat[:, ii] = torch.sign(llr_array[:, 0, ii])\n",
    "            else:\n",
    "                u_hat[:, ii] = use_gt[:, ii]\n",
    "            #start = time.time()\n",
    "            partial_llrs = self.updatePartialSums(ii, u_hat, partial_llrs)\n",
    "            #print('SC partial: {}s, {}', time.time() - start, 'frozen' if ii in self.frozen_positions else 'info')\n",
    "        decoded_bits = u_hat[:, self.info_positions]\n",
    "        return llr_array[:, 0, :].clone(), decoded_bits\n",
    "\n",
    "    def get_CRC(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # inout message should be int\n",
    "\n",
    "        padded_bits = torch.cat([message, torch.zeros(self.CRC_len).int().to(message.device)])\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + self.CRC_len + 1] = padded_bits[cur_shift: cur_shift + self.CRC_len + 1] ^ self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        return padded_bits[self.K_minus_CRC:]\n",
    "\n",
    "    def CRC_check(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # input message should be int\n",
    "\n",
    "        padded_bits = message\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + polar.CRC_len + 1] ^= self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        if padded_bits[self.K_minus_CRC:].sum()>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def encode_with_crc(self, message, CRC_len):\n",
    "        self.CRC_len = CRC_len\n",
    "        self.K_minus_CRC = self.K - CRC_len\n",
    "\n",
    "        if CRC_len == 0:\n",
    "            return self.encode_plotkin(message)\n",
    "        else:\n",
    "            crcs = 1-2*torch.vstack([self.get_CRC((0.5+0.5*message[jj]).int()) for jj in range(message.shape[0])])\n",
    "            encoded = self.encode_plotkin(torch.cat([message, crcs], 1))\n",
    "\n",
    "            return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6d51",
   "metadata": {},
   "source": [
    "# Part 3: DeepPolar Class and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b3d92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        for i in range(n - self.degree):\n",
    "            active_batches = result[:, i] == 1\n",
    "            if torch.any(active_batches):\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPolar(PolarCode):\n",
    "    def __init__(self, device, N, K, ell = 2, infty = 1000., depth_map : defaultdict = None):\n",
    "\n",
    "        # rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        # Frozen = np.argsort(rmweight)[:-K]\n",
    "        # Frozen.sort()\n",
    "\n",
    "        #self.args = args\n",
    "        Fr = get_frozen(N, K, rate_profile)\n",
    "        super().__init__(n = int(np.log2(N)), K = K, Fr=Fr,  infty = infty)\n",
    "        self.N = N\n",
    "\n",
    "        if depth_map is not None:\n",
    "            # depth map is a dict, product of values should be equal to N\n",
    "            assert np.prod(list(depth_map.values())) == N\n",
    "            # assert that keys od depth map start from one and go continuosly till some point \n",
    "            assert min(list(depth_map.keys())) == 1\n",
    "            assert max(list(depth_map.keys())) <= int(np.log2(N))\n",
    "            self.ell = None\n",
    "            self.n_ell = len(depth_map.keys())\n",
    "            assert max(list(depth_map.keys())) == self.n_ell\n",
    "\n",
    "            self.depth_map = depth_map\n",
    "        else:\n",
    "            self.ell = ell\n",
    "            self.n_ell = int(np.log(N)/np.log(self.ell))\n",
    "\n",
    "            self.depth_map = defaultdict(int)\n",
    "            for d in range(1, self.n_ell+1):\n",
    "                self.depth_map[d] = self.ell\n",
    "            assert np.prod(list(self.depth_map.values())) == N\n",
    "\n",
    "        self.device = device\n",
    "        self.fnet_dict = None\n",
    "        self.gnet_dict = None\n",
    "\n",
    "        self.infty = infty\n",
    "\n",
    "    @staticmethod\n",
    "    def get_onehot(actions):\n",
    "        inds = (0.5 + 0.5*actions).long()\n",
    "        if len(actions.shape) == 2:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)\n",
    "        elif len(actions.shape) == 3:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], actions.shape[1], -1)\n",
    "\n",
    "    def define_kernel_nns(self, ell, unfrozen = None, fnet = 'KO', gnet = 'KO', shared = False):\n",
    "\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "        #dec_hidden_size = dec_hidden_size\n",
    "        #enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        depth = 1\n",
    "        assert len(unfrozen) > 0, \"No unfrozen bits!\"\n",
    "\n",
    "        self.fnet_dict[depth] = {}\n",
    "\n",
    "        if fnet == 'KO_parallel' or fnet == 'KO_last_parallel':\n",
    "            bit_position = 0\n",
    "                   \n",
    "            self.fnet_dict[depth][bit_position] = {}\n",
    "            # input_size = self.N if depth == self.n_ell else self.N // int(np.prod([self.depth_map[d] for d in range(depth+1, self.n_ell+1)]))\n",
    "            input_size = ell             \n",
    "            # For curriculum, only for lowest depth.\n",
    "            output_size = ell#len(unfrozen)\n",
    "            self.fnet_dict[depth][bit_position] = f_Full(input_size, dec_hidden_size, output_size, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    " \n",
    "        elif 'KO' in fnet:\n",
    "            if shared:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for current_position in range(ell):\n",
    "                    self.fnet_dict[depth][current_position] = f_Full(ell + current_position, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                for current_position in unfrozen:\n",
    "                    if not self.fnet_dict[depth].get(bit_position):\n",
    "                        self.fnet_dict[depth][bit_position] = {}\n",
    "                    input_size = ell + (int(onehot)+1)*current_position\n",
    "                    self.fnet_dict[depth][bit_position][current_position] = f_Full(input_size, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "                \n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict[depth] = {}\n",
    "            if shared:\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth][bit_position] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "\n",
    "    def define_and_load_nns(self, ell, kernel_load_path=None, fnet='KO', gnet='KO', shared=True, dataparallel=False):\n",
    "        # Initialize decoder and encoder dictionaries\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "\n",
    "        # Loop through each depth level\n",
    "        for depth in range(self.n_ell, 0, -1):\n",
    "            if depth in polar_depths:\n",
    "                continue\n",
    "\n",
    "            ell = self.depth_map[depth]\n",
    "            proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "            # Handle parallel decoder case\n",
    "            if fnet == 'KO_last_parallel' and depth == 1:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for bit_position in range(self.N // proj_size):\n",
    "                    proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                    get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                    num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                    subproj_len = len(proj) // ell\n",
    "                    subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                    num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                    unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                    input_size = ell             \n",
    "                    output_size = ell\n",
    "\n",
    "                    # Use attention-enhanced decoder for parallel case\n",
    "                    self.fnet_dict[depth][bit_position] = f_Full(\n",
    "                        input_size=input_size,\n",
    "                        hidden_size=dec_hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        activation=dec_activation,\n",
    "                        dropout_p=dropout_p,\n",
    "                        depth=f_depth,\n",
    "                        use_norm=use_norm\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    # Load pretrained weights if available\n",
    "                    if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                        try:\n",
    "                            ckpt = torch.load(os.path.join(kernel_load_path + '_parallel', f'{ell}_{len(unfrozen)}.pt'))\n",
    "                            self.fnet_dict[depth][bit_position].load_state_dict(ckpt[0][1][0].state_dict())\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"Parallel File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                            pass\n",
    "\n",
    "                    if dataparallel:\n",
    "                        self.fnet_dict[depth][bit_position] = nn.DataParallel(self.fnet_dict[depth][bit_position])\n",
    "\n",
    "            # Handle sequential decoder case\n",
    "            elif 'KO' in fnet:\n",
    "                self.fnet_dict[depth] = {}\n",
    "\n",
    "                if shared:\n",
    "                    # Shared decoder network for all positions\n",
    "                    for current_position in range(ell):\n",
    "                        self.fnet_dict[depth][current_position] = f_Full(\n",
    "                            input_size=ell + current_position,\n",
    "                            hidden_size=dec_hidden_size,\n",
    "                            output_size=1,\n",
    "                            activation=dec_activation,\n",
    "                            dropout_p=dropout_p,\n",
    "                            depth=f_depth,\n",
    "                            use_norm=use_norm\n",
    "                        ).to(self.device)\n",
    "\n",
    "                        if dataparallel:\n",
    "                            self.fnet_dict[depth][current_position] = nn.DataParallel(self.fnet_dict[depth][current_position])\n",
    "\n",
    "                else:\n",
    "                    # Individual decoder networks for each position\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                        num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                        subproj_len = len(proj) // ell\n",
    "                        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                        unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                        # Load pretrained weights if available\n",
    "                        ckpt_exists = False\n",
    "                        if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                            try:\n",
    "                                ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                ckpt_exists = True\n",
    "                            except FileNotFoundError:\n",
    "                                print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                pass\n",
    "\n",
    "                        # Create decoders for unfrozen positions\n",
    "                        for current_position in unfrozen:\n",
    "                            if not self.fnet_dict[depth].get(bit_position):\n",
    "                                self.fnet_dict[depth][bit_position] = {}\n",
    "\n",
    "                            input_size = ell + (int(onehot)+1)*current_position\n",
    "                            output_size = 1\n",
    "\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = f_Full(\n",
    "                                input_size=input_size,\n",
    "                                hidden_size=dec_hidden_size,\n",
    "                                output_size=output_size,\n",
    "                                activation=dec_activation,\n",
    "                                dropout_p=dropout_p,\n",
    "                                depth=f_depth,\n",
    "                                use_norm=use_norm\n",
    "                            ).to(self.device)\n",
    "\n",
    "                            if ckpt_exists:\n",
    "                                try:\n",
    "                                    f_ckpt = ckpt[0][1][0][current_position].state_dict()\n",
    "                                    self.fnet_dict[depth][bit_position][current_position].load_state_dict(f_ckpt)\n",
    "                                except:\n",
    "                                    print(f\"Warning: Could not load weights for position {current_position}\")\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.fnet_dict[depth][bit_position][current_position] = nn.DataParallel(\n",
    "                                    self.fnet_dict[depth][bit_position][current_position]\n",
    "                                )\n",
    "\n",
    "            # Handle encoder network\n",
    "            if 'KO' in gnet:\n",
    "                self.gnet_dict[depth] = {}\n",
    "                if shared:\n",
    "                    if gnet == 'KO':\n",
    "                        if not dataparallel:\n",
    "                            self.gnet_dict[depth] = g_Full(\n",
    "                                ell, enc_hidden_size, ell-1,\n",
    "                                depth=g_depth,\n",
    "                                skip_depth=g_skip_depth,\n",
    "                                skip_layer=g_skip_layer,\n",
    "                                ell=ell,\n",
    "                                use_skip=use_skip\n",
    "                            ).to(self.device)\n",
    "                        else:\n",
    "                            self.gnet_dict[depth] = nn.DataParallel(\n",
    "                                g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    use_skip=use_skip\n",
    "                                )\n",
    "                            ).to(self.device)\n",
    "                else:\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        num_info_in_proj = sum([int(x in self.info_positions) for x in proj])\n",
    "\n",
    "                        if num_info_in_proj > 0:\n",
    "                            if gnet == 'KO':\n",
    "                                self.gnet_dict[depth][bit_position] = g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    activation=enc_activation,\n",
    "                                    use_skip=use_skip\n",
    "                                ).to(self.device)\n",
    "\n",
    "                            # Load pretrained weights if available\n",
    "                            if kernel_load_path is not None:\n",
    "                                try:\n",
    "                                    ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                    self.gnet_dict[depth][bit_position].load_state_dict(ckpt[1][1][0].state_dict())\n",
    "                                except FileNotFoundError:\n",
    "                                    print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                    pass\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.gnet_dict[depth][bit_position] = nn.DataParallel(self.gnet_dict[depth][bit_position])\n",
    "\n",
    "        if kernel_load_path is not None:\n",
    "            print(\"Loaded kernel from \", kernel_load_path)\n",
    "\n",
    "    def load_nns(self, fnet_dict, gnet_dict = None, shared = False):\n",
    "        self.fnet_dict = fnet_dict\n",
    "        self.gnet_dict = gnet_dict\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if self.fnet_dict is not None:\n",
    "                for bit_position in self.fnet_dict[depth].keys():\n",
    "                    if not isinstance(self.fnet_dict[depth][bit_position], dict):#shared or decoder_type == 'KO_parallel' or decoder_type == 'KO_RNN':\n",
    "                        self.fnet_dict[depth][bit_position].to(self.device)\n",
    "                    else:\n",
    "                        for current_position in self.fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "            if gnet_dict is not None:\n",
    "                if shared:\n",
    "                    self.gnet_dict[depth].to(self.device)\n",
    "                else:\n",
    "                    for bit_position in self.gnet_dict[depth].keys():\n",
    "                        self.gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def load_partial_nns(self, fnet_dict, gnet_dict = None):\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if fnet_dict is not None:\n",
    "                for bit_position in fnet_dict[depth].keys():\n",
    "                    if isinstance(fnet_dict[depth][bit_position], dict):\n",
    "                        for current_position in fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "                    else:\n",
    "                        self.fnet_dict[depth][bit_position] = fnet_dict[depth][bit_position].to(self.device)\n",
    "\n",
    "            if gnet_dict is not None:\n",
    "                for bit_position in gnet_dict[depth].keys():\n",
    "                    self.gnet_dict[depth][bit_position] = gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def kernel_encode(self, ell, gnet, msg_bits, info_positions, binary = False):\n",
    "        input_shape = msg_bits.shape[-1]\n",
    "        assert input_shape <= ell\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, info_positions] = msg_bits\n",
    "        output =torch.cat([gnet(u.unsqueeze(1)).squeeze(1), u[:, -1:]], 1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(output)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def deeppolar_encode(self, msg_bits, binary = False):\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, self.info_positions] = msg_bits\n",
    "        for d in range(1, self.n_ell+1):\n",
    "            # num_bits = self.ell**(d-1)\n",
    "            num_bits = np.prod([self.depth_map[dd] for dd in range(1, d)]) if d > 1 else 1\n",
    "            # proj_size = self.ell**(d)\n",
    "            proj_size = np.prod([self.depth_map[dd] for dd in range(1, d+1)])\n",
    "            ell = self.depth_map[d]\n",
    "            for bit_position, i in enumerate(np.arange(0, self.N, ell*num_bits)):\n",
    "\n",
    "                # [u v] encoded to [(u xor v),v)]\n",
    "                proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                subproj_len = len(proj) // ell\n",
    "                subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "                \n",
    "                if num_info_in_proj > 0:\n",
    "                    info_bits_present = True          \n",
    "                else:\n",
    "                    info_bits_present = False         \n",
    "                if d in polar_depths:\n",
    "                    info_bits_present = False\n",
    "\n",
    "                enc_chunks = []\n",
    "                ell = self.depth_map[d]\n",
    "                for j in range(ell):\n",
    "                    chunk = u[:, i + j*num_bits:i + (j+1)*num_bits].unsqueeze(2).clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[d](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        output = torch.cat([self.gnet_dict[d][bit_position](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(msg_bits.shape[0], -1, 1).squeeze(2)\n",
    "\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                u = torch.cat((u[:, :i], output, u[:, i + ell*num_bits:]), dim=1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(u)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def power_constraint(self, codewords):\n",
    "        return F.normalize(codewords, p=2, dim=1)*np.sqrt(self.N)\n",
    "\n",
    "    def encode_chunks_plotkin(self, enc_chunks, ell = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "\n",
    "        # to change for other kernels\n",
    "\n",
    "        if ell is None:\n",
    "            ell = self.ell\n",
    "        assert len(enc_chunks) == ell\n",
    "        chunk_size = enc_chunks[0].shape[1]\n",
    "        batch_size = enc_chunks[0].shape[0]\n",
    "\n",
    "        u = torch.cat(enc_chunks, 1).squeeze(2)\n",
    "        n = int(np.log2(ell))\n",
    "\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d * chunk_size\n",
    "            for i in np.arange(0, chunk_size*ell, 2*num_bits):\n",
    "                # [u v] encoded to [(u,v) xor v]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        return u\n",
    "            \n",
    "    def deeppolar_parallel_decode(self, noisy_code):\n",
    "        # Successive cancellation decoder for polar codes\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "        decoded_llrs  = self.KO_parallel_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "\n",
    "    def deeppolar_parallel_decode_depth(self, llrs, depth, bit_position, decoded_llrs):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        dec_chunks = torch.cat([llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "        Lu = self.fnet_dict[depth][bit_position](dec_chunks)\n",
    "\n",
    "        if depth == 1:\n",
    "            u = torch.tanh(Lu/2)\n",
    "            decoded_llrs[:, left_bit_position + unfrozen] = Lu.squeeze(1)\n",
    "        else:\n",
    "            for index, current_position in enumerate(unfrozen):\n",
    "                bit_position_offset = left_bit_position + current_position                \n",
    "                decoded_llrs = self.deeppolar_parallel_decode_depth(Lu[:, :, index:index+1], depth-1, bit_position_offset, decoded_llrs)\n",
    "\n",
    "        return decoded_llrs\n",
    "            \n",
    "    def deeppolar_decode(self, noisy_code):\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        \n",
    "        # don't want to go into useless frozen subtrees.\n",
    "        partial_sums = torch.ones(noisy_code.shape[0], self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "\n",
    "        decoded_llrs, partial_sums = self.deeppolar_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs, partial_sums)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "    \n",
    "    def deeppolar_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        # size of the projection of tht subtree\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        # This chunk - finds infrozen positions in this kernel.\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        if num_nonzero_subproj > 0:\n",
    "            info_bits_present = True      \n",
    "        else:\n",
    "            info_bits_present = False \n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "                \n",
    "        # This will be input to decoder\n",
    "        dec_chunks = [llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            if decoder_type == 'KO_last_parallel':\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                Lu = self.fnet_dict[depth][bit_position](concatenated_chunks)[:, 0, unfrozen]\n",
    "                u_hat = torch.tanh(Lu/2)\n",
    "                decoded_llrs[:, left_bit_position + unfrozen] = Lu\n",
    "                partial_sums[:, depth-1, left_bit_position + unfrozen] = u_hat\n",
    "\n",
    "            else:\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    if current_position > 0:\n",
    "                        # I am adding previously decoded bits . (either onehot or normal)\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "\n",
    "                    if bit_position_offset in self.frozen_positions: # frozen \n",
    "                        # don't update decoded llrs. It already has ones*prior.\n",
    "                        # actually don't need this. can skip.\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, depth-1, bit_position_offset])\n",
    "                    else: # information bit\n",
    "                        # This is the decoding.\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](concatenated_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "\n",
    "                        u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                        decoded_llrs[:, bit_position_offset] = Lu.squeeze(2).squeeze(1)\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = u_hat.squeeze(1)\n",
    "\n",
    "            # Encoding back the decoded bits - for higher layers.\n",
    "            # # Compute decoded codeword\n",
    "            i = left_bit_position * half_index\n",
    "            # num_bits = self.ell**(depth-1)\n",
    "            num_bits = 1\n",
    "\n",
    "            enc_chunks = []\n",
    "            for j in range(ell):\n",
    "                chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                enc_chunks.append(chunk)\n",
    "            if info_bits_present:\n",
    "                concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                if 'KO' in encoder_type:\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        # bit position of the previous depth.\n",
    "                        output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            else:\n",
    "                output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "            \n",
    "            return decoded_llrs, partial_sums\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "\n",
    "                if current_position in unfrozen:\n",
    "                    # General decoding ....\n",
    "                    # add the decoded bit here\n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](concatenated_chunks).squeeze(2)\n",
    "                    else:\n",
    "                        # if current_position == 0:\n",
    "                        #     Lu = self.fnet_dict[depth][bit_position][current_position](llrs)\n",
    "                        # else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "                    decoded_llrs, partial_sums = self.deeppolar_decode_depth(Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums)\n",
    "                else:\n",
    "                    Lu = self.infty*torch.ones_like(llrs)\n",
    "\n",
    "\n",
    "            # Compute decoded codeword\n",
    "            if depth < self.n_ell :\n",
    "                i = left_bit_position * half_index\n",
    "                # num_bits = self.ell**(depth-1)\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        else:\n",
    "                            # bit position of the previous depth.\n",
    "                            output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "\n",
    "                return decoded_llrs, partial_sums\n",
    "            else: # encoding not required for last level - we have already decoded all bits.\n",
    "                return decoded_llrs, partial_sums\n",
    "\n",
    "\n",
    "    def kernel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = [noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "\n",
    "        for current_position in range(ell):\n",
    "            if current_position > 0:\n",
    "                if onehot:\n",
    "                    prev_decoded = get_onehot(u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone().sign()).detach().clone()\n",
    "                else:\n",
    "                    prev_decoded = u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                dec_chunks.append(prev_decoded)\n",
    "            if current_position in info_positions:\n",
    "                if current_position in info_positions:\n",
    "                    concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                    Lu = fnet_dict[current_position](concatenated_chunks)\n",
    "                    decoded_llrs[:, current_position] = Lu.squeeze(2).squeeze(1)\n",
    "                    u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                    u[:, current_position] = u_hat.squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "\n",
    "    def kernel_parallel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = torch.cat([noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "\n",
    "        decoded_llrs = fnet_dict(dec_chunks).squeeze(1)\n",
    "        u = torch.tanh(decoded_llrs/2).squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "    \n",
    "\n",
    "    def deeppolar_list_decode(self, noisy_code, L, crc=None):\n",
    "        \"\"\"\n",
    "        List decoding implementation for DeepPolar with CRC checking\n",
    "        Args:\n",
    "            noisy_code: Input received codeword\n",
    "            L: List size\n",
    "            crc: CRC object for checking decoded messages\n",
    "        \"\"\"\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "        batch_size = noisy_code.shape[0]\n",
    "        depth = self.n_ell\n",
    "\n",
    "        # Initialize L copies of path metrics \n",
    "        PML = 1000*torch.ones(batch_size, L, device=noisy_code.device)\n",
    "        PML[:, 0] = 0\n",
    "\n",
    "        # Initialize L copies of LLRs and partial sums\n",
    "        decoded_llrs = self.infty * torch.ones(batch_size, L, self.N, device=noisy_code.device)\n",
    "        partial_sums = torch.ones(batch_size, L, self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # Expand noisy_code for L paths\n",
    "        noisy_code_expanded = noisy_code.unsqueeze(1).repeat(1, L, 1)\n",
    "\n",
    "        decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "            noisy_code_expanded.unsqueeze(3), depth, 0, decoded_llrs, partial_sums, PML, L)\n",
    "\n",
    "        # Extract information bits for all paths\n",
    "        info_llrs = decoded_llrs[:, :, self.info_positions]\n",
    "        decisions = torch.sign(info_llrs)\n",
    "\n",
    "        # Convert decoded bits to proper format for CRC checking\n",
    "        #decoded_bits = ((1 - decisions) / 2).to(torch.int64)  # Convert from {-1,1} to {1,0}\n",
    "        decoded_bits =decisions\n",
    "        \n",
    "        if crc is not None:\n",
    "            # Check CRC for each path in the list\n",
    "            valid_paths = crc.check_batch(decoded_bits.view(-1, decoded_bits.shape[-1]))\n",
    "            valid_paths = valid_paths.view(batch_size, L)\n",
    "\n",
    "            # For each batch, find first valid path or use first path if none valid\n",
    "            selected_paths = torch.zeros(batch_size, dtype=torch.long, device=decoded_bits.device)\n",
    "            for b in range(batch_size):\n",
    "                valid_indices = torch.where(valid_paths[b])[0]\n",
    "                if len(valid_indices) > 0:\n",
    "                    # Use first valid path\n",
    "                    selected_paths[b] = valid_indices[0]\n",
    "                else:\n",
    "                    # If no valid paths, use path with best metric (index 0)\n",
    "                    selected_paths[b] = 0\n",
    "\n",
    "            # Gather selected paths\n",
    "            batch_indices = torch.arange(batch_size, device=decoded_bits.device)\n",
    "            final_decisions = decisions[batch_indices, selected_paths]\n",
    "        else:\n",
    "            # If no CRC, just return first path\n",
    "            final_decisions = decisions[:, 0]\n",
    "\n",
    "        return final_decisions, info_llrs, PML\n",
    "\n",
    "    def deeppolar_list_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums, PML, L):\n",
    "        \"\"\"\n",
    "        Recursive list decoding implementation for DeepPolar decoder\n",
    "        Args:\n",
    "            llrs: Input LLRs [batch_size, L, N, 1]\n",
    "            depth: Current depth in the decoding tree\n",
    "            bit_position: Current bit position\n",
    "            decoded_llrs: Running decoded LLRs [batch_size, L, N]\n",
    "            partial_sums: Running partial sums [batch_size, L, n_ell+1, N]\n",
    "            PML: Path metrics for each path [batch_size, L]\n",
    "        \"\"\"\n",
    "        batch_size = llrs.shape[0]\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] * bit_position\n",
    "\n",
    "        # Calculate projection information\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj: sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj: [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        info_bits_present = num_nonzero_subproj > 0\n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "\n",
    "        # Initialize decoder chunks\n",
    "        dec_chunks = [llrs[:, :, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        \n",
    "        if depth == 1:  # Base case\n",
    "            if decoder_type != 'KO_last_parallel':\n",
    "            \n",
    "                # Sequential decoding of each position\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    \n",
    "\n",
    "                    if current_position > 0:\n",
    "                        # Add previously decoded bits\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "                    \n",
    "                     \n",
    "                    \n",
    "                    if bit_position_offset in self.frozen_positions:\n",
    "                        # Handle frozen bits\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, :, depth-1, bit_position_offset])\n",
    "                        DM = decoded_llrs[:, :, bit_position_offset]\n",
    "                        # Update path metrics for frozen bits\n",
    "                        PML = PML + torch.abs(DM) * (DM < 0).float()\n",
    "\n",
    "                    else:  # Information bit case\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                        orig_shape = concatenated_chunks.shape\n",
    "                        reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "\n",
    "                        # Get decoder output\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](reshaped_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                        Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "\n",
    "                        # Store LLRs and get decisions\n",
    "                        decoded_llrs[:,:, bit_position_offset] = Lu.squeeze(3).squeeze(2)\n",
    "                        DM = Lu.squeeze(3).squeeze(2)\n",
    "                        dec = (DM < 0).float()\n",
    "                        dec = 1-2*dec\n",
    "\n",
    "                        # Compute path metrics for both decisions\n",
    "                        PM2 = torch.cat([PML, PML + torch.abs(DM)], dim=1)  # [batch_size, 2L]\n",
    "\n",
    "                        # Select best L paths\n",
    "                        PML, pos = torch.topk(PM2, L, dim=1, largest=False)  \n",
    "\n",
    "                        # Update decisions and states\n",
    "                        pos_dec = pos.clone()\n",
    "                        pos_dec[pos >= L] = pos_dec[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "                        dec = torch.gather(dec, 1, pos_dec)  # Gather decisions for selected paths\n",
    "                        dec = torch.where(pos >= L, -dec, dec)  # Flip decisions for paths from second half\n",
    "\n",
    "                        # Update states with gathered indices\n",
    "                        # First adjust pos for gathering from L-sized tensors\n",
    "                        pos_adj = pos.clone()\n",
    "                        pos_adj[pos >= L] = pos_adj[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "\n",
    "                        # For decoded_llrs\n",
    "                        pos_expand = pos_adj.unsqueeze(-1).expand(-1, -1, decoded_llrs.shape[-1])\n",
    "                        decoded_llrs = torch.gather(decoded_llrs, 1, pos_expand)\n",
    "\n",
    "                        # For partial_sums \n",
    "                        pos_expand_sums = pos_adj.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, partial_sums.shape[2], partial_sums.shape[3])\n",
    "                        partial_sums = torch.gather(partial_sums, 1, pos_expand_sums)\n",
    "\n",
    "\n",
    "                        # Store updated decisions\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = dec\n",
    "\n",
    "                        \n",
    "                       \n",
    "                 \n",
    "\n",
    "            # Encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = 1\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        else:  # General case for deeper levels\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                #print(concatenated_chunks.shape)\n",
    "                orig_shape = concatenated_chunks.shape\n",
    "                reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                if current_position in unfrozen:\n",
    "                    \n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](reshaped_chunks).squeeze(3)\n",
    "                    else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                    Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "                    \n",
    "                    # Recursive call for each path\n",
    "                    decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "                        Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums, PML, L)\n",
    "                else:\n",
    "                    Lu = self.infty * torch.ones_like(llrs)\n",
    "\n",
    "            # Handle encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                        \n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        return decoded_llrs, partial_sums, PML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e848578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen(N, K, rate_profile, target_K = None):\n",
    "    n = int(np.log2(N))\n",
    "    if rate_profile == 'polar':\n",
    "        # computed for SNR = 0\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "\n",
    "            # for RM :(\n",
    "            # rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 3, 5, 8, 4, 2, 1, 0])\n",
    "\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "        elif n<9:\n",
    "            rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "        else:\n",
    "            rs = np.array([1023, 1022, 1021, 1019, 1015, 1007, 1020,  991, 1018, 1017, 1014,\n",
    "       1006,  895, 1013, 1011,  959, 1005,  990, 1003,  989,  767, 1016,\n",
    "        999, 1012,  987,  958,  983,  957, 1010, 1004,  955, 1009,  894,\n",
    "        975,  893, 1002,  951, 1001,  988,  511,  766,  998,  891,  943,\n",
    "        986,  997,  985,  887,  956,  765,  995,  927,  982,  981,  879,\n",
    "        954,  974,  763,  953,  979,  510, 1008,  759,  863,  950,  892,\n",
    "       1000,  973,  949,  509,  890,  971,  996,  942,  751,  984,  889,\n",
    "        507,  947,  831,  886,  967,  941,  764,  926,  980,  994,  939,\n",
    "        885,  993,  735,  878,  925,  503,  762,  883,  978,  935,  703,\n",
    "        495,  952,  877,  761,  972,  923,  977,  948,  758,  862,  875,\n",
    "        919,  970,  757,  861,  508,  969,  750,  946,  479,  888,  639,\n",
    "        871,  911,  830,  940,  859,  755,  966,  945,  749,  506,  884,\n",
    "        938,  965,  829,  734,  924,  855,  505,  747,  963,  937,  882,\n",
    "        934,  827,  733,  447,  992,  847,  876,  501,  921,  702,  494,\n",
    "        881,  760,  743,  933,  502,  918,  874,  922,  823,  731,  499,\n",
    "        860,  756,  931,  701,  873,  493,  727,  917,  870,  976,  815,\n",
    "        910,  383,  968,  478,  858,  754,  699,  491,  869,  944,  748,\n",
    "        638,  915,  477,  719,  909,  964,  255,  799,  504,  857,  854,\n",
    "        753,  828,  746,  695,  487,  907,  637,  867,  853,  475,  936,\n",
    "        962,  446,  732,  826,  745,  846,  500,  825,  903,  687,  932,\n",
    "        635,  471,  445,  742,  880,  498,  730,  851,  822,  382,  920,\n",
    "        845,  741,  443,  700,  729,  631,  492,  872,  961,  726,  821,\n",
    "        930,  497,  381,  843,  463,  916,  739,  671,  623,  490,  929,\n",
    "        439,  814,  819,  868,  752,  914,  698,  725,  839,  856,  476,\n",
    "        813,  718,  908,  486,  723,  866,  489,  607,  431,  697,  379,\n",
    "        811,  798,  913,  575,  717,  254,  694,  636,  474,  807,  715,\n",
    "        906,  797,  693,  865,  960,  852,  744,  634,  473,  795,  905,\n",
    "        485,  415,  483,  470,  444,  375,  850,  740,  686,  902,  824,\n",
    "        691,  253,  711,  633,  844,  685,  630,  901,  367,  791,  928,\n",
    "        728,  820,  849,  783,  670,  899,  738,  842,  683,  247,  469,\n",
    "        441,  442,  462,  251,  737,  438,  467,  351,  629,  841,  724,\n",
    "        679,  669,  496,  461,  818,  380,  437,  627,  622,  459,  378,\n",
    "        239,  488,  667,  838,  430,  484,  812,  621,  319,  817,  435,\n",
    "        377,  696,  722,  912,  606,  810,  864,  716,  837,  721,  714,\n",
    "        809,  796,  455,  472,  619,  835,  692,  663,  223,  414,  904,\n",
    "        427,  806,  482,  632,  713,  690,  848,  605,  373,  252,  794,\n",
    "        429,  710,  684,  615,  805,  900,  655,  468,  366,  603,  413,\n",
    "        574,  481,  371,  250,  793,  466,  423,  374,  689,  628,  440,\n",
    "        365,  709,  789,  803,  411,  573,  682,  249,  460,  790,  668,\n",
    "        599,  350,  707,  246,  681,  465,  571,  626,  436,  407,  782,\n",
    "        191,  127,  363,  620,  666,  458,  245,  349,  677,  434,  678,\n",
    "        591,  787,  399,  457,  359,  238,  625,  840,  567,  736,  665,\n",
    "        428,  376,  781,  898,  618,  675,  318,  454,  662,  243,  897,\n",
    "        347,  836,  816,  720,  433,  604,  617,  779,  808,  661,  834,\n",
    "        712,  804,  833,  559,  237,  453,  426,  222,  317,  775,  372,\n",
    "        343,  412,  235,  543,  614,  451,  425,  422,  613,  370,  221,\n",
    "        315,  480,  335,  659,  654,  364,  190,  369,  248,  653,  688,\n",
    "        231,  410,  602,  611,  802,  792,  421,  651,  601,  598,  708,\n",
    "        311,  219,  572,  597,  788,  570,  409,  590,  362,  801,  680,\n",
    "        464,  406,  419,  348,  647,  786,  215,  589,  706,  361,  676,\n",
    "        566,  189,  595,  244,  569,  303,  405,  358,  456,  346,  398,\n",
    "        565,  242,  126,  705,  780,  587,  624,  664,  236,  187,  357,\n",
    "        432,  785,  558,  674,  207,  403,  397,  452,  345,  563,  778,\n",
    "        241,  316,  342,  616,  660,  557,  125,  234,  183,  287,  355,\n",
    "        583,  673,  395,  424,  314,  220,  777,  341,  612,  658,  123,\n",
    "        175,  774,  555,  233,  334,  542,  450,  313,  391,  230,  652,\n",
    "        368,  218,  339,  600,  119,  333,  657,  610,  773,  541,  310,\n",
    "        420,  159,  229,  650,  551,  596,  609,  408,  217,  449,  188,\n",
    "        309,  214,  331,  111,  539,  360,  771,  649,  302,  418,  594,\n",
    "        896,  227,  404,  646,  186,  588,  832,  568,  213,  417,  301,\n",
    "        307,  356,  402,  800,  564,  327,   95,  206,  240,  535,  593,\n",
    "        645,  586,  344,  396,  185,  401,  211,  354,  299,  585,  286,\n",
    "        562,  643,  182,  205,  124,  232,  285,  295,  181,  556,  582,\n",
    "        527,  394,  340,   63,  203,  561,  353,  448,  122,  283,  393,\n",
    "        581,  554,  174,  390,  704,  312,  338,  228,  179,  784,  199,\n",
    "        553,  121,  173,  389,  540,  579,  332,  118,  672,  550,  337,\n",
    "        158,  279,  271,  416,  216,  308,  387,  538,  549,  226,  330,\n",
    "        776,  171,  212,  117,  110,  329,  656,  157,  772,  306,  326,\n",
    "        225,  167,  115,  537,  534,  184,  109,  300,  547,  305,  210,\n",
    "        155,  533,  325,  352,  608,  400,  298,  204,   94,  648,  284,\n",
    "        209,  151,  180,  107,  770,  297,  392,  323,  592,  202,  644,\n",
    "         93,  294,  178,  103,  143,  282,   62,  336,  201,  120,  172,\n",
    "        198,  769,  584,   91,  388,  293,  177,  526,  278,  281,  642,\n",
    "        525,  531,   61,  170,  116,  197,   87,  156,  277,  114,  560,\n",
    "        169,   59,  291,  580,  275,  523,  641,  270,  195,  552,  519,\n",
    "        166,  224,  578,  108,  269,   79,  154,  113,  548,  577,  536,\n",
    "        328,   55,  106,  165,  153,  150,  386,  208,  324,  546,  385,\n",
    "        267,   47,   92,  163,  296,  304,  105,  102,  149,  263,  532,\n",
    "        322,  292,  545,   90,  200,   31,  321,  530,  142,  176,  147,\n",
    "        101,  141,  196,  524,  529,  290,   89,  280,   60,   86,   99,\n",
    "        139,  168,   58,  522,  276,   85,  194,  289,   78,  135,  112,\n",
    "        521,   57,   83,   54,  518,  274,  268,  768,  164,   77,  152,\n",
    "        193,   53,  162,  104,  517,  273,  266,   75,   46,  148,   51,\n",
    "        640,  100,   45,  576,  161,  265,  262,   71,  146,   30,  140,\n",
    "         88,  515,   98,   43,   29,  261,  145,  138,   84,  259,   39,\n",
    "         97,   27,   56,   82,  137,   76,  384,  134,   23,   52,  133,\n",
    "        320,   15,   73,   50,   81,  131,   44,   70,  544,  192,  528,\n",
    "        288,  520,  160,  272,   74,   49,  516,   42,   69,   28,  144,\n",
    "         41,   67,   96,  514,   38,  264,  260,  136,   22,   25,   37,\n",
    "         80,  513,   26,  258,   35,  132,   21,  257,   72,   14,   48,\n",
    "         13,   19,  130,   68,   40,   11,  512,   66,  129,    7,   36,\n",
    "         24,   34,  256,   20,   65,   33,   12,  128,   18,   10,   17,\n",
    "          6,    9,   64,    5,    3,   32,   16,    8,    4,    2,    1,\n",
    "          0])\n",
    "        rs = rs[rs<N]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'RM':\n",
    "        rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        Fr = np.argsort(rmweight)[:-K]\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted_last':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds[::-1]\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'rev_polar':\n",
    "\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:target_K].copy()\n",
    "        rs[:target_K] = first_inds[::-1]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    return Fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(codebook):\n",
    "    \"\"\"Calculate pairwise distances between codewords\"\"\"\n",
    "    dists = []\n",
    "    for row1, row2 in combinations(codebook, 2):\n",
    "        distance = (row1-row2).pow(2).sum()\n",
    "        dists.append(np.sqrt(distance.item()))\n",
    "    return dists, np.min(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54073b6",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2a9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_original_path):\n",
    "    plt.figure()\n",
    "    plt.plot(bers_enc, label='BER')\n",
    "    plt.plot(moving_average(bers_enc, n=10), label='BER moving avg')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Training BER ENC')\n",
    "    plt.savefig(os.path.join(results_save_original_path, 'training_ber_enc.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Similar plots for losses_enc, bers_dec, losses_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96d3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save models\n",
    "def save_model(polar, iter, results_save_original_path, best=False):\n",
    "    torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map], \n",
    "               os.path.join(results_save_original_path, f'Models/fnet_gnet_{iter}.pt'))\n",
    "    if iter > 1:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt'))\n",
    "    if best:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e6cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        # Convert to binary if needed\n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        # Initialize result tensor\n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        \n",
    "        # Prepare dividend for all batches at once\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        \n",
    "        # Perform batch polynomial division\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        \n",
    "        # Combine message and remainder\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        # Convert back to float if needed\n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "            \n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        \"\"\"Check if received messages pass CRC in batch.\"\"\"\n",
    "        # Convert to binary if needed\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "            \n",
    "        # Perform polynomial division on all messages at once\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        \n",
    "        # Check if all remainder bits are zero for each message\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    \n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        \"\"\"Perform polynomial division in batch using vectorized operations.\"\"\"\n",
    "        # Make copy to avoid modifying input\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        # Find positions of 1s for all batches\n",
    "        for i in range(n - self.degree):\n",
    "            # Find batches where current bit is 1\n",
    "            active_batches = result[:, i] == 1\n",
    "            \n",
    "            if torch.any(active_batches):\n",
    "                # XOR with polynomial for active batches\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        \n",
    "        # Return last degree bits (remainder) for all batches\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b167a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crc = CRC(crc_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4986216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n"
     ]
    }
   ],
   "source": [
    "if anomaly:\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "#ID = str(np.random.randint(100000, 999999)) if id is None else id\n",
    "#ID = 207515\n",
    "\n",
    "\n",
    "###############\n",
    "### Polar code\n",
    "##############\n",
    "\n",
    "### Encoder\n",
    "\n",
    "if last_ell is not None:\n",
    "    depth_map = defaultdict(int)\n",
    "    n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "    for d in range(1, n+1):\n",
    "        depth_map[d] = kernel_size\n",
    "    depth_map[n+1] = last_ell\n",
    "    assert np.prod(list(depth_map.values())) == N\n",
    "    polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "else:\n",
    "    polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "info_inds = polar.info_positions\n",
    "frozen_inds = polar.frozen_positions\n",
    "\n",
    "print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "##############\n",
    "### Neural networks\n",
    "##############\n",
    "ell = kernel_size\n",
    "if N == ell: # Kernel pre-training\n",
    "    polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "elif N > ell: # Initialize full network with pretrained kernels\n",
    "    polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "if binary:\n",
    "    load_path = os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt')\n",
    "    assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "    results_save_original_path = os.path.join(results_save_original_path, 'Binary')\n",
    "    os.makedirs(results_save_original_path, exist_ok=True)\n",
    "    os.makedirs(results_save_original_path +'/Models', exist_ok=True)\n",
    "\n",
    "if load_path is not None:\n",
    "    if test:\n",
    "        if test_load_path is None:\n",
    "            print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "    else:\n",
    "        checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "        fnet_dict = checkpoint1[0]\n",
    "        gnet_dict = checkpoint1[1]\n",
    "\n",
    "        polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "        print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "if 'KO' in decoder_type:\n",
    "    dec_params = []\n",
    "    for i in polar.fnet_dict.keys():\n",
    "        for j in polar.fnet_dict[i].keys():\n",
    "            if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                for k in polar.fnet_dict[i][j].keys():\n",
    "                    dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "            else:\n",
    "                dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "elif decoder_type == 'RNN':\n",
    "    dec_params = polar.fnet_dict.parameters()\n",
    "else:\n",
    "    dec_train_iters = 0\n",
    "\n",
    "if 'KO' in encoder_type:\n",
    "    enc_params = []\n",
    "    if shared:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            enc_params += list(polar.gnet_dict[i].parameters())\n",
    "    else:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            for j in polar.gnet_dict[i].keys():\n",
    "                enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "elif encoder_type == 'scaled':\n",
    "    enc_params = [polar.a]\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "else:\n",
    "    enc_train_iters = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'BCE' in loss_type:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'L1':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_type == 'huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "info_positions = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d5c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053eafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__0.0_Encoder_KO_-2.0_Decoder/epochs_500_batchsize_20000'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_save_original_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e6b672b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "Checkpoint Loaded\n",
      "NN weights loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "times = []\n",
    "results_load_path = results_save_original_path\n",
    "\n",
    "\n",
    "\n",
    "checkpoint1 = torch.load(results_load_path +'/Models/fnet_gnet_final.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "fnet_dict = checkpoint1[0]\n",
    "gnet_dict = checkpoint1[1]\n",
    "print('Checkpoint Loaded')\n",
    "\n",
    "polar.load_nns(fnet_dict, gnet_dict, shared = shared)\n",
    "\n",
    "if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "    snr_range = [test_snr_start]\n",
    "else:\n",
    "    snrs_interval = (test_snr_end - test_snr_start)* 1.0 /  (snr_points-1)\n",
    "    snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# For polar code testing.\n",
    "\n",
    "ell = 2\n",
    "Frozen = get_frozen(N, K, rate_profile)\n",
    "Frozen.sort()\n",
    "polar_l_2 = PolarCode(int(np.log2(N)), K, Fr=Frozen, infty = infty, hard_decision=hard_decision)\n",
    "\n",
    "\n",
    "if pairwise:\n",
    "    codebook_size = 1000\n",
    "    all_msg_bits = 2 * (torch.rand(codebook_size, K, device = device) < 0.5).float() - 1\n",
    "    deeppolar_codebook = polar.deeppolar_encode(all_msg_bits)\n",
    "    polar_codebook = polar_l_2.encode_plotkin(all_msg_bits)\n",
    "    gaussian_codebook = F.normalize(torch.randn(codebook_size, N), p=2, dim=1)*np.sqrt(N)\n",
    "\n",
    "    from scipy import stats\n",
    "    w_statistic_deeppolar, p_value_deeppolar = stats.shapiro(deeppolar_codebook.detach().cpu().numpy())\n",
    "    w_statistic_gaussian, p_value_gaussian = stats.shapiro(gaussian_codebook.detach().cpu().numpy())\n",
    "    w_statistic_polar, p_value_polar = stats.shapiro(polar_codebook.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Deeppolar Shapiro test W = {w_statistic_deeppolar}, p-value = {p_value_deeppolar}\")\n",
    "    print(f\"Gaussian Shapiro test W = {w_statistic_gaussian}, p-value = {p_value_gaussian}\")\n",
    "    print(f\"Polar Shapiro test W = {w_statistic_polar}, p-value = {p_value_polar}\")\n",
    "\n",
    "    dists_deeppolar, md_deeppolar = pairwise_distances(deeppolar_codebook)\n",
    "    dists_polar, md_polar = pairwise_distances(polar_codebook)\n",
    "    dists_gaussian, md_gaussian = pairwise_distances(gaussian_codebook)\n",
    "\n",
    "    # Function to calculate and plot PDF\n",
    "    def plot_pdf(data, label, bins=30, alpha=0.5, color=None, linewidth=1.0):\n",
    "        counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, counts, label=label, alpha=alpha, \n",
    "                 color=color, linewidth=linewidth)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Larger figure size\n",
    "\n",
    "    # Define better colors\n",
    "    colors = ['#e74c3c', '#3498db']  # Red and Blue\n",
    "    linewidth = 2.5\n",
    "\n",
    "    # Plot with enhanced styling\n",
    "    plot_pdf(dists_deeppolar, 'DeepPolar', bins=300, color=colors[0], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "    plot_pdf(dists_gaussian, 'Gaussian', bins=300, color=colors[1], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "\n",
    "    # Enhance grid - both major and minor\n",
    "    plt.grid(True, which='major', linestyle='-', alpha=0.5)\n",
    "    plt.grid(True, which='minor', linestyle=':', alpha=0.3)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    # Enhance labels and title\n",
    "    plt.xlabel('Pairwise Distance', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Probability Density', fontsize=16, fontweight='bold')\n",
    "    #plt.title(f'Pairwise Distances Distribution (N={N}, K={K})', \n",
    "    #          fontsize=16, fontweight='bold', pad=15)\n",
    "\n",
    "    # Enhance legend\n",
    "    plt.legend(fontsize=16, frameon=True, fancybox=True, \n",
    "              shadow=True, loc='upper left')\n",
    "\n",
    "    # Enhance ticks\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save with high DPI for better quality\n",
    "    plt.savefig(os.path.join(results_save_original_path, f\"hists_N{N}_K{K}_{id}_2.pdf\"), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(f'dists_deeppolar: {dists_deeppolar}')\n",
    "    print(f'dists_gaussian: {dists_gaussian}')\n",
    "if epos:\n",
    "    from collections import OrderedDict, Counter\n",
    "\n",
    "    def get_epos(k1, k2):\n",
    "        # return counter for bit ocations of first-errors\n",
    "        bb = torch.ne(k1.cpu().sign(), k2.cpu().sign())\n",
    "        # inds = torch.nonzero(bb)[:, 1].numpy()\n",
    "        idx = []\n",
    "        for ii in range(bb.shape[0]):\n",
    "            try:\n",
    "                iii = list(bb.cpu().float().numpy()[ii]).index(1)\n",
    "                idx.append(iii)\n",
    "            except:\n",
    "                pass\n",
    "        counter = Counter(idx)\n",
    "        ordered_counter = OrderedDict(sorted(counter.items()))\n",
    "        return ordered_counter\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (k, msg_bits) in enumerate(Test_Data_Generator):\n",
    "            msg_bits = msg_bits.to(device)\n",
    "            polar_code = polar_l_2.encode_plotkin(msg_bits)\n",
    "            noisy_code = polar.channel(polar_code, dec_train_snr)\n",
    "            noise = noisy_code - polar_code\n",
    "            deeppolar_code = polar.deeppolar_encode(msg_bits)\n",
    "            noisy_deeppolar_code = deeppolar_code + noise\n",
    "            SC_llrs, decoded_SC_msg_bits = polar_l_2.sc_decode_new(noisy_code, dec_train_snr)\n",
    "            deeppolar_llrs, decoded_deeppolar_msg_bits = polar.deeppolar_decode(noisy_deeppolar_code)\n",
    "\n",
    "            if k == 0:\n",
    "                epos_deeppolar = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "            else:\n",
    "                epos_deeppolar1 = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC1 = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "                epos_deeppolar = epos_deeppolar + epos_deeppolar1\n",
    "                epos_SC = epos_SC + epos_SC1\n",
    "\n",
    "        print(f\"epos_deeppolar: {epos_deeppolar}\")\n",
    "        print(f\"EPOS_SC: {epos_SC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ada1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeppolar_example_test(polar, KO, snr_range, device, info_positions, binary=False, num_examples=10**6, noise_type='awgn', L=8, crc=crc):\n",
    "    bers_KO_test = [0. for _ in snr_range]\n",
    "    blers_KO_test = [0. for _ in snr_range]\n",
    "    bers_SC_test = [0. for _ in snr_range]\n",
    "    blers_SC_test = [0. for _ in snr_range]\n",
    "\n",
    "    kernel = N == KO.ell\n",
    "    num_batches = num_examples // test_batch_size\n",
    "\n",
    "    print(f\"TESTING for {num_examples} examples ({num_batches} batches)\")\n",
    "    for snr_ind, snr in enumerate(snr_range):\n",
    "        total_block_errors_SC = 0\n",
    "        total_block_errors_KO = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        sigma = snr_db2sigma(snr)\n",
    "\n",
    "        try:\n",
    "            for _ in range(num_batches):\n",
    "                msg_bits = 2 * (torch.rand(test_batch_size, K-crc_len) < 0.5).float() - 1\n",
    "                msg_bits = msg_bits.to(device)\n",
    "                \n",
    "                msg_bits_with_crc = crc.encode(msg_bits)\n",
    "                \n",
    "                polar_code = polar.encode_plotkin(msg_bits_with_crc)\n",
    "\n",
    "                if 'KO' in encoder_type:\n",
    "                    if kernel:\n",
    "                        KO_polar_code = KO.kernel_encode(kernel_size, KO.gnet_dict[1][0], msg_bits_with_crc, info_positions, binary=binary)\n",
    "                    else:\n",
    "                        KO_polar_code = KO.deeppolar_encode(msg_bits_with_crc, binary=binary)\n",
    "\n",
    "                noisy_code = polar.channel(polar_code, snr, noise_type)\n",
    "                \n",
    "                noisy_KO_code = polar.channel(KO_polar_code, snr, noise_type) if 'KO' in encoder_type else noisy_code\n",
    "\n",
    "                SC_llrs, decoded_SC_msg_bits_with_crc = polar.sc_decode_new(noisy_code, snr)\n",
    "                #decoded_SC_msg_bits = decoded_SC_msg_bits_with_crc[:,:K-crc_len]\n",
    "                ber_SC = errors_ber(msg_bits_with_crc, decoded_SC_msg_bits_with_crc.sign()).item()\n",
    "                bler_SC = errors_bler(msg_bits_with_crc, decoded_SC_msg_bits_with_crc.sign()).item()\n",
    "                total_block_errors_SC += int(bler_SC*test_batch_size)\n",
    "\n",
    "                \n",
    "                final_decisions, info_llrs, PML = KO.deeppolar_list_decode(noisy_KO_code, L, crc)\n",
    "                decoded_KO_msg_bits = final_decisions[:,:K-crc_len]\n",
    "                ber_KO = errors_ber(msg_bits_with_crc, final_decisions.sign()).item()\n",
    "                bler_KO = errors_bler(msg_bits_with_crc, final_decisions.sign()).item()\n",
    "                total_block_errors_KO += int(bler_KO*test_batch_size)\n",
    "\n",
    "                batches_processed += 1\n",
    "\n",
    "                # Update accumulative results\n",
    "                bers_KO_test[snr_ind] += ber_KO\n",
    "                bers_SC_test[snr_ind] += ber_SC\n",
    "                blers_KO_test[snr_ind] += bler_KO\n",
    "                blers_SC_test[snr_ind] += bler_SC\n",
    "\n",
    "                # Progress logging\n",
    "                if batches_processed % 10 == 0:  # Print every 10 batches\n",
    "                    print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, Progress: {batches_processed}/{num_batches} batches\", end='\\r')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        # Normalize by actual number of batches processed\n",
    "        bers_KO_test[snr_ind] /= batches_processed\n",
    "        bers_SC_test[snr_ind] /= batches_processed\n",
    "        blers_KO_test[snr_ind] /= batches_processed\n",
    "        blers_SC_test[snr_ind] /= batches_processed\n",
    "\n",
    "        print(f\"\\nSNR: {snr} dB, Sigma: {sigma:.5f}\")\n",
    "        print(f\"SC   - BER: {bers_SC_test[snr_ind]:.6f}, BLER: {blers_SC_test[snr_ind]:.6f}\")\n",
    "        print(f\"Deep - BER: {bers_KO_test[snr_ind]:.6f}, BLER: {blers_KO_test[snr_ind]:.6f}\")\n",
    "\n",
    "    return bers_SC_test, blers_SC_test, bers_KO_test, blers_KO_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "645cc944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "TESTING for 1000000 examples (500 batches)\n",
      "SNR: -5.0 dB, Sigma: 1.77828, Progress: 500/500 batches\n",
      "SNR: -5.0 dB, Sigma: 1.77828\n",
      "SC   - BER: 0.166424, BLER: 0.435178\n",
      "Deep - BER: 0.127515, BLER: 0.460441\n",
      "SNR: -4.0 dB, Sigma: 1.58489, Progress: 500/500 batches\n",
      "SNR: -4.0 dB, Sigma: 1.58489\n",
      "SC   - BER: 0.072594, BLER: 0.197168\n",
      "Deep - BER: 0.044962, BLER: 0.190128\n",
      "SNR: -3.0 dB, Sigma: 1.41254, Progress: 500/500 batches\n",
      "SNR: -3.0 dB, Sigma: 1.41254\n",
      "SC   - BER: 0.020022, BLER: 0.055726\n",
      "Deep - BER: 0.009121, BLER: 0.046806\n",
      "SNR: -2.0 dB, Sigma: 1.25893, Progress: 500/500 batches\n",
      "SNR: -2.0 dB, Sigma: 1.25893\n",
      "SC   - BER: 0.002997, BLER: 0.008516\n",
      "Deep - BER: 0.000943, BLER: 0.006294\n",
      "SNR: -1.0 dB, Sigma: 1.12202, Progress: 110/500 batches\n",
      "SNR: -1.0 dB, Sigma: 1.12202\n",
      "SC   - BER: 0.000221, BLER: 0.000607\n",
      "Deep - BER: 0.000060, BLER: 0.000478\n",
      "Test SNRs : [-5.0, -4.0, -3.0, -2.0, -1.0]\n",
      "\n",
      "Test Sigmas : [1.7782794100389228, 1.5848931924611136, 1.4125375446227544, 1.2589254117941673, 1.1220184543019633]\n",
      "\n",
      "BERs of DeepPolar: [0.1275153234153986, 0.04496194126456976, 0.009121382360346614, 0.0009426764737290795, 5.961134438946049e-05]\n",
      "BERs of SC decoding: [0.1664240588247776, 0.07259394115209579, 0.020021558824926615, 0.0029972941197920593, 0.00022058823632115882]\n",
      "BLERs of DeepPolar: [0.46044100000000016, 0.19012799999999982, 0.04680600000000002, 0.006293999999999975, 0.0004776785714285717]\n",
      "BLERs of SC decoding: [0.4351780000000001, 0.19716799999999976, 0.05572599999999994, 0.008515999999999987, 0.0006071428571428575]\n",
      "time = 161.94518307447433 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "\n",
    "start = time.time()\n",
    "bers_SC_test, blers_SC_test, bers_deeppolar_test, blers_deeppolar_test = deeppolar_example_test(polar_l_2, polar, snr_range, device, info_positions, binary = binary, num_examples=10**6, noise_type = noise_type, L=L, crc=crc)\n",
    "print(\"Test SNRs : {}\\n\".format(snr_range))\n",
    "print(f\"Test Sigmas : {[snr_db2sigma(s) for s in snr_range]}\\n\")\n",
    "print(\"BERs of DeepPolar: {0}\".format(bers_deeppolar_test))\n",
    "print(\"BERs of SC decoding: {0}\".format(bers_SC_test))\n",
    "print(\"BLERs of DeepPolar: {0}\".format(blers_deeppolar_test))\n",
    "print(\"BLERs of SC decoding: {0}\".format(blers_SC_test))\n",
    "print(f\"time = {(time.time() - start)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f42683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/0AAAKwCAYAAADKjh9mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1gU1/rA8e8uLEtfVFBAEAsoYu8Fe+9ii5rEa4m5uWosv2vMVW+KMSbGJBo1V2OMGk0VG/ZurKioiFgQ7IIIIpal193fHyurBFBUdEHfz/PMkzBzZuYcRmDfM+e8R6HX6/UIIYQQQgghhBDilaM0dQWEEEIIIYQQQgjxYkjQL4QQQgghhBBCvKIk6BdCCCGEEEIIIV5REvQLIYQQQgghhBCvKAn6hRBCCCGEEEKIV5QE/UIIIYQQQgghxCtKgn4hhBBCCCGEEOIVJUG/EEIIIYQQQgjxijI3dQVeBTqdjps3b2JnZ4dCoTB1dYQQQgghhBBCvOL0ej2JiYm4urqiVBb8Pl+C/iJw8+ZN3N3dTV0NIYQQQgghhBCvmaioKNzc3Ao8LkF/EbCzswMM32x7e3sT16ZgmZmZ7Ny5k06dOqFSqUxdHVEAeU7FnzyjkkGeU8kgz6n4k2dUMshzKhnkOZUMJeU5JSQk4O7uboxHCyJB/3NYsGABCxYsIDs7GwB7e/tiH/RbW1tjb29frP/xvu7kORV/8oxKBnlOJYM8p+JPnlHJIM+pZJDnVDKUtOf0pCnmksjvOYwZM4awsDCOHz9u6qoIIYQQQgghhBB5SNAvhBBCCCGEEEK8oiToF0IIIYQQQgghXlES9AshhBBCCCGEEK8oCfqFEEIIIYQQQohXlAT9QgghhBBCCCHEK0qW7BNCCCGEEMVCZmamcSlk8XQyMzMxNzcnLS1NvofFmDynksEUz8nMzOyFLQ8oQb8QQgghhDCphIQE4uPjSU9PN3VVSiy9Xo+zszNRUVFPXLNbmI48p5LBVM9JrVbj6OiIvb19kV5Xgv7nsGDBAhYsWCC9dEIIIYQQzyghIYHo6GhsbW1xdHREpVJJMPQMdDodSUlJ2NraolTKDN7iSp5TyfCyn5NeryczMxOtVkt0dDRAkQb+EvQ/hzFjxjBmzBgSEhLQaDSmro4QQgghRIkTHx+Pra0tbm5uEuw/B51OR0ZGBpaWlhJMFmPynEoGUzwnKysr7OzsuHHjBvHx8UUa9Mu/NCGEEEIIYRKZmZmkp6ej0Wgk4BdCvPYUCgUajYb09HQyMzOL7LoS9AshhBBCCJPImSL5opJXCSFESZPz+7Aop5BL0C+EEEIIIUxK3vILIYTBi/h9KEG/EEIIIYQQQgjxipKgXwghhBBCCCGEeEVJ0C+EEEIIIYQQQryiJOgXQgghhBCimFAoFLk2lUqFo6MjtWrVYtiwYaxdu5asrCxTV/Op7du3L0/bzM3NcXZ2pnfv3uzdu/e579GmTRsUCgXXrl17/go/p+PHj/Pmm2/i7u6OhYUFDg4OVKtWjf79+7N48WK0Wm2+5+n1elatWkW/fv1wd3fH0tISOzs7atSowahRozh27Fih6zBs2DAUCgXLly9/Ytlr166hUCho06ZNoa8vSg4J+oUQQgghhChmhg4dytChQxk8eDC+vr5kZWXxyy+/0L9/f6pXr/5UwV9xUq5cOWPb+vfvj4ODAxs3bqR9+/b88MMPpq5ekVi6dClNmzblzz//xNLSkq5du9KlSxc0Gg2bNm3iP//5D+fPn89z3q1bt/D19WXgwIFs2LABV1dXevfuTYcOHcjMzGTRokU0adKEzz//3ASterJp06YVupNBvFzmpq6AEEIIIYQQIrf8AqfLly8zdepUVq1aRdu2bQkMDKRu3bovvW7Pw9vbO1fb9Ho906dPZ9q0aUycOJF+/fpRtmxZ01XwOUVHRzNmzBj0ej1LlixhxIgRubKxx8XFsWTJEhwcHHKdl5SURJs2bQgPD6d79+4sXLiQChUq5Cpz4sQJPvzwQy5fvlzk9S5fvjznz5/H2tq6yK8tTE/e9AshhBBCCFECVKlSBX9/f9555x1SUlIYMWKEqav03BQKBR9//DFVqlQhNTWVnTt3mrpKz2Xr1q2kp6fj6+vLO++8k2f5NUdHR0aPHo23t3eu/VOmTCE8PJwOHTqwYcOGPAE/QMOGDdm9ezfvvfdekddbpVLh7e2d731FySdB/3NYsGABPj4+NGrUyNRVEUIIIYQQhXD6xn0GLz7K6Rv3TV2VZzZ79mxsbGwICQnh0KFDeY5fu3aN9957j4oVK6JWq3FycqJ///6cPn26wGseOnSIPn36ULZsWdRqNRUrVmTcuHHcvn07T9mcueL79u1j27ZttGjRAltbW0qVKkXfvn0JDw9/qvYolUrq1KkDQFRUlHF/SkoKn3/+OTVr1sTKygqNRkOrVq1YuXLlU13/4MGDvP/++9SuXZtSpUphZWWFt7c3kydP5v79+3nK5+QfGDZsGLGxsYwcORI3NzfMzc2ZO3fuY++V8/1ycnIqdP3u3r3L0qVLAZg/fz5mZmYFllUqlTRr1qzQ1y6sx83p37FjB507d8bNzQ21Wo2rqystWrTgs88+M5apWLGi8evhw4fnyt2wb9++Iq+veDoS9D+HMWPGEBYWxvHjx01dlUIJuxPG0sSlhN0JM3VVhBBCCCFMYt3JaI5cucO6k9Gmrsoz02g0dO3aFSBPArxDhw5Rp04dFi9ejK2tLb169cLLy4t169bRtGnTfBPmzZ8/n1atWrFp0yY8PT3p1asXVlZWfP/99zRp0oSYmJh867F69Wq6d+9ORkYGPXv2xNXVlYCAAJo2bUpoaOhTtSkxMREAtVpt/LpVq1Z88sknxMXF0aNHD3x9fTl27BiDBw9mwoQJhb72pEmTWLJkCRYWFrRr14727duTkJDArFmzaNGiBUlJSfmed/v2bRo1asSWLVto1qwZXbt2feLwdzc3NwD27NnDxYsXC1W/vXv3kpqaSr169ahevXqh2/UyLFq0iC5durB//36qV69Ov379qFGjBteuXWPatGnGcv379zd23Pj6+hrzNgwdOhRnZ2cT1V7kkDn9r5HNVzdzNfsqW65uoY5zHVNXRwghhBCiQHq9ntTM7CK5VvT9VO6nZKBAwcbQmwBsDL1Jj9ou6NHjYG1BeQer576Plcosz3DuF6Vu3bqsWbMmV0K4hIQEBg4cSGpqKqtXr6Z///7GY7t376Z79+4MGTKEK1euYGFhAcDRo0f5v//7PypUqMDGjRupXbs2YPj+z5gxg08++YRx48axevXqPHVYuHAhixcv5t133zWeM2XKFGbNmsWIESMIDg4uVFvi4uIICgoCMN5/6tSpBAcH06FDBwICArC1tQUgPDyc1q1bM2/ePDp16kS3bt2eeP1PPvmEZs2aUapUKeO+9PR0xo0bx+LFi5kzZw6ffPJJnvO2bt1Knz59+OOPP7C0tCxUW3r37o2TkxO3b9+mdu3a9OjRgzZt2tCsWTPq1KmT77+PkJAQAOrXr1+oe7xMX331Ffb29oSGhlKxYkXjfr1en+sN/rfffsu0adMIDQ1l5MiRDBs27KXXVRRMgv5X3M2km9xLv4cCBTuu7wBg+/Xt+FX1Q4+eUupSuNq6mriWQgghhBC5pWZm4/PJjhd2/bvJGfRfdKRIrxk2vTPWFi/n47WjoyMA9+7dM+77/fffiY2NZcqUKbkCfoAOHTowevRo5s6dy+bNm+nbty9gCOp0Oh2LFy82BtxgmGv/0UcfERAQwLp164iPjzfeM0fz5s2NAX/OOZ9//jl//PEHJ0+e5MiRI48dip6WlkZoaCjjx48nISGBatWq0bZtW5KTk1m6dClKpZKFCxcaA34wJAL86KOPGDduHPPnzy9U0J9fGbVazdy5c1m2bBkbNmzIN+hXq9V8//33hQ74wTAKY/v27bz55ptERESwZs0a1qxZYzw2cOBAJkyYgL29vfGcO3fuAE83JeBliYuLo2rVqrkCfjA867Zt25qmUuKpyfD+V1zntZ0ZtHkQAzcPxC38DnMWZ+EWfoeBmwcyaPMgOq/tTLauaHrRhRBCCCHEy6HX6wFyvTnOGbrv5+eX7zktWrQAME5N1el07NmzBzs7O9q3b5+nvEKhwNfXF51Ol+9b+0GDBuXZp1Kp6NevH0C++Qb2799vnOttZWVF06ZNCQoKwtPTk/Xr12NmZkZwcDCpqak0btwYLy+vPNcYMmQIAIGBgcbvw5NER0ezaNEiJkyYwIgRIxg2bBijRo3CwsKiwGH49evXp3z58oW6/t/PO3fuHFu2bOH999+nYcOGqFQqtFotixcvpnXr1kRERBjLF7YNptCgQQNCQ0OZPHnyC1k1QLwc8qb/FTez5Uw+OvQR2bosBu/X4XYHBu/XcaaiAh78kWjl34rGzo3pUqkLnSt2NnGNhRBCCCEMQ+XDphfd55Kwmwn5vtlf869m+Lja53PG07NSFZyArajFx8cDULp0aeO+nCR4TZo0KdS5d+7cMc5nNzd/fFiQc86jPDw88i2b81b45s2beY6VK1eOLl26GO9ZpkwZmjZtSo8ePVCpVLnO+/vb5RwODg5oNBq0Wi0JCQloNJrH1n3OnDlMmTKFjIyMx5b7u+fJZG9mZka3bt2MowwSEhJYtWoVkydP5vbt24wdO5bdu3cDD0dt5Jc00dQWLFiAn58fs2bNYtasWbi6utKyZUv69+9P3759USrlHXJJIEH/K65H5R5U1lTmy/kD8HyQg8UzBupc1WPWtAER9yJIyEhgd+RunKydjEF/RnYGO67toLFzY8rZlDNhC4QQQgjxOlIoFEU6VN7yQUCuUIBe//C/liqzlzYkvyidOnUKAB8fH+O+7GzD6M0BAwY8NuFcTqdATnk7OzvjcP+CFBTg5+dxb669vb1Zvnx5oa5TmPwITypz9OhRJk6ciEajYfHixbRp0wZnZ2djwkBXV9cCExU+zbD+J7G3t2fkyJGULVuW3r17s2/fPlJSUrC2tqZu3boAnDx5ssjuV1Rq165NWFgY27dvZ+vWrezfvx9/f3/8/f1p0aIFe/bsMeaHEMVXyfsNJ56eXs/AAzqyFWCmBx0wbJcO13fHU9W1NmfjzxIUE0Qj54dLD4beDmXqoakAVLSvSBOXJjR1aUoj50Zo1I/vTRVCCCGEKG7K2FrgZKvGxcGSgY3c8T8eRcz9NMrYlryARavVsn37doBc86pdXV25ePEiH330Ua75+QVxdHRErVajUqkKHYg/6vr16/nuj4yMNNbnWeScd/Xq1XyPa7VatFotNjY22NnZPfZaAQEBAMyYMYOhQ4fmOpaamkpsbOwz1fFZ5SyJl52dzf3797G2tqZdu3ZYWloSEhJCeHg43t7eL7VOT2JpaYmfn59x2khYWBiDBw/m0KFDLF26lFGjRpm2guKJZDzGa8Au5DKeMYaAHwwPvfxdUHQaQtTgt3D5eSdv3q5CbVVF4zmZukxqlKmBAgXXEq7hH+HP/+37P1qubMnAzQM5HlsylikUQgghhABw0VhxaHJbNozx5a0mHmwY48uhyW1x0Tx/1v6XbeLEiSQnJ9OoUaNcifJat24NwPr16wt1HXNzc9q0acPdu3c5cODAU9fD398/z76srCzWrl0LGJZuexYNGjTAysqKY8eO5Tvf/rfffgMMOQqe9KY/J9Ghu7t7nmOrV68u8vn0T7pezrx4CwsL47D+0qVLM2LECADGjh1rHIFR0PWPHj1aRLV9Nj4+PowZMwaAM2fOGPfnvPHPysoySb1EwSTof8Xp9XqyfvwV8ptvo9ORFnqauz//zI33xxLz34+Mh5q7NueXOt9wYOAB5raZy6Bqg6isqYwePWF3wrBWPRwydjTmKD+G/sipuFNk6jJfRrOEEEIIIZ6a2vzhknoKhQK1+cubg18Urly5wsCBA1m6dCk2NjYsXbo01/Hhw4fj5OTEl19+yc8//5wnAE1OTuaXX37hxo0bxn1Tp05FqVQydOjQfBPv3bx5kwULFuRbn8DAQJYtW2b8Wq/X8+mnnxIZGUmdOnVo3rz5M7XTxsaGESNGoNPpGDNmDMnJycZjFy5cYMaMGYAhQH6SqlWrArB06VIyMx9+Tg0LC+M///nPM9XvcX744Qfee+89zp49m+fYzZs3GT16NGBYUeDRYfFfffUVXl5e7N69Gz8/P2N+hkeFhobSqVMnFi1aVOT1zk9KSgrz58/n/v37ufbrdDp27twJ5M57kDNC49EkhaJ4kOH9r7jkQ4Gk5fNLJ0fpke+gS0oiNfgk1g0bGPdn3rzJ5Y6dMHN0pFr9+tRrUJ9/1+9NgkdpjsefxLvUw2FHW65sYf2l9fzv1P+wUdnQoFwDmjg3oYlLE7xKeaFUSN+SEEIIIcTTyFnnXKfTkZCQwIULFwgPD0ev1+Pl5cUff/xBrVq1cp3j4ODA2rVr8fPzY8SIEXz22WfUrFkTtVpNZGQk58+fJzk5mZCQENzc3ABo1aoV8+bNY8KECbRs2ZLatWvj5eVFWloa169f5/z589ja2hrf7D5q1KhRjBw5kh9//JEqVapw+vRpzp07h52dHT///PNztX/mzJkcPXqUXbt2UblyZVq3bk1ycjJ//fUXaWlpjBs3ju7duz/xOsOHD2f27Nls2rSJatWq0ahRI+7evcv+/fvx8/Pj2LFjBU5TeBYZGRksXryYxYsXU6lSJWrVqoW1tTXR0dEEBQWRkZGBh4cHc+fOzXWenZ2dsU6bN29m27ZtNGzYkIoVK5KRkcH58+cJDw8HMHZ6FNbnn39eYEdB1apV+eWXXwpsy/jx45k0aRL169c31uXEiRNERkZSuXJl3nvvPWP5Tp06YWlpyXfffcfZs2dxdXVFoVAwadIkqlWr9lR1FkVLgv5XmF6v5/a8eQ8z1fydQkHK0SAqrl6FQqHI1RucfvkKCpWK7Ph4EnfuJPFBb57C2ppadWqTOtwe21atAGjm0ozkzGSOxR5Dm67lwI0DHLhhGCJW2rI0W/tuxUZl8+IbLIQQQgjxilixYgVgGIJvb2+Pq6sr//jHP+jVqxe9evUqMNu+r68vZ86cYc6cOWzZsoW//voLMzMzXF1d6dGjB3379s2V/A/g/fffp1mzZnz33XccOHCAjRs3Ymdnh5ubG//6178YMGBAvvd644036NatG19++SUbNmxApVLRu3dvvvzyyzz3eFo5QfDs2bPx9/dn48aNWFhY0LBhQ0aPHs3gwYMLdZ0yZcpw/Phx/vOf/7B//342btxIpUqVmD59OpMmTaJKlSrPVc+/GzFiBG5ubmzfvp3g4GCOHDnCvXv3sLOzo0GDBvTs2ZO3334736UAXVxcOHLkCKtWrcLf35/jx48TEhKCSqXCw8ODUaNG8c4779CgQYN87lywK1eucOXKlXyPpaWlFXiera0tCxYsYM+ePYSGhnL69GksLCzw8PDg3Xff5f3338fBwcFY3tXVlQ0bNjB9+nQOHTpkXBni7bfflqDfxBT64rwwZAmRs1SIVqvF3r5olnwpCrqMDC61bUf2nTsFljFzdMTzrz0o88m6qUtPJ+3cOVKCg0kNPklKSAg6rRaA8nO/w/7BciupZ8+h3bgBq/r1iK5kT1DmBYJigjgZdxJXG1fW+603XvPjwI9RKpQ0cW5CY5fGOFo5Fm2jXwGZmZls3bqVbt26GZeuEcWLPKOSQZ5TySDPqfh7kc8oLS2Nq1evUqlSpSLNlP46yhkRYG9v/8KXURs2bBgrVqxg7969xsR0onBe5nMSz86Uz+lpfi8WNg6VN/2vMKWFBZXWrCbr7l3AkFQjMDAQX19fY++weZky+Qb8AEq1Guv69bGuXx/eBb1OR8bly6QEn8S6cWNjueRDB7n3y6/c++VXFEDLChXoXL8+FvX+TXKVCuj1ehQKBenZ6Wy7uo307HTWXVwHgKeDJ01dmtLEpQkNyzXE1sL2xX5ThBBCCCGEEOI1IkH/c1iwYAELFix4bIZNU1O5uKBycQEMPfXp165h6ePzTD31CqUStZcXai+vXPut6ten1FtvkXLyJOnh4WRGRqKNjIQHmWPTVq/GqlZNlAolc+t9ztGEUI7ePkHEvQgu3b/EpfuX+O38b/i6+rKo48P5RpnZmajM5K2PEEIIIYQQQjwrCfqfw5gxYxgzZoxxWMXryqZxY2wevPnPTkwk9VQoKScNUwLSL13Csroh6Z9KqaLKysM4btzEgFq1UNR5kysVLTlcOp5D2hCauDQxXjMuJY7u67pTr2w9mrg0oalLU7xLe2OmLFlZdoUQQgghhBDClCToF0XKzM4O25YtsG3ZAgB9djYKs4eBevqly+jT00k5cQJOnKAc0EehYFDVqlg2iEJf3VA++FYwadlpHIk5wpGYIwDYWdjR2LkxTVya0Na9Lc42zqZoohBCCCHEa2358uUsX77c1NUQQhSSBP3ihXo04Afw+ON3Mq5eI/VkMCnBJ0k5GUzm9UjSIyLQZ2QYy3ep2IXK60O4RjyHHe+xS3mexIxE9kTuYU/kHuwt7Ole2bBMy920u2RkZ0gngBBCCCGEEEL8jQT94qVSKBSoK1dCXbkSDv37A5B1+zYpJ0PQZ2U+LJiVhf7XtVRISaEC8Ka9HVk+tYisZMNRp/s0Ll3XWHTdxXXMOzmPivYVaeLShCYuTWjs3BiN+vWdciGEEEIIIYQQIEG/KAbMnZyw79wp1z59RgZlRowwjAg4FYouIRHl0RAqHoWKQGrodPjxR8Aw/98uTcE1rnEt4Rr+Ef4oUOBd2pumLk0ZWXsk9hbFZylFIYQQQgghhHhZJOgXxZLSxgan98cAoM/KIi084uGUgOBgrOvVM5adVHEkfYb+SqaHMzcq2XG8bCL7y9zmvD6MawnXGFtvrLHswRsHsbWwpaZjTVRKWRlACCGEEEII8WqToF8Uewpzc6xq1sCqZg1K/+Mf6PV6yHw4FSDtfBgAquuxVLoeSyXgDSCrjD3aaq5keIagamJYXeCbE99wVXsVa3NrGpRrYFwZwKuUF0qF0gStE0IIIYQQQogXR4J+UeIoFAqwsDB+bdemDV6HA0kNCSEl+CSpwcGknjuH+Z0EyhxOIKtPHACZ2Zk0Tnam+dFoTrkkcSzlAAejDwJQ2rI03St358NGH5qkTUIIIYQQQgjxIkjQL14J5qVLY9e+PXbt2wOgS00l9cwZUk+exLqx4S2/ykzFqNTGxO09SG9AZ6Ykzs2aEJc0zrrGk625a7xeti6bmcdmUq9sPZq4NMHRytEUzRJCCCGEEEKI5yJBv3glKa2ssGncGJsHAX8OtZcX9t26kRIcTNatWzhfT6TrdegKsG4DqavfxqpWTcLuhBFwdiX+5itBocDTwdOwMoBzExo6N8TOws4k7RJCCCGEEEKIpyFBv3it2LZujW3r1uj1erJu3iTlpCExYGrwSTKiolBXqwqARq3hixAvygRd5Fz5bMLdLnDU7SIry/2G3tyMj5p+xICqA0zcGiGEEEIIIYR4PMlcJl5LCoUCVfnyaHr2xGXaNCpv2kjVwEMoH+QKqGBfgWoxSmyTsmkSoWfoHh0zV2Sz4jsd//09k2prQ9BnZwOwL2of7+58lyVnlnDm9hmyddkmbJkQQgghSrpdu3bh5+eHs7MzFhYWlClTBh8fH9566y1++uknMjIy8j0vMzOTJUuW0K1bN1xdXVGr1Wg0GurXr8/EiRM5f/58kdRv+fLlKBQKpk2bViTXM5VXpR1CPIm86RfiAaWNTa6vPVb+SdrZcw+XCjx5EgutllrXwfyv4yimmAFwKPoQdlsOE2R1mF/cFGSVtqehc0PjygCVNZUNyQeFEEIIIZ7g008/Zfr06QDUrFkTX19fzMzMiIiI4M8//+SPP/6gZ8+eODs75zrvwoUL9OrVi4sXL2JhYUHjxo1p3bo1ycnJnDp1ijlz5jB37lyWLVvG0KFDTdE0IYSJSNAvRAGUFhZY16+Hdf16lBkJep2OjCtXSAk+mavc29XeJOngGsxS0gGIdbhHhNtujrvv4Vc3BUve3YabvTsA6dnpqM3UL70tQgghhCj+Tpw4wfTp07GwsCAgIIBu3brlOh4dHc1PP/2EWp37s8TNmzdp3bo1cXFxDB06lNmzZ1OmTJlcZf766y8++OADrl69+sLbIYQoXiToF6KQFEolak9P1J6eufa7q8pxu+8AUk4Gkx4egfN9Hc739bQ+qwdAf2UWLPgfAB/s+4Brdy/TyK0pTVya0Ni5MaUsS730tgghhBCi+AkICADgjTfeyBPwA5QvXz7foejvvfcecXFxvPnmmyxbtgylMu8M3nbt2nHkyBHOnDlT5PUWQhRvMqdfiOdkZmuD80f/pfK6dVQ9FoT7kiU4jh6FdZMmKCwtsfT2BkCn13HxWjAzPrtKjU/+5MT0/2P8ly0Zsqov3x7/lsM3D5u4JUIIIYQwpdu3bwPg5ORU6HPOnz/P5s2bsbKy4osvvnhsWbVaTcOGDQt97dOnT9OjRw80Gg0ajYaOHTty5MiRx56TkZHBvHnzaNSoEXZ2dtjY2NC4cWOWLl2KXq/P95z4+HimTJlCzZo1sbGxwcHBgbp16/Lf//6XO3fu5CqbkpLC559/Ts2aNbGyskKj0dCqVStWrlxp0nYoFAoqVqxIRkYG06dPx9vbG7VajZ+f32PvI8TLIG/6hShCZra22LbwxbaFLwD6zEx06YZkO0qFkl/c/sudrA/wiQKfKD2QjW7VeaKcznO16ibqjZ2HeY0aAITdDcPH0QeVmcpUzRFCCCFePZf3wrb/QNdZUKWtqWuTi5ubGwBr165lypQphQr+t27dCkDnzp1xcHAosroEBQXRrl07UlJSqFu3Lt7e3pw9e5bWrVszbNiwfM9JTk6ma9euHDx4EEdHR1q0aIFSqeTIkSOMHDmS48ePs2jRolznhIWF0alTJ6Kjo3FxcaFLly5kZ2cTERHBl19+SceOHWnTpg0AiYmJtG3bluDgYJycnOjRowfJycn89ddfHDx4kKNHjzJ37lyTtANAp9Ph5+fHgQMHaN26NbVr184zzUIIU5Cg/zksWLCABQsWkJ0t2dpF/hQqFWaqh0G7U6duaLb5kHryJCnBJ0k6cQwib+BxGzxux5He/SrmNWqQokth0h9vUz/SDPO6tfCq144mbs2oWqoqSoUM0BFCCCGeiV4Pez6D+AjDfyu3gWKUbPett95i5syZREZG4unpiZ+fHy1btqRZs2b4+Pjkmxg4JCQEgPr16xdZPXQ6HcOGDSMlJYWZM2cyefJk47GPP/6YGTNm5HvepEmTOHjwIEOGDGHhwoXY2toChhEMPXv25Mcff6Rnz550794dgKysLPr160d0dDQTJ05k5syZqB753BQSEpKr42Pq1KkEBwfToUMHAgICjNcPDw+ndevWzJs3j06dOhmnRrysduSIiopCrVYTERFB+fLlC/fNFuJl0IvnptVq9YBeq9WauiqPlZGRoV+/fr0+IyPD1FURj8i8fVuv3bFDH/vlTH3GjRv6jIwM/fdrvtdPG9dAH1bNWx9WzVt/vLa3/reu1fVfjqqv/3rxMP3RqwdMXe3XmvwslQzynEoGeU7F34t8RqmpqfqwsDB9ampq3oM6nV6fnlS02/nNev2n9g+385uL9vo63XN/T3bs2KF3dXXVA7m2smXL6idNmqS/d+9ervJdunTRA/qFCxfq7927p8/Ozn7uOuzZs0cP6KtWrarX/a1NmZmZ+goVKugB/aeffmrcf+vWLb1KpdJXqlRJn5aWlueap06d0gP6nj17Gvf5+/vrAX3t2rWfWO+kpCS9lZWVXqlU6i9cuJDn+Pz58/WAvnPnzi+9HXq93vicVq9e/dh2ZGdnF9lzEi+OKZ/TY38v/k1h41B50y+EiZk7OmLfqRP2nToBhjV23c3dGdxxGnF3fyP7zHls0jKof0VP/Ssp8NdR9POOk+rvj1WNGtxMusnJ2BM0cW2Gk3Xh5wAKIYQQxVpmCnzp+mLvsfLNor3e1JtgYfPkco/RqVMnrly5wsaNG9m1axdBQUGcPXuWuLg4vvnmGwICAjh8+LDxDbi+gHnyz+PQoUMADBgwIM/oAnNzc/r378+cOXNy7d+/fz+ZmZl06dIlz+oCAHXq1MHOzo7jx48b9+3evRuAd999N9/kg48KDg4mNTWVpk2b4uXllef4kCFDGDduHIGBgej1ehQKxUtrRw6FQkHPnj0f2w4hTEHGCQtRTNl37kz1X1dS40QwFdeuwXHKf8hu24R0B2sUKFBXqQLAnsg9hE+bzKmOrVjxj6b8Nnsk+4NWkZCeYOIWCCGEEOJZqNVqBgwYwOLFiwkNDSU2Npavv/4aa2trLl26xNSpU41lHR0dAUMyvKJy8+ZNACpUqJDv8fz2X7t2DYAffvgBhUKR75aYmJirnlFRUQBUefCZpjB1qlixYr7HHRwc0Gg0JCUlkZCQ8FLbkaNs2bL5dhQIYWrypl+IYk5hbo5VjRpY1aiB09Bh6PV6suLiUFpaAmBvYY9rjBrXO2m43dHCsUD4KZAztp8SW8WBuh0GU3nEGBRmZiZuiRBCCPEUVNaGN+dFQa+H5d0g9izoH8nFpDAD55owbGvRzO1XWT//NfLh5OTEpEmTsLKyYuzYsWzZssV4rG7duvz++++cPHmyyO6XM3ogvxwCBcnJcVWvXj1q1679VPd7mvsUpmxOmZfdDssHn82EKG4k6BeihFEoFKjKlTN+3duzN1lrWhEfdIjIwB1khISiuRpP6SQoHXqf7FsBKN4dB8CaC2sw230Ez8oNqNaiBxa29qZqhhBCCPF4CsVzD5U3urQbYkLz7tdnG/ZHHQXPDkVzrxcoJ4v9o2+Zu3XrxqRJk9ixYwf379/H3v75/7a7uhqmVVy/fj3f45GRkXn25aw80KZNmzxD5gvi7u4OwKVLlwpdp6tXr+Z7XKvVotVqsbGxwc7OLtc5L7odQhR3MrxfiFeAealSOHfpSePP/0eLzQepERyC7U9zSR7RmzJvv2Ust+r8Ssov3or5hM+50KgJ+zo3Yd+kYVwI+IXMB2sDCyGEEK8UvR7+mkHBH3uVhuMvYG7803rS/PzLly8DD4NZAB8fH7p160ZqaiofffTRY8/PyMjgxIkTT6xHixYtAMPSgX+vU1ZWFmvXrs1zTtu2bTEzM2Pz5s2FXtmqQwdDR8uSJUue2PYGDRpgZWXFsWPHuHjxYp7jv/32m7HuOW/2X1Y7hCjuJOgX4hWktLTEvWVnGn74FWVGjgQMHyQGuPcktpYLd+wVmOmh3PUEym0KInvKTC61bEX0xA9yXedFJAcSQgghXqrsDNBGA7oCCuggIdpQzsQ+/vhjPvzww3zfZl+8eJGJEycC0Ldv31zHfvzxRxwdHfn999955513uHPnTp7zDxw4QPPmzdm8efMT69G2bVuqVq1KeHg43377ba5jM2bMyPfNefny5Rk2bBgXL15kyJAh+c55P3z4MFu3bjV+3bdvX6pWrUpoaCiTJ08mKysrV/lTp05x48YNAGxsbBgxYgQ6nY4xY8aQnJxsLHfhwgXj8ntjx4596e0QoriT4f1CvCYUCgUD6g+FX4eSrcsmPOwglw5sJvXkSUpduIX7bR2qB0PadHod764dzJivL6Cv6UXZZm1wbNICy+rVUTyyfq4QQghR7Jmr4Z97Ifkxie5snAzlTCwpKYl58+bx7bffUq1aNapXr45KpSIyMpJjx46h0+lo0KABn376aa7z3Nzc2L9/P7169WL58uX88ccfNGnSBDc3N5KTkwkNDeX69euYmZkxbty4J9ZDqVSyfPly2rdvz4cffsiff/6Jt7c3Z8+eJTw8nJEjR7JkyZI8582fP58rV67w559/snnzZurWrYurqyuxsbFcunSJ6Ohoxo8fT7du3QBDBv21a9fSsWNHvv76a3777TeaN29OVlYWERERnD9/nr179xqH3M+cOZOjR4+ya9cuKleuTOvWrUlOTuavv/4iLS2NcePG0b1795feDiGKOwn6hXgNmSnNqFGzDTVqtgEgIzsDbXw0pVQaAC7eu0hm6FmsEnRw+AxJh8+QxPdkW5iRXb0KTk1aUrp7TyyrVTNhK4QQQohC0rgZtmLuo48+okGDBuzYsYPQ0FD2799PQkICDg4OtG7dmv79+zNy5EgsLCzynOvt7c3hw4dZt24d69ev59SpUxw9ehRLS0s8PT3p378///znP6latWqh6tKsWTMOHz7M1KlTOXToEJcuXaJRo0b88MMPXLx4Md9g2dramp07d7JixQp+/fVXTp8+TVBQEGXLlqVKlSqMHz+ewYMH5zqnZs2anDp1im+++YaNGzeyadMmrK2t8fDw4KOPPsqVTM/Ozo79+/cze/Zs/P392bhxIxYWFjRs2JDRo0fnufbLbIcQxZlCL+N3n1tCQgIajQatVlskyVNelMzMTLZu3Uq3bt1QydvaYqs4PKeUzBSORx4m4ug2koJP4HjxNt5ReuzSHpZx/nw6pQYMIFOXSWZ0DFlnzmLVoEGuJIOvquLwjMSTyXMqGeQ5FX8v8hmlpaVx9epVKlWqJJnPn5NOpyMhIQF7e/snrnkvTEeeU8lgyuf0NL8XCxuHypt+IUQe1iprWlfpQOsqHeAtiE+N5/jNIA6G7CHxRBB+Kd7YNGoEwJGbR9g+exxDtqcDoHcpi6ZRU6wbNMC6QX0sKldGIX/UhBBCCCGEMAkJ+oUQT+Ro5UjXKt3pWqU79Dck+MvJjHsq7hQJZplccYaKt0AZE0fCxo0kbNwIgMLejoorVmBZvbopmyCEEEIIIcRrSYJ+IcRTywn4AcbWG8vFSl0Iigli99VAtCePU/FaKt43wOumHsvkZCwqVADgesJ19D/+DqfCsK5fH6sG9bGuVw8zjcZUTRFCCCGEEOKVJkG/EOK5KBQKqpaqStVSVRniM4TMrpmciz9HUEwQv8Wf5wu30ShtbAD4PuR7Wm7bQtWbkBocDD8ZrqH28jJ0ADRogH23bijMzEzYIiGEEEIIIV4dEvQLIYqUSqmibtm61C1bN8+x5MxkFvQ0p9oNHd5Rerxv6HG9C+kXL5J+8SKJu/dg36OHsXzSgQOYlyuH2tNTOgKEEEIIIYR4BhL0CyFemh86/IC2pZYTsSc4GnOUebFB3Ll5hWo39LS4U4Ye3n2NUwcCLqyj2n9mobiXgNLWFqt69bBuUB+r+vWxql0bpWR5FkIIIYQQ4okk6BdCvFQatYb2Hu1p79EegFvJtzgWewy1mZqyFTsBkJSRxNf7P2OcQybeyWCZlETywYMkHzxouIhKhYOfHy6fTzdVM4QQQgghhCgRJOgXQphUOZty9KzSM9e+xIxEmnq243//OEZSmpYKceB9wzAdwOeGAofETJT2dsby2UlJXBs0COt69bCqb1gqUOXunivhoBBCCCGEEK8jCfqFEMWOi60L37X9jmxdNuH3wgmKCSIoJohFt06SlpXKZ5XG0bOqHwBRiVFs/vML2ly6TMaly9xfvQYAMydHrB90ANi2bo2Fh4cJWySEEEIIIYRpSNAvhCi2zJRm1ChTgxplajCi5ggysjMIvR1KJU0lVFaOABy5eYSfOURQfyXeN/TUjbHE/UY63I4ncccOEnfsAHNzSj8I+rNu3yb94kWs6tQxrioghBBCCCHEq0qCfiFEiWFhZkEj50a59tVwrEH/ev8gyDmI370u8DuZqDIVVIk1w+eGgv5pNbBp9PCcxL/2Evvpp2BmhqW3t2GpwAcjAsydnF52k4QQQgghhHihJOgXQpRoOSMBAO6k3uF47HGOxhwlqFQQ6yvc5INBP6G2MMz//+n0T2Sc24ivoz3q+ATSzp0j7dw57v3yKwCqChVw+34+ltWqPfaeKUeO4jF7DimlSqNp1fLFNlAIIYQQQojnIEG/EOKVUcaqDF0qdaFLpS4A3E65jZ3Fw4R/+27s43SVayyqAmW0ZtSLtcQ3vgyVI9Oxuh5HZlQUKhcXY/n4n34i9VQo1vXrY92gPpY+PqBScWfePNRxcdyZNw/7li0kYaAQQgghhCi2JOgXQryynKxzD9f/rNlnhlEAMUEcVx1ntyaZ3dVugi+46EqxzmcOZvb2ACRnJpO0bz+pwcEk7dkDgEKtxsLDg/QLFwBIP3eO5EOB2LZs8XIbJoQQQgghRCEpTV2BkmzBggX4+PjQqFGjJxcWQpicZylP3vZ5m+/bf8+hQYf4rdtvjK03lsbOjWng2QrbJk0A0Ov19F7fm6+b3OL0wHqkNquF0kGDPj3dGPAD6BQKbs+bh16vN1WThBBCvGIUCkWuTaVS4ejoSK1atRg2bBhr164lKyvL1NV8avv27cvTNnNzc5ydnenduzd79+597nu0adMGhULBtWvXnr/Cz+n48eO8+eabuLu7Y2FhgYODA9WqVaN///4sXrwYrVab73l6vZ5Vq1bRr18/3N3dsbS0xM7Ojho1ajBq1CiOHTtW6DoMGzYMhULB8uXLn1j22rVrKBQK2rRpU+jrF6Wcuj66KZVKSpUqRatWrVixYkW+n7eWL1+OQqFg2LBhhbpPxYoV89zn79vfvwc5/64e3WxsbPDx8WHixIncvn0733t99913KBSKp3pmL4q86X8OY8aMYcyYMSQkJKDRaExdHSHEUzBXmlPHqQ51nOrwz9r/zPWHJDY5lriUOG5p9BzUxEJloLWeNy6Upf+6OGM5pV5P2tmzhG39HYstByjdqDmanj0wd3Q0QYuEEEK8SoYOHQqATqdDq9Vy4cIFfvnlF1asWIGnpye///47jRs3NnEtn165cuXo0sUwDS8tLY1Tp06xceNGNm3axIIFCxg1apSJa/j8li5dyj//+U90Oh2enp507doVKysrrly5wqZNmwgICKBFixY0b94813m3bt2iT58+HDlyBDMzMxo0aEDz5s3JyMjg3LlzLFq0iEWLFjF9+nQ+/vhjE7WuYNOmTeOzzz7j559/LnQQ/ne+vr54enoCkJmZyeXLlzl48CAHDx4kMDCQxYsXF0ld+/Xrh62tbb7HvL29893fuXNnnJ2dAYiJieHo0aPMmTMHf39/goKCKF++fK7y//rXv/j666/54IMPOHDgQJHU+1lJ0C+EEJBrXr6LrQsHBx3kxK0TBMUEERQTxJX7l6l7JI5sBZg90tGcrYCbX36B+x2I++sgcd9+i22rVmj6+GHXpg0KCwsTtEYIIURJl9/b2cuXLzN16lRWrVpF27ZtCQwMpG7dui+9bs/D29s7V9v0ej3Tp09n2rRpTJw4kX79+lG2bFnTVfA5RUdHM2bMGPR6PUuWLGHEiBG5PmPExcWxZMkSHBwccp2XlJREmzZtCA8Pp3v37ixcuJAKFSrkKnPixAk+/PBDLl++XOT1Ll++POfPn8fa2rrIr/00Ro4cmafDYNu2bXTv3p2ffvqJ9957jwYNGjz3fb799lsqVqxY4HGdTpdn3+TJk3ONAoiJiaF9+/acP3+eTz/9lCVLluQqb2Vlxfjx45kyZQrbtm2ja9euz13vZyXD+4UQIh8atYb2FdoztclUNvht4EuLgXjG5A74wfC1+x2IaOeJRa0akJ1N0t69RI8bz8WWrYj9fAbpV6+aphFCCCFeKVWqVMHf35933nmHlJQURowYYeoqPTeFQsHHH39MlSpVSE1NZefOnaau0nPZunUr6enp+Pr68s477+RJ9uvo6Mjo0aPzvE2eMmUK4eHhdOjQgQ0bNuQJ+AEaNmzI7t27ee+994q83iqVCm9v73zva2pdu3alRQtD/qSDBw+auDYPubi48OmnnwKwY8eOfMu89dZbKBQKfvjhh5dZtTwk6BdCiCfQ6/XUXHcafQFZ+nWA2flLDPGL5q+Zfpj9YwDmTk5ka7Xc+/13Mm/ezHUtIYQQpnMu/hzv7HiHc/HnTF2VZzZ79mxsbGwICQnh0KFDeY5fu3aN9957j4oVK6JWq3FycqJ///6cPn26wGseOnSIPn36ULZsWdRqNRUrVmTcuHH5zlfOmX+9b98+tm3bRosWLbC1taVUqVL07duX8PDwp2qPUqmkTp06AERFRRn3p6Sk8Pnnn1OzZk2srKzQaDS0atWKlStXPtX1Dx48yPvvv0/t2rUpVaoUVlZWeHt7M3nyZO7fv5+nfE7+gWHDhhEbG8vIkSNxc3PD3NycuXPnPvZeOd8vJyenx5Z71N27d1m6dCkA8+fPx8zMrMCySqWSZs2aFfrahfW4Of07duygc+fOuLm5oVarcXV1pUWLFnz22WfGMhUrVjR+PXz48Fzz3/ft2/fc9StXrhxAsctnUaOGYdnouLi4fI+7u7vTokULtm7dys1HPg++bBL0CyHEE+gzM8mMiUFRQMCuBMommpGalsiihM30Kx/A11O9iJ8xCs0bA7Bp2tRY9vacOUS99y8Stu9Al5HxkloghBAix8bLGzkWe4xNVzaZuirPTKPRGIcK/z0B3qFDh6hTpw6LFy/G1taWXr164eXlxbp162jatGm+CfPmz59Pq1at2LRpE56envTq1QsrKyu+//57mjRpQkxMTL71WL16Nd27dycjI4OePXvi6upKQEAATZs2JTQ09KnalJiYCIBarTZ+3apVKz755BPi4uLo0aMHvr6+HDt2jMGDBzNhwoRCX3vSpEksWbIECwsL2rVrR/v27UlISGDWrFm0aNGCpKSkfM+7ffs2jRo1YsuWLTRr1oyuXbs+cfi7m5sbAHv27OHixYuFqt/evXtJTU2lXr16VK9evdDtehkWLVpEly5d2L9/P9WrV6dfv37UqFGDa9euMW3aNGO5/v37GztufH19GTp0qHHLmQf/rLKzszl16hRAsfv+5Py7fdyUlDZt2pCdnc327dtfVrXykDn9QgjxBEoLCyqtWc2t6ItMOTiFMpalcU93J0odxZ20u8xsOZPK5T35XncF/3B/9t/Yz9G4Y1y3iWLbtG0olIYee312NvcD1pMdH0/S/v0oNRo03buh6dMHy5o18wwBFEIIASmZKQUeM1OaoTZTP7FsTHIMCekJqM3VbL9m+OC99cpWOnl0Qo8eB7UDLjYuxvJKhRJLc0vj16lZqQWO1FIoFFiZWz1Vm4pC3bp1WbNmDefPnzfuS0hIYODAgaSmprJ69Wr69+9vPLZ79266d+/OkCFDuHLlChYPcs4cPXqU//u//6NChQps3LiR2rVrA4aRaTNmzOCTTz5h3LhxrF69Ok8dFi5cyOLFi3n33XeN50yZMoVZs2YxYsQIgoODC9WWuLg4goKCAIz3nzp1KsHBwXTo0IGAgABj0rXw8HBat27NvHnz6NSpE926dXvi9T/55BOaNWtGqVKljPvS09MZN24cixcvZs6cOXzyySd5ztu6dSt9+vThjz/+wNLSMs/x/PTu3RsnJydu375N7dq16dGjB23atKFZs2bUqVMn37/1ISEhANSvX79Q93iZvvrqK+zt7QkNDc01B16v1+d6g//tt98ybdo0QkND852X/ywyMzO5cuUKX375JZcuXaJevXrGJJDFRU4g/7h65STcPHjwoMmm5EjQ/xpRXN1P27DJKKrbQNUOpq6OECWKysUFNxcXltbbC9mGpDJju3YFM7AwM3xwaoErLcq3IDopmjUX1lDWuixmDwL+TF0mXwR9QY85k6hw6BLaDRvJunWLe3/8yb0//sSiShVKD3mbUoMGmbKZQghR7DT5o0mBx1qWb8nCDguNX7dZ1YbUrNRCXfde+j2Gbh+a77EaZWqwssfDIeR+6/24mZz/0Nwqmiqs91tfqHsWJccHK8Xcu3fPuO/3338nNjaWKVOm5Ar4ATp06MDo0aOZO3cumzdvpm/fvoAhqNPpdCxevNgYcIOhM+Ojjz4iICCAdevWER8fb7xnjubNmxsD/pxzPv/8c/744w9OnjzJkSNHHjsUPS0tjdDQUMaPH09CQgLVqlWjbdu2JCcns3TpUpRKJQsXLsyVZd3b25uPPvqIcePGMX/+/EIF/fmVUavVzJ07l2XLlrFhw4Z8g361Ws33339f6IAfDKMwtm/fzptvvklERARr1qxhzZo1xmMDBw5kwoQJ2NvbG8+5c+cO8HRTAl6WuLg4qlatmifpnUKhoG3btkV+v+HDhzN8+PA89xozZgwzZsx47NSHp1GpUqUCj3333XeMGzfusefHxMSwdu1avv76azw9PZk+fXqBZXPyNzzt6JeiJEH/60KvR7l3BvbpN9HtnQFe7UHeKgrx1CzMLMjUZQKGP0IqM1WeMuVtyzO+/vhc+/6K/Iu1F9eylrV4VvFk4MJ/0iG+HOmbtpO4axcZly+TfuWKsbxep0OfmYlSrf775YUQQgjjyINH3xznDN338/PL95wWLVowd+5cjh8/Tt++fdHpdOzZswc7Ozvat2+fp7xCocDX15eQkBCCg4Pp3LlzruOD8umoVqlU9OvXj7lz53Lo0KE8Qf/+/fvzfdvt6enJ+vXrMTMzIzg4mNTUVJo2bYqXl1eeskOGDGHcuHEEBgai1+sLNVIuOjqaTZs2ER4eTkJCgjE7u4WFRYHD8OvXr59nGbbCqF+/PufOnWPHjh1s27aNo0ePEhoailarZfHixQQEBBiHy0PxzvfToEEDDh06xOTJk3n33XepUqXKC73fo0v26fV6YmNjOXHiBEuWLMHOzo4vvvgCpfL5Z6g/bsk+Hx+ffPfn18lRr1499u7d+9jl20uXLg2Qb36Ml0WC/tfF5T0oYwxDh5QxIXB5D3jK234hXhavUl70r9qfLVe2cOn+Jb44MZPvzK3p2b8nb4xfjtORC1g/sgRNyrHj3Bg3DvtuXXHo0wfL2rVl+L8Q4rUU9GZQgcdyRlPl2PfGvgLLXrh3gSHbhuTZv6LLCrxL586krlTkDirW+61/7PB+U4iPjwceBhTwMAlekyYFj4549Nw7d+4Y57Obmz8+LMg551EeHh75ls15K5xf4rJy5coZh0Kbm5tTpkwZmjZtSo8ePVCpVLnOK2hJNQcHBzQaDVqtloSEhMcGXABz5sxhypQpZDxlLp3nyWRvZmZGt27djKMMEhISWLVqFZMnT+b27duMHTuW3bt3Aw9HbZgyKCzIggUL8PPzY9asWcyaNQtXV1datmxJ//796du3b5EE4I/Kb2pAYmIigwYN4quvvsLOzo6pU6c+932eZcm+zp074+zsTFZWFleuXOHIkSOEhIQwduxYfvnllwKvlTOqQ6vVPne9n5UE/a8DvR7+moEeBQr0hv/umgZV5G2/EC9LZU1lPm32Kf9u8G82Xt7IyvCVXEu4hn+EP/4R/mzus5lS9g8/PCXu3o0uIYH7K/25v9Ifi0qV0PTpg6Z3L1QPMtgKIcTrwFpV+HXDH1c2ZyrWI5+G0KPH0tzyifcwxZz9J8lJbPboW8ns7GwABgwY8NiEczmdAjnl7ezsjMP9C1JQgJ+fx7259vb2Zvny5YW6TmE6VJ5U5ujRo0ycOBGNRsPixYtp06YNzs7OxoSBrq6uBSYqfJph/U9ib2/PyJEjKVu2LL1792bfvn2kpKRgbW1N3bp1ATh58mSR3a+o1K5dm7CwMLZv387WrVvZv38//v7++Pv706JFC/bs2WPMD/Gi2NnZ8fXXX7N161Zmz55dJEH/s5g8eXKu1Q327dtH165d+fXXX+nZsycDBgzI97ycYP9JnVMvkgT9r4PLe+BmCDm/EhXo4dYZmF0dqnYED1/D5uBu0moK8Tqws7Djrepv8ab3mxyLPYZ/hD930+7i8UjAv/v6bmqMH06F9u24HxBA4s5dZFy9yu05c7g9dy42zZpRfs5szEz4x0MIIUqa0palKWNZBmcbZ/p69WXdxXXEJsdS2rL0k08uZrRarTGB2KNDjl1dXbl48SIfffRRrvn5BXF0dEStVqNSqQodiD/q+vXr+e6PjIw01udZ5Jx39erVfI9rtVq0Wi02NjbY2dk99loBAQEAzJgxg6FDc+dwSE1NJTY29pnq+Kxygsbs7Gzu37+PtbU17dq1w9LSkpCQEMLDw41zwIsLS0tL/Pz8jNNGwsLCGDx4MIcOHWLp0qWMGjXqhdchZw7+3bt3880vYQpt2rThk08+YerUqfz3v/+lb9+++eYcyMm7YcqcDbJk36vuwVt+FPkkvUiKgZO/QMB7MLcmzK0FAaMg5De4e9VwrhDihVAoFDRxacKcNnNY0mmJcf/9tPtMPjiZLgFd+W+aP5ET+uB58AAuX8zAqmED0OnIvHED5SMJgDJuRBfr+YBCCFEcONs4s7P/Tv7s/idvVHuDP7v/yc7+O3G2eb7lxExh4sSJJCcn06hRo1xz5lu3bg3A+vXrC3Udc3Nz2rRpw927dzlw4MBT18Pf3z/PvqysLNauXQsY5mc/iwYNGmBlZcWxY8fynW//22+/AYYcBU96058TcLm75325tXr16iL/+/mk612+fBkw5BLICVxLly5tzOo+duxY4wiMgq5/9OjRIqrts/Hx8WHMmDEAnDlzxrg/541/VlZWkd/zyoO8RwqFAiur4jPyZsKECTg7O3Px4sV8fx4A4wobOSM6TEGC/lfdg7f86Av45VG9F5RvYOgUuB8JoX/AhjEwvy58VwPWjoQTP0P8RekEEOIFMVc+HHR1N/0utZ1qo9Pr2BO5h3/u+id9dr/J5uqplF62kCo7d+D8+XTjhxxdejpX+/blSpeuxC/6kcwChigKIYQwDPHP+f2pUCiMQ/5LiitXrjBw4ECWLl2KjY0NS5cuzXV8+PDhODk58eWXX/Lzzz/nCUCTk5P55ZdfuHHjhnHf1KlTUSqVDB06lEOHDuW5582bN1mwYEG+9QkMDGTZsmXGr/V6PZ9++imRkZHUqVOH5s2bP1M7bWxsGDFiBDqdjjFjxpCcnGw8duHCBWbMmAEYAuQnqVq1KgBLly4lMzPTuD8sLIz//Oc/z1S/x/nhhx947733OHv2bJ5jN2/eZPTo0YBhRYFHh8V/9dVXeHl5sXv3bvz8/Iz5GR4VGhpKp06dWLRoUZHXOz8pKSnMnz+f+/fv59qv0+nYuXMnkDvvQc4IjYiIiCKtR2JiIh9++CFg6NiysbEp0us/DysrKyZPngzAzJkz8+30OXbsGAAtW7Z8qXV7lAzvf5XlvOVHCeRNRgFK0EbBu3shIwmiguBaIFwPhOiTkBANZ1YbNgDbcuDR3DAVoGILcKwGRZy8Q4jXXWVNZZZ1Xsale5dYdWEVGy9v5FrCNWYdn8X8kPl82/pbWjVuZSyfHhGBPjOTjOvXuT13LrfnzcOmWTM0ffpg16E9ymLUGy6EEKLwcpKZ6XQ6EhISuHDhAuHh4ej1ery8vPjjjz+oVatWrnMcHBxYu3Ytfn5+jBgxgs8++4yaNWuiVquJjIzk/PnzJCcnExISgpubGwCtWrVi3rx5TJgwgZYtW1K7dm28vLxIS0vj+vXrnD9/HltbW+Ob3UeNGjWKkSNH8uOPP1KlShVOnz7NuXPnsLOz4+eff36u9s+cOZOjR4+ya9cuKleuTOvWrUlOTuavv/4iLS2NcePG0b179ydeZ/jw4cyePZtNmzZRrVo1GjVqxN27d9m/fz9+fn4cO3aswGkKzyIjI4PFixezePFiKlWqRK1atbC2tiY6OpqgoCAyMjLw8PBg7ty5uc6zs7Mz1mnz5s1s27aNhg0bUrFiRTIyMjh//jzh4eEAxk6Pwvr8888L7CioWrVqgUnoMjIyGD9+PJMmTaJ+/frGupw4cYLIyEgqV67Me++9ZyzfqVMnLC0t+e677zh79iyurq4oFAomTZpEtWrVClXXJUuWsG/fPsDQiXTr1i2OHz/O3bt3cXR0LLADasuWLTRt2rTA6+7evTtXtv4PPvigwOz91tbW/O9//ytUfQHee+89vv76a86ePcvGjRvp3bt3ruP79u3DzMyMTp06FfqaRU2C/ldZdgZoo8k/4MewPyHaUE5tZ8jmn5PRPyMFbhyD64cNHQE3jkPSLTgXYNgArMtAhWaGDgAPXyhXUzoBhCginqU8mdpkKuPrj2fLlS2sjFjJVe1VfMo8TNgUkxRD6RrV8Dp4kMSdO9EGBJBy/DjJhw+TfPgwShsbXGZ+ib0J/8gIIYR4NitWrAAMQ/Dt7e1xdXXlH//4B7169aJXr14FZtv39fXlzJkzzJkzhy1btvDXX39hZmaGq6srPXr0oG/fvnmWJHv//fdp1qwZ3333HQcOHGDjxo3Y2dnh5ubGv/71rwITlL3xxht069aNL7/8kg0bNqBSqejduzdffvllgcueFVZOEDx79mz8/f3ZuHEjFhYWNGzYkNGjRzN48OBCXadMmTIcP36c//znP+zfv5+NGzdSqVIlpk+fzqRJk4p8CboRI0bg5ubG9u3bCQ4O5siRI9y7dw87OzsaNGhAz549efvtt/NdCtDFxYUjR46watUq/P39OX78OCEhIahUKjw8PBg1ahTvvPMODR5Z7acwrly5Yhwe/3dpaWkFnmdra8uCBQvYs2cPoaGhnD59GgsLCzw8PHj33Xd5//33cXBwMJZ3dXVlw4YNTJ8+nUOHDhlXhnj77bcLHfQHBgYSGBho/NrKyopKlSoxfPhwPvjgA5yd85+OEx8fn+8KEzn+PuUgZwpKfjQazVMF/ZaWlkyePJlx48bxxRdf5Ar6IyMjCQwMpEePHs+0/GNRUehlIuhzy1kqRKvVGpdkKDa0NyDZ8AOQmZVFYGAgvr6+qHL+UNg4gaYQ/wAz0yA62DAK4NohiDoGWam5y1hqoEJzqOhrGBHgXAfMpF/paWVmZrJ161a6detmXLpGFC+meEZ6vZ5rCdeopKlk3PfOjne4eO8ifbz6MKDqANzs3MiIikK7YSPa9evJvHGDylu3oq5sOCf96lWUajWqZ0ysVNLIz1LJIM+p+HuRzygtLY2rV69SqVKlIs2U/jrKGRFgb29f5Muo/d2wYcNYsWIFe/fuzZXNXDzZy3xO4tkV1XOaOXMmU6dOZevWrXTt2rVQ5zzN78XCxqESkb3qNG6GDSAzE611NLjUgaf9o62yNATzFX2h9YeQlQExpwwdANcDIfIopGnhwjbDBmBhBxWaPJwO4FoPzOQDnRDPQqFQ5Ar4EzMSiUyM5F76PZadXcbPZ3+mlVsrBlYbiO+YUTiOHkXauTBjwA9we+48EnfuxLppExz69MGuQweUj1nSSQghhBBCPJvU1FTmz59Py5YtCx3wvygS9ItnY24B7o0NW8t/Q3YWxIY+zAlw/Qika+HSbsMGoLI2lM9ZItCtIZirTdsOIUooOws7tvXdxoEbB/CP8OfwzcPsv7Gf/Tf242brxrj64+ha6+EfGL1Ohy4lBfR6Uo4cJeXIUZTW1th17YJDnz5YNWhQqPWQhRBCCCHEk/3444/ExsayYcMGU1dFgn5RRMzMDasAlG8AvuNAlw23zj2cDnD9MKTehSv7DBuAmRrcGj2YDuBr+H8LeesoRGGZK81pV6Ed7Sq045r2GqsurGL9pfXcSLpBlu7h3LVsXTZKhZIKPy0m40Y02o0b0AasJzMqCu3adWjXrsO2bVvcf1howtYIIYQQQrw6JkyYwIQJE0xdDUCCfvGiKM3ApbZhazoKdDq4HZ67EyA5Dq4fMmwAShWUr/9gOoAvuDcFdf5ZNYUQuVXUVOTDRh8ytt5YdlzbQaeKD5P3/Xb+N7Ze3cqgaoPoUqkLTqNH4zhqFKnBwdxfv57EbduxbtLYWF6XnEzCzl3Yd+qIshgtiyOEEKJ4WL58OcuXLzd1NYQQhSRBv3g5lEoo52PYGr9rWE7wzqWHOQGuBULiTcOygVFBcGgOKMzAte7DnAAVmhqSBQohCmRlboWfp1+ufesvrefS/Ut8cvgTvj3xLX6efrxR7Q08GjbEumFDdP/9r6Fj7oGEHTuJmTqV2M8/x75zZzR9/LBu2BCFJBwSQgghhChxJOgXpqFQgKOXYWs43NAJcO/qg5wAhw1v/+9HGlYMiA6Gw/NBoTQsC5izRKBHc7AubeqWCFHsLeu8jPWX1uMf4U90UjS/hP3CL2G/0Ny1OW96v0lr99a5yitUKlQeFci8Hok2IABtQACq8uXR+Pmh8euNhbu7iVoihBBCCCGelgT9onhQKKB0ZcNWf4hh3/2oR6YDBMLdKxB72rAdfTD3uGyNhzkBPHzB1sl0bRCimCplWYrhNYcztMZQAqMDWRmxkoM3DnL45mE0Fpo8Qb+mZw/se3QnNeQU2oAAErZtIzM6mvgFC4j/4Qe8Dh7AvEwZE7VGCCGEEEI8DQn6XyNnorX875wS9zpa6ld0NHV1nszBHRwGQZ1Bhq8TYh6sDPBgOkB8BMSdM2zHFhvKOFZ9OB3AwxfsXUxXfyGKGaVCSUu3lrR0a8mNxBusvrCatu5tjcevaK+wKHQRg6oNol7ZeljXN2zlpk4hcfcetOvXA+QK+O8s+xlLHx+sGzeS4f9CCCGEEMWQBP2vkYBTMVxMULL+VEzJCPr/zt4FavU3bABJt3N3AsSdg/gLhi34Z0OZ0pUfjgKo6AsOFUxXfyGKETc7N/6vwf/l2rcqYhXbrm5j29VteJXyYlC1QfSo3ANrK2s0PXug6dkDfWamsXxmXBxx334LOh0qV1c0fr3R+PlhUUF+zoQQQgghigsJ+l9xN+6lcC85E4UCNoXGALDlTCxvNKqAXg+lbFS4lSqhy+TZOkENP8MGkHIXIo88yAtwCGLPGKYE3L0CIb8aymgqPJwOUNEXSlUyTC0QQuDn6UdaVhpbrmzh4r2LfH70c+YEz6FXlV4MrDaQKg5VUKhUD0/IzsZhwAAStm4l8+ZN4hf+QPzCH7Bq0ACHPn7YdemCma2swCGEEEIIYUoS9L/iWszam2ffneQMenx/yPj1ta+6v8wqvTjWpcG7u2EDSNNC5NGHSwTeDAFtJIRGQuifhjJ2roaEgBV9waOFIbGgdAKI15R3aW+mNZ/G/zX4PzZe3oh/hD/XE67zZ/ifbL+6nT1v7EGlfBj0q1xccPlsGuWmTCZxzx606zeQHBhIanAwqcHB6LOyKTVooAlbJIQQQgghJOh/xc0dWJcPVoeSpdPne7xmeXtWnYiivXdZytiqX3LtXjBLDVTtbNgA0pMMywHmTAeIDjYsE3h2jWEDsCn7oBPgQU4AJ2/DcoNCvEY0ag1DfIbwVvW3CIoJYmX4Sio7VDYG/Dq9jl/DfqVLxS6UsymH0tISTffuaLp3J/PWLbQbN5KwdRv23boar6ndtJn0y5dw8PPDomJFE7VMCCGEEOL1I0H/K86vXnk8y9rmerP/qLPRCXy45jRKBTTwKEVHn3J09HGmkqPNS67pS6C2Bc/2hg0gIwVuHH+QF+AwRB2D5DgIW2/YAKxKGzoBcqYDlKsJSjNTtUCIl0qpUNLMtRnNXJuh1z/sODx68yjfnviW74K/o12FdgysNpDGzo1RKBSoypXD8d13cXz33VzXuvvLL6SdOcOdRT9iVa8emj5+2Hftipmd3ctulhBCCCHEa0VeYb5Gckat5/x33qC6TOjgRQ1Xe3R6OH7tHl9uDaftt/voMGc/s7aHczLyHroCRgmUeBbWULk1tJ0KwzbDlCgYvg3afgSV24DKGlLvQvhm2DEFfmwFsyrBHwMhcD7cCIbsLFO3QoiXQvHItBe1uZr6ZeuTrc9m1/VdjNw5kt4bevP7+d9JzEjMc65er6fMOyOwad0KlEpSQ0KI/eRTLrZoSfTED0g+fPhlNkUIIYq9Xbt24efnh7OzMxYWFpQpUwYfHx/eeustfvrpJzIyMvI9LzMzkyVLltCtWzdcXV1Rq9VoNBrq16/PxIkTOX/+fJHUb/ny5SgUCqZNm1Yk1zOV4taOS5cuYWFhwZQpU3LtnzZtGgqFIs9mb29P48aNmTt3LllZeT+T7tu3D4VCQZs2bQp1/zZt2uR7n0e3in8brTds2LA8ZaysrPDy8uK9997j6tWr+d4rICAAhULB6tWrC1U38XzkTf9roIytBU62apw1aqqr73E+vRSx2nQaVypN77rlmdChKtH3U9kddotdYbc4euUOl+KSuBSXxA/7LuNkp6ZD9bJ09ClH8yqOWKpe0Tfd5uoHb/WbA5MgOxNunjIkBbwWaMgPkK6FC9sNG4CFLbg3eZgTwLUemFuYshVCvHANyjVgRdcVXLh3gVURq9h0eRNXtVf56thXzDs5jzU911DB/mEGf4VCgX2XLth36UJmXBwJmzZxPyCAjEuXSdiyBV1qKjbNm5uwRUIIUXx8+umnTJ8+HYCaNWvi6+uLmZkZERER/Pnnn/zxxx/07NkTZ2fnXOdduHCBXr16cfHiRSwsLGjcuDGtW7cmOTmZU6dOMWfOHObOncuyZcsYOnSoKZomnmDKlCmo1WomTpyY7/E6depQt25dALKzs4mMjCQwMJDjx4+zfft2tm7dirIIpqV27tw5z7+vHI6O+a8A5uvri6enJwDx8fEEBQWxePFiVq5cycGDB6ldu3au8n5+ftSpU4cpU6bQu3dvLCzk8/OLJEH/a8BFY8WhyW1R6LLZtm0bM7o2Qa80Q23+MHgv72DF0OYVGdq8ItrUTPZFxLEr7Bb7I25zOzGdP49F8eexKKwtzGjl5URHn3K08y5LKZtX+AfUTAXujQxbi/8zvNWPPf0wJ0DkYUOywMt7DBuAuRW4N344HaB8Q1BZmrYdQrwgVUtV5aOmHzGh/gQ2X9nMyvCVKBQK3O3cjWXO3TmHl4MXFmaG3xWqsmUp8847lB4xgrSzZ9EGrMe2TWtj+YwbN7j5wSQ0fn7Yd+uKmb39S2+XEEKYyokTJ5g+fToWFhYEBATQrVu3XMejo6P56aefUKtz52G6efMmrVu3Ji4ujqFDhzJ79mzKlCmTq8xff/3FBx98UOCbV2FaJ0+eZM2aNUyYMKHAwNrPzy/PqISQkBB8fX3ZsWMH69evp2/fvs9dl8mTJxd6dECOkSNHMmzYMOPXWq2W3r17s3//fv7973+ze/fuXOUVCgWTJ09m8ODBLF26lFGjRj13vUXBJOh/TajNzcjM1AGGHzIL84Lf1musVPSuW57edcuTkaXj6JU77Aq7xe7zt4jRprH9XCzbz8ViplTQ8EEegE4+zlQoU0KX/issM3MoX9+wNR8LOh3EnXu4ROD1w5ByB67uN2wAZmpwa/iwE8CtsWFagRCvEFsLWwZ5D2JgtYHcSbtjnAqQkpnCuzveRWWmoq9XXwZUHYCrrStg+D1kVasWVrVq5bqWdv0GUk+dIvXUKW59+SV2Hdqj6dMHm+bNUZi9oqOMhBDigYCAAADeeOONPAE/QPny5fMdiv7ee+8RFxfHm2++ybJly/J929uuXTuOHDnCmTNnirze4vn98MMPAPzjH/94qvPq1atH//79+fXXXzlw4ECRBP1FQaPRMGvWLJo2bcr+/ftJS0vD0jL3i7DevXtjZ2fHokWLJOh/wWROv3gsC3Mlrao68blfTQ5Pbsem91swrp0n1V3sydbpCbp6lxlbztPqm710/u4A3+6IIDTq/qubB+BRSiU414Km/4KBv8EHl2D0Uej2LdToY1gJIDvdMDLgwNfwS2/4qgIs7QS7p8HF3ZCed/6zECWVQqHA0erh24nrCdexUllxN+0uS84soeu6roz9ayyB0YHo9Lp8r1Fq4BuU/fBD1F5e6DMySNi6jah3/8mltu2I+/Zbsu/ff0mtEUK8qpIPH+Zy9x7FMp/I7du3AXBycir0OefPn2fz5s1YWVnxxRdfPLasWq2mYcOGhb726dOn6dGjBxqNBo1GQ8eOHTly5Mhjz8nIyGDevHk0atQIOzs7bGxsaNy4MUuXLs2VFPZR8fHxTJkyhZo1a2JjY4ODgwN169blv//9L3fu3MlVNiUlhc8//5yaNWtiZWWFRqOhVatWrFy50qTtyJnvnpGRwfTp0/H29katVuPn5/fY+wAkJSWxcuVKqlevTr169Z5Y/u/KlSsHkO+8flOqUaMGYKjXvXv38hy3srLCz8+P06dPExQU9LKr91qRN/2i0BQKBbXcNNRy0/DvTtWIupvC7vOGPABBV+8ScSuRiFuJ/G/vJcrZq+lQvRwdfcrRrEqZXFMJXllKJZStbtgavwt6Pdy5/DAnwPVASIg2LBsYFQSHvgOFGbjUeZgToEJTMH8FV04Qr6XqZaqzo98O9kXtY2XESoJigtgXtY99Uftwt3Pns+af0ci5Ua5zzJ2cKDNiOKWHDyMtLAxtwHoSNm0iKy6Oe3+uxHH0aGNZfXa2vP0XQjwVvV5P3JzvyLh8mbg531GxWbNciUpNzc3NDYC1a9cyZcqUQgX/W7duBQzzsB0cHIqsLkFBQbRr146UlBTq1q2Lt7c3Z8+epXXr1rmGcT8qOTmZrl27cvDgQRwdHWnRogVKpZIjR44wcuRIjh8/zqJFi3KdExYWRqdOnYiOjsbFxYUuXbqQnZ1NREQEX375JR07djQONU9MTKRt27YEBwfj5OREjx49SE5O5q+//uLgwYMcPXqUuXPnmqQdADqdDj8/Pw4cOEDr1q2pXbt2nmkW+dm/fz9JSUlPPaQ+R3BwMADVq1d/pvNflMREw8sthUJR4PehTZs2/Prrr2zZsoUmTZq8zOq9ViToF8/MvbQ1w30rMdy3EtqUTPY+yAOwLyKOWwnp/B4Uye9BkdiqzWld1ZAHoG21smisVaau+suhUICjp2FrMMzQCXDv2sMlAq8dgvvX4eZJw3b4e0CBebma1NS5oAjXQ5VWYF3axA0R4tmZK83p4NGBDh4duKK9wuqI1Wy4tIEbiTdwtn6YJCg1KxUrcyvj1wqFAqsaNbCqUYOyH04iad8+sm7fRmltmB6j1+u5OmAAFhU8cOjjh42vLwpz+ZMmxKtIl5JS8EEzM5SPzG9/bFmlkpTjJ0g7exaAtLNnSdqzJ/9EokolykeGIutSUw1/x/OjUKC0ssr/2FN66623mDlzJpGRkXh6euLn50fLli1p1qwZPj4++XZQhISEAFC/fv0iqQMYgtdhw4aRkpLCzJkzmTx5svHYxx9/zIwZM/I9b9KkSRw8eJAhQ4awcOFCbG1tAcMIhp49e/Ljjz/Ss2dPunfvDhjeAPfr14/o6GgmTpzIzJkzUakefk4MCQnJ1fExdepUgoOD6dChAwEBAcbrh4eH07p1a+bNm0enTp2MUyNeVjtyREVFoVariYiIoHz58oX7ZgMHDx4EoFGjRk8o+VB2djZRUVEsXLiQvXv34u7uzpAhQwp9/suwfbsh8XX79u0LTNTXuHFj4OH3QLwY8gnpgT59+rBv3z7at2/PmjVrTF2dEkdjrcKvXnn86pUnPSubI5cf5gG4lZDOljMxbDkTg5lSQZNKpenoYxgF4FbqNZrfrlBA6UqGrd7bhn3aGw9zAlwLhLuXUdw6QxXOwNqdhjJlfR7mBPDwBduypmuDEM+hsqYy/2n8H8bWG8uJWydwt3+Y8G/ygcnEpcQx0HsgXSp2wdL84YdtpYUF9p065bpWekQE6WHnSQ87T+L27Zg5OaLp2QuHPn6ovbxeWpuEEC9eRP0GBR6zad2KCj/+aPz6gm8L9Kmp+Za1atgQfVqaYWSezjDF6Mb7Y/Mta1mzJpXWPFxK7Er3HmTevJlvWQvPKlTZvPmJ7SiMKlWqsGHDBoYPH87Nmzf55Zdf+OWXXwAoW7YsQ4cOZerUqbne6OcMfy8o+duz2LdvH+Hh4VStWpX//Oc/uY59+umn/PLLL0RGRubaHxcXx5IlS6hUqVKeZINOTk78+OOP1K1blx9//NEYLK9bt47w8HBq167N119/nScXwaND3ZOTk1m6dClKpTJXIA7g7e3NRx99xLhx45g/f74x6H9Z7XjUzJkznyrgB8P0A4Bq1ao9ttxnn33GZ599lmf/oEGD+Pbbb7EvouS3bdu2LfDY+PHj84ym+Lv4+Hh27NjBBx98gKOjI/PmzSuwrLe3NwChoaHPVFdROBL0PzBu3DhGjBjBihUrTF2VEk9tbkabamVpU60sn/euyZloLbseLAcYcSuRw5fvcPjyHT7bFEZ1F/sHiQDLUcPVvlgNsXspNG5QZ6BhA0iMJevKAaIO/klFolHER0BcmGE7/pOhTBmvh9MBKvqCvavp6i/EM7BWWdPKrZXx64SMBI7EHCE1K5WzgWf55vg39PHsw8BqA3N1DDxKXa0aldat5f769SRs2kz27XjuLlvG3WXLsKxZE6cJE1A3afyymiSEKAF0CQmkX7hg6mo8UadOnbhy5QobN25k165dBAUFcfbsWeLi4vjmm28ICAjg8OHDxjfgBc2Tfx6HDh0CYMCAAXk+m5mbm9O/f3/mzJmTa//+/fvJzMykS5cueVYXAMNyc3Z2dhw/fty4Lyej+7vvvvvEpeaCg4NJTU2ladOmeOXTuTtkyBDGjRtHYGAger0ehULx0tqRQ6FQ0LNnz8e2Iz9xcXEAlCpV6rHlHl2yDwwjD0JCQli9ejVWVlb88MMP+db5aT1uyb6cN/N/N3z4cIYPH55rn4eHBwcPHsTdPf+/5WB4DnZ2dty/f5+srCzMZdTeCyHf1Qfatm3Lvn37TF2NV45SqaCOuwN13B34oHM1rt9JNnYAHL92l/MxCZyPSWD+nou4aizp8GAEQJNKZbAwfw3zTNo5o/fpw+lraty6dUOVoX24ROD1QLh1Du5cNGzByw3nlKr0cBSAhy+U8jBpE4R4WvYW9mzvt511F9exOmI1N5NvsiJsBSvCVuBb3pd3ar6TZ+6/QqHA0scHZx8fyn3wAUkHDnB//XqS9u03DN195EOwLikJva0tCtVrMrVIiFdMtZPBBR/8W16PqoGH8i2m1+u5/o+hud7yA6BUovb2xuPXX3IHhX8LQCtv2fzY4f1FTa1WM2DAAAYMGAAYgrvly5czbdo0Ll26xNSpU/npJ8PLgJw3/PHx8UV2/5sPRjVUqFAh3+P57b927RpgyEKfk4k+P6mPjMSIiooCDCMcClunihUr5nvcwcEBjUaDVqslISEBjUbz0tqRo2zZss8UdGu1WgDs7OweWy6/JfsyMjIYPXo0S5cuxdzcnMWLFz/1/f/uWZbs8/X1xdPTE51Ox40bNzhw4ADXr19n6NCh7Nq1C7PH5OCxt7cnMTGRhIQESpeWaa0vQokI+g8cOMA333xDcHAwMTExBAQE5MmEuXDhQr755htiYmKoUaMGc+fOpWXLlqapsCiQRxkbRraszMiWlbmXnMFf4YY8AAcu3uamNo1fjlznlyPXsVOb07ragzwA3mWxt3xNP6zbOIJPb8MGkHIXIo8+6Ag4BLGn4d5Vwxbym6GMxj33dIDSlV/IBxIhilJpy9KMrDWS4TWGcyj6ECsjVhIYHUhgdCCt3VrnCfofpbCwwK5DB+w6dCDr7l0Sd+zApnkzsh58sL+7eDGJGzeh6dkTTZ8+WFar+rKaJYQoAjm5PJ6nbNLBQ6SfO5f3gE5HelgYqSdDsG3ZouDrFtGc/Wfl5OTEpEmTsLKyYuzYsWzZssV4rG7duvz++++cPHmyyO6XM3rgaUZgZmdnA4Yh+bVr136q+z3NfQpTNqfMy27H35ekKyyNRgNAQkLCU59rYWHBd999x7Jly1i2bBlff/11kSZ0LKyRI0fmSox49uxZ2rZty969e5kzZw6TJk0q8FytVotCoSiy6QkirxIR9CcnJ1OnTh2GDx9Ov3798hz39/dnwoQJLFy4EF9fX3788Ue6du1KWFiYsQevQYMGpKen5zl3586duLrK8GhTKGVjQb8GbvRr4EZaZjaHL8c/GAUQR3xSOptPx7D5dAzmSgVNK5cx5gFwdTDtH16Tsi4N3t0MG0CaFiKDDDkBrh+GmyGgjYLTKw0bgJ0LeDR/0BHQAhyrSieAKLbMlGa0dm9Na/fWRCVEsebiGnpWfjhUcuPljQRGBzLYezB1nOrkHa5ZujSlBg82fPEg6E85cpTsO3e4u3w5d5cvx9LHB02fPtj36I75E4ZSCiFKPr1ez+158wx/+/J7W69QcHvePGxa+Bb7aYY5b18ffavfrVs3Jk2axI4dO7h//36RBE45n42vX7+e7/G/z4OHhysPtGnTJs+Q+YLkDPu+dOlSoet09erVfI9rtVq0Wi02NjbGN+Yvqx3Pq2xZQ76mu3fvPtP5dnZ2ODo6cvv2bS5duvRUyzK+KDVr1mT+/Pm8+eabzJw5k3/+85/Gzo1HZWZmkpSURKlSpWRo/wtUIr6zXbt2pWvXrgUenzNnDu+88w4jR44EYO7cuezYsYMffviBmTNnAg+XsigK6enpuToQcnrlMjMzyczMLLL7FLWcuhXHOpoBLauUpmWV0kzr7k1otJY952+zOzyOy7eTOXQpnkOX4vl04zlquNrRvlpZ2ld3orqzXbH/A/20nuo5mVlDpbaGDSAjCcWNEygiDxu2mydRJMbA2bWGDdDbOKF3b4a+QnN0Hs3ByRsUr+FUiudQnH+WXiXOVs68X/t9wPC91uv1/HruV8LvhbP16laqOlRlQNUBdPXoirUq79u9nOfjvGI5mceOkbBhA8n79pMWFkZaWBi3Zs3Cvncvyv5tqKR4ueTnqfh7kc8o52dbp9Ohe3TYfRHSZWSQGRNT8PB8vZ7M2Fiy09NRFpBh/GXJmYtekIsXLwKGYDbn++Xt7U3Xrl3Ztm0bH330EStWrCjwe5mRkcHp06efGBQ2f7Ciwdq1a/nss89y1SkrK4u1a9ca65tzr9atW2NmZsbmzZuZNWvWY4dz52jXrh0//fQTS5YsYdSoUY9te7169bCysuLYsWNERETkmdf/66+/AoZh5nq9Hr1e/9La8agn/TvOGX3w6D1r167Ntm3bCAsLM9b5Sec8KjEx0dgRZGVlZSzzaNmn+fl6mp/HnLrld84bb7zB119/zalTp/jf//7HlClT8pwfFhYGGEasvKjfAc/iSd/zF0mn06HX68nMzHziv7/C/l4uEUH/42RkZBAcHJxrCQ4wJEE5fPjwC7nnzJkz882cuXPnTqyfYgiaqezatcvUVSgUH8DHE+LKw9l7Cs7cVXI1Ec7dTOTczUTm771MabWemqX01Cytx9NOj9krFLs+33OqC451UZbOoHTyJcokhVMmKYLSyZcwS76NInwjhG/EDMgws+GObTXibb25Y+uN1qqCdAIUUkn5WXqVtM1qi7WFNaczTnPh/gW+OPYF3x77lvoW9WmsboyTWd41rXfn5Gvp2BFl8+bYnzqFffBJLKOjuR4Ty4kHa1yj02FxK44Ml/yTF4kXS36eir8X8YzMzc1xdnYmKSmJjIyMIr9+jjLLlqK7d7/A48rSpUhKS4O0tBdWh8KYMWMGGRkZvPPOO3h45M7Rc/nyZSZOnAhA9+7dcw0F/+abbzh27Bi///47ANOnT88zNzowMJCPPvqIzp07U7Xq46c5NWjQAE9PT8LDw/niiy8YN26c8dhXX31lfHOenp5urIednR1vvvkmv/76K4MHD2bWrFl51mYPCgpCq9XS6cGKLB06dMDT05PQ0FD+/e9/8/HHH+d623vmzBlKly5tzIb/1ltvGTsIfv31V2xsbADDSIGc5fdGjBhhrNPLakcOnU5X6CH6OWvYw8PlFg8fPswbb7yRp2zOy8ZH65kjIyODDz74AL1ej4eHB66ursYyKQ+WsMzKyipUvbKysoznFbYdOUFnWlpavudMmjSJt956i7lz5zJ8+PA8sdKBAwcAw3KFzzK94UV79Dm9LBkZGaSmpnLgwAHjMylIyuOWKX1EiQ/64+Pjyc7Oply5crn2lytXjtjY2EJfp3Pnzpw8eZLk5GTc3NwICAgocK3MKVOm8O9//9v4dUJCAu7u7nTq1KlYz0XJzMxk165ddOzYMdcaqCXJneQM9kbcZs/5OA5dvsPddB0HYhUciAV7S3NaV3Wkg3dZWno5YmdZMv95v8jnpMtKRx8TguL6g5EAN45jkZmMi/YkLlrDXEC92h69exP0FZqjr+CL3rkWmJXMfy8vyqvws1SSvcu7aNO1bLqyidUXVxOVFMWRjCMoyij4X9v/GcsV+JweJMZKv3ABDxsbVA8+TKYeP0H0lKlYVKuGfe9e2HbrhvnfPuiJoic/T8Xfi3xGaWlpREVFYWtr+8zzoQulGH8+e1RmZibff/89//vf/6hWrRre3t6oVCqioqI4duwYOp2OBg0aMGPGjFyfOe3t7dm/fz+9e/fm999/Z/Xq1TRp0oTy5cuTnJzM6dOnuX79OmZmZowfP75Qn1eXL19Ox44d+fTTT1m/fj3VqlXj3LlzhIeH884777B06VLUanWuay1cuJAbN26wdu1adu7cSd26dXFxceHWrVtcunSJ6Ohoxo0bR//+/Y3nrF27ls6dOzN//nzWrFlDs2bNyMrK4sKFC5w/f549e/ZQvXp1AL799ltCQkLYu3cv9evXp1WrViQnJ7N3717S0tIYO3asMfnhy24HgFKpfOL3Vq/Xk5iYiJ3dw9GqXbp0wdbWlsDAwHzPz0kOuH37dmJiYoz74+PjOXXqFDdv3sTa2pply5blGkKfE2CfPn2aLl26FFinFStW4OXlZexw+f7771m9enWB5RcsWGC8ds7vBEtLy3zrPmjQIGbPns3JkydZtWpVro4XMHSggCFJYXGKo/J7Ti9LWloaVlZWtGrV6om/FwvbUVIyo6J8/P1hPGl41N/t2LGj0GXVanW+mTlVKlWJ+MBSUuqZH2cHFYOb2DC4SUVSM7I5dCmeXWGx7Dkfx53kDDadjmXT6VgszJQ0rfIgD0D1cjhrXuAHiRfkhTwnlQoqtzRsANmZEBNqSAp4PRAij6JIT0BxaRdcevBGR2UDFZo8zAngWh/MTTv8sbgoyT9LJZ2jypHhtYcztNZQjt48ysqIlfSv2t/4PGKTY1kTsQYHnUOBz0lVo0aurxOvXkGhUpEREUH8198QP+c7bFu3xqGPH7atWqEw8bDfV538PBV/L+IZZWdno1AoUCqVT1yy7XXw8ccf07BhQ3bs2EFoaCgHDhwgISEBBwcHWrduTf/+/Rk5ciQW+fw+ql69OocPH2bdunWsX7+eU6dOcfToUSwtLfH09KR///7885//fOJb/hy+vr4cPnyYqVOncujQIS5dukSjRo344YcfuHjxIkuXLjU+uxy2trbs3LmTFStW8Ouvv3L69GmCgoIoW7YsVapUYfz48QwePDjXObVr1+bUqVN88803bNy4kc2bN2NtbY2HhwcfffQRdevWNZbXaDTs37+f2bNn4+/vz6ZNm7CwsKBhw4aMHj2awTk5XUzQjhxP+necM1T80Xva29szePBgfvrpJ4KDg/O8eMyJaUJDQ3OtZ69Wq3F3d+e9997jgw8+wNPTM9+6JCYmGoPr/KSmpuaq986dOx/bhnnz5hnL59TtcT/D06ZNo1evXsyePZvRo0cb//2mpqayceNGatWqRbNmzR57z5ctv+f0siiVShQKRaF+5xb2d7JC/yIW93yBFApFruz9GRkZWFtbs3r1avr06WMsN378eE6dOsX+/ftfeJ1ylgXRarXFqofq7zIzM9m6dSvdunV75T5YZev0hETeMy4HeCU+Odfx2m4aOlYvR8ca5ahWrnjnATDpc9JlG1YEyFki8PphSLufu4y5Fbg3Ao8WhgSBbo1AVfI6VZ7Hq/yz9Kr4X8j/+PH0jyhR0r5CewZXH0zDcg2f+LOfde8eCVu3ol2/gbQzZ4z7zUqVouLqVVg8SPAkio78PBV/L/IZpaWlcfXqVSpVqvRi3/S/BnKGltvb20sHSjFW0HM6deoU9erVY+zYscyfP9+ENXx5/vzzT958800WLlzIqFGjTF2dXEz58/Q0vxcLG4eW+Df9FhYWNGjQgF27duUK+nft2kXv3r1NWDPxMpkpFTSsWJqGFUszpVt1LsUlPegAiCUk6j6nb2g5fUPL7F0XcC9tRcfqznT0KUejiqUwf5USATwvpRm41jNszd83ZD+PC3u4ROD1w5ASD1cPGDYAMwso3/DhEoHujcHCxrTtEK+9GmVqUNepLqdun2JX5C52Re6iiqYKA70H0rNyT2wtbPM9z7xUKUq/9Ral33qL9IsXub9+PQkbN6GwtDROAwBIPnoUtZeXDP8XQghRJOrWrcuAAQNYtmwZH3/8MU5OeXPUvEr0ej2zZs2iSpUqvPPOO6auziuvRAT9SUlJuZbyuHr1KqdOnaJ06dJUqFCBf//73wwZMoSGDRvSrFkzFi9eTGRkJP/6179MWGthSp5lbfEsa8uoNlW4nZjOnvOGEQCHLsUTdTeVZYFXWRZ4FQdrFe2qlaWjTzlaVXXCRl0ifiReHqUSnGsatibvGTIf344wLBGYMxog6RZEHjZsfANKc8MUAI/mhukA7k3AsviOgBGvprYV2tLCpQVLNy0ltlwsW69t5bL2Ml8Gfcni04vZ2X8nKuXj31iqvbwoN2kSZf/v/8iMiTGOEtBlZHBj/AR0ycnYtmyJpo8fdm3ayPB/IYQQz2XmzJmsX7+e2bNn89VXX5m6Oi/Uhg0bCA0Nxd/fP9/pKqJolYgI58SJE7Rt29b4dU4SvaFDh7J8+XIGDhzInTt3mD59OjExMdSsWZOtW7fmyXoqXk9OdmoGNa7AoMYVSMnI4sCFeHaF3eKv8FvcS8lkXUg060KisTBX4lulDB19nOlQvSxl7WWYYR4KBZT1NmyNRho6Ae5eeZgT4FogJNyAG8cMW+Bcw0oALnUe5gSo0BSsZG108XK4mLnwTuN3mNhoIpsub8I/wp8G5RoYA369Xs/B6IM0c2mGqoCElQpzcywerCUNkBUXh0VFD9JCT5O0dy9Je/di5uCAfffuaPr0wbKGT7GeQiSEEKJ4qlKlygtdxaI48fPzo4TNMi/RSkTQ36ZNmyf+oxg9ejSjR49+STUyWLBgAQsWLCA7O/ul3lc8O2sLc7rUdKZLTWeysnUEX3+QB+D8La7fSWFvxG32RtxmagDUdXego085OvmUw7OsrXyIz49CAWWqGLYGQw2dAPevPxgFcNgwIuDeNbgZYtiO/A9QQLmaD6cDePiCjQyRFi+WnYUdb1Z/k8Heg0nNSjXuPxt/ljF7xlDGsgz9qvZjQNUBONs8fsk+Czc3Kvn7k37lCtqA9Wg3bCArLo57v//Ovd9/p+ykSZR5Z8SLbpIQQgghRKGUiKC/uBozZgxjxowxJlAQJYu5mZImlcvQpHIZ/tu9OheNeQBucSrqvnH7ZkcEFctYG1YC8HGmgUcpzJTSAZAvhQJKVTRs9d4y7NPeMHQA5IwGuHMJbp0xbEGLDGWcqufuBLArV9AdhHguCoUCa9XDNYJvp96mrFVZ4lLjWHx6MUvOLKGNWxsGeg+kqUtTlIqCc36oK1em7MR/4zRhPMmHj6ANCCBxzx5s27Yxlkk9c4bM6JvYtmuLUoYvCiGEEMIEJOgXAkMgULWcHVXL2TGmrSdxCWnsPh/HrrBYAi/f4dqdFH46eJWfDl6ltI0F7bwNeQBaejlibSE/Ro+lcYPabxg2gMTYB6MAHkwHuH3+4XZ8iaFMGc+H0wE8fEFTvuDrC/Ec2lVoR0u3luyL2sfK8JUciz3GX1F/8VfUX3jYe7CowyLc7B6fsV9hZoZtyxbYtmxBdlIyZrYPE1neWbaMxG3bUWo0aLp3Mwz/r1lTRg4JIYQQ4qWRaEWIfJS1t+TNJhV4s0kFktOzOHDhNrvCbrEnPI67yRmsCb7BmuAbqM2VtPRypKNPOdp5l8PJTm3qqhd/ds5Qs69hA0iOz90JcOusYTTAnUtwcoWhTKmKhiUCK/oaEgQ6eBhGFQhRBFRKFR09OtLRoyNX7l/BP8KfjZc3kpGdgYuNi7Hc3bS7lLYs/dhrPRrwA6g9PUl1diYrNpZ7f/zJvT/+xMKzCg5+ftj37IWqXNkX0iYhhBBCiBwS9AvxBDZqc7rWcqFrLReysnUcv5aTByCWqLup7D4fx+7zcSgUZ6hfoRQdfcrRobohD4AoBBtH8Oll2ABS70Hk0YfTAWJCDXkB7l2DU78Zyti7PZwOULEFlK4snQCiSFR2qMyUJlMYX388kYmRmCnNAMjMzqTfxn642rgy0HsgnSt2Rm325E4+pzFjcPzXv0g+ehRtwHoSd+0i49Jl4r6djXbzFiqvD3jRTRKiRJCEXkIIYfAifh9K0C/EUzA3U9KsShmaVSnDxz2qE3ErkV3nDIkAT9/QEnz9HsHX7/HVtnAqO9rQsYYhEWBdd8kDUGhWpaBaV8MGkJYAUUEPOgEOw82ThhUCTvsbNgBb5wdLBPoaRgQ4VZNOAPFcrFXWeJf2Nn4ddjeM++n3iU+N5/Sh03xz/Bv6ePXhjapvFG74v68vtr6+ZCcmkrB9O9qA9dh16GAso0tOJm7Od2h69cSydm0Z/i9eG2ZmDzrWMjOxsrIycW2EEML0MjMzgYe/H4uCBP1CPCOFQoG3sz3ezvaMbe9FjDb1QR6AWxy5HM+V+GR+3H+FH/dfwdHWgvbe5ejoU44WXo5Yqoruh/iVZ2kPXh0NG0BGMkQdezgdIPoEJMXCuXWGDcDa8UEnwIOcAGV9QFlwQjYhnqSOUx129d9FwMUAVl1YRWxyLD+f/ZnlZ5fTonwLxtUfl6uToCBmdnaUGjCAUgMG5OrJT9i1y5j936JSJTR9+qDp3QtVOUlqKV5tKpUKtVqNVqvFzs5OOryEEK81vV6PVqtFrVajUuW/lPCzkKD/OciSfeJRLhorhjT1YEhTDxLTMtn/IA/AX+FxxCdl4H8iCv8TUViqlLT0cqKjTznae5eljK3kAXgqFjZQpa1hA8hMhRsnDJ0A1wMh6jikxMP5jYYNwNLB0Ang4WsYDeBcG5TS8SKejqOVI+/WfpcRNUdw4MYB/CP8CbwZyMHog4yvP95YTq/XFypwebSMuoonmt69SNixk4yrV7k9Zw63587FpnlzNH5+2HXsgFItvyvEq8nR0ZHo6Ghu3LiBRqNBpVJJ8P8MdDodGRkZpKWloZSO7mJLnlPJ8LKfk16vJzMzE61WS1JSEuXLF20Sawn6n4Ms2ScKYmepokdtV3rUdiUzW8exq3eNywFG3081/r9SAQ08ShmXA6zkaPPki4vcVFZQqaVhA8jKMEwByMkJEBkEafchYqthA1DbQ4WmD3MCuNQBs6LrTRWvNjOlGW0rtKVthbZcT7jOwRsHqVa6mvH450c/Jy0rjUHeg6jlWKtQwYtVrZpYzZpFuY8/JnHHDu4HBJB6IpjkQ4dIPnQIzz27URbxBwAhigt7e3sA4uPjiY6ONnFtSi69Xk9qaipWVlbSaVKMyXMqGUz1nNRqNeXLlzf+XiwqEvQL8YKpzJT4ejri6+nIpz19CItJMAb9524mcPzaPY5fu8eXW8PxLGtL+2pOWCeCTidJjZ6JuYUhoK/QFPgAsjMh5jRcP2SYDhB5BNIT4OJOwwagsgH3xg9zApSvD+YFv1VVXN1P27DJKKrbQNUOBZYTrz4Pew88fDyMX2vTtWy4tIEMXQabrmyieunqDPIeRNdKXbEyf/J8ZTNbWxz69cOhXz8yIiPRrt9AZnQ0qkcC/tjPZ2Du5GQY/u/i8pirCVFy2NvbY29vT2ZmpoygfEaZmZkcOHCAVq1aFemwYFG05DmVDKZ4TmZmZi/sXhL0C/ESKRQKarhqqOGqYUKHqkTfT2X3gw6Ao1fucCkuiUtxSYA5v13bTwcfQx6A5lUkD8AzM1OBWwPD5jsedNkQe+ZhToDIw4YVA67sNWwA5pbg1uhhTgC3hoYRBQB6Pcq9M7BPv4lu7wzwai9JA4WRRq1heZflrIxYyfar2zl/9zyfHv6Ub098S+8qvRnkPQgPe48nXwiwqFABp3Fjc+3Lun2beytXQnY2t+fNw6ZZUzR9+mDXoQNKSYImXgEqlUoCoWdkZmZGVlYWlpaW8j0sxuQ5lQyv2nOSoF8IEyrvYMXQ5hUZ2rwi2tRM9kXEsfNsLHvOx3A7KYM/j0Xx57EorC3MaPUgD0A777KUsrEwddVLLqUZuNY1bM3GgE4Ht88bOgByRgOkxMO1g4YNwMwCyjcwdABYWKOMCTFcKiYELu8BT3nbLx6q5VSLWk61mNRwEusvrcc/wp8bSTf47fxvlLYszbu1333mayttbXH5/HO0AQGkHD9O8uEjJB8+gtLGBruuXSj95ptY+vgUYWuEEEIIUdJJ0C9EMaGxUtG7bnm61SjLxs03KOXdmL0Rd9h9/hYx2jS2n4tl+7lYzJQKGj7IA9DJx5kKZaxNXfWSTamEcjUMW5N/gl4P8Rce5gS4FmhYHSDyiGED9IAC0KNAsfszqCJv+0VeDpYODKs5jH/U+AeB0YGsurCKPl59jMcPRR/iXPw5+lXth6OVY6GuqbSywqFvHxz69iEjKgrtho1o168n88YNtGvWYlWzpjHoL2xCQSGEEEK82iToF6IYMldCS09H2lV3YXrvGpyNTmBXWCw7w24RHptI0NW7BF29y4wt56lWzu5BIsBy1CqvQamUD/nPRaEAp2qGrdE7hk6Au1cMHQBn1sDV/eR8hxXoIfY0/NwVWk6EKu1kVQCRh1KhpKVbS1q6tcy1f9nZZRyPPc6i04voWKEjA70HUr9s/UIH6hbu7ji9PwbH0aNIOXEC7YYN2Hftajx+338VCdu349DHD7uOHVFaSwehEEII8TqSoF+IYk6hUFDLTUMtNw3/7lSNqLspxkSAx67dJeJWIhG3Evnf3kuUs1fTobqhA6BZlTKozSUAfW4KBZSpAqUrw4lloDAD/d+STEUegd/7g50r1BkE9d42nCNEAfR6PX08+5CRnUHo7VC2XdvGtmvb8HTwZFC1QfSo0gMbVeFW81Aoldg0boxN48a59t8PWEda6GlSjh5F+dl07Lp2wcHPD6uGDWUEgBBCCPEakaBfiBLGvbQ1I1pUYkSLStxPyWBvRBy7wm6xP+I2txLS+T0okt+DIrFVm9O6qiEPQNtqZdFYl/wkJCZ1eQ/cDCn4uIUtJN6EQ3MMW4XmUO8t8PEDte1Lq6YoGRQKBT2r9KRnlZ6E3QljVcQqtlzZwqX7l5gRNIPdkbv5qdNPz3WP8rPnoN2w3rACQFQU2rXr0K5dh8rdHYd+/XD813tF1BohhBBCFGcS9D+HBQsWsGDBAllaRpiMg7UFfeq50aeeG+lZ2Ry+fIddYbfYHXaLuMR0tpyJYcuZGMyVChpXKm2cBuBWSob5PhW9Hv6aASgBXT4FlFDGE3wnQOgfcGm3YVWAyMOw9UOo0cfw9r9CU5n7L/LwKePDtObT+HfDf7Px0kb8I/zp7dnbeFybruVIzBHau7dHZVb4zjsLt/I4jRmD4+jRpAYHcz8ggMRt28mMiiL11KlcZXXp6SjVBS9TKYQQQoiSS4L+5zBmzBjGjBlDQkICGo3G1NURrzm1uRltq5WlbbWyzOhdk9PRWnaFxbIr7BYXbiVx+PIdDl++w2ebwqjuYv8gEWA5arjay1DfJ8nOAG00+Qf8GPYn3gTvblCzDyTchNCVEPIb3L0Mp34zbKWrGN7+1xkM9q4vswWiBLC3sOdtn7d5q/pb6PQP/62tv7Seb098i6OVI/28+tG/an+cbZwLfV2FQoF1w4ZYN2yI7r//JXH3blQuLsbjGTeiudq7N3YdO6Lp0wfrRg1RKJVF2jYhhBBCmI4E/UK8gpRKBXXdHajr7sCkzt5cv5NszANw/NpdzsckcD4mgfl7LuKqsaTDgxEATSqVwcJcPuznYa6Gf+6F5HgAMrOyCAwMxNfXF5X5g1+jNk6GcmAI6Fv+G1r8H0QeNQT8ZwMMHQB7phtGDVRpb3j7X63rw/OEwBCkmyke5uOwMLOgjGUZ4lPj+fH0jyw5s4S27m0Z6D2QJs5NnqrTTmltjaZXr1z7kvbsRpecjHb9erTr16MqXx6Nnx8av95YuLsXWbuEEEIIYRoS9AvxGvAoY8PIlpUZ2bIy95Iz+CvckAfgwMXb3NSm8cuR6/xy5Dp2anNaV3uQB8C7LPaWkgfASONm2AAyM9FaR4NLHVA95nukUIBHM8PWZRaEbTC8/Y88DJd2GTarUlB7INR9C1xqv5y2iBJlsPdg+nv1Z0/UHlaGryT4VjC7I3ezO3I3XqW88O/hj0r57D+rpf7xDyxr1UIbsJ6EbdvIjI4mfsEC4hcswLpRI1y+mIFFhQpF2CIhhBBCvEwS9AvxmillY0G/Bm70a+BGWmY2hy/HPxgFEEd8UjqbT8ew+bQhD0DTymWMeQBcHaxMXfWSTW1rGNpf7y24cxlO/Q6n/jRMCwhaZNica0O9IVCrP1iXNnWNRTGiMlPRpWIXulTswsV7F/GP8GfT5U14ajxzBfzXE67jYe/xVNdWKBRY16+Pdf36lJs6hcTde9AGBJB85Ahp585h7uhoLJt56xbmTk4y/F8IIYQoQSToF+I1Zqkyo513Odp5l+MLPz2nbtw3TgO4FJfEof9n767Do7q2Po5/z0hciBBiQHAIEiw4wd3doUWKpGhpqVEvpcW9UKRYcXeHQLDgEjwBQoAkJJAQl5n3j+lNb99bgWTCJGF9nuc8lzkz7P0LU7izZp+z9t1nnLj7jC+3X6eCh13mdoDebtIHIFucSkCTL6DRZ3DvCFxcCbd2w9MrsOdD2P8ZlG0DlftCiUagkq0XxR9KOZTi81qfM7baWOJT4zPPh7wIocO2DvgU9KFHmR4092qOufr1bh1RWVpi364t9u3akvbkCck3b6KyMjT+1Ov1hA0eQkZCPAU6dsS+QwfMir7eFwxCCCGEePOk6BdCAIY+AFWLOFC1iAMTWpYl9FlCZiPAcw+ecy08jmvhccw8eAePApaZVwDUKOaIVi2rflmiUkOppoYjMQaubjBc/v/0ClzfYjjsPAyN/yr3NnxZIMTvrLXWWGutMx9fjrqMRtFwOeoyl6MuMyVoCp1LdaZbmW542Hi89vhaN7c/NfxLj4gg7elTdC9f8mz+Ap7NX4BltWoU6NQR25YtUdvI1pRCCCFEbiRFvxDiLxVztuY9vxK851eC6PgUDv3eB+D4nSjCXyTx68n7/HryPnYWGhqVdaGZdyEalC6IrfQByBorR6g51HA8uQwXV8PV9RAXDsenGo6idQ33/nt3MNwuIMR/6VSqE/U967Pp9iY23N5ARGIES64tYem1pfh5+jGx1kQKWRfK8vhaV1dKHQ/g5aFDxG7ZSsLJkySdP0/S+fM8/e57XD4cj2OfPkb8iYQQQghhDFL0CyH+lZONOd2rF6Z79cIkpWZw4u4zDgQ/5dCNSKITUtl26THbLj3GTK2iVonf+wCUK4SrvYWpo+dNbj6Go/m3hsv+L66Ge4fgQaDh2PMRlO9k6P5fuKahYaAQgLOlM0N9hjKo4iCOhR1j7a21nH5ymitRVyhgUSDzdRm6DNRZuG1EZWGBfZs22LdpQ1pEBLHbtxO7ZSupISF/6vSfFhGJPikRMy8vI/xUQgghhMgOKfqzYd68ecybN4+MjAxTRxHijbE0U2de2p+h03Px4fPMPgAhzxIIuB1FwO0oJm69RiVPe5qVK0Sz8oUoU8hW+gC8Lo25obgv3wliw+HyGkMDwJgQQx+AiyvBqaRh9d+nF9i5/fuY4q2gUWloUrQJTYo2ITQ2lAdxDzLv79fpdXTd0RVvJ296lulJxYIVszSHtlAhnIcMwWnwYJKvXsXC2zvzueerVhL9y2Isq1bFvmMH7Fq1Qm1ra5SfTQghhBCvR4r+bPD398ff35+4uDjs7e1NHUeIN06tUqju5Uh1L0c+aV2Ou5Hxv38B8JSLYS+48iiWK49imXbgNoUdLWlWzpVm3oXw9XJAI30AXo+9B/iNh/ofwMNThtX/61sg+i4c+hoOfwslmxpW/0u3Ao2ZqROLXKKYfTGK2RfLfHwh4gJ3X9zl7ou7bL+3nfJO5elRpgcti7XEUvP6u3QoioJlpT9vN5keEwMqFUkXLpB04QIR30/Ctlkz7Dt2xLp2LRT1H1cZJJ46TdFp00l0cMTer37Wf1AhhBBC/CUp+oUQRlPSxYaSLjYMb1iCqJcpHLphuALgxN1nhMUksTQwlKWBoRSw0tK4jKEPgF/pglibyz9Fr0xRoGgdw9FqMlzfalj9f3gK7uw3HFZOULG74QsA1wqmTixymWqFqrGq9SrW3VzH3vt7uR59nS9OfsHUc1PpWLIjfcv1xc0me1eNuH//PQVHjyZuxw5ebNlC6t17xO3cSdzOnZiXKUOxrVtQFAW9Xk/0rFmYR0YSPWsWdvXryRVBQgghhJHJJ20hRI4oaGtOzxpF6FmjCImp6QTcfsaB4AgO34zgeWIamy+Gs/liOGYaFXVLONHM25Wm5VxwsZM+AK/M3Baq9jMcz+4aiv/La+DlEzizwHC4+UCVflChi6FZoHjrKYqCT0EffAr6MN53PFvvbmX9rfWEx4ezIngFjQo3ynbRD6B1ccFp0CAcBw4k+dp1YrdsIXbXLqyqV88s7ONPnCDl+nUAUq5fJ+FEIDb162V7biGEEEL8QYp+IUSOszLT0LKCKy0ruJKeoeP8g9/7ANyI4EF0IkduRXHkVhSfboHKhQvQzLsQzb0LUdLFRlb9XpVzSWj6JTT6DO4dhkur4OZuw04ATy7Dvs+gbBvD6n/xhobtAsVbz9HCkYEVBjLAewCBjwMJeBRAtULVMp//5covgGFnAGdL5yzNoSgKlhUrYFmxAi4fT0CfmAiAXq8nctIP//1CombOxLpeXfl7L4QQQhiRFP1CiDdKo1ZRs7gTNYs78Vmbctz5vQ/A/uAILoe94NLvx5R9t/Bysvq9aaAr1Yo6oFZJIfCv1Boo3dxwJETD1Q2Ghn8R1+D6ZsNh5wGVexsOx+KmTixyAbVKjZ+nH36efpnnEtMSWXptKfFp8cy/PJ/mRZvTs2xPKhesnOWiXGVmBmaGfhMJJwJJDQ3940m9nuTr13k2Zy7OI9+Xwl8IIYQwEin6hRAmoygKpQvZUrqQLf6NShIRl8zB3/sAnLwbzf3oRH45Hsovx0NxtDajcVlDH4D6pZyxMpN/vv6VtRPUGgY1hxpW+y+thivrIS4cAqYYjqL1DKv/3u3BzNrUiUUuolVp+aTmJ6y7uY4rz66wO3Q3u0N3U8ahDD3K9qBNsTZYaa2yNLZerydq1ixQqUCn+9Nzz+bPJ+HMGQp9PAHLilnbWUAIIYQQf5BPzUKIXKOQnQV9ahalT82ixKekE3A76vc+AJHEJKSy8fwjNp5/hLlGRf1SzjTzLkTjsoUoaGtu6ui5m6KAe2XD0exbuLUbLq4y3Abw4ITh2P0hVOhkuP/f09fwe8RbTavW0r5Ee9qXaM/16Ousv7We3SG7ufX8Ft+c+obH8Y8ZXXV0lsZOOBFI8rVrf/t80vnzhI/7gBJ79/yp078QQgghXp8U/UKIXMnGXEPrim60ruhGWoaOoPsxv28HGMGj50kcvBHJwRuRKMpVqhZxoJl3IZqWM/QBEP9AawEVOhuO2EeGxn8XV8PzULiwwnA4lTKs/vv0BFtXUycWuUB5p/J8XedrxlUbx/Z721l/az2dS3XOfP5q1FWeJDyhUZFGaFXafxwrc5VfUUCv/98XKApqe3sKjhubWfDr09PRJSaitrMz6s8lhBBCvA2k6BdC5HpatYo6JZypU8KZL9p6c/Ppy8wvAK6Gx3L+wXPOP3jO5D03Ke5sTbPyhkaAlQtLH4B/ZO8Jfh9C/fHw4KRh9T94K0TfgYNfwqFvoFQzwxcApVqAxszUiYWJ2Zvb08+7H33L9f3TPfe/XP2FI2FHcLF0oWvprnQp3QUXK5e/HEOflkbakyd/XfCD4bxGg22TJpmnXmzYQNSs2Tj7++PQsweK9p+/WBBCCCHEH6ToF0LkKYqiUM7NjnJudoxqUoonsYZV/wPBEZy694yQZwksPBbCwmMhONuY0aRsIZp5F6JeKWcstHKZ8F9SFPCqazha/wTXtxi+AAg7A7f3Gg4rJ6jUE6r0gULlTZ1YmNh/F/x6vZ6yjmW5EnWFyKRI5l+ez8IrC2lcpDE9y/TE19X3T69XmZlRbOMG0mNiAEhPTycwMJC6deui0Rg+lmicnAxN/34fP273HjJevCDi++95vmoVLh+Ox6ZJE2n2J4QQQrwCKfqFEHmam70l/WoVpV+torxMTuPYf/UBeBafyrpzYaw7F4aFVkX9UgVp5l2IJmVdcLKRPgB/ydwWqvY3HM/uGIr/y2sh/imcnmc43KtA5T5QsStYOpg6sTAxRVEYUXkEQyoO4eDDg6y9uZYLkRc48OAABx4coEmRJsxsNPNPv0fr5obWzQ2AtLQ0Uu7fx8LbG+1frOArikKRZUt5sXEjUbPnkPrgAY/eH4lV9eq4TJiAZcUKb+LHFEIIIfIsKfqzYd68ecybN4+MjAxTRxFCALYWWtpWcqdtJXfSMnScCYnJ3A0g/EVS5i0BKgWqFXXI3A6wmLN0rf9LzqWg2dfQeCLcO2T4AuDWHnh80XDs+wzKtTOs/hdraOjELt5aWrWWVsVa0apYK24/v836W+vZcW8HNd1qZr4mMS2RsJdhlHEsk3kuODqYJS+X4BXthY+rz1+OrWg0OPTsiV3btkT/spiYX38l8dw57nfrhsv4D3AaPDjHfz4hhBAir5KiPxv8/f3x9/cnLi4Oe3t7U8cRQvwXrVpFvVLO1CvlzJftvAl+EpdZ9F9/HEfQ/ecE3X/OpN03Keli8/sXAIWo7FkAlfQB+DO1Bkq3MBwJzwzb/l1cBZHX4dpGw2FfGHx6QeXe4FjM1ImFiZV2KM3ntT5nTNUxqFV/3FazJ3QPX536iqouVelRpgfNijZjZ+hOQjNC2RW662+L/v9Q29jgMnYMDj17EDVzFrE7dmBVu3ZO/zhCCCFEniZFvxAi31MUhfLu9pR3t2dM09KEv0ji4O9fAJwOieZuZDx3I+NZcPQeBW3NaVrOhWbehahT4q/7AFwNj2XudRWFfWKp6uVsgp/IhKydofYIqDUcnlwydP6/uh5iwyDgJ8PhVd/Q/K9cezDL2j7uIn+wMfvzbhrh8eFoFA0XIi9wIfIC35/5ntSMVAD2PdhHx9Id0aPHwdwBdxv3vx1X6+aG+4+TKThqJFoPj8zzUfPno7a3x6F7d2n2J4QQQvxOin4hxFvHo4AlA+p4MaCOF7FJaRy9ZWgEePRWFFEvU1hzNow1Z8OwMlPj93sfgMZlXXCwNjQW23LpCXfiVGy99OTtK/r/Q1EM9/a7V4Hm38HNnXBpNdw7AvePG45d4w1bA1bpB57VDb9HvNVGVR1Fz7I9abLB0Jk/LjUu87mYlBh67OyR+fjqgKv/Ot5/F/ypYWE8W/AzpKXxfNVqQ7O/Ro2k2Z8QQoi3nhT9Qoi3mr2llg6VPehQ2YPUdB2nQ6IzbwN4GpfM3utP2Xv9KSoFvN3sqFnckR2XnwCw6+pTuvsWQa8HB2stng5v6aq21sLQ1K9iV3gRZmj8d2kVPL8PF5YbDucyhnv/K/UE20KmTixMyMXKhR/q/8DnJz4nQ/+/PXHUiprv6n332uNqXV1x/fQToubMJTU0lEcj/LGqUQOXjz7CsoLsOCGEEOLtJUW/EEL8zkyjwq90QfxKF+SbDuW5Fh7HgeCn7A+O4ObTl1x7HMe1x3+sTEYnpNJ2zonMx/cntzFF7NylQGFo8CHU/wAeBBpW/69vhWe34MAXcPBrKNXccPl/6Raglkuw30Zti7eluH3xP63s/8dvbX7D09aTRy8f4Wnr+cpjKlotDr16YdeuHdGLfiFm+XISz57lfteu2LVvR6EPP0RTsKAxfwwhhBAiT5BWy0II8RcURaGipz3jmpdh7xg/JrYpx9/191MpMLlLxTcbMLdTqaBYfej0M4y/De1mg2cN0GfA7T2wrg9ML2fYASAi2NRphQkpKH/6X4B5F+fRcVtH5l+aT3J68muNp7axwWXcWErs2Y19h/YAvDx4yHiBhRBCiDxGin4hhHgFg+oXZ/v79f7yOZ0eJu26wbT9t4iOT3nDyfIACzuoNgAGHwD/IKg7GmwKQUIUnJoLC2rDokYQtASSXpg6rXhDHC0ccbJwopxjOdpbtqecYzmcLJwoYFaA+3H3SclIYcHlBXTc1pFDDw+h1+tfa3ytuzvuP/6I18aNuH391Z9W+V8ePow+Lc3YP5IQQgiRK0nRL4QQr+k/fcH+sy7pWcCCuOR05hy+S90fD/PV9uuEv0gyWb5crWBpaPYNjA2GXuugbFtQaeDxBdg1DqaVgU2DIeQo6HSmTitykKu1K/u77mdli5XUMK/ByhYr2d91P+627vzc9GemNZiGq7Ur4fHhjDkyhuEHhxMaG/ra81hWKI99u3aZjxNOneLRCH9C2ncwFP+v+WWCEEIIkddI0S+EEK/IycaMgjbmVHC3o3vxDCp42FHQxpx1Q2vzc9+qVPK0JzlNx68n79PgpyN8sP4ydyNfmjp27qTWQJmW0HM1jLsJLSaBizekJ8PVDbCiA8zygSM/wPMHpk4rcoiZ2iyzu76iKJipzTJ/3dyrOds6bGNIxSFoVVoCHwfSeXtnDjw4kK05M2LjUDs4ZDb7ezjgHZKuXc/2zyKEEELkVlL0CyHEK3Kzt+TEx43YNLQmdQvp2TS0Jic+boSHgxUtK7ixzb8uqwbVpG5JJ9J1ejZdeESzGQEMXXmOy2EvTB0/97IpCLX9YfhJGHIEqg8Cc3uIfQjHJsOsSrC8HVxZD6mJpk4r3iArrRWjqo5iS4ct1POoh6XGkqouVbM1pl3LFpTYvw+nIUNQzMwym/2Ff/QRaU+eGCm5EEIIkXtI0S+EEK/BXKP+08qkuUad+ZyiKNQr5czqwbXY6l+XFuULodfDvusRdJgXSJ/Fpzlx55lcTvx3FAU8qkLb6TD+FnRZAsUbAgqEBsDmIYbL/3eMgUfnQP4c3xpF7Yoyv8l8NrXbhJOlU+b5uRfncuf5ndceT21ri8sH4yixZzd27Q2X/sdt38HDIUPk76cQQoh8R4p+IYTIAZULF2Bhv+ocHOdHl6qeaFQKgXej6bvkDB3nBbL32hN0Oiku/pbWEip2hf7bYMwVaPgpFCgKKXFwfhksbgLza0HgbIiPNHVa8QYoioKbjVvm42Nhx1h4ZSHddnTjx7M/8jL19W+l0Xp44PHTT3ht2ICVry8F/f0zv9TTp6ejT083Wn4hhBDCVKToF0KIHFTSxZZp3X04+mFD3qnjhYVWxeVHsQxbdYFmM46x4VwYaRnSsO4fFSgCDSfAqEswYAdU6gEaS4i6CQcmGrb+W9Mbbu6CDOnI/rYo5VCKZkWbkaHPYNWNVbTd0patd7ei07/+3yfLihUosmI5ti1bZp57sXGTodnfkSOy+i+EECJPk6I/G+bNm4e3tze+vr6mjiKEyOU8Haz4qn15Aic0ZmTjkthZaLgXlcCHG6/Q4KcjLAsMJTFVVhX/kUoFxfyg8yLD5f9tZ4KnL+jS4dYuWNvb8AXAvs8g8qap04oc5m7jzvSG01nYbCFedl7EJMcwMXAi/fb043r06zfmUxTlj1V+vZ7nq1eRGhLCo+EjePjOuyRdl2Z/Qggh8iYp+rPB39+f4OBggoKCTB1FCJFHONmY80HzMgR+3JhPWpWloK05j2OT+XpHMPV+PMLsQ3eITZTV6n9lYQ/V34XBB2HEGagzEqxdICEKTs2F+TVRL2tB0WeHITnO1GlFDqrjXofN7Tczrto4rDRWXIm6woSACWToMrI8pqIoFP3tN5yGDDY0+ztzhvtduvJ4wgRp9ieEECLPkaJfCCFMwNZCy9AGJTj+USO+71SBIo5WxCSkMv3AbepMPsSk3TeIjEs2dcy8waUsNP8OxgVDzzVQti2oNKgen6dy2K9oZnnDpiEQcgx0citFfqRVa3m3wrvs6LSDNsXbML76eNQqQ5PNDF1Glr4AMDT7+8DQ7K+dodlf7Lbt3GvZihebtxg1vxBCCJGTpOgXQggTstCq6VOzKIc/aMCsnpUp62pLQmoGiwJCqPfjET7ZfJUH0Qmmjpk3qLVQtjX0XA3jbpLR9BviLDxQ0pPh6npY0R5m+8DRyfDioanTihzgYuXC5PqTaVi4Yea5dbfW0WtXLy5FXsrSmFoPDzym/ITXhvVYVa+OPiUF81KljBNYCCGEeAOk6BdCiFxAo1bRobIHe0bXZ9k7vvh6OZCaoWPN2Yc0mnqUkWsucv1xrKlj5h02BdHVHMGRspNIf3c/VB8I5naGYv/oDzCzEixvD1c2QFqSqdOKHJKuS2dF8ApuxNyg355+fHbiM54lPcvSWJYVK1Jk5Qq8NmzAsmKFzPPRv/4qzf6EEELkalL0CyFELqIoCo3KurBhWB02DKtNozIF0elhx+XHtJl9gneWneVsaIypY+YdioLevSq0nQHjb0PnxVCsAaCH0GOweTBMLQM7x0L4eZDCLV/RqDSsbr2aTiU7AbD93nbabWnHyuCVpOlev3eGoih/KvhTw8KInDY9s9lfcnCw0bILIYQQxiJFvxBC5FK+Xo4se7cGu0fVp52POyoFjt6KovvCU3RdcJLDNyNkdfF1aC2hUjcYsB1GX4GGn4B9EUiJhXNL4ZfGML82nJwL8VGmTiuMxMnSiW/qfsPq1qvxdvImPi2en4J+ovuO7lx7di1bY6sLFMBpQH8UrZbEM2cI7dKVxxM+lmZ/QgghchUp+oUQIpfzdrdjTq8qHP6gIb1qFMFMreLcg+cM/PUcrWYdZ9ulcNIzpEHda3EoCg0/htGXof92qNgdNBYQdQP2fwbTy8LaPnBrD2TIVor5QaWClfit9W98WftLCpgXICQ2BK1Km60x1ba2uIwfT/E9e7Br0wb0emK3beNey1ZEzpxJRrz04xBCCGF6UvQLIUQe4eVszQ+dK3JiQiOG+hXH2kzNzacvGb32Eo2nHWPV6Qckp2V9m7K3kkoFxRtAl1/gg1uG2wA8qoEuHW7uhDU9YXo52D8Rom6ZOq3IJrVKTdfSXdnZaSc/+v1IGccymc+deXKG1IzULI1r5umBx7SpeK1fh2X1auhTUohZsRJ9UqKxogshhBBZJkW/EELkMS52FnzSuhwnP27CB81K42htxsOYRD7feo36Px3h52P3eJn8+vcrv/UsCxga/g05DCNOQ+33wbogJETCydkwrwYsbgrnf4XkOFOnFdlgb25PS6+WmY/vvbjHsAPD6LK9C4HhgVke17JSJYquXInn3DkUmjABTcGCmc8lXbkit+MIIYQwCSn6hRAij7K30jKySSkCJzTmy3beuNtbEPUyhcl7blJ38mGm7rtFdHyKqWPmTS7loMX3MO4G9PwNyrQGRQ2PgmDHaJhaGjYPhdAA0MmtFXldRGIE9ub23I+7z7CDwxh9eDSPXj7K0liKomDbtCkOPbpnnks4fZr73XvwcOBAkm/cMFZsIYQQ4pVI0S+EEHmcpZmad+sW49hHjZjazYcSBa2JS05n7pG71P3xMF9uu8aj53KZcZaotVC2DfRaY/gCoNm34FwG0pPgylpY3g5mV4ajPxq2AxR5Uh33OuzstJP+3v1RK2oOhx2m47aOLLi0gOT05GyPnxISYmj2d+o0oZ278PiTT0l7+tQIyYUQQoh/J0W/EELkE1q1iq7VPDkwtgE/962Gj6c9yWk6lp96QMMpRxm3/hJ3Il6aOmbeZVsI6o4C/zMw+BBUewfM7eDFAzg6CWZWghUd4epGSEsydVrxmmzMbPjQ90M2tttITdeapGSkMP/yfPrs7oNOn72rORx79/5zs78tWwzN/mbNkmZ/QgghcpwU/UIIkc+oVAotK7iy1b8uqwfXpF5JZ9J1ejZfCKfZjADeW3GOS2EvTB0z71IU8KwO7WYZmv91WgTF/AA9hByBTYNgWhnYOQ7CL4Dcx52nlHQoyS/Nf2Fqg6kUsipE+xLtUSnZ/7iU2exv3Vosq1VDn5xM9IKfCRs0yAiphRBCiL+nMXUAIYQQOUNRFOqWdKZuSWcuh71gwdF77At+yv7gCPYHR1CnhBMjGpakbkknFEUxddy8ycwKfHoYjuf34dJvhiM2DM4tMRwu3lClL1TqAdbOpk4sXoGiKLTwakF9j/p/2tbv1ONTnHlyhvcqvYeV1ipLY1v6+FB01UpeHjxI5NSpOPTvl/mcXqcDRZG/j0IIIYxKVvqFEOIt4FO4AD/3q8aBsX50reaJRqVw8l40fZecocO8QPZcfYJOJyvS2eLgBY0+hdFXoN9WqNgN1OYQGQz7PjWs/q/tA7f2Qka6qdOKV2CltUKrNhT9abo0Jp2ZxJJrS2i3tR17Q/dmuRu/oijYNWtGiR07sGvVKvP8iw0bpdmfEEIIo5OiXwgh3iIlXWyZ2s2HYx814p06XlhoVVx5FMvw1RdoOuMY68+FkZou3eizRaWCEo2gy2IYfwvaTAP3qqBLh5s7YU0PmOENB76AqNumTitekUbR8EH1D/Cw8SAyMZIPAz5k0P5B3Hl+J8tjKmZmKCrDRzF9RgbPFv7852Z/ERHGii+EEOItJkW/EEK8hTwKWPJV+/Kc/LgJoxqXxM5CQ0hUAh9tvEKDKUdYeiKUxFRZjc42SwfwHQzvHYHhp6D2+2DlDPEREDgL5vnC4mZwfjkkx5k6rfgHiqLQsHBDtnbYin9lf8zV5gQ9DaLbjm78ePZHXqZmr0mmolZTdMUK7Fq3/qPZX4uWRM2eLc3+hBBCZIsU/dkwb948vL298fX1NXUUIYTIEkdrM8Y1L8PJT5rwaeuyuNia8yQ2mW92BlN38mFmHbzDi8RUU8fMHwp5Q4vvDVv/9VgFpVuBooZHZ2HHKMPl/1uGwf0T0vwvF7PQWDDMZxjbOm6jSZEmZOgzWHVjFWefnM322GaennhMn2Zo9le1KvrkZJ7NX8C9li15efRo9sMLIYR4K0nRnw3+/v4EBwcTFBRk6ihCCJEtNuYa3vMrQcBHjZjUqSJFnax4npjGjIO3qTv5MN/vCiYiLvv7lQtAYwbl2kHvtYYvAJp9A86lIS0RLq+BX9vA7MpwbArEPjJ1WvE3PGw8mNloJgubLqR76e40LtI487n41PhsjW3p40PR1avwmD0LbdEiZDx7hsZJmkAKIYTIGin6hRBCZLLQquldswiHxjVgdq8qlHOzIyE1g1+Oh1L/xyN8svkKoc/kUmOjsS0EdUeD/1kYdACqDgAzW8NOAEe+gxkVYGUnuLoR0uRLl9yojkcdJtaemNlx/0XyC9psacO3p77lRfKLLI+rKAp2zZtTYscOCi9aiGXFCpnPvdi4keSbN7MbXQghxFtCin4hhBD/Q6NW0d7Hnd2j6rHsXV9qeDmSmqFjzdkwmkw7iv9vF7j+ONbUMfMPRYHCNaD9bEPzv04Lwas+oId7h2HTIJhWGnaNh8cX5fL/XOxI2BFikmNYf3s9bbe2Zf2t9WToMrI8nmJmho2fX+bj1LAwnn79DaGdOvP4089Ii4g0RmwhhBD5mBT9Qggh/paiKDQq48L6YbXZOKw2jcu6oNPDritPaDP7BAOWnuVMSHSWty4Tf8HMGnx6wjs7YdQl8PsI7DwhORaCfoFFDeHnenBqPiQ8M3Va8f90KtWJZS2WUcqhFLEpsXx7+lt67erFpchLRhlf0WqxbdbU0Oxv82butWxJ1Ow56BLkChwhhBB/TYp+IYQQr6S6lyNL3/Flz+j6tPdxR6XAsdtR9Fh0mq4/n+LQjQgp/o3NsRg0/gzGXIF+W6BCF1CbQ8Q12PcJTCsL6/rB7X2QIbst5BbVXauzvu16Pq7xMbZaW27E3KDfnn5MDJyITp+9LTG1rq54TJ+O19o1WFapgj4piWfz53O3ZUueb9iAPiPrVxUIIYTIn6ToF0II8VrKudkxu1cVjo5vRJ+aRTDTqDj/4DmDlp+j5czjbL0YTnpG9gob8f+o1FCiMXRdarj8v/VUcKsMujS4sR1+6w4zysOBL+FZ1veNF8ajUWnoU64POzrtoFPJTgCoFTUqxTgfvSwrV6bob6vxmDULbZEiZEQ9I2LSD6RHRxtlfCGEEPmHxtQBhBBC5E1FnKz4vlNFRjcpxZLAUFaffsitiJeMWXeJaQdu8Z5fCbpV88RCqzZ11PzF0gFqDDEcT6/BpdVwZR3EP4XAmYajcC2o0gfKdwJzW1Mnfqs5WTrxTd1v6Fq6K562npnnH8Y9JCIxAl/XrG/7qygKdi2aY9uoIc/XrkWv06F1ccl8PvXRI8w8Pf9+ACGEEG8FWekXQgiRLS52FnzSqhyBHzdmfPPSOFqbERaTxMSt16j34xEWHL3Hy+Q0U8fMn1wrQMsfYNxN6L4SSrUARQVhp2H7SJhaGrYMh/uB0vzPxCoVrISjhSMAer2eSWcnMXDfQD469hFPE55ma2zFzAzH/v1xeuedzHMJZ85yr1lzafYnhBBCin4hhBDGYW+p5f3GpQic0Jiv2nnjUcCSZ/Ep/Lj3JnUmH2bKvps8i08xdcz8SWMG3u2hz3oYGwxNvwKnUpCWCJd/g19bw5yqEDAFYsNNnfatl65Lx9PGEwWFPff30H5re5ZcXUJahvG+HEs8c0aa/QkhhACk6BdCCGFklmZq3qlbjKMfNmRaNx9KutjwMjmdeUfuUXfyYb7Ydo2wmERTx8y/7Nyg3lh4PwgG7oeq/cHMBmJC4PB3MLMCrOwM1zZDunwJYwpatZbPa33O2rZr8SnoQ1J6EjMvzKTz9s6cDD9plDkKjhpJ0TW/YVm5sjT7E0KIt5wU/UIIIXKEVq2iSzVP9o/xY2G/avgULkBKuo4Vpx7QcOpRxq27xO2Il6aOmX8pChSpCe3nwPjb0HEBFK0Heh3cOwQb3zVc/r/7Q3hy2dRp30reTt6saLWC7+t9j5OFE/fj7jP04FD23d9nlPGtqlSh6Jrf8Jg5E23hwmREPePpxC945P++UcYXQgiRN0gjPyGEEDlKpVJoUd6V5t6FOHUvmvlH73Hi7jM2Xwxn88VwmnkXYkTDElQp4mDqqPmXmTVU7m04YkLg0m+GIy4czi4yHIUqQpW+UKk7WDmaOvFbQ6WoaF+iPY0KN+Lnyz8TGB5Io8KNjDa+oijYtWyBTeNGvFizhqj5C7Br29Zo4wshhMj9ZKVfCCHEG6EoCnVKOrNqcE22v1+XVhVcURQ4EBxBp/kn6bXoNAG3o9BLw7mc5VgcGn8OY65C301QvjOozSDiKuydYFj9X98f7hwAnVwG/qbYmtnyoe+HrG+3HjO1GQBpujTeP/Q+hx8ezvbfC5WZGY4DBlDywH7sWrfKPP9i40Yef/65NPsTQoh8TFb6hRBCvHGVPAuwoG817kbGs/DYPbZcDOdUSDSnQqKp6GHP8IYlaFHeFbVKMXXU/EulhpJNDUdiDFzbBBdXGi71D95mOGzdwKeX4QoApxKmTvxW+E/BD7DlzhaOPTrGsUfHqOtRl499P8bL3itb46vt7DJ/rUtNJXLWLDKinhG3azdOgwbhNPBdVFZW2ZpDCCFE7iIr/UIIIUympIsNU7r5EPBRI96t64WlVs3V8FhGrL5As+nHWB8URmq6ztQx8z8rR6gxBIYGwLATUHM4WDrCyydwYrqh8//SlnBxFaTEmzrtW6Nt8bYMrjgYjUpDYHggnbZ3Yub5mSSmGacRpsrMDM9Zs/9o9jd3LvdatOTFpk3S7E8IIfIRKfqFEEKYnHsBS75sV57Ajxszqkkp7C21hDxL4KNNV2gw5QhLToSSmJpu6phvB9eK0GoyfHATuq+AUs1BUcHDU7DN33D5/1Z/eHAS5FaMHGWltWJ01dFsab+Fuh51Sdels+TaEtptbcfe0L1GuRXGqup/mv3NQOvpSXpUFE8++5zQTp1JunQp+z+EEEIIk5OiXwghRK7haG3GuGalCfy4MZ+1LoeLrTlPYpP5dmcwdSYfZubB27xITDV1zLeDxhy8O0CfDTD2OjT5EhxLQFoCXFoFy1rBnGpwfBrEPTZ12nzNy96LBU0WMLvRbDxsPIhMjGTdrXVGG9/Q7K8lxXfvwuXjCajs7Um5fRtU8jFRCCHyA7mnXwghRK5jY65hiF9x+tcpyuYL4Sw8do/70YnMPHiHRQEh9K5RhMH1i+Nqb2HqqG8HO3eoPw7qjYWwM4Z7/69tgZh7cOgbOPwdlGgCVfpAmdaGLwyEUSmKQqMijajtXptl15bRpGgTFMXQ8yIhLQGdXoetmW225lCZmeH0zjsU6NiR+GPHsKxUKfM5m6tXSff1Revunq05hBBCvHnyFa4QQohcy1yjpleNIhz6oCFzelXB282OxNQMFp8Ipf5Ph/l40xVCnyWYOubbQ1GgSC3oMA/G34YO86FIHdDr4O4B2PAOTCsDeybAkyumTpsvWWgsGF55OKUdSmeem3txLu22tGP7ve3o9NnvgaEuUAD7Dh0yH6eFh+O6Zi0P2rQlat48dInG6SkghBDizZCiXwghRK6nVim083Fn16h6/PquLzWKOZKWoWdtUBiNpx3Ff/UFroXHmjrm28XcxrCyP3APjLwA9T8AW3dIeg5nfoaF9eHn+nBmoWF3AJEjUjNSOf3kNNHJ0Xx24jMG7BnAjegbRp1Dl5REioeHodnfHGn2J4QQeY0U/UIIIfIMRVFoWMaF9UNrs2l4bZqUdUGvh11Xn9B2zgn6Lz3L6ZBoozQ4E6/BqQQ0+QLGXoM+m6B8J1CbwdMrsOcjw+r/+gFw5yDo/lwoKqHHaBT8MUroMROFz9vM1Gasb7uesdXGYqmx5FLUJXrs7MF3p78jNsU4X4SZlyxJ2IjhFJoy5c/N/jp3IT4w0ChzCCGEyDlS9AshhMiTqhV1ZMk7vuwdU58Old1RKRBwO4qei07TZcFJDt2MRCe1/5ulUkOpptDtV/jgFrT6CVwrQUYqBG+F1V1gRgVDH4Doe6DXozryHXYpj1Ed+U52A8girVrLwAoD2dFxB62KtUKPnnW31tF2S1vOPjlrnEkUBduWLQzN/j76CJWdHSm3bvHo/ZGkP39unDmEEELkCCn6hRBC5GllXe2Y1bMKR8c3om+tIphpVFx4+IJhqy/x02U12y49Jj0j+/c5i9dk5Qg1h8Kw4zD0ONQcBpYO8PKxoeP/nKowvzaqJxcBDP9775CJQ+dthawL8ZPfTyxtsZSSBUqSrkuneIHiRp1DZWaG08B3KbFvLw79++E89D00Dg6Zz2fEym02QgiR20jRL4QQIl8o4mTFdx0rcmJCI4Y1KIG1uZonSQrjN12j4dSjrDx1n+Q0uQfZJNwqQasfDav/3X6Fks0ABaL+uPdcj2LYBUBW+7PN19WXDe02sKzlMpwtnTPPr76xmmdJz4wyh8bBAddPP8V52LDMcwlnz3KnUWOi5s+XZn9CCJGLSNGfDfPmzcPb2xtfX19TRxFCCPE7F1sLPm5VloAP/GhTOANHay2Pnicxcdt16v14hPlH7xKXnGbqmG8njbnhfv++G6Hzoj89paCHxxfhxAwThctfNCoNZR3LZj4+/ug4k89Opv2W9qy+sZp0XbrR54zbsRN9YiLPZs/hXstWvNi0WZr9CSFELiBFfzb4+/sTHBxMUFCQqaMIIYT4f+wstTT31HN0nB9fty+PRwFLnsWn8NPeW9T94TA/7r1J1MsUU8d8O+n1cHo+KOr/fe7Q17C6Bzy78+Zz5WOOlo54O3nzMu0lk89OptuObgQ9Ne7nF9dvvsZj+jS0Hh6kR0by5LPPCO3SlYSTJ406jxBCiNcjRb8QQoh8zdJMzYA6Xhz9sCHTu/tQysWGlynpLDh6j3o/Hmbi1muExcilyG/UvUOGVX3936wC39kL82vB7g8hIfrNZsunyjuV57fWv/FF7S+wN7fn7ou7DNw3kI+OfcTThKdGmUNRFOxat6b4nt2GZn+2tqTcvMnDgYN4MvELo8whhBDi9UnRL4QQ4q2gVavoXNWTfWP8WNSvGpULFyAlXcfK0w9oOPUoY9dd4nbES1PHzP/0esO9+3/7EUQBc3vQpcPZRTC7CpycA+lyVUZ2qVVqupXuxs6OO+lRpgcKCnvu72H4weFG3eYys9nf/n049O8HGg1WNeRWSCGEMBUp+oUQQrxVVCqF5uVd2TKiDr8NqUn9Us5k6PRsuRhO8xkBDF5+jgsPZQuyHJORCrHhwN/tqKAHrTn02QSuFSElFvZ/DvNqQPA2afRnBAUsCvB5rc9Z23YtPgV9GFllJIqiABi1+P9Ps78Se/dg16ZN5vnY7dt5tmABuqQko80lhBDi72lMHUAIIYQwBUVRqFPCmTolnLn6KJYFx+6y59pTDt6I4OCNCGoWc2REo5L4lXLOLIiEEWjM4b0jkGDoIp+Wnk5gYCB169ZFq/n9Y4l1QbD3gBKN4PIaOPQtPL8P6/tDkdrQ4nvwqGa6nyGf8HbyZmWrlX86t/7Wek49OcWHvh/iYeNhlHnMPD0zf61LTCRiyhQyop7xfO06Co4ejX2H9ijqv+jvIIQQwihkpV8IIcRbr6KnPfP7VOPguAZ0r+6JVq1wJjSGAUvP0m7uCXZdeUKGTlaYjcbeE9wrGw43H2KtvMDN549z9r8Xmyo1VOkLI89Dg49BYwkPT8EvjWHzexD7yGQ/Qn6hKErml1opGSnMvzyfQw8P0WFrBxZcXkByerJx57OwoNDHH6N1dyc9IoInn35KaNduJJw6ZdR5hBBC/EGKfiGEEOJ3JQra8FNXHwI+asTAusWw1Kq5Fh6H/28XaDb9GOuCHpKa/neXpYscY24DjT4xFP8+vQ3nrqyDOdUM/QFSpBeDMZirzVncfDE1XGsYvgC4NJ+O2zpy7NExo132r6hU2LdpY2j29+F4Q7O/Gzd4+O5AHg4dSkpIqFHmEUII8Qcp+oUQQoj/x83eki/aeRP4cWNGNymFvaWWkGcJTNh0Fb+fjrD4eAgJKcbf51z8C3sP6LQA3jsKRetBejIETIHZVeH8ctDJnvDZVcqhFIubL2ZKgym4WLkQHh/O2ICxrExYSdjLMKPNozI3x2nQIEOzv759QaMh4VgAupdxRptDCCGEgRT9QgghxN9wtDZjbLPSnPy4MZ+3KUchO3OexiXz3a4b1P3xMDMO3OZ5QqqpY7593KvAOzuhx2pwLA4JkbBjFCz0g3tHTJ0uz1MUhZZeLdnRcQeDKw5Go9JwJ/0OCWkJRp9L4+CA6+efUXzHdgp98jGWPj6ZzyWcOiXN/oQQwgik6BdCCCH+hbW5hsH1ixPwUSMmd65IMWdrXiSmMevQHer+eJhvdwbzJFaKkzdKUaBcWxhxBlr8ABYFIOIarOwIq7tD1C1TJ8zzrLRWjK46mg2tN9DOsh1lHctmPncr5pZRO/2bFyuG44ABmY9TH4UT9t5Q7rVsxYstW9Hr5LYaIYTIKin6hRBCiFdkrlHTs0YRDo5rwLzeVSnvbkdiagZLToTi99MRJmy8QkhUvKljvl00ZlB7BIy6CDWHg0oDd/bB/Nqwa3zmLgEi64raFaWGeY3MxyGxIfTc1ZNB+wdx5/mdHJkzPTICTcGChmZ/n3xCaJeuJJw+nSNzCSFEfidFvxBCCPGa1CqFNpXc2DmyHssH1qBmMUfSMvSsOxdGk+nHGLH6PNfCY00d8+1i5QitJhtW/su2BX0GBP1iuN8/cDakp5g6Yb5xM/omakVN0NMguu3oxk9BP/Ey1bjNFK2qVv3fZn/vvEvY0GGk3Ltn1LmEECK/k6JfCCGEyCJFUWhQuiDrhtZm0/A6NC3ngl4Pu68+pe2cE/RbcoZT96KNehm0+BfOJaHnahiwE1wrQUosHJgIc33h+haQ9yLbWhdvzbaO22hSpAkZ+gxWBq+k3ZZ2bL+3HZ3eeJfh/1Wzv/hjx7jfoycZ8cbvLyCEEPmVFP1CCCGEEVQr6sDiAb7sHVOfTlU8UKsUjt95Rq9fTtN5wUkOBEeg00nB+cYUqw/vHYOOC8DWDV48gA3vwNIW8Oi8qdPleR42HsxsNJOfm/6Ml50X0cnRfHbiM0YcHGH0L7n+u9mfTdMmOPbvj9rGOvN5fao00xRCiH8iRb8QQghhRGVd7ZjRozJHxzekX62imGlUXHz4giErztFyVgCbLzwiLUOakr0RKhVU7g0jz0PDT0BrBWFnYHFj2DQYXhhvC7q3VV2Pumxuv5mx1cZiqbGkhlsNFEXJkbnMixWj8Ny5OL/vn3kuMSiIu81b8GKrNPsTQoi/I0W/EEIIkQMKO1rxbccKBE5ozPCGJbA113A7Ip5x6y/TcMpRVpy6T3Ka7Cv/RphZQ8OPDcV/5T6AAlc3wNzqcOgbSDHu/ehvG61ay8AKA9nRcQf9yvXLPB/0NIiNtzeSoTPuf+eK6o+PrzErVpD+9ClPPv6E0K7S7E8IIf6KFP1CCCFEDipoa86ElmUJ/KQxH7Yog7ONGeEvkvhi23Xq/XiYeUfuEpecZuqYbwc7d+g4H4YeA6/6kJ4Mx6fB7CpwbhlkpJs6YZ5WyLoQWrUWgDRdGt+d/o6vT31Nn919uBJ1JUfmdJ86FZfxH6CysSEl+Pdmf8OGS7M/IYT4L1L0CyGEEG+AnYUW/0YlOTGhMd92KI+ngyXP4lOZsu8WdX84zOQ9N4l6KR3m3wg3HxiwA3quAccSkBAFO8fAwvpw95Cp0+ULCgrdy3THRmvD9ejr9Nndh4mBE4lOijbqPCpzc5wGDzY0++vTB9Rq4o8eJaR9B6LmzjPqXEIIkVdJ0S+EEEK8QRZaNf1qe3FkfENm9PChdCEbXqak8/Oxe9T98TCfb71KWEyiqWPmf4oCZVvDiNPQ8kewKACRwbCqM6zqCpE3TZ0wT9OoNPQp14cdnXbQoUQHALbe3Uq7Le1YfWM16TrjXlWhcXTEdeLnFN+xA5smTSAjA7MihY06hxBC5FVS9AshhBAmoFWr6FTFk72j/filf3WqFClAarqOVacf0nDqUcasvcitp3KveY7TmEGtYTDqItTyB5UW7h6ABXVg5ziIjzJ1wjzN2dKZ7+p9x8pWKynnWI6XaS+ZfHYygeGBOTKfefFiFJ43F6+1a7Br2zbzfNzevcRu2ybN/oQQbyUp+oUQQggTUqkUmnkXYvPwOqwZUov6pZzJ0OnZeukxLWYGMOjXIM4/iDF1zPzPyhFaTgL/M1C2Legz4NwSmFMVTsyAtGRTJ8zTKrtUZk2bNUysNZHmRZvj5+mX+ZyxV/0BLCtXzmz4p0tIIOL7STye8DH3u3Yj4cxZo88nhBC5mRT9QgghRC6gKAq1SzixclBNdo6sR5uKbigKHLoZSZcFp+i+8BRHb0UafQ908f84lYCeq+Gd3eBWGVLi4OBXMNcXrm0C+fPPMrVKTfcy3ZnWcFrmtn6xKbG03dKWpdeWkpaRQw0tNRoc+vdDZWNDcnAwDwcMIGz4CFJCQnJmPiGEyGWk6BdCCCFymQoe9szrU5VD4xrQo3phtGqFs6ExvLMsiLZzTrDzymMydFJ85iivujDkCHRaCLbuEPsQNg6EJc0hLMjU6fKNLXe2EB4fzozzM+i8vTMnw08afQ6VuTnOQ4YYmv317m1o9nfkCCHt2vP0m29IjzZuc0EhhMhtpOgXQgghcqniBW34sWslAj5qxKB6xbAyU3P9cRzv/3aRJtOOsubsQ1LSjbsHuvgvKhX49ISR56HRZ6C1gkdnYUlTwxcAzx+YOmGe1798f76r+x2OFo7cj7vP0INDGXNkDOHx4UafS+PoiOsXE//U7O/5b2tIe/TI6HMJIURuIkW/EEIIkcu52Vsysa03gRMaM6ZpKQpYabkfncgnm6/i99MRfgkIISFF9pjPMWZW0OAjGHkBqvQFFMOl/nN9DZf+J8eZOmGepVJUdCjZgZ2ddtK3XF/UippDDw/RYWsHfr78c47czvKfZn9FVizH2d8fSx+fzOeSb9yQZn9CiHxHin4hhBAij3CwNmNM09IETmjM523K4WpnQURcCt/vvkGdyYeZfuA2zxNSTR0z/7Jzgw7zYGgAFPODjBRDk7/ZVeDcUsiQL16yytbMlgk1JrCh3QZ8XX1JyUjhScKTzHv/c4J1jRoUHPl+5uO08HDu9+jJ/W7dpdmfECJfkaJfCCGEyGOszTUMrl+cYx815McuFSnmbE1sUhqzD92hzuTDfLMjmMcvkkwdM/9yqwT9t0OvteBUChKfwc6x8HM9uHvQ1OnytFIOpVjSfAlT/KYwqsqozPOP4x/zIC5nb6dIvnUbRasl+fp1Q7O/Ef7S7E8IkS9I0S+EEELkUeYaNT18i3BwXAPm9a5KeXc7ktIyWBoYSoMpR/hww2XuRcWbOmb+pChQphWMOAWtpoClA0TdgFVdYGVniAg2dcI8S1EUWhZriZOlU+a5SWcm0WlbJ2ZdmEViWmKOzGvbuNHvzf56GZr9HT4szf6EEPmC0Yr+x48fExQUREBAgLGGFEIIIcQrUKsU2lRyY+fIeqwYWINaxR1Jy9Cz4fwjmk4/xvBV57n6KNbUMfMntRZqvgejLkLt90GlhXuH4Oe6sGMMxEeaOmGel5SeRLounTRdGouvLqb91vbsu78vR+731zg54frFFxTfsR2bRo0ym/2FdOyILiXF6PMJIcSbkO2if8GCBZQqVYrChQtTq1YtGjdu/KfnP/jgA+rUqcPDhw+zO5UQQggh/oGiKPiVLsja92qzeUQdmpYrhF4Pe649pd3cE/RbcoaT957lSLH01rN0gBbfw/tnoVx70Ovg/DKYXRWOT4e0ZFMnzLMsNZYsaLqAWY1m4WHjQURiBOOPjWfI/iHce3EvR+Y0L16cwgvmU+TXX7Hw9sahWzdU5uaZz8vfISFEXpLlol+v19OjRw/ef/99QkJC8PLywsbG5n/+EaxZsyanT59m8+bN2Q4rhBBCiFdTtYgDiwdUZ98YPzpX8UCtUjh+5xm9fzlDp/kn2Xf9KTqdFC5G51gceqyEd/eAexVIfQmHvjZ0+r+6EaRYzBJFUWhcpDFbO2xlhM8IzNXmnHl6hq7bu3Ly8ckcm9e6Vk28Nm7AadiwzHOJ584Zmv2dlWZ/Qoi8IctF/5IlS9iwYQPe3t5cunSJe/fuUalSpf95XZs2bVCr1ezatStbQYUQQgjx+sq42jK9R2WOjm9I/9pFMdeouBT2gqErz9NiZgCbzj8iLUO2KDO6onVg8GHotAjsPCD2IWwaBEuaQZgUi1llobFgeOXhbO2wlcaFG+Nq7Uq1QtVydE5FpUJlZpb5OGrePJKvXeNh/wGE+b9PSkhojs4vhBDZla2iX6VSsWHDBipWrPi3r7O2tqZEiRKESPdTIYQQwmQKO1rxTYcKnJjQmBENS2BrruFOZDwfbLhMwylHWX7yPkmpGaaOmb+oVODTA94/B40/B601PAoyFP4b3oHn902dMM/ytPVkVuNZrG27FnO14bL7dF06XwR+wY3oGzk6t8fUqRTo1dPQ7O/QIULat+fpt9+RHhOTo/MKIURWZbnov379OsWLF6ds2bL/+loHBweePHmS1amEEEIIYSQFbc35qGVZAj9pzEcty+BsY0b4iyS+3H6dej8eZt6Ru8QmpZk6Zv5iZgV+H8KoC1C1P6DA9S2GS/4PfAHJ0mQxq+zN7TN/vf7Werbc3ULPXT357vR3xKbkzJ+rxskJty+/pPj2bYZmf+npPF+9mnvNW/B8/focmVMIIbIjy0W/TqfD/L8amvyTuLi4V36tEEIIIXKenYWWEQ1LcmJCY77tWAFPB0uiE1KZsu8WdScf5oc9N4h8Kc3njMrWFdrPgWHHoVgDyEiFwFkwuwoELYaMdFMnzNMaF2lMK69W6PQ61t1aR9stbdl4eyMZupy5gsW8RInfm/0tw9y7HLr4+D81+xNCiNwiy0V/sWLFuHv3LvHx/7z/79OnT7l16xblypXL6lRCCCGEyCEWWjX9ahXl6PiGzOxRmTKFbIlPSWfhsRDq/XiEz7Zc5WF0zuyL/tZyrQj9t0Hv9eBcGhKjYdcHsKAO3N4vzf6yyNXalZ8a/MTSFkspWaAkL1Je8PWpr+mzuw9Xoq7k2LzWtWpRbONGPObMxq5du8zzL48eJTEoKMfmFUKIV5Xlor99+/akpKTwxRdf/OPrPvjgA/R6PZ06dcrqVDkuLCyMhg0b4u3tTaVKldiwYYOpIwkhhBBvlEatomMVD/aMrs/i/tWpWqQAqek6Vp95SMOpRxi99iI3n8aZOmb+oShQugUMPwmtp4KlIzy7Bb91g5WdIOK6qRPmWb6uvqxvt54JvhOw0dpwPfo6089Pz9Ft9hSVCrtmzVBUho/WusREnn7xJQ/69Sfs/fdJCZVmf0II08ly0T9+/Hjc3d2ZNWsW3bp1Y+/evSQnGy4DDA0NZfv27TRt2pQ1a9ZQrFgxRowYYbTQxqbRaJg5cybBwcEcPHiQsWPHkpCQYOpYQgghxBunUik09S7EpuF1WPteLfxKF0Snh22XHtNy5nEG/RrEufvSsMxo1FqoMQRGXYQ6o0BtBiFH4Od6sH0UvIwwdcI8SavS0te7Lzs67aBjyY58UuMTFEUBIDk9mXRdzt5KoU9Px6ZxI0Ozv4OHCGnXnqfffU/68+c5Oq8QQvyVLBf9Dg4O7Nu3j2LFirFp0ybatGnDhQsXAChZsiSdOnXi8OHDFC9enF27dmFtbW200Mbm5uZG5cqVAXBxccHR0ZEY6cAqhBDiLaYoCrWKO7FiYA12jqxHm0puKAocuhlJ159P0f3nUxy5FZmjq6dvFcsC0Pxb8D8L3h1Br4MLy2FOVQiYCmlJpk6YJzlbOvNt3W8p41gm89zci3PpvrM7556ey7F51XZ2uH31FcW3bcWmYUNDs79Vq7jXrDnRixejS0nJsbmFEOL/y3LRD1C+fHmuXLnCrFmzaNCgAY6OjqjVauzt7alduzZTp07l8uXLlClT5t8H+wcBAQG0a9cOd3d3FEVh69at//Oa+fPnU6xYMSwsLKhWrRrHjx/P0lznzp1Dp9NRuHDhbGUWQggh8osKHvbM612Vwx80pKdvYbRqhbP3Y3h3WRBtZp9gx+XHZOik+DcKx2LQfTkM3Ace1SA1Hg5/C3Oqw5UNoNOZOmGelpiWyM6Qndx5fod3973LhIAJRCZG5th85iVLUvjnBRRZthTzcoZmf5FTp5FyI2e3FRRCiP+WraIfwMrKipEjR3L48GGioqJITU0lJiaGEydOMG7cOKOs8CckJODj48PcuXP/8vl169YxZswYPvvsMy5evEj9+vVp1aoVDx8+zHxNtWrVqFChwv8cjx8/znxNdHQ0/fv3Z9GiRdnOLIQQQuQ3xZytmdylEsc/aszgesWwMlMT/CSOkWsu0njaUX4785CU9JzplP7WKVILBh2EzovBzhPiHsHmwbCkKTw8bep0eZaV1oqtHbbSvXR3FBR2h+6m3ZZ2LLu2jLSMnNuq0rp2bYpt2ojb5B9w6NcPy9+vMAVIk22thRA5TJPV3xgQEIC9vT0+Pj7/+torV67w4sUL/Pz8sjRXq1ataNWq1d8+P336dAYNGsTgwYMBmDlzJvv27WPBggX88MMPAJw/f/4f50hJSaFTp0588skn1KlT519fm/Jfl2XFxRkaG6WlpZGWlnv3Nv5PttycUcj7lBfIe5Q3yPuUc5ys1ExoUYr36hdl1ekwVpx+yIPoRD7dcpWZB2/zbp2i9PT1xMb83z9myPv0L8p1hJItUJ39GdXJmSjh52FpC3Rl25PR+Atw8MrxCPntPbJWW/Nx9Y/pULwDk4MmczX6KtPPT2fznc38UPcHyjhk7wrVf5y7TRus27T548/0yRMetmuPVd26OI0dg5mXV5bHzm/vU34l71PekFfep1fNp+izeDOeSqWifv36HDt27F9f26hRI44fP056evabpiiKwpYtW+jYsSMAqampWFlZsWHDhj/tEDB69GguXbr0Svn0ej29e/emTJkyfPXVV//6+q+++oqvv/76f87/9ttvWFlZvfLPIoQQQuQHKRlwKlLhyGMVL1INzdKs1Hrqu+rxc9NhozVxwHzCPO0FZZ9soWj0URT0ZCgaQgo243ah9qRrcm/vpNxMp9dxKe0S+5L2kaZPY6zdWGxVtm9sfrtz5yi0cROKXo9epeJFrVpEN22CLhf3whJC5B6JiYn07t2b2NhY7Ozs/vZ12Sr669WrR0BAwL++tlGjRgQEBJCRkf1L/v5/0f/48WM8PDwIDAz80wr9pEmTWL58Obdu3frXMU+cOIGfnx+VKlXKPLdy5UoqVqz4l6//q5X+woUL8+zZs3/8wza1tLQ0Dhw4QLNmzdBq5RNYbiXvU+4n71HeIO/Tm5earmPb5Sf8cjyU0OhEACy0KrpX82RwPS/c7C3+5/fI+5QFkcGoD36BKvQoAHpLR3R+E9BV6W/YDcDI3ob36GXqS24+v4lvId/Mc/se7KOhZ0PM1eY5OnfqvXs8mz6DxN8/U6tsbXEYMhj73r1Rmb/63G/D+5QfyPuUN+SV9ykuLg5nZ+d/LfqzfHn/64iOjsbS0jJH5/jPNiz/odfr/+fc36lXrx6612iMY25ujvlf/COs1Wpz9X8U/5FXcr7t5H3K/eQ9yhvkfXpztFroXcuLHjWKsu/6U+Yfvcu18DhWnH7Ib2fD6FjFg2ENSlDSxSbz91wNj2XudRWFfRKp6uVswvR5iIcP9N8Kdw/Cvs9Qnt1CvW8C6vNLoPl3UKo5vOJnoNeRn/8uOWodqWP9x+LRyfCTfBL4CZ42nkyoMYEGng1e+XPl69KWLYv1ooUknDpFxI8/kXLzJtHTZ/By+3aKb92Konm9j+v5+X3KT+R9yhty+/v0qtle+V+RuLg4Xrx48adzKSkphIWF/e12PUlJSRw7doxr16690r3/WeHs7Ixarebp06d/Oh8ZGUmhQoVyZE4hhBBC/D21SqF1RTdaVXDlxN1nzD9yj1Mh0Ww8/4hNFx7RwtuVEY1KUMmzAFsuPeFOnIqtl55I0f86FAVKNYPijeDCr3BkEjy7Db91h+INofn34FrB1CnzrHR9Oi5WLjyKf8TIwyOp71GfCTUmUNSuaI7N+Z9mf7HbdxA1cya2zZq9dsEvhBB/5ZX/JZkxYwbffPPNn86dO3cOr1dsODJo0KDXCvaqzMzMqFatGgcOHPjTPf0HDhygQ4cOOTKnEEIIIf6doijUL1WQ+qUKcuHhcxYcvceB4Aj2Xn/K3utPqexZgJBn8QDsuvqU7r5F0OvBwVqLp4P0yHklag34DoaK3eD4NDi9AEKOws/1oEpfaPw52LqaOmWe4+fpx46OO1h0ZRHLg5dzPPw4p7ed5p3y7zC44mCstDnz36eiVlOgU0fsWraA/1pUS7xwgZhlv+LywbhsNfsTQrydXrnoL1CgAEWKFMl8/PDhQ8zMzHB1/ev/I1EUBUtLS4oXL06PHj3o27dvlkPGx8dz9+7dzMehoaFcunQJR0dHihQpwrhx4+jXrx/Vq1endu3aLFq0iIcPHzJs2LAszymEEEII46laxIFf+lfndsRLms8w3Lt86dGLzOejE1JpO+dE5uP7k9u86Yh5m4U9NPsGqg+Eg1/D9c1wcSVc2wz1xkJtfzCTL1Jeh5XWijHVxtCxZEcmn51M4ONAfrn6C+cjzrO81fIcnVv1/26LjZw6jaQLF3h55AgOvXvhPHw4GgeHHM0ghMg/XrnoHz16NKNHj858rFKp8PX1faVGftl17tw5GjVqlPl43LhxAAwYMIBff/2VHj16EB0dzTfffMOTJ0+oUKECu3fvpmjRnLsESwghhBCvr3QhW2b2qMwHGy6Tofvf2wM1KoWp3XLmlsC3goMXdFsGNYfBvk8h/Bwc+Q7OL4MmXxquCFCpTJ0yT/Gy92JB0wUcDjvMT2d/op93vzeewe3rr4iYOpWEYwE8X7GS2C1bcR42DId+fVGZmQGQeOo0RadNJ9HBEXu/+m88oxAi98ryv/rLli3j008/NWaWv9WwYUP0ev3/HL/++mvma0aMGMH9+/dJSUnh/Pnz+Pn55XiuefPm4e3tja+v77+/WAghhBAAdKziwTb/un/5XAV3e3yLOb7hRPlQkZow+CB0WQL2hSEuHLa8B4sbw4OTpk6X5yiKQpMiTdjeaTtNijTJPL/lzhamBE0hPjU+R+c3L1WKIgsXUmTpEszLlEH38iWRU6YQ0qo1Lw8fQa/XEz1rFuaRkUTPmvW3/baEEG+nLBf9AwYMoGXLlsbMkuf4+/sTHBxMUFCQqaMIIYQQedL/b4h+6dELWswIYF3QQylcsktRoGJXeD/IsMpvZguPL8KyVrCuH8SEmDphnmOuNs/s4p+QlsD089NZEbyCdlvbsePejhz/b9a6Th2Kbd6E26RJaFxcSAsPJyM2loQTgaRcvw5AyvXrJJwIzNEcQoi8Ra7vEkIIIcQb52RjRkEbcyq429G9eAYVPexwtNJS0cOe+JR0Jmy6yjvLgngSm2TqqHmf1hLqj4NRFw33/CsquLEd5taAfZ9B0nNTJ8yTrLXWTKo3iaJ2RXmW9IxPT3zKgL0DuBlzM0fnVdRqCnTuRIm9e3D98gvs2rcjatasP27bUKmIktV+IcR/yXbRv3LlSlq2bImbmxvm5uao1eq/PDSy5YgQQgghfudmb8mJjxuxaWhN6hbSs2loTU592oSt/nX5vE05zDQqjt2OovmMADac+/vtgcVrsCkIbWfAsEAo2RR0aXBqLsyuAmcWQkaaqRPmOfU967O5/WZGVx2NpcaSi5EX6bGzB9+f/p7YlNgcnVtlZYVDr14knjxF8rVroNMZntDpSL52TVb7hRCZslz0Z2Rk0L59e9555x32799PREQEaWlpf3nvvV6vR/eff4iEEEIIIQBzjTrzUmlFUTDXqFGrFAbXL87uUfWpXLgAL5PT+XDjFQYtP0dEXLKJE+cThbyh7yboswkKljOs9O/5CObXglt7/rRVnPh3ZmozBlcczPaO22np1RKdXse6W+t49PJRjs+t1+v/vMr/X55+9ZV8WSaEALJR9M+fP5+dO3fi5+fH3bt3qVu3LoqikJaWRkhICFu2bKFWrVpYWlqyePFiKfqFEEII8cpKutiwcVhtPm5VFjO1isM3I2k2/RhbLj6SQsZYSjWFYScMq/9WzhB9F9b0hBXt4ckVU6fLc1ytXZnSYApLmi9hVNVRlHcun/lcZGJkjsyZcCLwz6v8/yUtPJyw94aiS0nJkbmFEHlHlov+1atXo1arWbZsGcWLF888r1ar8fLyokOHDpw8eZLBgwfz3nvvceDAAaMEFkIIIcTbQaNWMaxBCXaOqkclT3viktMZu+4y7608T+RLWfU3CrXGcJ//qItQbyyozSE0ABb6wTZ/iHti6oR5Tg23GgyuODjz8f3Y+7Ta1IovAr8gOinaaPNkrvL//26Y/yXh+HHu9+5DWni40eYVQuQ9WS76b968iZeXF15eXgCZl+dlZGT86XU//fQTNjY2TJkyJespcynZsk8IIYTIeaUL2bJ5eB0+bFEGrVrhQHAEzWcEsP3yY1n1NxYLO2j6laHTf4UugB4uroI5VVEdn4I6Q1aLs+pE+AlSdalsubuFdlvasfrGatJ16dkeV5+WRtqTJ/98O4aikHL9OlFz52V7PiFE3pXl7nqpqak4OTllPraysgIgJiaGggULZp43NzendOnSnD9/Phsxcyd/f3/8/f2Ji4vD3t7e1HGEEEKIfEujVuHfqCSNy7owfsNlrj+OY9Sai+y5+oRvO1bA2cbc1BHzB4ei0HUp1BwO+z6FR2dRB/xIE60DStFUqNL7L+8fF3+vr3dfKjhXYNKZSdyIucHks5PZdGcTn9b4lOqu1bM8rsrMjGIbN5AeEwNAeno6gYGB1K1bN7OBtj41jZgVyyn06SdG+VmEEHlTlv/V9vDwIDLyj/uTihQpAsDly5f/57WPHj0iMTExq1MJIYQQQgBQzs2Orf51Gdu0NBqVwp5rT2k+I4DdV+UydKMq7AuD9kPXZejti2CZ9hzNDn/4pSHcP2HqdHlOZZfKrGmzhom1JmJvbs+d53d4d9+7fH3q62yNq3Vzw7J8eSzLl8fC25sUDw8svL0zz1lVqYznjBmobW0Bwy0BMStWkPHypTF+LCFEHpHlor98+fI8efKEtDTD9i6NGjVCr9fz5ZdfEhv7xxYl33//PU+fPsXb2zv7aYUQQgjx1tOqVYxuWopt79elrKstMQmpjFh9gfd/u0BMQqqp4+UfigIVOpM+7CTX3XugN7eFJ5fh1zawtg9E3zN1wjxFrVLTvUx3dnbcSbfS3VBQ8LDxeKMZnq9aTcSkHwjt2pXk27ff6NxCCNPJctHfrl07UlJSOHjwIABdunShdOnSnDp1Ck9PT3x9fSlatChffPEFiqIwfvx4o4UWQgghhCjvbs/29+sxqnFJ1CqFnVee0HzGMfZee2rqaPmLxoK7hdqQPvwsVB8Eigpu7oR5NWHvJ5AYY+qEeUoBiwJ8UfsL1rVdR3/v/pnnL0Ve4uTjkzk6t2Xlymjc3Uh78JD7PXoSu3NXjs4nhMgdslz0d+3alZUrV1K4cGEAzMzMOHDgAA0bNiQhIYHz588TFhZGgQIFmDNnDr169TJaaCGEEEIIADONinHNy7B1RF1KF7LhWXwqw1adZ8zai7xIlFV/o7IuCG2nw/CTULIZ6NLg9HyYXQVOL4B0+fN+HeWcymGmNgMgTZfG16e+ZuiBoYw7Oo7H8Y9zZE7LihUotmkT1nXqoE9K4vH48Tz9fhL6VHnvhMjPslz029vb06dPHypUqJB5rnDhwhw+fJjw8HBOnjzJxYsXiYiIYMSIEUYJK4QQQgjxVyp62rNjZD1GNCyBSoGtlx7TbEYAB4MjTB0t/3EpB303Qt/N4OINyS9g78cwvxbc3PXP3eTFX0rXpVPLrRZqRc2BBwfosLUDCy8vJCUHdk3QODhQ+JdFOA0bCsDzlSt58M67pEVE/svvFELkVTnSftXNzY1atWrh4+OT2T00Otp4+5IKIYQQQvx/5ho1H7Usy+YRdSlR0JqolykMXnGOD9ZfJjYpzdTx8p+STWDocWg3y3AVQMw9WNsblreDx5dMnS5PsdRYMqHGBNa3W0/1QtVJzkhm7qW5dNzakaNhR40+n6JW4zJmDJ7z56GysSHp8mVSH9w3+jxCiNwhx/dcefz4MWPHjqVYsWI5PZUQQgghBJULF2DXqPoM9SuOosCmC49oPuMYR27JSqbRqTVQ7R0YdRHqfwBqc7h/HBY1hK0jIC5nLlPPr0o7lGZpi6X85PcTLpYuPIp/xMjDIznz5EyOzGfbuDHFNm3EfdL3WNeokSNzCCFML0tFv16vJyoqioSEhL99TUhICEOHDqVEiRLMmjXrH1+bV82bNw9vb298fX1NHUUIIYQQ/8VCq+aT1uXYOKw2xZytiYhL4d1lQUzYeIW4ZFn1NzpzW2jyBYw8BxW7AXq4tBrmVIMjP0Bq/vscmFMURaFVsVbs6LSDgRUGUtutNjVc/yjI9Ua+fcKsaFHsO3TIfJwSEsLjzz5Dlw8/uwvxtnqtov/p06f069ePAgUK4Orqip2dHaVLl2bZsmWZr4mJieG9996jbNmyLF68mJSUFOrXr8+OHTuMHt7U/P39CQ4OJigoyNRRhBBCCPEXqhV1ZPeo+gyqVwxFgXXnwmg5I4Djd6JMHS1/KlAEuiyGwYegcE1IS4Rjkw3F/8XVoNOZOmGeYaW1Ymy1sfzc7GcURQEgLjWOXrt6sf/+fqMX/wB6nY7wcR8Qu2kzoT16kBISavQ5hBBv3isX/bGxsdSpU4fffvuNly9fotfr0ev13L17l8GDB7NgwQKuXr1KxYoVWbJkCTqdjg4dOnDq1CmOHTtG69atc/LnEEIIIYT4S5Zmaia29Wbde7Up6mTF49hk+i05y6dbrhKfkm7qePmTZ3UYuA+6LYcCReHlE9g2AhY1gNAAU6fLU1TKHx/XVwav5Hr0dT449gFDDgzh3ot7mc8FRwez5OUSgqODszyXolLh+sVENAULknr3Hve7dSPuwIFs5RdCmN4rF/3Tp0/n/v37uLq6snjxYi5fvsypU6eYOHEiZmZmfP3113Tt2pUnT57Qvn17rl27xubNm6lZs2ZO5hdCCCGEeCU1ijmyZ3R93qnjBcBvZx7SYkYAJ+8+M22w/EpRoHxHeD8Imn0L5nbw9Iqh0d+a3vDsrqkT5jmDKgxiuM9wzFRmnHlyhq7buzI1aCrxqfHsDN1JaEYou0J3ZWsOq6pVKbZ5E1bVq6NLSCB85Cgip01Dny5fkAmRV71y0b9z505UKhXbtm1j4MCBVKxYkZo1a/L111/z/fffExkZyd27d/nqq6/YsmULZcuWzcncQgghhBCvzcpMw1fty7NmSC0KO1oS/iKJ3ovPMHHrNRJk1T9naMyh7ihDsz/fIaCo4dYumF8T9nwMiTGmTphnWGgsGFF5BFs7bqVR4Uak69NZHrycVptbsSPEcCvtvgf7CI4O5nr0dR7HZ62RoqZgQYosW4rjO+8AEP3LYh4OHkJGXJyxfhQhxBv0ykX/3bt3KVy4MNWrV/+f53r06AGAg4MDn376qfHSCSGEEELkgNolnNg72o9+tYoCsPL0A1rOCuB0iGwxnGOsnaHNVBhxCkq1AF06nFkAs6vAqfmQnmrqhHlGYdvCzG48O/Pxi5QXJKQbGu/FpMTQY2cPeu7sSYtNLbI8h6LVUujjCXjMmI5iZYU+PQ2VpWW2swsh3rxXLvrj4+Px9PT8y+c8PDwAKFmyJBqNxjjJhBBCCCFykLW5hm87VmD14Jp4FLAkLCaJnotO89X26ySmyqp/jilYBvqsh35bwKU8JL+AfZ8YVv5v7IAcaFCXX/1Q/wfUivovn1Mran6o/0O257Br1Ypi69fhMX06ilYLgD4jI0caCQohcsYrF/16vT6zc+jfMTMzy3YgIYQQQog3qW5JZ/aOqU+vGkUA+PXkfVrPOk7QfbnsPEeVaAzDjkO72WDtAjEhsK4v/NoGHl80dbo8oW3xtvzW5re/fK59ifa09GpplHnMS5ZE6+KS+Tjyp5948smn6JKTjTK+ECJnvdaWfUIIIYQQ+ZGthZYfOldk+cAauNlbcD86ke4LT/HdzmCS0zJMHS//Uqmh2gAYdQH8PgSNBTwIhEUNYcswiA03dcI8Q0H50/9uubuFoQeG8izJuI0qU0JCiVm5ititW7nfqzepYWFGHV8IYXyvVfQHBgaiVqv/8lAU5R+fz4+X/c+bNw9vb298fX1NHUUIIYQQRtCgdEH2jfWje3VP9HpYfCKU1rOOc+Hhc1NHy9/MbaHx5zDyPFQy9Iri8hqYUw2OTIKUeNPmy8UcLRxxsnCinGM52lu2p5xjOWy1tlioLTj79CzddnQj6GmQ0eYzL16MIkuXoHZ0JOXGDUK7diM+QLZhFCI3e62iX6/XZ+vIb/z9/QkODiYoyHj/kAohhBDCtOwstPzU1Ydl7/hSyM6ckGcJdF1wkh/23JBV/5xm7wmdF8GQw1CkNqQnwbEfDcX/hZWgkz///8/V2pX9XfezssVKapjXYGWLlRztcZR17dZRskBJniU9Y/D+wSy5ugSdXmeUOa1r1aLYpo1Y+FRCFxtL2NBhRM2dh15nnPGFEMb1ysvvR44cyckcQgghhBC5SqOyLuwf04Cvd15n84VwFh4L4dCNSKZ188GncAFTx8vfPKrBu3vgxnY48AU8vw/b34czC6HF91C8gakT5ipmajPSdGkAKIqCVq2luH1xVrdezXenv2NHyA5mXphJ2MswvqrzlVHm1Lq5UXTlSiJ++IEXa9bybO5cUkNC8Jg+zSjjCyGM55WL/gYN5B9XIYQQQrxd7K20TO9emVYV3Ph0y1XuRsbTecFJhjUozqgmpTDX/HXndGEEigLeHaB0Szj7Cxz7CSKuwor2ULoVNP8WnEuZOmWuZqW14vt631O1UFWmBE2hfYn2Rh1fZWaG25dfYlnJh6dff41ti6xvESiEyDnSyE8IIYQQ4l808y7E/jF+dKjsToZOz7wj92g/J5Br4bGmjpb/acyhzvsw6iLUGAqKGm7vgfm1YPdHkCi7LPwTRVHoWror+7rso2qhqpnn78feN9rttwU6daTkgf3YtWieeS49OtooYwshsk+KfiGEEEKIV+BgbcasnlX4uW9VnKzNuBXxkg7zApm+/xap6XIvc46zdoLWP8GI04aVfl06nF0IsyvDyTmQnmLqhLlaAYsCmb+++/wu3Xd2Z0LABBLSEowyvqZgwcxfpz19Skj7Djz56it0qalGGV8IkXVS9AshhBBCvIaWFdzYP9aPNpXcyNDpmX34Lh3mBRL8OM7U0d4OBUtD77XQfxsUqgjJsbD/c5hXA4K3QT5sHm1sN2JukJaRxp77e+i5syd3n9816vgJJ0+RERPDi7XreNC3H2lPnhh1fCHE65GiXwghhBDiNTnZmDOvd1Xm9q6Cg5WWG0/iaD/3BLMP3SEtQ1b934jiDWHoMWg/F2wKGZr9re8Py1pB+HlTp8vV2pVox7KWy3CxcuF+3H167+7Njns7jDZ+gc6dKLzwZ1T29iRfuUJo5y4knD5ttPGFEK9Hin4hhBBCiCxqW8md/WMb0KJ8IdJ1eqYfuE2n+YHcevrS1NHeDio1VO0HIy9AgwmgsYSHp+CXxrD5PYh9ZOqEuVZll8psaLeB2m61SUpP4tMTn/L1qa9JyTDObRI2fn4U27QRc+9yZDx/zsOBg4hevDhfbuMtRG4nRb8QQgghRDYUtDXn577VmNWzMvaWWq6Fx9F2znHmHblLuqz6vxnmNtDoUxh5Hnx6Gc5dWQdzqsHh7yAl3rT5cilHC0cWNF3ACJ8RKChsvL2RDbc2GG18M09PvH77DftOnUCnI3LqNJ6vXGW08YUQr0aKfiGEEEKIbFIUhQ6VPTgw1o+m5VxIy9AzZd8tuiw4yZ0IWfV/Y+w9oNPPMOQIFK0L6ckQMAXmVIULK0CXYeqEuY5apWZ45eH83OxnmhVtRs+yPY06vsrCArdJ3+P61VdYlC9Pga5djDq+EOLfZbnoX7FiBStWrCAlRTqlCiGEEEIAuNhZ8Ev/6kzv7oOdhYbLj2JpM+cEC4/dI0MnlzW/MR5V4Z1d0GMVOBSD+AjYPhIW+sG9I6ZOlyvVca/D9IbT0ag0AKRlpLEqeBVpurRsj60oCg49e+C1fh0qKysA9DodiUFB2R5bCPHvslz0v/vuu3z77beYm5sbM0+eMm/ePLy9vfH19TV1FCGEEELkEoqi0LmqJ/vHNqBRmYKkpuv4Yc9Nuv58kntRcpn5G6MoUK4d+J+FFpPAwh4irsHKjrC6O0TdMnXCXG3quan8GPQjg/YNIiIhwihjKmp15q+jf1nMg379ifhhMvq07H+xIIT4e1ku+gsWLIiDg4Mxs+Q5/v7+BAcHEyTfUgohhBDi/3G1t2DpO75M6VoJW3MNFx++oPWs4yw+HiKr/m+Sxgxq+8OoS1BzOKg0cGcfzK8Nu8ZDQrSpE+ZKNVxrYKO14WLkRbrv7M6px6eMOr4uMRGAmOXLefDuu6RHRRl1fCHEH7Jc9NerV49bt26RnJxszDxCCCGEEPmGoih0q16YfWP98CtdkJR0Hd/tukGPhacIfZZg6nhvFytHaDUZRpyBMm1AnwFBv8DsKhA4G9LlltX/1qRoE9a3XU9Zx7LEJMcw9MBQFlxaQIaR+iK4jB2Dx5zZqKytSTp3ntDOXUi8cMEoYwsh/izLRf/EiRNJTU1l3LhxxswjhBBCCJHvuBewZPm7vkzuXBEbcw3nHjyn1awAlgWGopNV/zfLuST0+g0G7ADXipASCwcmwlxfuL4VZEu5TIXtCrOy1Uq6lOqCHj3zL89nxKERxCTHGGV8u2bN8Nq4AfNSJUmPiuJB/wHErFgp2/oJYWSarP7G2NhYPv30U7755hvOnDlDnz59KFeuHNbW1n/7e/z8/LI6nRBCCCFEnqYoCj1rFKFeKWcmbLpC4N1ovt4RzJ5rT5na1YciTlamjvh2KeYH7x2Dy2vh0Dfw4gFsGACFaxl6AHhWM3XCXMFCY8FXdb6iaqGqfHvqW65GXSUhNQFHC0ejjG9erBhea9fyZOJE4nbvIXLKFGz86mPm5WWU8YUQ2Sj6GzZsiKIo6PV6Ll68yKVLl/7x9YqikJ6entXphBBCCCHyBU8HK1YNqsnqMw+ZtPsGZ0NjaDkrgE9alaVPzaKoVIqpI749VGqo0gfKdzRc4h84C8JOw+LGULEbNPkSChQ2dcpcoX2J9pRzLEdkYiSF7Yz7Z6KytsZ92jQsK1dGMbeQgl8II8ty0e/n54eiyP8pCSGEEEK8LkVR6FurKA1KF+TDjZc5HRLDxG3X2XPtKT92qURhR1n1f6PMrKHRJ1BtABz6Fi6vgasb4MYOQxPAemPB3NbUKU2ulEMpSjmUynx88vFJNt3exFd1vsLWLHt/Poqi4Ni//5/OJd+8SVp4OLZNmmRrbCHedlku+o8ePWrEGEIIIYQQb5/Cjlb8NrgWK08/YPKem5y8F03LmQF81sabXjUKywLLm2bnDp0WQM2hsO8zeHACjk+DCyug8edQpZ/h6gBBakYqEwMnEpkYyc2Ym0xrOI2yjmWNNn5GXByPRo4iLSwMp6FDKThq5J+2/BNCvLosN/ITQgghhBDZp1IpDKjjxZ7R9fH1ciAhNYNPt1yl/9KzPH6RZOp4byf3yvDOTuj5GziWgIQo2DEafq4Pdw+ZOl2uYKY2Y2bDmbhbu/Pw5UP67OrD5jubjdaET2VpiU3DhgBEL1xI2JD3SH/+3ChjC/G2kaJfCCGEECIX8HK2Zu17tZnY1htzjYrjd57RYkYA64PCpJu5KSgKlG0DI05Dy8lgUQAir8OqzrCqK0TeNHVCk6tYsCLr263Hz9OPVF0qX578ks8DPycpPftfVilaLa6ffYr71KkolpYknDxJaJcuJF29ZoTkQrxdsl30R0RE8NVXX1GnTh2cnZ0xNzfH2dmZOnXq8M033xAZGWmMnEIIIYQQ+Z5apTCoXjH2jK5P1SIFeJmSzkebrvDur0E8jU02dby3k8YMag2HUReh1ghQaeDuAVhQB3aOg/goUyc0KXtze+Y0nsPoqqNRKSq239tO7129eZn60jjjt22D17q1mBUtSvrjJzzo3ZvnGzYYZWwh3hbZKvr37NlDuXLl+Pbbbzl9+jQxMTGkpaURExPD6dOn+frrrylXrhx79+41Vl4hhBBCiHyveEEbNgyrw6ety2KmUXH0VhTNZhxj4/lHsupvKlaO0PIH8D8LZduCPgPOLYE5VeHETEh7e7+UUSkqBlcczOLmi3GycMLbyRsbrY3RxrcoXRqvjRuwadIEfVoaL/ftR6/TGW18IfK7LBf9N2/epEuXLrx48QJvb28WLlzIiRMnuHPnDidOnGDhwoV4e3vz/PlzOnfuzM2bcgmUEEIIIcSrUqsU3vMrwe5R9fApXICXyemM33CZwcvPERn39haYJudUAnquhnd2gZsPpMTBwS9hni9c2wRv8Zcyvq6+bGy/kc9rfZ7ZhPJl6ktSM1KzPbba1hbPObMp9OmnuE/5CUUldykL8aqy/Lflhx9+IDk5GX9/f65evcqQIUOoU6cOJUqUoE6dOgwZMoSrV6/y/vvvk5yczOTJk42ZWwghhBDirVDSxZZNw2rzUcsymKlVHLoZSbMZAWy9GC6r/qbkVQ+GHIWOP4OtG7x4CBsHwpLmEBZk6nQm42zpjKXGEgCdXseEgAkM2DOAx/GPsz22olLh2L8fGgeHzHMRP00h/viJbI8tRH6W5aL/8OHDODg4MH369H983bRp0yhQoACHDuW/Tqfz5s3D29sbX19fU0cRQgghRD6mUasY0bAkO0bWo6KHPbFJaYxZd4mhK88T9TLF1PHeXioVVO4FI89Dw09BawWPzsKSpoYvAJ4/MHVCkwp7GcblqMtci75Gtx3dCHgUYNTx4/btJ2bpUsLee4+o+fPlkn8h/kaWi/7IyEhKliyJVqv9x9dptVpKlSpFVFT+a3Li7+9PcHAwQUFv77e5QgghhHhzyrjasnlEHT5oVhqtWmF/cATNZxxjx+Xsr6KKbDCzhoYTYOQFqNwXUAyX+s/1hYNfQXKcqROaRFG7oqxvt54KThWIS43D/5A/sy7MIl2XbpTxbRo2oED37qDX82z2HB4NH0FGbKxRxhYiP8ly0e/g4MDDhw//9XV6vZ6HDx9SoECBrE4lhBBCCCF+p1WrGNmkFNv86+HtZsfzxDRGrrmI/+oLRMfLqr9J2blBx3kw9Bh41YeMFDgxA2ZXgXNLIcM4xW5e4mHjwfJWy+lZpicAi68u5r0D7/Es6Vm2x1aZm+P2zde4ff89ipkZ8ceOEdq1G8nSS0yIP8ly0V+nTh0iIyP/9fL+GTNmEBERQd26dbM6lRBCCCGE+H+83e3Y6l+X0U1KoVEp7Lr6hOYzAthz9Ympowk3HxiwA3quAaeSkPgMdo6Fn+vB3YOmTvfGmanN+KzWZ0zxm4KVxoqgp0GMPTLWaD0pCnTpTNE1v6F1dyctLIz7PXsRu2uXUcYWIj/IctE/fvx4AD788EO6dOnCkSNHiIiIQK/XExERwZEjR+jcuTMffvghKpUq8/VCCCGEEMI4zDQqxjYrzVb/upR1tSU6IZXhqy8wcs1Fnidkv2O6yAZFgbKtYcRpaPUTWDpA1A1Y1cVwRN4wdcI3rmWxlqxtuxZvJ28+rvlxZod/Y7AsXx6vTRuxrlcPfUoKaltbo40tRF6XrZX+uXPnolar2bp1K02bNsXd3R2NRoO7uztNmzZl69atqNVq5s6dS+3atY2ZWwghhBBC/K6Chz3b36/HyMYlUasUdlx+TLMZAey//tTU0YRaCzWHwqiLUPt9UGkNq/0L6sCOMRAfaeqEb1Qx+2KsbbOW8k7lM8+dCD9BbEr278XXODhQeOHPFPn1V2z8/DLP6zMysj22EHlZtja4HD58OEFBQfTq1QtnZ2f0en3m4ezsTN++fQkKCmLYsGHGyiuEEEIIIf6CmUbFB83LsGVEHUq52PAsPoX3Vp5n7LpLvEiUVX+Ts3SAFt+D/xko1w70Oji/DGZXhePTIS3Z1AnfmP9e4Q+ODmbU4VF039Gda8+uZX9stRrrmjUyH6eGhRHSth0JZ85me2wh8qpsFf0APj4+rFq1ioiICJ4/f05YWBjPnz8nIiKCFStW4OPjY4ycQgghhBDiFVTyLMCOkfUY3rAEKgW2XAyn+YwADt2IMHU0AeBUAnqsgnd2g1tlSH0Jh742dPq/uhGMdJ97XqFW1Lhau/I44TH99/Rn7c21RrvXHyBqzhxSQ0N5OHAg0UuWGnVsIfKKLBf9KpUKZ2dnUlL+6BJrb2+Ph4cH9vb2RgknhBBCCCFen4VWzYSWZdk0vA7FC1oT+TKFQcvPMX7DZWKT0kwdTwB41YUhR6DTIrDzgNiHsGkQLGkGYW/PqnQZxzKsbbuWxoUbk6ZL4/sz3zMhYAKJaYlGGd/t66+x79AeMjKInDKF8DFjyYhPMMrYQuQVWS76bWxsKFGiBObm5sbMI4QQQgghjKRKEQd2j6rPe37FURTYeP4RLWYEcPTW23Ufea6lUoFPD3j/HDT6HLTW8CjIUPhveBee3zd1wjfCzsyOmY1mMr76eDSKhj3399BzV0/uPr+b7bFVlpa4TZ5MoS8mglbLy337uN+9Oyn37hkhuRB5Q5aL/rJlyxIRIZeJCSGEEELkZhZaNZ+2LseGobUp5mzN07hk3lkWxMebrvAyWVb9cwUzK2jwIYy6AFX6AQpc32y45P/AF5Cc/SZ3uZ2iKAwoP4ClLZfiYuVCaGwoRx8dNdrYjr1747VyBZpChUgNCeF+t+4kXb1qlPGFyO2yXPQPGTKEhw8fskv2wBRCCCGEyPWqezmye1R9BtYthqLA2qAwWswI4MSdZ6aOJv7D1hU6zIVhx6FYA8hIhcBZMLsKBC2GjHRTJ8xxVVyqsKHdBob5DGNghYFGHduycmWKbd6EVY0amJUogXmZMkYdX4jcKltF/7Bhw+jVqxezZs0iJibGmLmEEEIIIYSRWZqp+aKdN2uH1KKIoxWPY5Ppu+QMn225SnxK/i8o8wzXitB/G/ReD06lIDEadn1g2ObvzoF83+zP0cIR/8r+qBRDqZKUnsTHxz8mLC4s22NrnJwosnQJhRctRGVmBhi29Et//jzbYwuRW2W56C9evDh79+4lKSmJcePGUbBgQQoVKkTx4sX/8ihRooQxcwshhBBCiCyqWdyJvWPqM6B2UQBWn3lIy5kBnLwnq/65hqJA6RYw4hS0mgKWjvDsFqzuCqs6Q8R1Uyd8Y2ZfmM2ukF1039mdQw8OZXs8RaNB4+CQ+ThqzhxCO3Yi8eLFbI8tRG6U5aL//v373L9/n4yMDPR6PXq9nqioqMzzf3UIIYQQQojcwcpMw9cdKvDbkJp4Oljy6HkSvX85wxfbrpEgq/65h1oLNd+DURehzkhQaeHeYfi5HmwfBS8NPbaU0GM0Cv4YJfSYiQMb34DyA6hcsDLxafGMOTqGKUFTSNMZpx+FLjmZlwcPkh4RwYP+A4j57TfZ1k/kO1ku+kNDQ1/rCAkJMWZuIYQQQghhBHVKOLN3jB99ahYBYMWpB7SadZwzIdEmTib+xLIANP8O3j8L3h1Ar4MLy2FOVTg2BdXhb7BLeYzqyHf57vJ/V2tXlrZcygDvAQCsCF7BwL0DeZrwNNtjqyws8Fq7DtuWLSEtjYhvvuXJxx+jS0rK9thC5BZZLvoVRUFRFAoXLkzRokVf6RBCCCGEELmPjbmG7ztVZOWgGrjbW/AwJpGev5zm6x3XSUrNMHU88d8ci0P3FfDuXnCvCqnxcOQ7VE8vA6B6chHuZf8S+NxGq9Iy3nc8MxvOxEZrw6WoS3Tf0Z1LkZeyPbbaxhqPGdNxmTAB1Gpit23nfs9epD58mP3gQuQCWS76vby8qFmzpjGzCCGEEEIIE6pfqiD7xvrR07cwej0sC7xP+/mnCIkzdTLxP4rWhsGHoNMiwyX/v9OjwKFv8t1q/380KdqE9W3XU86xHGC4CsAYFEXB6d13KLJsKWonJ1Ju3eJBn77okpONMr4QppTlot/e3p6iRYuiUmV5iDxv3rx5eHt74+vra+ooQgghhBBGYWuhZXKXSvz6ri+udhbcj05k9nU1k/feIjlNVv1zFZUKrJ3gv+5vV9DDk8twcZUJg+WswnaFWdl6Jb80/+VPRX9yevYLdOsaNSi2eROWlSvj8uF4VBYW2R5TCFPLcsVesWJFHr7ll7z4+/sTHBxMUFCQqaMIIYQQQhhVwzIu7BvrR+cq7uhRWBL4gNazj3PxoWxtlmvo9XD4O1DU//vcjlEQvP3NZ3pDzNXmlHEsk/n40MNDtN3SlouR2e/Ary1UiKKrV2Hfvn3mueRbt2RbP5FnZbnoHz16NE+fPmXp0qXGzCOEEEIIIXIJe0stP3auwJCyGbjYmhMSlUCXBSeZvOemrPrnBvcOweOLoP+L90Kvg/X9YP9EyMjfuzHo9XqWXl1KRGIEA/cOZPn15dnuwK+o//giJT06mrD3hnK/S1eSrr09WyWK/CPLRX+XLl2YPHky/v7+jB07lgsXLpAkXS6FEEIIIfKdCg56dr1fh05VPNDp4edj92g35wRXHr0wdbS3139W+f/t4/zJ2bCiPbzMfqf73EpRFBY1X0RLr5ak69OZem4qY4+OJS7VOM0oMmJjUczNSXv8mAe9e/Ni0yajjCvEm5Llol+tVvPJJ5+QmprK7Nmz8fX1xcbGBrVa/ZeHRqMxZm4hhBBCCPEGFbDSMqNHZRb1q4azjTl3IuPpNP8kU/fdIiVdVv3fuIxUiA0HdH//Ggt70NrAg0BY6Af3A99YvDfNWmvNT34/8WnNT9GoNBx6eIieO3tyM+Zmtsc2L16cYhs3YNOwIfrUVJ589jlPJn6BLiXFCMmFyHlZLvr1ev1rHTrdP/yDJIQQQggh8oTm5V05MNaP9j7uZOj0zD1ylw5zA7kWHmvqaG8XjTm8dwTeOwbvHSNt4CGOlvmGtIGHMs8x/BQMPQoFy0F8BCxvB4Gz821nf0VR6FW2FytbrcTd2p2wl2H03d2X8PjwbI+ttrPDc/48Co4eBYrCiw0beNCnL2mPHxshuRA5K8tFv06ne+1DCCGEEELkfQ7WZszuVYUFfariZG3Gzacv6TgvkBkHbpOaLp/53hh7T3CvbDjcfIi18gI3nz/O2XuAcykYcggqdjfc+39gouFe/+T8+yVNBecKrG+3Hj9PPzqV7ISHjYdRxlVUKpyHD6fwokWo7e1JvnaNqLnzjDK2EDnp7d1vTwghhBBCZEurim7sH+tH64qupOv0zDp0h47zAgl+bJx7qYWRmFlD50XQZhqotHBjByxqBBH5tymdvbk9cxrP4aMaH2Wee5b0jNDY0GyPbVO/Hl6bNmHXuhWFPv0k2+MJkdOk6BdCCCGEEFnmZGPO/D7VmNu7Cg5WWoKfxNFh3gnmHLpDWoas+ucaigK+g2HgPrDzhJh78EsTuLzW1MlyjEpRoVVpAUjXpfNRwEf03NmTvaF7sz22macHHtOno7axAQy3PscsX07Gy5fZHlsIY3vlon/FihXs27fvL5+Li4sjMTHxb3/v3LlzGTdu3OunE0IIIYQQeULbSu7sH9uA5t6FSMvQM+3AbTrPP8mtp1IE5Sqe1WBoAJRoDOlJsGUo7BwL6fm7KV1CWgIAiemJfBjwIZPOTCI1I9Vo4z9fuYqIHyYT2rUrybduG21cIYzhlYv+d955h0mTJv3lcwUKFKBVq1Z/+3vXrVvHrFmzXj+dEEIIIYTIMwramrOwXzVm9ayMvaWWq+GxtJtzgvlH75Iuq/65h7UT9NkIDT4GFDi3FJa2gBcPTZ0sx9ib27Oo2SIGVxwMwJqbaxiwZwCP443TiM+yShU07m6kPXjI/Z49id25yyjjCmEMr3V5v/4fOn3+03NCCCGEEOLtoCgKHSp7cGCsH03KupCaoeOnvbfo8vMp7kbKqn+uoVJDo08Mxb+lAzy+aNjW785BUyfLMRqVhtFVRzOvyTzszOy4Fn2Nbju6EfAoINtjW1asQLFNm7CuUwd9UhKPx4/n6feT0Kca72oCIbJK7ukXQgghhBBG52JnweIB1ZnWzQdbCw2Xw17QevYJFgXcI0Mni0W5Rqmmhsv93atA0nNY3RWO/AC6DFMnyzF+nn5saLeBCk4ViEuNY9q5aaTp0rI9rsbBgcK/LMJp2FAAnq9cyYN33iUtIjLbYwuRHVL0CyGEEEKIHKEoCl2qeXJgbAMalilIarqOSbtv0u3nk4RExZs6nviPAkUMDf6qDwT0cGyyofhPiDZ1shzjbuPO8lbL6efdj2kNpmU2/MsuRa3GZcwYPOfPQ2VjQ9Lly6Q9fGCUsYXIKin6hRBCCCFEjnK1t2DZO7781KUStuYaLjx8QatZx1l8PERW/XMLjTm0nQGdFoLGEu4dNlzu/+i8qZPlGDO1GR/5fkRJh5KZ5zbc3kDQ06Bsj23buDHFNm7A/YdJWPn6Zns8IbJDin4hhBBCCJHjFEWhu29h9o71o34pZ1LSdXy36wY9F53i/rMEU8cT/+HTE4YcAscSEPfI0ODv7C/wFvTvuhp1le9Pf8/g/YNZfHUxOn32mk+aeXlh37595uOUe/eImPgFSkr+3ilB5D5S9AshhBBCiDfGo4AlKwbWYFKnilibqQm6/5yWswL4NTAUnaz65w6FysN7R6BcO9Clwe7xsPk9SM3fX86UdChJm+Jt0Ol1zLowi5GHRxKbEmuUsfU6HeFjx/Fy61aKzJ1HamioUcYV4lVoXufFkZGRrFixIkvPCSGEEEIIAYZV/941i1C/lDMTNl3h5L1ovtoRzJ5rT5nS1YciTlamjigs7KH7Sjg1Fw58CVfXw9Or0GMlOJcydbocYamx5Lu631HVpSqTzkwi4FEA3Xd0Z1rDaVRwrpCtsRWVCtevvuTR6DGYR0YS1qs37pN/wK5ZMyOlF+LvvVbRf+fOHd59993/Oa8oyt8+B4bt/BRFyVpCIYQQQgiRLxV2tGLVoJqsPvOASbtvciY0hpazAvikdTn61CiCSiWfH01KUaDOSHCvChvfhagbsKgRdJgL5TuaOl2OUBSFLqW74O3kzQfHPiDsZRj99vTj/9q77/CoqsSN4987k56QQAiEDkFEQKoQSugqCEhVmihFuoS1rQ11EV3sDZUgIAiK0ruIKEoPIAEBgYD03lsSAqlzf39kyU+lCGk3M/N+nodnncmdM288uaxvzp1zh9UdRte7umZrbL977qH0zBnE9u2H34EDHPvXkyQN6E+Rp57C8LitWiZyW275p6tMmTIq7iIiIiKSo2w2g54NytG0YlGem72VDQfO85/521my/QTvPlydUoW06m+5cg1h0OqM4n8oGmb1hqND4f4RYM+ZXe/zm8qFKzOj7Qz+E/0ffjn8CynpKTkyrkdICEcH9Kfurj+4+PXXnPtiAle2bafUp59gDwzMkfcQ+btbLv0HDx7MxRgiIiIi4s7KFPZj+oD6fLXuIO8u2UX03nO0GrWaVx6sTPfw0lp8slqBUOi1EH55HdZ+mnHZ/7FN0HkSBBa3Ol2uKOBVgI+bfcyKIytoVrpZ5vMO04HNyMbWaHY7Ic8/h3+tmhx/5VVIS8Pm65vtvCI3oo38RERERCRfsNkMHm8Yxg9PNaFO2UJcSk5j2Nxt9J4Uw/GLV6yOJ3YPaPlf6PYNeAfC4XUwrjEcWG11slxjGAbNyzTP/KXTpZRLdF/Une/2fZftsQNbtyZs5gxKfvwRhmfGFRNmejqmG9wpQfKWSr+IiIiI5CthIf7MGNSAVx+sjLeHjVW7z/DAx6uYufGIClF+ULkdDFwBRe+GxDPwdXtY87Fb3NZv+h/T2Xl+Jy+veZkRa0eQnJ692+95V6iAR5EimY9PvfsuJ15+BUdSUnajimRS6RcRERGRfMduM+jfuDyLn2pMrTIFSUhO44XZv9N3cgwn41SILFf4Duj/M9R4BEwH/DwCpj8KVy5anSxXPX734wypMQQDgzl75tBzcU+OxB/JkbGT9x/gwrdTiZs3j4OP9CDl6NEcGVdEpV9ERERE8q07igQwe3AEw1pXwsvDxvI/ztDy45XM/e2oVv2t5uUHHT+HtqPA7gV/fA/jm2Xc2s9F2W12nqj5BGNbjKWQdyF2nt9Jt0Xd+OXQL9ke27t8GGUmTsAeHEzyzp0ceLgzl1atyoHU4u5U+rMhKiqKKlWqEB4ebnUUEREREZdltxkManoH3/+rETVKBRGflMazM7cy4OtNnE7Qqr+lDAPqPA59f4SgMnDhAEy4HzZ/a3WyXBVRIoKZ7WZSs0hNElITeHrF08zZPSfb4/rXr0/YnNn41KiOIy6OI4MGc2Z0FKbDkQOpxV2p9GdDZGQksbGxxMTEWB1FRERExOXdGVqAOU9E8PwDd+FpN/h55ylafryKBVuOadXfaiXvgUEroUILSEuCBUNg4ZOQ6rq/lCnmX4wvW31J7yq9KepblKalm+bIuJ7Fi1N2yhQK9XgETJOzo0dz/Lnnc2RscU8q/SIiIiLiNDzsNiKbV+C7fzWiaslALl5O5anpW3jim984eyl7m6pJNvkFQ4+Z0PwVwIDfvoIvW8KFg1YnyzWeNk+eC3+OuR3mEuIbkvn8/ov7szWuzcuLYsOHU/ydtzF8fCjQulV2Dmi96wAAV7xJREFUo4obU+kXEREREadTqVgg84Y05NkWFfGwGSzZcZKWH6/i+99PWB3Nvdls0PQFeGwO+AbDia0wrins/tHqZLkqyDso858X7V9ExwUdGbNlDOmO9GyNW7BjRyos/YnAFi0yn0s7ezZbY4r7UekXEREREafkabfx5H13smBoQyoXD+R8YgqRU38jcupvnE9MsTqee6twHwxaBSVrQ9JFmNoVlo2EbJZgZxB7LhYTk8+3fs4TPz/B+aTz2Rrvz7f0Sz15kv3tO3Di9ddxpOhnXG6NSr+IiIiIOLW7SwSxILIhT953J3abwfe/n6DlxytZsv2k1dHcW8HS8PgPED4g4/Gq9+GbhyDRtVeqXwh/gbcavYWvhy/rTqyjy3dd2Hx6c46MnRi9lvQLF7g4bTqHevYk9aR+xuWfqfSLiIiIiNPz8rDxbIuKzB/SkLtCC3D2UgqDv9nEk9M2c0Gr/tbx8IYHP4CHJoCnH+xfAeOawBHX3gi73R3tmNpmKmFBYZy+fJq+S/ry1Y6vsr3hZMGHH6L0uLHYgoJI2vo7Bx56mMT163MotbgqlX4RERERcRnVSgWx8F8NiWx+BzYDFm49TouPV7E09pTV0dxb9S4wYBkUvhPij8Gk1vDrOHDhuy5UKFSB6Q9Op3VYa9LMND7Y+AHbz23P9rgBTZoQNnsW3pUrk37+PIf79uPchAm6g4XckEq/iIiIiLgUbw87zz9QiXlDGlKhaABnLyUz4OuNPDtjC3GXU62O576KVoaBy6FKB3Ckwg8vwJx+kHzJ6mS5xs/Tj3cbv8ur9V5lUPVBVAupliPjepUuTblpUwnq2BEcDk5/8CEXvvk2R8YW16PSLyIiIiIuqUbpgiz6VyMGNS2PzYC5m4/RctRKlu3Sqr9lvAtAl6/ggbfB5gHb58AX98KZP6xOlmsMw6BbpW4MrTU087kTiSeYt2detlbnbT4+FH/7LYqNGIFPtWoU7PxwTsQVF6TSLyIiIiIuy8fTzrDWlZk1OILyIf6cik+m7+SNPD9rK/FJWvW3hGFAgyHQexEEFIOzf8D45rB9rtXJ8kSamcaLa15k+NrhvBr9KpdTL2d5LMMwKNS9G+WmT8Pm6wuA6XCQuGFDTsUVF6DSLyIiIiIur3bZQix+qjH9G4VhGDBr01Ee+HgVK3efsTqa+yrbAAavhnKNITURZj8OP7wEaa698aING81LNcdm2Fi4byGPLn6U/XH7szWmYbdn/vO58eM53Ks3p95+BzNVv9gSlX4RERERcRM+nnZebVuFmYMaUK6wHyfikuj95QaGzf2dBK36WyOgKPScD42eyXj86+fwVVuIP25prNxkM2w8fvfjTGg5gRDfEPZe3Msjix7hhwM/5Mj4jqQkAM5/9RWHHn+ctDP6xZa7U+kXEREREbcSXi6YxU81pk9EOQCmbThCq1Grid7r2vePz7fsHnD/COg+DbyD4MivMLZxxu39XFh4sXBmtZtFeLFwLqdd5oVVL/Dm+jdJSc/elQ5Fn36akp99is3fnysbN3HgoYe5/NtvOZRanJFKv4iIiIi4HT8vD0a0v5vpA+tTOtiXYxev8OiEX3l1/jYSk9OsjueeKrWBQSsgtBpcPgtTOsHqD8HhsDpZrgnxDWF8i/EMqDYAgC1ntmCS/VvvBbZoQbnZs/C+swJpZ85wqFdvzn89Rbf1c1Mq/SIiIiLituqXL8ySp5rQq0FZAL5Zf5hWn6xi3b5zFidzU8Hlof9SqPkYmA745Q2Y/ghcuWB1slzjYfPgyXueJOq+KD5s+iHedu8cGdc7LIxy06cT2KY1pKVx+v33ST18OEfGFuei0i8iIiIibs3f24M3OlRlav96lCzoy5HzV3jki/WMWLiDyyla9c9znr7QMQrafwZ2b9i9BMY1hRNbrU6Wq5qUakKZwDKZj8duHcsnv31CmiPrP4M2f39KfPghoS8PI3T4f/AqWzYnooqTUekXEREREQEiKoTw4zNN6FEvo3hNXnuQ1p+sZsOB8xYnc1P39IJ+P0HBsnDxEExoAb99bXWqPHEg7gBjtoxhwrYJDPhpAGcuZ30zPsMwCO7Vi0JdumQ+lxQbS8Ivv+REVHECKv0iIiIiIv8T4O3BW52q8XXfupQI8uHQuct0G7+O/y6K5UpKutXx3E+JmjBoJVRsBenJsPBfsCASUq9YnSxXhQWF8V6T9/Dz8GPjqY10+a4LMSdjcmTs9Lg4jj75FEcjh3L641GY6fq5dnUq/SIiIiIif9OkYhGWPNOEbnVKY5owcc0BHvx0NZsOue5ny/Mt30IZO/vf+x8wbLD5G5jYAs5n7972+V2rsFZMbzudCgUrcC7pHP1/6s+EbRNwmNnb2NDm50fAvc0BODduHEcGDCTtgn6uXZlKv4iIiIjIdQT6ePJu5+pMejyc0EBv9p9NpMvYtby9eCdJqVodzVM2GzR5DnrOA78QOLkNxjWDXYutTparwoLCmPrgVNrf0R6H6eCT3z7huZXPZWsXfsPTk2Ivv0yJDz7A8PUlce1aDjz8MFe2bcvB5JKfqPSLiIiIiNxE87uK8tPTTXn4nlI4TBi3aj8PfrqaLUcuWh3N/ZRvBoNWQam6kByXsbP/z69DuutuuOjr4cvIhiN5PeJ1vGxeNCzREMMwsj1uUNsHKTdjOl5ly5J2/ASHejzKhVmzciCx5Dcq/SIiIiIi/yDIz5MPu9ZgQq86FCngzb4ziTw0Jpr3luwiOU2r/nkqqCT0+R7qDc54vOYjmNIRLp22NFZuMgyDh+58iO86fcdDdz6U+fzZK2eztervU7Ei5WbPIuC++zBTU0n4aSmmI3sfH5D8R6VfREREROQW3V8llKXPNKFjzRI4TBizYh/tPlvDtqNxVkdzLx5e0Ppd6PwlePrDwdUwrgkcXm91slxVIqBE5ip/XHIcj37/KC+seoHE1MQsj2kvUIBSn31K6CuvUPL99zBsqoiuRjMqIiIiInIbCvp5Map7LcY+VpuQAC92n7pExzHRfPjTH6SkaZU0T1V9GAYuh5C7IOEETH4Q1o2BbKx+O4tNpzZx+vJplhxcQvdF3dlzYU+WxzJsNoJ7Poa9YMHM5069+x6XVq/JgaRiNZV+EREREZEsaFW1GD8905R2NUqQ7jD5bNle2o9ew/ZjWvXPU0XuggHL4O6HwJEGPw6DWX0gOcHqZLnq3jL3MqnVJIr6FeVg/EF6fN+DhfsW5sjY8Ut+5PykSRwZOJCzn3+uS/6dnEq/iIiIiEgWBft78dkjtRjz6D0E+3ux62QCHaOiGfXzblLTVZTyjHdAxqX+rd8DmwfEzofxzeH0TquT5aqaRWsyq90sIkpEkJSexCtrXmHE2hEkpydna9yA5s0o2LUrmCZnPvmUo0MiSY+Pz5nQkudU+kVEREREsqlNteL89EwTWlctRprDZNTPe+gYFc3OEypKecYwoN4gePwHKFACzu2BL+6FbbOtTpargn2CGXPfGIbUHIKBwZw9c/jst8+yNabN25vib7xO8TdHYnh5cWnFCg507kLSH3/kUGrJSyr9IiIiIiI5ICTAmzGP3sOnj9SioJ8nO47H0370GkYv20OaVv3zTum6Gbf1C2sKqZdhTj9Y/DykpVidLNfYbXaeqPEEY1uMpVpINQZUH5Aj4xZ8+GHKTpuKZ4kSpB4+zMFu3YlfvDhHxpa8o9IvIiIiIpJDDMOgfY0S/PRME1pUCSU13eSDn3bz0Odr2X3KtT9jnq8EFIGe86DxcxmPN4yHSa0h7qi1uXJZRIkIvm3zLUHeQQCYpsmi/YtIdaRmeUzfu++m3JzZ+DdqhJmcjK1AYE7FlTyi0i8iIiIiksOKFvBhfM/afNytBoE+Hvx+NI62n67h8xX7tOqfV2x2uO8/8MgM8AmCYxszbuu3b5nVyXLV1Vv6AczeM5thq4fRd0lfTiaezPKYHoUKUXrcWMp8NZmAxo0ynzfT07OVVfKGSr+IiIiISC4wDINOtUqx9Nmm3FupKCnpDt5dsovOY9ex9/Qlq+O5j7taZVzuX6w6XD4HUx6Cle+DG+xIX9inMAU8C7DlzBa6fteVtcfWZnksw27Hv27dzMcphw+zv207En/dkBNRJRep9IuIiIiI5KLQQB8m9q7D+52rU8Dbgy1HLtLm09V8sWo/6Q7Xv598vlCoHPRbCvf0AkxYPhKmdYPL561OlqvuLXMvM9rOoHJwZS4kX2Dwz4MZs2UM6Y7sr9Cf+Ww0KQcOcLhvX85N/BLT1M9yfqXSLyIiIiKSywzDoEud0vz0bBOaVixCSpqDNxfvpOu4dew/o1X/POHpA+0/gw5R4OEDe36CcU3h+Gark+Wq0oGlmdJmCp0rdsbE5POtnzP458GcT8reLzyKv/E6QR3aQ3o6p99/n2NPP0P6pcQcSi05SaVfRERERCSPFA/yZfLj4bz7cDUCvD3YdOgCbT5dzZdrDuDQqn/eqPVYxqp/oTCIOwwTW8LGSeDCK9Xedm9ea/AabzV6C18PX3498St7LuzJ1pg2X1+Kv/MOocP/A56eJPz4Iwe7diV5374cSi05RaVfRERERCQPGYZBt/Ay/PhMExpVCCEp1cEbi2LpPn49h85ppTRPFK8OA1fAXW0gPQUWPQ3zh0DKZauT5ap2d7Rjapup/KfBf6hXvF62xzMMg+AePSj79Vd4FC1Kyv79HOzSlSvbtuVAWskpKv0iIiIiIhYoWdCXKf3q8manqvh52dlw8DytRq3m63UHteqfF3wLQrdv4f4RYNhg61SY2ALOufZKdYVCFehSsUvm40Pxhxi2ehjxKfFZHtOvVi3C5s7Br25dvCpUwPuuu3IiquQQlX4gISGB8PBwatasSbVq1fjiiy+sjiQiIiIibsAwDB6tV5Yfn25Cg/KFuZKazvAFO3h0wq8cOe/aq875gs0GjZ6BXgvAvwic2g7jm8HORVYnyxOmafLSqpdYtH8R3b7rxs5zO7M8lkdICGW+nEjpcWOxeXlljJ+eTtqFCzkVV7JIpR/w8/Nj5cqVbNmyhV9//ZW3336bc+fOWR1LRERERNxE6WA/vu1fjzc63I2vp511+8/RatQqvv31kHZFzwthTWDQaihdH5LjYcajsHQ4pKdZnSxXGYbBq/VfpYR/CY5eOspjix9j1u5ZWf6ZMzw88ChUKPPxmVGfcKBjJy5vdu3NEvM7lX7Abrfj5+cHQFJSEunp6frLVURERETylM1m0KtBOZY83Zi65YJJTEnnlXnb6TlxA8cuXrE6nusLLA59FkH9yIzH0Z/A1x0g4ZS1uXLZ3SF3M7PdTJqWakqKI4U31r3BK2te4XJq9q40cVy5QsLyZaSdOsWhXr05/+236lgWcYrSv2rVKtq1a0eJEiUwDIP58+dfc8yYMWMICwvDx8eH2rVrs3r16tt6j4sXL1KjRg1KlSrFCy+8QEhISA6lFxERERG5dWUL+zN9YH2Gt62Cj6eNNXvP8sDHq5gRc1ilKbfZPaHVW9DlK/AKgENrYFwTOLTW6mS5Ksg7iE/v/ZSn73kam2Hju/3f8ejiRzmVmPVfeNh8fSk3fQYFHngAUlM59d+RHH/xRRxX9AusvOYUpT8xMZEaNWowevTo6359xowZPP3007zyyits3ryZxo0b07p1aw4fPpx5TO3atalateo1f44fPw5AwYIF2bp1KwcOHGDq1KmcOuXav9ETERERkfzLZjPo2yiMxU82pnbZQlxKTuPFOdvoMymGE3EqTbnu7o4Zu/sXqQyXTsLktrD2M5e+rZ/NsNGvWj8mtJxAiG8I/p7+BPsEZ2tMe4A/JUd9TNEXXwS7nfiF33Gw+yOk/KmnSe7zsDrArWjdujWtW7e+4dc/+ugj+vXrR//+/QEYNWoUP/74I59//jlvv/02AJs2bbql9woNDaV69eqsWrWKLl26XPeY5ORkkpOTMx/Hx2fsdJmamkpqauotvY8VrmbLzxlF8+QMNEfOQfPkHDRP+Z/myFqlC3rzbd86TF53iI9+3svK3Wdo+fEqXml9Fw/VyrgKFjRPuSKoHPRZgn3xs9h2zIGfXsVxaD3p7T4D7wJZGtIZ5qlm4ZpMbTUVh+kAB6Q6Ukl1pGKaJl52ryyNGfjYo3jedRcnn3uO5D/+4OBjPSm7+Hts3t45nD5nOMM8wa3nM0wnu0bIMAzmzZtHx44dAUhJScHPz49Zs2bRqVOnzOOeeuoptmzZwsqVK/9xzFOnTuHr60tgYCDx8fE0aNCAadOmUb169eseP2LECF5//fVrnp86dWrm3gAiIiIiIjnp1BX4dq+dQ5cyin6Vgg663+EgyAsOX4KFh2y0L+ugTIDFQV2NaVLu7C9UO/YtNjOdS96hbAh7kgTf0lYnyzNLrizhQNoBuvt1p5C90D+/4AY84uIo/s23XIyIIKFWzZwL6KYuX75Mjx49iIuLIzAw8IbHOcVK/82cPXuW9PR0QkND//J8aGgoJ0+evKUxjh49Sr9+/TBNE9M0GTp06A0LP8CwYcN49tlnMx/Hx8dTunRpWrZsedN/2VZLTU1l6dKltGjRAk9PT6vjyA1onvI/zZFz0Dw5B81T/qc5yl96pjv4cu0hRv2yl9iLNj7Y4cXwBytx8vAF9sQf45RvGQa3qWJ1TBf0II5jj2LM7UtA/DGa7x1JepsPMat1va1RnPF8uph8kQ8WfcDF9It8kfwFbzR4gyYlm2R5PLNrVwy7PfNx8h+78Qgtir1gwRxImzOcZZ6uXnH+T5y+9F919dKmq0zTvOa5G6lduzZbtmy55ffy9vbG+zqXonh6eubrH4qrnCWnu9M85X+aI+egeXIOmqf8T3OUP3h6QuS9FWlxd3GenLaZXScTeG7OdjztGf/d+8OO03SvVw7ThEL+npQqpKtQc0y5+hm39ZvbH2PfMjwWDoHjm6DV2+Bxe5epO9P5VMSzCDPbzuTfK//NtrPbeHrl0/Sr2o+htYbiYctCnfzT95129iwnhgzB8PSk5Kef4Hv33TmYPPvy+zzdajan2MjvZkJCQrDb7des6p8+ffqa1X8REREREVdQMbQAu04mZD5OTc/4xO65xBTafraGdqPX0Ojd5VbFc13+heHR2dD0xYzHGyfCl63gomtvTFc8oDhftfqKHpV6ADBx+0QG/DSAM5fPZGvc9Ph4DB8fUo8d49AjPbg4Z25OxJW/cfrS7+XlRe3atVm6dOlfnl+6dCkREREWpRIRERERyV2jutXEw3b9K1s9bAajutXM20DuwmaH5i9nlH/fQnD8t4zb+u352epkucrT7smwesN4v+n7+Hn4sfHURvos6UOqI+ub3XmXL0/Y7FkENG+OmZLCiVde4cR/huP406bpkn1OUfovXbrEli1bMi/BP3DgAFu2bMm8Jd+zzz7LhAkT+PLLL9m5cyfPPPMMhw8fZvDgwRamFhERERHJPR1rlWR+ZMPrfu3eSkVpU614HidyM3e2gIEroXhNuHIBvu0MK94Bh8PqZLmqVblWTG87nTsL3cnQWkPxtGXv8nd7YCClokZT5OmnwDC4OGsWhx59jNT/3Vpdss8pSv/GjRupVasWtWrVAjJKfq1atRg+fDgA3bp1Y9SoUbzxxhvUrFmTVatWsXjxYsqWLWtlbBERERGRPPH3rax+ij1Fjy/WcyZBK6a5qlBZ6Psj1H4cMGHF2xnlP/Gc1clyVVhQGDPazqB12P/fVn3nuZ3EJcdlaTzDZiNk8GBKjx+PPSiIpO3bORMVlVNx3Z5TlP5mzZpl7qz/5z+TJ0/OPGbIkCEcPHiQ5ORkNm3aRJMmWd9R8lZFRUVRpUoVwsPDc/29RERERET+rnCAF0UCvKlaIpCu5dOpVjKQIF9P/L3tbDx0gQ6j17D9WNaKmNwiTx9oNwo6jgUPX9j3C4xvCsc2WZ0sV/15hf/slbMM+WUIXb/ryrYz27I8ZkDjRpSbM4fANm0IHTYsJ2IKTlL686vIyEhiY2OJiYmxOoqIiIiIuKHiQb6seak5cwbVo2GoyZxB9djwyn0sHNqI8kX8OR6XROexa/luqy6VznU1H4H+P0NweYg7krHBX8wEME2rk+W6+OR4/Dz8OJ54nF5LejF151TMLH7fXqVKUvKjD7EHBAAZd2U7N3ky6QkJ//BKuRGVfhERERERJ+btYc+8VbVhGHh72LmjSADzhjSk2V1FSEp18K9pm3n/x104HK5fQC1VrCoMXAGV2kJ6Cnz/b5g3CFISrU6Wq8oXLM/0ttO5v8z9pDnSeHvD27yw6gUSU7P/fV+YMoXT77zLgc6dSdq9OwfSuh+VfhERERERFxTk68nE3uEMaloegKjl+xg4ZSMJSVnfbV1ugU8QdPsGWvwXDDv8PgMm3A9n91qdLFcV8CrAR80+4oXwF/AwPFhycAndF3Vn94XsFXXfWrXwKFGc1EOHOditO3GLvs+hxO5DpV9ERERExEXZbQbDWlfm42418PKw8fPO0zw0Zi0Hz7r2yrPlDAMaPgm9v4OAUDgdC+ObYez6zupkucowDHpW6cmkVpMI9QvlYPxBvtrxVbbG9K1WjbA5c/CPiMC8coXjzz3HyTffwkzVL69ulUq/iIiIiIiL61SrFLMGNSA00Js9py/RISqaNXvOWh3L9ZVrCINWQZkISEnAY87j3H1sGqS7dmGtWbQmM9vNpEvFLrxc7+Vsj+dRqBClvxhP4UGDgIxL/g/17kPq6dPZHtsdqPSLiIiIiLiBGqUL8t3QRtQqU5C4K6n0+vJXvlxzIMsbrsktKlAMei+EiH8BUOH0D9i/7QQJJy0OlruCfYIZ3mA4/p7+QMaGfKM2jeJw/OEsjWfY7RR95mlKRY3GFhDAla1bST2ctbHcjUp/NuiWfSIiIiLiTIoG+jBtQH061y6Fw4Q3FsXywuzfSU5Ltzqaa7N7QsuRpD08mVSbD7Yj62FsYzi4xupkeWbarmlM3D6Rbou68fOhn7M8ToH77iNs9ixKvPM2fnXq5GBC16XSnw26ZZ+IiIiIOBsfTzvvd67Oqw9WxmbArE1HeWT8ek4nJFkdzeWZldqy8q7XMYtWgcTT8FV7iP7ELW7rd1+Z+6hVtBaXUi/xzIpneD/mfVIdWfuYg1e5cgS1a5f5OHnvXo4PexlHovaquB6VfhERERERN2MYBv0bl2fy43UJ9PHgt8MXaf9ZNL8fvWh1NJeX6FOctD5LoHp3MNNh6XCY8RgkxVkdLVeF+ocy8YGJ9Lm7DwBfx35N3yV9OZmYvY85mA4Hx555lrh58zjQrRvJ+w/kQFrXotIvIiIiIuKmmlQswoKhjahQNICT8Ul0GbuOBVuOWR3L9Xn6Qaex0PZjsHvBrkUwvhmc3G51slzlafPk33X+zajmoyjgWYAtZ7bQ9buu/Hri1yyPadhsFHv9dTyKFCFl7z4OdulC/NKlOZja+an0i4iIiIi4sbAQf+YNieDeSkVJTnPw1PQtvPPDLtIdrn/JuaUMA+r0hb4/QlAZOL8fJtwPW6ZanSzX3VfmPma0m0Hl4MokpCTgbffO1nh+99QibO4c/OrUwZGYyLF/PcnpDz/ETEvLocTOTaVfRERERMTNFfDx5ItedXii2R0AjF25jwFfbyQ+ybVvLZcvlLwHBq2ECvdD2hWY/wR89xSkuvYeC6ULlGZKmymMuX8MNYvWzHw+3ZG1TSU9ihShzKQvCe7TB4BzX0zgcP8BpMfH50Ba56bSLyIiIiIi2G0GL7aqxCfda+LtYWPZrtN0iopm/5lLVkdzfX7B0GMWNHsZMGDTZPjyAbhwyOpkucrb7k2DEg0yH+++sJv289uz+fTmLI1neHoS+tKLlPzoQww/P3A4sPn55VRcp6XSLyIiIiIimTrULMnswREUD/Jh35lEOkZFs2r3GatjuT6bDZq9CI/NBt9gOLEFxjWB3T9ZnSzPjN48msMJh3l8yeN8teMrzCze1SCwTRvCZkzPKP8eHgCY6elZHs/ZqfSLiIiIiMhfVCsVxIKhDaldthDxSWn0mbSBCav3u21pylMV7odBq6BkbUi6CFO7wLI3IYuXvTuTdxq/Q+uw1qSb6Xyw8QOeWfEM8SlZuzzf+8478QgJyXx86u13OPHyKziSXPtjE9ej0p8NUVFRVKlShfDwcKujiIiIiIjkqKIFfJg6oB5d65TCYcLI73fy71lbSUp1/fJpuYKl4fEfILx/xuNV78E3D0PiWWtz5TI/Tz/ebfwur9Z7FU+bJ78c/oVu33Vj57md2Ro3ef9+LkydSty8eRx8pAcpR4/mUGLnoNKfDZGRkcTGxhITE2N1FBERERGRHOftYefdh6szol0V7DaDub8do/v49ZyKd7/V0jzn4Q0PfggPfZFxi7/9yzMu9z/i2t3DMAy6VerGlNZTKBlQkqOXjvLY4sfYfjbrtzP0Ll+eMl9OxB4cTPLOnRx4uDOXVq3KwdT5m0q/iIiIiIjckGEY9GkYxtd96xLk68mWIxdpP3oNW45ctDqae6jeFfr/AoUrQPwxmNQafh0PLv5Ri7tD7mZG2xk0LdWUWkVrUTm4crbG869fn7C5c/CpUR1HXBxHBg3mzOgoTIcjhxLnXyr9IiIiIiLyjxpWCGHh0IZUDA3gVHwyXcetY+5v7nWZtGVCq8CA5VClAzhS4YfnYU5/SHbtOysEeQfx6b2f8sm9n2C32QFISU/hYNzBLI3nWawYZadMoVCPR8A0OTt6NMefez4HE+dPKv0iIiIiInJLyhb2Z+6QhtxfOZSUNAfPztzKW4t3ku5w7VXnfMEnELp8BQ+8BYYdts+GCffBmd1WJ8tVNsOGv6d/5uP3Yt6j66KuLN6/OGvjeXlRbPhwir/zNoavL4EPtsmpqPmWSr+IiIiIiNyyAG8Pxveszb/urQDA+FX76Ts5hrgrqRYncwOGAQ0ioc/3EFAMzuyCL5rD9rlWJ8sTKekpHIg7wJW0K7y4+kVGrh9JSnpKlsYq2LEjFZb+RIH77st8Lu1sxkaJl9etp+yHH3F53focyW01lX4REREREbktNpvBv1vexegetfDxtLFy9xk6RUWz74xrX26eb5RtkHFbv3KNIeUSzH4clgyDdNf+xYuX3YvxLcYzoNoAAGb8MYNeP/Ti2KVjWRrvz7f0Sz1xgv3t2nN8xAjOjRqF9+nTnPvkE5e4TaVKv4iIiIiIZEnb6iWYPTiCEkE+7D+bSMfR0Sz/47TVsdxDgVDoOR8aPp3xeP0YmPwgxB+3MlWus9vsPHnPk4y5bwxB3kHsOLeDrt91ZeWRldkaN3HtOtIvXiRu+gySY2MBSN6xg8Q10TkR21Iq/SIiIiIikmVVSwax8F+NCC9XiITkNPpOjmHcyn0usUKa79k9oMXr0H0qeAfBkV8zbuu3P3sF2Bk0LtWYWW1nUT2kOvEp8bwS/QoJKQlZHq/gww9RauznYLdnfIwCwGbjjAus9qv0Z0NUVBRVqlQhPDzc6igiIiIiIpYJCfDm2/71eaRuaUwT3v5hF8/O3EpSarrV0dxDpQdh4HIIrQqJZ2BKR1j9Ebj47eiKBxRncqvJPFr5UUY2HEkBrwLZGs+w2SE9/f9vh+hwkLR9u9Ov9qv0Z0NkZCSxsbHExMRYHUVERERExFJeHjbe6lSNNzrcjd1mMG/zMbqOW8fJuCSro7mHwndAv6VQ81EwHfDL6zC9B1y5YHWyXOVp9+Slui/RrHSzzOfWHl/LhhMbbmsc0zQ588knYPtbRXaB1X6VfhERERERyRGGYdCrQTmm9KtLIT9Pfj8aR7vRa/jtsGsXz3zDyw86REG7T8HuDbt/gPHN4MTvVifLMycTT/LCqhcYsHQAX/z+BQ7z1q52SFwTTdL27ddeHeECq/0q/SIiIiIikqMi7ghh4dBG3BVagDMJyXQft57Zm45aHcs9GAbU7g39foKCZeDCQZjYAn6bYnWyPBHkHUSzUs1wmA4+3fwpQ38ZysWkizd9TeYq/9XP8v+dYTj1ar9Kv4iIiIiI5LjSwX7MHRLBA3eHkpLu4LlZW/nvoljS0l37c+b5RomaMHAl3PkApCXBwqGwYCikXrE6Wa7y9fBlZKORvBHxBt52b1YfW03XRV3ZdmbbDV9jpqaSeuLE/3+W/5oDTFJPnsRMdc5bInpYHUBERERERFyTv7cHnz9am09+2cMnv+xh4poD7D6VwOhH7iHIz9PqeK7PLxgemQ5rPoLlb8LmKXBiK3T9GoLDrE6Xqzrd2Ykqhavw7IpnOZxwmF5LevFcnefoUakHxt9W9G1eXoTNnkXa+fMApKWlER0dTcOGDfHwyKjMHoULY/PyyvPvIydopV9ERERERHKNzWbwTIuKfP7oPfh62lm95ywdotaw93TWb68mt8FmgybPwWNzwa8wnPwdxjeFP36wOlmuuyv4Lqa3nU6Lsi1Ic6Sx58Keawr/VZ7Fi+N799343n03PlWqkFyyJD5VqmQ+51msWB6nzzkq/SIiIiIikutaVyvOnCciKFnQl4PnLtMxai2/7DxldSz3cUdzGLQaSoVDUhxM6w6/vAEO176tYgGvAnzY9ENGNhzJS3VfynzeWT+fnxUq/SIiIiIikieqlAhk4dCG1AsL5lJyGv2/3siYFXvdqoBZKqgk9FkMdQdlPF79IUzpCJfOWBortxmGQYcKHfDx8AEg3ZHOMyueYcHeBRYnyxsq/SIiIiIikmcKB3jzTf96PFa/DKYJ7y35g6emb+FKimuvOOcbHl7Q5j14eCJ4+sOBVTCuCRz+1epkeWbxgcX8cvgXXo1+ldfWvkZSWpLVkXKVSr+IiIiIiOQpT7uNkR2rMbJjVTxsBgu3HqfLuLUcv+jaO8vnK9U6w4BlEFIREo7D5DawfuyNd7B3IW3C2jCk5hAMDObumctjix/jUPwhq2PlGpV+ERERERGxxGP1y/JN/3oE+3ux/Vg87UdHs+nQeatjuY+ilTKK/90PgSMNlrwIsx+HZNfeZNFus/NEjScY12IcwT7B/HHhD7ov6s7Ph34GIPZcLBMTJhJ7LtbipDlDpT8boqKiqFKlCuHh4VZHERERERFxSvXLF2ZBZEMqFSvA2UvJdB+/npkxR6yO5T68C0DnL6HVu2DzgB3z4It74fQuq5PlugYlGjCz7UzuKXoPl1Iv8cyKZ5i4bSKLDiziQPoBvj/wvdURc4RKfzZERkYSGxtLTEyM1VFERERERJxW6WA/5g6JoHXVYqSmm7ww53dGLNxBWrrD6mjuwTCg/uCMTf4KlICzuzOK/7bZVifLdaH+oUx4YAKd7+yMp82TYv7F+PHQjwD8eOhHYs/FsuPcDo5fOm5x0qxT6RcREREREcv5eXkQ1eMenm1REYDJaw/Se9IGLiSmWJzMjZSpB4NWQVgTSE2EOf1g8QuQ5tpz4GnzZPae2aQ6Unlp9UtcSL4AwPnk83Rb1I3ui7rzwJwHLE6ZdSr9IiIiIiKSL9hsBk/edydjH6uNn5ed6L3n6BAVze5Trv0Z83wloAj0nA+N/53xeMO4jE3+4o5ZGiu3vd34beyG/bpfsxt23m78dh4nyjkq/SIiIiIikq+0qlqMuUMiKB3sy+Hzl+kUFc3S2FNWx3IfNjvcNxwemQ4+QXA0BsY1hn3LrU6Wa9qWb8vUB6de92tTH5xK2/Jt8zhRzlHpFxERERGRfKdSsUAWRDaiQfnCJKakM3DKRkYv24PpBreUyzfuag0DV0Kx6nD5HEzpBKveB4dr77VgYPzlf52dSr+IiIiIiORLwf5efN2vLr0blMU04YOfdjN02mYup6RZHc19BIdBv5+gVk/AhGUjYVp3uOx6t1YM9gmmsE9hKgdXpr1veyoHV6awT2GCfYKtjpYtKv0iIiIiIpJvedptvN6hKm8/VA1Pu8H3v5+g8+frOHbxitXR3IenL3QYDe1Hg4cP7PkRxjeF45utTpajivkX46fOPzHlgSnU9a7LlAem8FPnnyjmX8zqaNmi0i8iIiIiIvneI3XLMHVAfQr7exF7Ip72n61hwwHXW23O1+7pmbHqX6gcXDwMEx+ATZPBhT5y4WX3wjD+d3m/YeBl97I4Ufap9IuIiIiIiFMILxfMwn814u4SgZxLTOHRCeuZtuGw1bHcS/EaGZ/zr9ga0pPhu6dgQSSkXLY6mdyASr+IiIiIiDiNkgV9mT04ggerFyc13WTY3G0MX7Cd1HTX3lwuX/EtCN2nwn2vgWGDLd/CxJZwbp/VyeQ6VPpFRERERMSp+HrZGf1ILZ5/4C4Avl53iF4TN3A+McXiZG7EZoPGz0KvBeBfBE5tg/HNYNf3VieTv1HpFxERERERp2MYBpHNK/BFrzr4e9lZt/8c7UevYdfJeKujuZewJjBoFZSuB8nxML0HLB0O6brDQn6h0i8iIiIiIk6rRZVQ5kU2pGxhP45euMJDY9ayZPtJq2O5l8AS0Od7qB+Z8Tj6E5jSERJOWRpLMqj0Z0NUVBRVqlQhPDzc6igiIiIiIm6rYmgBFkQ2pGGFwlxOSWfwN5v45Oc9OByus6t8vmf3hFZvQZfJ4BUAB1fDuCZwaJ3VydyeSn82REZGEhsbS0xMjNVRRERERETcWkE/L756vC59IsoB8PHPu4mc+huJybrMPE/d3QkGLIcileDSSZj8IKyLcqnb+jkblX4REREREXEJHnYbI9rfzXsPV8fTbvDD9pM8/PlajpzX7eTyVJGK0P8XqNoZzHT48WWY1RuStN+CFVT6RURERETEpXQNL830gfUJCfBm18kEOkRFs37/OatjuRfvAHh4ArT5AGyeELsAvmgOp2KtTuZ2VPpFRERERMTl1C4bzMKhDalWMojziSk8NuFXvll/yOpY7sUwoO4A6LsEAkvCub0w4T74fabVydyKSr+IiIiIiLikEgV9mTmoAe1rlCDNYfLq/O28Mm8bKWkOq6O5l1J1Mm7rV745pF6GuQPg+39DWrLVydyCSr+IiIiIiLgsXy87n3SvyYutKmEY8O2vh3ls4q+cu6TCmaf8Q+CxOdD0xYzHMRNgUmu4eMTaXG5ApV9ERERERFyaYRg80ewOJvSqQ4C3BxsOnKf96Ghij2tjuTxls0Pzl6HHLPApCMc2ZdzWb+/PVidzaSr9IiIiIiLiFu6rHMr8yAjKFfbj2MUrPPz5WhZvO2F1LPdTsWXG5f7Fa8KV8/BNZ1jxLjj0sYvcoNIvIiIiIiJuo0LRAiyIbETjO0O4kprOkG9/46Olu3E4dB/5PFWoLPT9EWo/Dpiw4i2Y2gUun7c6mctR6RcREREREbcS5OfJpD7h9G8UBsCnv+zhiW83kZicZnEyN+PpA+1GQcfPwcMn4zL/cU0yLvuXHKPSLyIiIiIibsfDbuPVtlX4oEsNvOw2ftxxiofGrOXwuctWR3M/NXtA/18guDzEHYEvW8HGL8HU1Rc5QaVfRERERETcVufapZg+qD5FCnjzx6kE2ketYe2+s1bHcj/FqsLAFVCpLaSnwKJnYN5gSNEvYbJLpV9ERERERNzaPWUK8d3QRtQoFcTFy6n0nLiBr9cdxNRKc97yCYJu30CLN8Cww+/TYcL9cG6f1cmcmkq/iIiIiIi4vWJBPswY1IBOtUqS7jAZvmAHL8/bRkqadpTPU4YBDZ+C3gvBvyic3gHjm0HsQquTOS2VfhEREREREcDH085HXWvwcptK2AyYtuEIj05Yz9lLyVZHcz/lGsHg1VAmApLjYWZP+OlVSNdmi7dLpV9EREREROR/DMNgYJM7mNgnnAI+HsQcvED7z9aw/Vic1dHcT4FiGSv+Ef/KeLz2M/i6PSSctDaXk1HpFxERERER+ZvmdxVlfmRDyof4czwuic5j1/Ld1uNWx3I/dk9oORK6fg1eBeBQNIxtDAfXWJ3Maaj0Z0NUVBRVqlQhPDzc6igiIiIiIpLD7igSwLzIhjStWISkVAf/mraZD378A4dDG/zluSodMnb3L1oFEk/DV+0h+hPd1u8WqPRnQ2RkJLGxscTExFgdRUREREREckGQrydf9glnUJPyAIxevpeBUzaRkJRqcTI3FFIB+v8M1buBmQ5Lh8OMxyBJH724GZV+ERERERGRm7DbDIa1qczH3Wrg5WHj552neGjMWg6dS7Q6mvvx8odO4+DBj8DuBbsWZezuf3K71cnyLZV+ERERERGRW9CpVilmDmpAaKA3e05fov3oaNbsOWt1LPdjGBDeD/ougaDScH4/TLgftkyzOlm+pNIvIiIiIiJyi2qWLsjCoY2oWbogcVdS6T1pA5OiD2Dqs+V5r2RtGLQKKtwPaVdg/mD47mlITbI6Wb6i0i8iIiIiInIbQgN9mD6wPg/fU4p0h8nr38Xy4pzfSU5Ltzqa+/ELhh6zoNnLgAGbJsGXD8CFQ1YnyzdU+kVERERERG6Tj6edD7pU59UHK2MzYObGo/T44ldOJ2iVOc/ZbNDsRXhsNvgWghNbYFwT2LPU6mT5gkq/iIiIiIhIFhiGQf/G5Zn0eF0CfTzYdOgCHUZHs+2odpO3RIX7My73L3EPJF2Eb7vAsjfB4d5XYKj0i4iIiIiIZEPTikVYMLQRdxTx50RcEp3HrmXBlmNWx3JPBctkbPAX3h8wYdV78M3DkHjO6mSWUekXERERERHJprAQf+ZFNuTeSkVJTnPw1PQtvLtkF+kObfCX5zy84cEPodN48PCF/cszLvc/utHqZJZQ6RcREREREckBgT6efNGrDk80uwOAz1fsY8DXG4lPSrU4mZuq0Q0GLIPCFSD+KHzZCjZ8AW52pwWVfhERERERkRxitxm82KoSn3SvibeHjWW7TtMpKpoDZxOtjuaeQqvAgOVQuT04UmHxczB3AKS4z3yo9IuIiIiIiOSwDjVLMmtwA4oF+rDvTCIdRq9h9d6zVsdyTz6B0PVraPkmGHbYNgu+uA/O7rE6WZ5Q6RcREREREckF1UsVZOG/GnJPmYLEJ6XR/+vfWH7cwHSzy8vzBcOAiKHQZxEEFIMzO2F8M9gx3+pkuU6lX0REREREJJcULeDDtIH16VqnFA4T5h+y8+K8HSSluvdt5CxTNiLjtn5lG0HKJZjVG5a8DOmuu++CSr+IiIiIiEgu8vaw8+7D1Xm1zV3YMJm3+Tjdx6/ndHyS1dHcU4FQ6LUAGj6d8Xh9FExuC/HHATAOrKR57EsYB1ZalzEHqfSLiIiIiIjkMsMw6N2gLIMrOwjy9WDLkYu0G72GrUcuWh3NPdk9oMXr0O1b8A6EI+szbuu3fyW25SMJTD6ObflIl9jpX6VfREREREQkj9xV0GTOoPrcWTSAU/HJdBm3jnmbj1ody31VbgsDV0BoVUg8A193wHZiM0DG/+77xdp8OUClX0REREREJA+VLezH3CER3F+5KClpDp6ZsZW3F+8k3eH8q8pOqfAd0G8pVH8E+P85MA07LHP+1X6VfhERERERkTxWwMeT8T3rMLR5BQDGrdpPv69iiLviuhvK5WteflCt81+eMsx0OO78q/0q/SIiIiIiIhaw2Qyee+AuPnukFj6eNlb8cYZOUdHsO3PJ6mjuxzRh+Ugw7H993gVW+1X6RURERERELNSuRglmD46gRJAP+88m0jEqmuV/nLY6lnvZ90vGqr75t1spusBqv0q/iIiIiIiIxaqWDGLB0EbUKVuIhKQ0+k2OYfyqfZhOvMLsNEwzYzX/hvXY5tSr/Sr9IiIiIiIi+UCRAt5MHVCf7uGlcZjw1uJdPDtzK0mp6f/8Ysm69BSIOwY4bnCAA+KPZRznhDysDiAiIiIiIiIZvDxsvP1QNaqUCOT172KZt/kY+89cYlzPOhQL8rE6nmvy8IaByyHxLACpaWlER0fTsGFDPD3+V5n9i2Qc54RU+rMhKiqKqKgo0tP1mzcREREREckZhmHQq0E5KhQJYMjU39h6NI72o9cwrmdtapUpZHU81xRUKuMPQGoqcX7HoHgN8PS0NlcO0OX92RAZGUlsbCwxMTFWRxERERERERcTUSGEhZGNuCu0AKcTkuk2bj2zNx21OpY4GZV+ERERERGRfKpMYT/mDImgZZVQUtIdPDdrKyMXxZKWfqPPn4v8lUq/iIiIiIhIPhbg7cHYx2rz5H13AjBhzQEenxxD3OVUi5OJM1DpFxERERERyedsNoNnW1RkzKP34OtpZ/Wes3QcE83e0wlWR5N8TqVfRERERETESbSpVpzZTzSgZEFfDpxNpGPUWpbtOmV1LMnHVPpFREREREScyN0lglg4tCF1w4K5lJxGv6828vmKfZimaXU0yYdU+kVERERERJxM4QBvvulXj0frlcE04d0lu3h6xhaSUnU7cfkrlX4REREREREn5OVh481O1fhvx6p42AwWbDlOl7HrOBF3xepoko+o9IuIiIiIiDixnvXL8k3/egT7e7HtWBztPotm06HzVseSfEKlX0RERERExMnVL1+YBZENqVSsAGcvJfPI+F+ZGXPE6liSD6j0i4iIiIiIuIDSwX7MeSKC1lWLkZLu4IU5v/P6dztIS3dYHU0spNIvIiIiIiLiIvy9PYjqcQ/P3F8RgEnRB+kzKYaLl1MsTiZWUekXERERERFxITabwVP338nYx2rj52Vnzd6zdIiKZvepBKujiQVU+kVERERERFxQq6rFmDskglKFfDl07jKdoqJZGnvK6liSx1T6RUREREREXFSlYoEsHNqI+uWDSUxJZ+CUjYxetgfTNK2OJnlEpV9ERERERMSFBft7MaVfPXo1KItpwgc/7eZf0zZzJSXd6miSB1T6RUREREREXJyn3cYbHaryVqdqeNgMFv1+gs5j13Ls4hWro0kuU+kXERERERFxEz3qlWHqgPoU9vdix/F4OoxeQ8zB81bHklyk0i8iIiIiIuJG6oYFs2BoQ6oUD+TspRR6fLGeaRsOWx1LcolKv4iIiIiIiJspVciP2U804MFqxUlNNxk2dxuvLdhOarrD6miSw1T6RURERERE3JCflweje9TiuZYVAfhq3SF6TdzAhcQUi5NJTlLpFxERERERcVOGYTD03jsZ37M2/l521u0/R/uoNew6GW91NMkhKv0iIiIiIiJuruXdxZgX2ZAywX4cOX+Fh8as5ccdJ62OJTlApV9ERERERESoGFqABZENibijMJdT0hk0ZROf/LwHh8O0Oppkg0q/iIiIiIiIAFDI34uv+9alT0Q5AD7+eTeRU3/jckqatcEky1T6RUREREREJJOH3caI9nfz3sPV8bQb/LD9JA9/vo6jFy5bHU2yQKVfRERERERErtE1vDTTBtQnJMCLnSfiaT86ml/3n7M6ltwmlX4RERERERG5rjrlglk4tBFVSwZyPjGFRyf8yjfrD1kdS26DSr+IiIiIiIjcUImCvswaFEG7GiVIc5i8On87r87fRmq6w+pocgtU+kVEREREROSmfL3sfNq9Ji+0ugvDgG/WH+axCb9y7lKy1dHkH6j0i4iIiIiIyD8yDIMhzSowoVcdArw9+PXAedqPjib2eLzV0eQmVPpFRERERETklt1XOZR5QyIoV9iPYxev8PDna/lh2wmrY8kNqPSLiIiIiIjIbbkztAALIhvR+M4QrqSm88S3v/Hx0t04HKbV0eRvVPpFRERERETktgX5eTKpTzj9GoUB8Mkve3ji200kJqdZnEz+TKVfREREREREssTDbuM/bavwfufqeNlt/LjjFA9/vpYj5y9bHU3+R6VfREREREREsqVLndJMG1ifIgW82XUygfaj17B231mrYwkq/X9x+fJlypYty3PPPWd1FBEREREREadSu2whvhvaiOqlgrhwOZWeEzcwZd1BTFOf87eSSv+fvPnmm9SrV8/qGCIiIiIiIk6pWJAPMwc1oGPNEqQ7TP6zYAcvz9tOSprD6mhuS6X/f/bs2cOuXbto06aN1VFERERERESclo+nnY+71WRY60oYBkzbcJhHJ6zn7KVkq6O5Jaco/atWraJdu3aUKFECwzCYP3/+NceMGTOGsLAwfHx8qF27NqtXr76t93juued4++23cyixiIiIiIiI+zIMg0FN7+DL3uEU8PYg5uAFOoyOZsfxOKujuR2nKP2JiYnUqFGD0aNHX/frM2bM4Omnn+aVV15h8+bNNG7cmNatW3P48OHMY2rXrk3VqlWv+XP8+HEWLFhAxYoVqVixYl59SyIiIiIiIi6veaWizItsSPkQf45dvMLDn69l0e/HrY7lVjysDnArWrduTevWrW/49Y8++oh+/frRv39/AEaNGsWPP/7I559/nrl6v2nTphu+fv369UyfPp1Zs2Zx6dIlUlNTCQwMZPjw4dc9Pjk5meTk/780JT4+HoDU1FRSU1Nv+/vLK1ez5eeMonlyBpoj56B5cg6ap/xPc+QcNE/OwV3nqWwhb2YNrMszs35n1Z5zDJ26mR3HLvL0vRWw2Qyr413DWebpVvMZppNtpWgYBvPmzaNjx44ApKSk4Ofnx6xZs+jUqVPmcU899RRbtmxh5cqVtzX+5MmT2b59Ox988MENjxkxYgSvv/76Nc9PnToVPz+/23o/ERERERERd+Aw4btDNpadyLjgvFohB4/d6cDHbnEwJ3X58mV69OhBXFwcgYGBNzzOKVb6b+bs2bOkp6cTGhr6l+dDQ0M5efJkrrznsGHDePbZZzMfx8fHU7p0aVq2bHnTf9lWS01NZenSpbRo0QJPT0+r48gNaJ7yP82Rc9A8OQfNU/6nOXIOmifnoHmCtsD8Lcd5ZUEs2y7AhIMF+PzRWpQNzj+Lp84yT1evOP8nTl/6rzKMv14WYprmNc/dij59+vzjMd7e3nh7e1/zvKenZ77+objKWXK6O81T/qc5cg6aJ+egecr/NEfOQfPkHNx9nrqEl+XOYkEM/Hoje04n8vDYXxnz6D00rBBidbS/yO/zdKvZnGIjv5sJCQnBbrdfs6p/+vTpa1b/RURERERExHo1Sxfku381okbpgsRdSaXXlxuYFH0AJ/v0uVNw+tLv5eVF7dq1Wbp06V+eX7p0KRERERalEhERERERkZsJDfRhxsD6PHRPSdIdJq9/F8tLc7aRnJZudTSX4hSX91+6dIm9e/dmPj5w4ABbtmwhODiYMmXK8Oyzz9KzZ0/q1KlDgwYNGD9+PIcPH2bw4MEWphYREREREZGb8fG082GXGlQpHshbi3cyY+MR9p65xNjHalOkwLUfqZbb5xSlf+PGjTRv3jzz8dVN9Hr37s3kyZPp1q0b586d44033uDEiRNUrVqVxYsXU7ZsWasii4iIiIiIyC0wDIP+jctzZ2gBhk79jU2HLtB+9BrG96xDtVJBVsdzek5xeX+zZs0wTfOaP5MnT848ZsiQIRw8eJDk5GQ2bdpEkyZNcj1XVFQUVapUITw8PNffS0RERERExJU1rViEBZENKV/EnxNxSXQeu5aFW49bHcvpOUXpz68iIyOJjY0lJibG6igiIiIiIiJOr3yRAOZHNqT5XUVITnPw5LTNvLtkF+kObfCXVSr9IiIiIiIikm8E+ngyoXc4g5veAcDnK/Yx4OuNJCSlWpzMOan0i4iIiIiISL5itxm81LoSn3SvibeHjWW7TtNpzFoOnE20OprTUekXERERERGRfKlDzZLMGtyAYoE+7D19iQ6j17Bq9xmrYzkVlX4RERERERHJt6qXKsjCoQ2pVaYg8Ulp9Jm0gQmr92Oa+pz/rVDpFxERERERkXytaKAP0wfWp0vtUjhMGPn9Tp6f/TvJaelWR8v3VPqzQbfsExERERERyRveHnbe61yd4W2rYDNg9qajdB+/ntPxSVZHy9dU+rNBt+wTERERERHJO4Zh0LdRGF/1rUuQryebD1+k/ehoth65aHW0fEulX0RERERERJxK4zuLsCCyIRWKBnAyPoku49Yxf/Mxq2PlSyr9IiIiIiIi4nTKhfgzb0gE91cuSkqag6dnbOHtH3aS7tAGf3+m0i8iIiIiIiJOqYCPJ+N71iGy+R0AjFu5n35fxRB3JdXiZPmHSr+IiIiIiIg4LZvN4PkHKvHZI7Xw8bSx4o8zdBoTzf4zl6yOli+o9IuIiIiIiIjTa1ejBLMHR1AiyIf9ZxLpEBXNij9OWx3Lcir9IiIiIiIi4hKqlgxiwdBG1ClbiISkNPpOjmH8qn2Ypvt+zl+lX0RERERERFxGkQLefDugHt3qlMZhwluLd/HszK0kpaZbHc0SKv3ZEBUVRZUqVQgPD7c6ioiIiIiIiPyPt4eddx6uxuvt78ZuM5i3+Rjdxq/nVHyS1dHynEp/NkRGRhIbG0tMTIzVUURERERERORPDMOgd0Q5pvStS0E/T7YeuUi7z9aw+fAFq6PlKZV+ERERERERcVkRFUJYGNmIiqEBnE5Iptv49czZdNTqWHlGpV9ERERERERcWpnCfswd0pAWVUJJSXPw71lbGbkolrR0h9XRcp1Kv4iIiIiIiLi8AG8Pxj1WmyfvrQDAhDUH6PvVRuIup1qcLHep9IuIiIiIiIhbsNkMnm15F1E97sHX086q3WfoOCaavacvWR0t16j0i4iIiIiIiFt5sHpxZj/RgJIFfTlwNpFOUdEs33UagG3H4hi9w8a2Y3EWp8wZKv0iIiIiIiLidu4uEcSCoQ2pWy6YhOQ0+n4Vw+cr9jFv83H2xNuYv+WE1RFzhEq/iIiIiIiIuKWQAG++6V+PDjVLYJrw7pJdzNiYsbP/99tOsv1YHNuOxnH0wmWLk2adh9UBnFlUVBRRUVGkp6dbHUVERERERESywMvDxoItxzMfp6SbAJxLTKHtZ2synz/4zoN5ni0naKU/GyIjI4mNjSUmJsbqKCIiIiIiIpJFo7rVxMNmXPdrHjaDUd1q5m2gHKSVfhEREREREXFrHWuVpELRgL+s7F81P7IhVUsGWZAqZ2ilX0REREREROR/DOOv/+vstNIvIiIiIiIibq9wgBdFArwpFuRNZe8L7EwuxMm4ZAoHeFkdLVtU+kVERERERMTtFQ/yZc1LzTEc6fzwww+MbF0P02bH28NudbRs0eX9IiIiIiIiIoC3hx3jf9f1G4bh9IUfVPpFREREREREXJZKv4iIiIiIiIiLUukXERERERERcVEq/SIiIiIiIiIuSqVfRERERERExEWp9GdDVFQUVapUITw83OooIiIiIiIiItdQ6c+GyMhIYmNjiYmJsTqKiIiIiIiIyDVU+kVERERERERclEq/iIiIiIiIiItS6RcRERERERFxUSr9IiIiIiIiIi5KpV9ERERERETERan0i4iIiIiIiLgolX4RERERERERF6XSLyIiIiIiIuKiVPpFREREREREXJRKv4iIiIiIiIiLUukXERERERERcVEq/SIiIiIiIiIuSqU/G6KioqhSpQrh4eFWRxERERERERG5hkp/NkRGRhIbG0tMTIzVUURERERERESu4WF1AFdgmiYA8fHxFie5udTUVC5fvkx8fDyenp5Wx5Eb0Dzlf5oj56B5cg6ap/xPc+QcNE/OQfPkHJxlnq72z6t99EZU+nNAQkICAKVLl7Y4iYiIiIiIiLiThIQEgoKCbvh1w/ynXwvIP3I4HBw/fpwCBQpgGIbVcW4oPj6e0qVLc+TIEQIDA62OIzegecr/NEfOQfPkHDRP+Z/myDlonpyD5sk5OMs8maZJQkICJUqUwGa78Sf3tdKfA2w2G6VKlbI6xi0LDAzM1z+8kkHzlP9pjpyD5sk5aJ7yP82Rc9A8OQfNk3Nwhnm62Qr/VdrIT0RERERERMRFqfSLiIiIiIiIuCiVfjfi7e3Na6+9hre3t9VR5CY0T/mf5sg5aJ6cg+Yp/9McOQfNk3PQPDkHV5snbeQnIiIiIiIi4qK00i8iIiIiIiLiolT6RURERERERFyUSr+IiIiIiIiIi1LpFxEREREREXFRKv0urly5chiG8Zc/L7300k1fY5omI0aMoESJEvj6+tKsWTN27NiRR4ndV3JyMjVr1sQwDLZs2XLTY/v06XPNvNavXz9vgrq525knnUt5r3379pQpUwYfHx+KFy9Oz549OX78+E1fo/Mpb2VljnQu5a2DBw/Sr18/wsLC8PX15Y477uC1114jJSXlpq/TuZS3sjpPOp/y1ptvvklERAR+fn4ULFjwll6jcynvZWWenOlcUul3A2+88QYnTpzI/PPqq6/e9Pj33nuPjz76iNGjRxMTE0OxYsVo0aIFCQkJeZTYPb3wwguUKFHilo9v1arVX+Z18eLFuZhOrrqdedK5lPeaN2/OzJkz+eOPP5gzZw779u2jc+fO//g6nU95JytzpHMpb+3atQuHw8G4cePYsWMHH3/8MWPHjuXll1/+x9fqXMo7WZ0nnU95KyUlhS5duvDEE0/c1ut0LuWtrMyTU51Lpri0smXLmh9//PEtH+9wOMxixYqZ77zzTuZzSUlJZlBQkDl27NhcSCimaZqLFy82K1WqZO7YscMEzM2bN9/0+N69e5sdOnTIk2zy/25nnnQu5Q8LFiwwDcMwU1JSbniMzidr/dMc6VzKH9577z0zLCzspsfoXLLeP82TzifrTJo0yQwKCrqlY3UuWedW58nZziWt9LuBd999l8KFC1OzZk3efPPNm172deDAAU6ePEnLli0zn/P29qZp06asXbs2L+K6nVOnTjFgwACmTJmCn5/fLb9uxYoVFC1alIoVKzJgwABOnz6diynldudJ55L1zp8/z7fffktERASenp43PVbnkzVuZY50LuUPcXFxBAcH/+NxOpes9U/zpPPJeehcyt+c7VxS6XdxTz31FNOnT2f58uUMHTqUUaNGMWTIkBsef/LkSQBCQ0P/8nxoaGjm1yTnmKZJnz59GDx4MHXq1Lnl17Vu3Zpvv/2WZcuW8eGHHxITE8O9995LcnJyLqZ1X1mZJ51L1nnxxRfx9/encOHCHD58mAULFtz0eJ1Pee925kjnkvX27dvHZ599xuDBg296nM4la93KPOl8cg46l/I/ZzuXVPqd0IgRI67Z3OPvfzZu3AjAM888Q9OmTalevTr9+/dn7NixTJw4kXPnzt30PQzD+Mtj0zSveU5u7Fbn6LPPPiM+Pp5hw4bd1vjdunXjwQcfpGrVqrRr144ffviB3bt38/333+fSd+SacnueQOdSTridv/MAnn/+eTZv3sxPP/2E3W6nV69emKZ5w/F1PmVfbs8R6FzKCbc7TwDHjx+nVatWdOnShf79+990fJ1LOSO35wl0PmVXVuboduhcyhm5PU/gPOeSh9UB5PYNHTqU7t273/SYcuXKXff5qzt/7t27l8KFC1/z9WLFigEZv70qXrx45vOnT5++5jdZcmO3OkcjR45k/fr1eHt7/+VrderU4dFHH+Wrr766pfcrXrw4ZcuWZc+ePVnO7I5yc550LuWc2/07LyQkhJCQECpWrEjlypUpXbo069evp0GDBrf0fjqfbl9uzpHOpZxzu/N0/PhxmjdvToMGDRg/fvxtv5/OpazJzXnS+ZQzsvPf4lmhcylrcnOenO1cUul3Qlf/YykrNm/eDPCXH84/CwsLo1ixYixdupRatWoBGbtZrly5knfffTdrgd3Qrc7Rp59+ysiRIzMfHz9+nAceeIAZM2ZQr169W36/c+fOceTIkRvOq1xfbs6TzqWck52/866uHt/OJZE6n25fbs6RzqWcczvzdOzYMZo3b07t2rWZNGkSNtvtXxyqcylrcnOedD7ljOz8nZcVOpeyJjfnyenOJYs2EJQ8sHbtWvOjjz4yN2/ebO7fv9+cMWOGWaJECbN9+/Z/Oe6uu+4y586dm/n4nXfeMYOCgsy5c+ea27ZtMx955BGzePHiZnx8fF5/C27nwIED190V/s9zlJCQYP773/82165dax44cMBcvny52aBBA7NkyZKaozxyK/NkmjqX8tqvv/5qfvbZZ+bmzZvNgwcPmsuWLTMbNWpk3nHHHWZSUlLmcTqfrJOVOTJNnUt57dixY2aFChXMe++91zx69Kh54sSJzD9/pnPJWlmZJ9PU+ZTXDh06ZG7evNl8/fXXzYCAAHPz5s3m5s2bzYSEhMxjdC5Z73bnyTSd61xS6XdhmzZtMuvVq2cGBQWZPj4+5l133WW+9tprZmJi4l+OA8xJkyZlPnY4HOZrr71mFitWzPT29jabNGlibtu2LY/Tu6cblck/z9Hly5fNli1bmkWKFDE9PT3NMmXKmL179zYPHz6c94Hd1K3Mk2nqXMprv//+u9m8eXMzODjY9Pb2NsuVK2cOHjzYPHr06F+O0/lknazMkWnqXMprkyZNMoHr/vkznUvWyso8mabOp7zWu3fv687R8uXLM4/RuWS9250n03Suc8kwzX/YOUdEREREREREnJJ27xcRERERERFxUSr9IiIiIiIiIi5KpV9ERERERETERan0i4iIiIiIiLgolX4RERERERERF6XSLyIiIiIiIuKiVPpFREREREREXJRKv4iIiIiIiIiLUukXERGRfGv79u3Y7XYGDx58W69bsWIFhmHQrFmzHMsSHx9PoUKFaNSoUY6NKSIikttU+kVERFzA4cOHefbZZ6latSr+/v74+vpSpkwZIiIieP755/nxxx+veU2zZs0wDAPDMBg1atQNx+7fvz+GYTBixIi/PH+1WP/5j81mIzAwkHvuuYfhw4dz8eLFbH1fL774Ina7nWHDhmVrnKsOHjx4TWbDMLDb7QQHB9O4cWOioqJIS0u75rWBgYE8+eSTREdHs2DBghzJIyIikts8rA4gIiIi2bNs2TI6duxIQkICdrud0qVLU7RoUc6fP8/69etZt24dkyZN4uzZszcc45133mHgwIH4+fllKUPDhg0BME2To0ePsmXLFjZv3syUKVOIjo6mRIkStz3m6tWrWbx4MX369KFs2bJZynUzderUwdvbG4CUlBQOHTrEmjVrWLNmDbNnz+bHH3/Ey8vrL695+umn+eCDDxg2bBjt27fHMIwczyUiIpKTtNIvIiLixOLj4+nWrRsJCQk8+OCD7Nu3jwMHDvDrr7+yZ88ezp8/z+TJk6lXr94Nx7Db7Zw6dYoxY8ZkOcfVshwdHc2hQ4dYv349xYsX5+DBgzz//PNZGnP06NEA9O7dO8u5bmbWrFmZuTds2MDJkyeZOnUqdrudFStWMGHChGteU6hQIdq1a8fOnTtZtmxZruQSERHJSSr9IiIiTmzx4sWcPXuWwMBAZs6cec2KeMGCBenduzfff//9Dcd45JFHAHjvvfdITEzMkVx169blv//9LwALFy4kPT39tl5/5swZ5s+fT4kSJWjSpEmOZPonhmHwyCOP8NBDDwHw888/X/e47t27A1z3lwIiIiL5jUq/iIiIE9u/fz8AFStWzPKl+Q888AARERGcOXMmc3U9J4SHhwNw6dKlm3604HrmzZtHSkoKrVu3xma78X+uzJs3j4iICPz9/SlcuDBt27Zl48aN2cp99RcnKSkp1/36Aw88gIeHB/Pnzyc5OTlb7yUiIpLbVPpFREScWGBgIAB79uzJ1qZ5r7/+OgDvv/8+ly5dyoloXL58OfOfb/cXEqtWrQIyrhi4kffee4+HHnqIdevWERQURFhYGCtXrqRRo0asWbMma6Eh85cGlSpVuu7XfX19qVatGklJScTExGT5fURERPKCSr+IiIgTa9myJTabjbi4OO6//37mzJlDXFzcbY9z//3306RJE86dO8enn36aI9l++OEHAMqXL0+BAgVu67Vr164FoHbt2tf9+ubNm3n55ZcxDIPRo0dz7NgxNm7cyIkTJ+jYsSNvvPHGbb1fSkoKe/bs4amnnmLFihUEBQURGRl5w+OvXsWQnV8uiIiI5AWVfhERESdWsWLFzM/Ob9q0ic6dO1OoUCEqVarE448/zowZM275EvSrq/0ffvgh8fHxWcpzdff+jz76iHfffRfgtm+3Z5omR44cAaB48eLXPeajjz4iPT2dzp07ExkZmbmLfkBAAJMnT6ZQoUL/+D5hYWGZt+zz9vamYsWKfPrpp3Tt2pX169cTFhZ2w9dezXXo0KHb+t5ERETymkq/iIiIk3v55ZdZtmwZbdq0wcvLC9M0+eOPP5g8eTLdu3enYsWKrFix4h/HadasGc2aNeP8+fOMGjXqtjJcLc82m43SpUvz73//m8DAQD777DP69+9/W2NdvHiRtLQ0AIKDg697zE8//QTAE088cc3XfHx86Nu37z++T506dWjYsCENGzakQYMGlC1bFpvNxvfff89XX32Fw+G44Wuv5jpz5sw/vo+IiIiVVPpFRERcQPPmzfn++++5ePEiq1at4v3336d58+YYhsHhw4dp06YNu3bt+sdxrl4W//HHH9/WHgFXy3N4eHjmKntQUBCNGze+7e8lKSkp85+9vLyu+frFixc5ffo0AJUrV77uGDd6/s/+fMu+tWvXcvDgQXbu3EnlypV55513bnqrQV9fXwCuXLnyj+8jIiJiJZV+ERERF+Lr60vjxo157rnnWLZsGatWrcLf358rV67w4Ycf/uPrGzduzP3338/Fixf5+OOPb/l9/36/+9dee429e/fSqlWr2965/8+r+9fbn+DPGw0WKVLkumOEhobe1nteVbFiRSZNmgTA6NGjOXXq1HWPO3/+PAAhISFZeh8REZG8otIvIiLiwho1asSQIUMA2LBhwy295upn+0eNGsWFCxdu+z29vLwYMWIEHTp04OTJk7z00ku39Xpvb+/MuxJcLdd/FhAQkPnPN7q8/uqVAFlRtWpVChQoQEpKClu3br3uMVdz3eiXDiIiIvmFSr+IiIiLK1++PHDj+87/XUREBA888ADx8fG3dHXAjbz99tvYbDYmT57M3r17b+u1NWvWBGDnzp3XfK1gwYIULVoU4IYfWbje626HaZrA9X/pABAbGwvAPffck633ERERyW0q/SIiIk7s7NmzmQX1Rq7e/u7OO++85XGvfrb/008/5dy5c1nKVrlyZdq3b096enrmTv63qlGjRgBs3Ljxul9v0aIFAGPHjr3ma8nJyXz55Ze3mfb//f7775kfIbj6C5O/i4mJAcjSngUiIiJ5SaVfRETEiX3zzTfUrFmTL7744ppyfvHiRYYPH84333wDwOOPP37L49atW5c2bdqQkJDAd999l+V8L774IgBff/01R48eveXXtWzZEsjYK+B6nnnmGWw2GzNnzmTs2LGZv/hITEykb9++N1yh/yd//PFH5r+nSpUqUadOnWuO2bt3L6dOnaJSpUqULl06S+8jIiKSV1T6RUREnJhhGPz+++8MHDiQkJAQypcvT7169ahYsSKhoaH897//xTRNnnvuOTp16nRbY19d7U9PT89yvvr169O4cWNSUlL44IMPbvl1TZo0oUKFCqxYseK6m+nVrl2bkSNHYpomTzzxBKVKlSI8PJzixYszZ84chg8f/o/v0aVLFxo1akSjRo1o2LAhYWFhVKlShd9++42QkBCmTZuGzXbtfyrNmDED4JZuCygiImI1lX4REREnNmTIEJYtW8bzzz9PREQE6enpbNmyhWPHjlG2bFl69erF6tWref/992977Nq1a9O+fftsZ7y62v/FF1/c8n3tDcNgwIABpKenZ5bsvxs2bBizZ8+mXr16XLhwgX379tG4cWPWrFmT+fGAm9m4cSPR0dFER0ezdu1azp49S9WqVXnppZfYsWNH5r4Cfzdt2jQ8PT3p3bv3LX0vIiIiVjLMf/ogoIiIiIgF4uPjueOOOwgODmbnzp3XXXXPa8uXL+fee+9lyJAhREVFWR1HRETkH1n//54iIiIi1xEYGMirr77K7t27mT59utVxgIyPPAQEBNzSxwdERETyAw+rA4iIiIjcyBNPPEF8fDwOh8PqKMTHx9OsWTOefPJJQkNDrY4jIiJyS3R5v4iIiIiIiIiL0uX9IiIiIiIiIi5KpV9ERERERETERan0i4iIiIiIiLgolX4RERERERERF6XSLyIiIiIiIuKiVPpFREREREREXJRKv4iIiIiIiIiLUukXERERERERcVEq/SIiIiIiIiIuSqVfRERERERExEX9H7ZePwV++H82AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BER\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "ok = 0\n",
    "plt.semilogy(snr_range, bers_deeppolar_test, label=\"DeepPolar SC List\", marker='*', linewidth=1.5)\n",
    "\n",
    "plt.semilogy(snr_range, bers_SC_test, label=\"SC decoder\", marker='^', linewidth=1.5)\n",
    "\n",
    "## BLER\n",
    "plt.semilogy(snr_range, blers_deeppolar_test, label=\"DeepPolar SC List BLER)\", marker='*', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.semilogy(snr_range, blers_SC_test, label=\"SC decoder (BLER)\", marker='^', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=16)\n",
    "plt.ylabel(\"Error Rate\", fontsize=16)\n",
    "\n",
    "plt.legend(prop={'size': 15})\n",
    "if test_load_path is not None:\n",
    "    os.makedirs('Polar_Results/figures', exist_ok=True)\n",
    "    fig_save_path = results_save_path + 'Polar_Results/figures/SCListDeepPolar.pdf'\n",
    "else:\n",
    "    fig_save_path = results_save_path + f\"/SCList_Step{model_iters if model_iters is not None else 'final'}{'_binary' if binary else ''}.pdf\"\n",
    "if not no_fig:\n",
    "    plt.savefig(fig_save_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
