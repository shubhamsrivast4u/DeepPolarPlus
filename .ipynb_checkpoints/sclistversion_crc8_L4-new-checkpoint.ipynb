{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8752b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc45a",
   "metadata": {},
   "source": [
    "# Configuration variables (previously args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b957ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # Block length\n",
    "K = 37   # Message size\n",
    "kernel_size = 16  # Kernel size (ell)\n",
    "rate_profile = 'polar'  # Rate profiling; choices=['RM', 'polar', 'sorted', 'last', 'rev_polar', 'custom']\n",
    "infty = 1000.  # Infinity value for frozen position LLR in polar dec\n",
    "lse = 'minsum'  # LSE function; choices=['minsum', 'lse']\n",
    "hard_decision = False  # Polar code sc decoding hard decision?\n",
    "\n",
    "# DeepPolar parameters\n",
    "encoder_type = 'KO'  # Type of encoding; choices=['KO', 'scaled', 'polar']\n",
    "decoder_type = 'KO'  # Type of decoding; choices=['KO', 'SC', 'KO_parallel', 'KO_last_parallel']\n",
    "enc_activation = 'selu'  # Activation function\n",
    "dec_activation = 'selu'  # Activation function\n",
    "dropout_p = 0.\n",
    "dec_hidden_size = 128  # Neural network size\n",
    "enc_hidden_size = 64   # Neural network size\n",
    "f_depth = 3  # Decoder neural network depth\n",
    "g_depth = 3  # Encoder neural network depth\n",
    "g_skip_depth = 1  # Encoder neural network skip depth\n",
    "g_skip_layer = 1  # Encoder neural network skip layer\n",
    "onehot = False  # Use onehot representation of prev_decoded_bits\n",
    "shared = False  # Share weights across depth\n",
    "use_skip = True  # Use skip connections\n",
    "use_norm = False  # Use normalization\n",
    "binary = False  # Use binary quantization\n",
    "\n",
    "# Infrastructure parameters\n",
    "id = None  # Optional ID for multiple runs\n",
    "test = False  # Testing mode flag\n",
    "pairwise = False  # Plot codeword pairwise distances\n",
    "epos = False  # Plot error positions\n",
    "seed = None  # Random seed\n",
    "anomaly = False  # Enable anomaly detection\n",
    "dataparallel = False  # Use dataparallel\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture parameters\n",
    "polar_depths = []  # List of depths to use polar encoding/decoding\n",
    "last_ell = None  # Use kernel last_ell last layer\n",
    "\n",
    "\n",
    "# Channel parameters\n",
    "radar_power = None  # Radar power parameter\n",
    "radar_prob = 0.1  # Radar probability parameter\n",
    "\n",
    "# Training parameters\n",
    "full_iters = 500  # Full iterations\n",
    "enc_train_iters = 30  # Encoder iterations\n",
    "dec_train_iters = 300  # Decoder iterations\n",
    "enc_train_snr = 0.  # SNR at which encoder is trained\n",
    "dec_train_snr = -2.  # SNR at which decoder is trained\n",
    "weight_decay = 0.0\n",
    "dec_lr = 0.001  # Decoder Learning rate\n",
    "enc_lr = 0.001  # Encoder Learning rate\n",
    "batch_size = 20000  # Size of batches\n",
    "small_batch_size = 5000  # Size of small batches\n",
    "noise_type = 'awgn'  # Noise type; choices=['fading', 'awgn', 'radar']\n",
    "regularizer = None  # Regularizer type; choices=['std', 'max_deviation','polar']\n",
    "regularizer_weight = 0.001\n",
    "loss_type = 'BCE' # loss function; choices=['MSE', 'BCE', 'BCE_reg', 'L1', 'huber', 'focal', 'BCE_bler']\n",
    "initialization = 'random'  # Initialization type; choices=['random', 'zeros']\n",
    "optim_name = 'Adam'  # Optimizer type; choices=['Adam', 'RMS', 'SGD', 'AdamW']\n",
    "\n",
    "# Testing parameters\n",
    "test_batch_size = 1000  # Size of test batches\n",
    "num_errors = 100  # Test until _ block errors\n",
    "test_snr_start = -5.  # Testing SNR start\n",
    "test_snr_end = -1.   # Testing SNR end\n",
    "snr_points = 5       # Testing SNR num points\n",
    "\n",
    "\n",
    "\n",
    "# Model saving/loading parameters\n",
    "model_save_per = 100  # Model save frequency\n",
    "model_iters = None  # Option to load specific model iteration\n",
    "test_load_path = None  # Path to load test model\n",
    "\n",
    "load_path = None  # Load path \n",
    "kernel_load_path = 'Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new'   # Kernel load path\n",
    "no_fig = False  # Plot figure option\n",
    "\n",
    "\n",
    "# Scheduler parameters\n",
    "scheduler = 'cosine' # choices = ['reduce', '1cycle', 'cosine']\n",
    "scheduler_patience = None  # Scheduler patience\n",
    "batch_schedule = False  # Use batch scheduler\n",
    "batch_patience = 50  # Batch scheduler patience \n",
    "batch_factor = 2  # Batch multiplication factor\n",
    "min_batch_size = 500  # Minimum batch size\n",
    "max_batch_size = 50000  # Maximum batch size\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117821f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab1d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "crc_len = 3  # CRC length \n",
    "# Initialize CRC\n",
    "crc_poly = [1, 0, 1, 1]  # CRC polynomial\n",
    "L=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc384a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_original_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}/{encoder_type}__{enc_train_snr}_Encoder_{decoder_type}_{dec_train_snr}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e40922",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}_SClist_L_{L}_crc_{crc_poly}/{encoder_type}_Encoder_{decoder_type}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0c3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path +'/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e521",
   "metadata": {},
   "source": [
    "# Part 1: Core Utilities and Model Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_db2sigma(train_snr):\n",
    "    return 10**(-train_snr*1.0/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a23a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2bb73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a smoother version using product of bit probabilities\n",
    "def soft_bler_loss(logits, targets):\n",
    "    bit_probs = torch.sigmoid(logits)  # For correct bits\n",
    "    bit_probs = torch.where(targets == 1., bit_probs, 1 - bit_probs)\n",
    "    block_probs = torch.prod(bit_probs, dim=1)  # Probability of whole block being correct\n",
    "    return -torch.mean(torch.log(block_probs + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b989d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_ber(y_true, y_pred, mask=None):\n",
    "    if mask == None:\n",
    "        mask=torch.ones(y_true.size(),device=y_true.device)\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "    mask = mask.view(mask.shape[0], -1, 1)\n",
    "    myOtherTensor = (mask*torch.ne(torch.round(y_true), torch.round(y_pred))).float()\n",
    "    res = sum(sum(myOtherTensor))/(torch.sum(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_bler(y_true, y_pred, get_pos = False):\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "\n",
    "    decoded_bits = torch.round(y_pred).cpu()\n",
    "    X_test = torch.round(y_true).cpu()\n",
    "    tp0 = (abs(decoded_bits-X_test)).view([X_test.shape[0],X_test.shape[1]])\n",
    "    tp0 = tp0.detach().cpu().numpy()\n",
    "    bler_err_rate = sum(np.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
    "\n",
    "    if not get_pos:\n",
    "        return bler_err_rate\n",
    "    else:\n",
    "        err_pos = list(np.nonzero((np.sum(tp0,axis=1)>0).astype(int))[0])\n",
    "        return bler_err_rate, err_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92df8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_signal(input_signal, sigma = 1.0, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 0.05):\n",
    "    data_shape = input_signal.shape\n",
    "    device = input_signal.device\n",
    "    if noise_type == 'awgn':\n",
    "        dist = torch.distributions.Normal(torch.tensor([0.0], device=device), torch.tensor([sigma], device=device))\n",
    "        noise = dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 'fading':\n",
    "        fading_h = torch.sqrt(torch.randn_like(input_signal)**2 + torch.randn_like(input_signal)**2)/np.sqrt(3.14/2.0)\n",
    "        noise = sigma * torch.randn_like(input_signal)\n",
    "        corrupted_signal = fading_h *(input_signal) + noise\n",
    "\n",
    "    elif noise_type == 'radar':\n",
    "        add_pos = np.random.choice([0.0, 1.0], data_shape, p=[1 - radar_prob, radar_prob])\n",
    "        corrupted_signal = radar_power* np.random.standard_normal(size=data_shape) * add_pos\n",
    "        noise = sigma * torch.randn_like(input_signal) +\\\n",
    "                    torch.from_numpy(corrupted_signal).float().to(input_signal.device)\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 't-dist':\n",
    "        dist = torch.distributions.StudentT(torch.tensor([vv], device=device))\n",
    "        noise = sigma* dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    return corrupted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e97bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp(x, y):\n",
    "    log_sum_ms = torch.min(torch.abs(x), torch.abs(y))*torch.sign(x)*torch.sign(y)\n",
    "    return log_sum_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5937279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp_4(x_1, x_2, x_3, x_4):\n",
    "    return min_sum_log_sum_exp(min_sum_log_sum_exp(x_1, x_2), min_sum_log_sum_exp(x_3, x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c239bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, y):\n",
    "    def log_sum_exp_(LLR_vector):\n",
    "        sum_vector = LLR_vector.sum(dim=1, keepdim=True)\n",
    "        sum_concat = torch.cat([sum_vector, torch.zeros_like(sum_vector)], dim=1)\n",
    "        return torch.logsumexp(sum_concat, dim=1)- torch.logsumexp(LLR_vector, dim=1) \n",
    "\n",
    "    Lv = log_sum_exp_(torch.cat([x.unsqueeze(2), y.unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "    return Lv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655fe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bitarray(in_number, bit_width):\n",
    "    binary_string = bin(in_number)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(bit_width, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[bit_width-i-1] = int(binary_string[length-i-1])\n",
    "    return bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a081f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSetBits(n):\n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, enc_quantize_level = 2, enc_value_limit = 1.0, enc_grad_limit = 0.01, enc_clipping = 'both'):\n",
    "        ctx.save_for_backward(inputs)\n",
    "        assert enc_clipping in ['both', 'inputs']\n",
    "        ctx.enc_clipping = enc_clipping\n",
    "        ctx.enc_value_limit = enc_value_limit\n",
    "        ctx.enc_quantize_level = enc_quantize_level\n",
    "        ctx.enc_grad_limit = enc_grad_limit\n",
    "\n",
    "        x_lim_abs = enc_value_limit\n",
    "        x_lim_range = 2.0 * x_lim_abs\n",
    "        x_input_norm = torch.clamp(inputs, -x_lim_abs, x_lim_abs)\n",
    "\n",
    "        if enc_quantize_level == 2:\n",
    "            outputs_int = torch.sign(x_input_norm)\n",
    "        else:\n",
    "            outputs_int = torch.round((x_input_norm +x_lim_abs) * ((enc_quantize_level - 1.0)/x_lim_range)) * x_lim_range/(enc_quantize_level - 1.0) - x_lim_abs\n",
    "\n",
    "        return outputs_int\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.enc_clipping in ['inputs', 'both']:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input>ctx.enc_value_limit]=0\n",
    "            grad_output[input<-ctx.enc_value_limit]=0\n",
    "\n",
    "        if ctx.enc_clipping in ['gradient', 'both']:\n",
    "            grad_output = torch.clamp(grad_output, -ctx.enc_grad_limit, ctx.enc_grad_limit)\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d695a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'tanh':\n",
    "        return F.tanh\n",
    "    elif activation == 'elu':\n",
    "        return F.elu\n",
    "    elif activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'selu':\n",
    "        return F.selu\n",
    "    elif activation == 'sigmoid':\n",
    "        return F.sigmoid\n",
    "    elif activation == 'gelu':\n",
    "        return F.gelu\n",
    "    elif activation == 'silu':\n",
    "        return F.silu\n",
    "    elif activation == 'mish':\n",
    "        return F.mish\n",
    "    elif activation == 'linear':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Activation function {activation} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth=3, skip_depth=1, skip_layer=1, ell=2, activation='selu', use_skip=False, augment=False):\n",
    "        super(g_Full, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.ell = ell\n",
    "        self.ell_input_size = input_size//self.ell\n",
    "        self.augment = augment\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "        self.skip_depth = skip_depth\n",
    "        self.skip_layer = skip_layer\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        if self.use_skip:\n",
    "            self.skip = nn.ModuleList([nn.Linear(self.input_size + self.output_size, self.hidden_size, bias=True)])\n",
    "            self.skip.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.skip_depth)])\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        self.linears.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.depth)])\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_augment(msg, ell):\n",
    "        u = msg.clone()\n",
    "        n = int(np.log2(ell))\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, ell, 2*num_bits):\n",
    "                if len(u.shape) == 2:\n",
    "                    u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                elif len(u.shape) == 3:\n",
    "                    u = torch.cat((u[:, :, :i], u[:, :, i:i+num_bits].clone() * u[:, :, i+num_bits: i+2*num_bits], u[:, :, i+num_bits:]), dim=2)\n",
    "\n",
    "        if len(u.shape) == 3:\n",
    "            return u[:, :, :-1]\n",
    "        elif len(u.shape) == 2:\n",
    "            return u[:, :-1]\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y.clone()\n",
    "        for ii, layer in enumerate(self.linears):\n",
    "            if ii != self.depth:\n",
    "                x = self.activation_fn(layer(x))\n",
    "                if self.use_skip and ii == self.skip_layer:\n",
    "                    if len(x.shape) == 3:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=2)\n",
    "                    elif len(x.shape) == 2:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=1)\n",
    "                    for jj, skip_layer in enumerate(self.skip):\n",
    "                        skip_input = self.activation_fn(skip_layer(skip_input))\n",
    "                    x = x + skip_input\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if self.augment:\n",
    "                    x = x + g_Full.get_augment(y, self.ell)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d72065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape should be: (batch_size, seq_len, hidden_dim)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class f_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0., activation='selu', depth=3, use_norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.use_norm = use_norm\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "\n",
    "        # Initial layers same as original f_Full\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        if self.use_norm:\n",
    "            self.norms = nn.ModuleList([nn.LayerNorm(self.hidden_size)])\n",
    "        \n",
    "        # Attention layer after first linear\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,  # Reduced number of heads\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Remaining layers same as original\n",
    "        for ii in range(1, self.depth):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size, bias=True))\n",
    "            if self.use_norm:\n",
    "                self.norms.append(nn.LayerNorm(self.hidden_size))\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    def forward(self, y, aug=None):\n",
    "        x = y.clone()\n",
    "        \n",
    "        # First linear layer\n",
    "        x = self.linears[0](x)\n",
    "        if self.use_norm:\n",
    "            x = self.norms[0](x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        # Reshape for attention: [batch, seq_len, hidden]\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = attn_out if len(y.shape) == 3 else attn_out.squeeze(1)\n",
    "        \n",
    "        # Remaining layers\n",
    "        for ii in range(1, len(self.linears)):\n",
    "            if ii != self.depth:\n",
    "                x = self.linears[ii](x)\n",
    "                if self.use_norm:\n",
    "                    x = self.norms[ii](x)\n",
    "                x = self.activation_fn(x)\n",
    "            else:\n",
    "                x = self.linears[ii](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10845154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        try:\n",
    "            m.bias.data.fill_(0.)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e38e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(actions):\n",
    "    inds = (0.5 + 0.5*actions).long()\n",
    "    return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594f46",
   "metadata": {},
   "source": [
    "# Part 2: Core PolarCode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarCode:\n",
    "\n",
    "    def __init__(self, n, K, Fr = None, rs = None, use_cuda = True, infty = 1000., hard_decision = False, lse = 'lse'):\n",
    "\n",
    "        assert n>=1\n",
    "        self.n = n\n",
    "        self.N = 2**n\n",
    "        self.K = K\n",
    "        self.G2 = np.array([[1,1],[0,1]])\n",
    "        self.G = np.array([1])\n",
    "        for i in range(n):\n",
    "            self.G = np.kron(self.G, self.G2)\n",
    "        self.G = torch.from_numpy(self.G).float()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.infty = infty\n",
    "        self.hard_decision = hard_decision\n",
    "        self.lse = lse\n",
    "\n",
    "        if Fr is not None:\n",
    "            assert len(Fr) == self.N - self.K\n",
    "            self.frozen_positions = Fr\n",
    "            self.unsorted_frozen_positions = self.frozen_positions\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "            self.info_positions = np.array(list(set(self.frozen_positions) ^ set(np.arange(self.N))))\n",
    "            self.unsorted_info_positions = self.info_positions\n",
    "            self.info_positions.sort()\n",
    "            \n",
    "        else:\n",
    "            if rs is None:\n",
    "                # in increasing order of reliability\n",
    "                self.reliability_seq = np.arange(1023, -1, -1)\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "            else:\n",
    "                self.reliability_seq = rs\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "\n",
    "                assert len(self.rs) == self.N\n",
    "            # best K bits\n",
    "            self.info_positions = self.rs[:self.K]\n",
    "            self.unsorted_info_positions = self.reliability_seq[self.reliability_seq<self.N][:self.K]\n",
    "            self.info_positions.sort()\n",
    "            self.unsorted_info_positions=np.flip(self.unsorted_info_positions)\n",
    "            # worst N-K bits\n",
    "            self.frozen_positions = self.rs[self.K:]\n",
    "            self.unsorted_frozen_positions = self.rs[self.K:]\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "\n",
    "            self.CRC_polynomials = {\n",
    "            3: torch.Tensor([1, 0, 1, 1]).int(),\n",
    "            8: torch.Tensor([1, 1, 1, 0, 1, 0, 1, 0, 1]).int(),\n",
    "            16: torch.Tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]).int(),\n",
    "                                    }\n",
    "\n",
    "    def get_G(self, ell):\n",
    "        n = int(np.log2(ell))\n",
    "        G = np.array([1])\n",
    "        for i in range(n):\n",
    "            G = np.kron(G, self.G2)\n",
    "        return G\n",
    "\n",
    "    def encode_plotkin(self, message, scaling = None, custom_info_positions = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "        if custom_info_positions is not None:\n",
    "            info_positions = custom_info_positions\n",
    "        else:\n",
    "            info_positions = self.info_positions\n",
    "        u = torch.ones(message.shape[0], self.N, dtype=torch.float).to(message.device)\n",
    "        u[:, info_positions] = message\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                # u[:, i:i+num_bits] = u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits].clone\n",
    "        if scaling is not None:\n",
    "            u = (scaling * np.sqrt(self.N)*u)/torch.norm(scaling)\n",
    "        return u\n",
    "    \n",
    "    def channel(self, code, snr, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 5e-2):\n",
    "        if noise_type != \"bsc\":\n",
    "            sigma = snr_db2sigma(snr)\n",
    "        else:\n",
    "            sigma = snr\n",
    "\n",
    "        r = corrupt_signal(code, sigma, noise_type, vv, radar_power, radar_prob)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def define_partial_arrays(self, llrs):\n",
    "        # Initialize arrays to store llrs and partial_sums useful to compute the partial successive cancellation process.\n",
    "        llr_array = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        llr_array[:, self.n] = llrs\n",
    "        partial_sums = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        return llr_array, partial_sums\n",
    "\n",
    "\n",
    "    def updateLLR(self, leaf_position, llrs, partial_llrs = None, prior = None):\n",
    "\n",
    "        #START\n",
    "        depth = self.n\n",
    "        decoded_bits = partial_llrs[:,0].clone()\n",
    "        if prior is None:\n",
    "            prior = torch.zeros(self.N) #priors\n",
    "        llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth, 0, leaf_position, prior, decoded_bits)\n",
    "        return llrs, decoded_bits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def partial_decode(self, llrs, partial_llrs, depth, bit_position, leaf_position, prior, decoded_bits=None):\n",
    "        # Function to call recursively, for partial SC decoder.\n",
    "        # We are assuming that u_0, u_1, .... , u_{leaf_position -1} bits are known.\n",
    "        # Partial sums computes the sums got through Plotkin encoding operations of known bits, to avoid recomputation.\n",
    "        # this function is implemented for rate 1 (not accounting for frozen bits in polar SC decoding)\n",
    "\n",
    "        # print(\"DEPTH = {}, bit_position = {}\".format(depth, bit_position))\n",
    "        half_index = 2 ** (depth - 1)\n",
    "        leaf_position_at_depth = leaf_position // 2**(depth-1) # will tell us whether left_child or right_child\n",
    "\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            # Left child\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position:left_bit_position+1]\n",
    "            elif leaf_position_at_depth == left_bit_position:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                elif self.lse == 'lse':\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                #print(Lu.device, prior.device, torch.ones_like(Lu).device)\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu + prior[left_bit_position]*torch.ones_like(Lu)\n",
    "                if self.hard_decision:\n",
    "                    u_hat = torch.sign(Lu)\n",
    "                else:\n",
    "                    u_hat = torch.tanh(Lu/2)\n",
    "\n",
    "                decoded_bits[:, left_bit_position] = u_hat.squeeze(1)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # Right child\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "            if leaf_position_at_depth > right_bit_position:\n",
    "                pass\n",
    "            elif leaf_position_at_depth == right_bit_position:\n",
    "                Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "                llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv + prior[right_bit_position] * torch.ones_like(Lv)\n",
    "                if self.hard_decision:\n",
    "                    v_hat = torch.sign(Lv)\n",
    "                else:\n",
    "                    v_hat = torch.tanh(Lv/2)\n",
    "                decoded_bits[:, right_bit_position] = v_hat.squeeze(1)\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            # LEFT CHILD\n",
    "            # Find likelihood of (u xor v) xor (v) = u\n",
    "            # Lu = log_sum_exp(torch.cat([llrs[:, :half_index].unsqueeze(2), llrs[:, half_index:].unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                Lu = llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "            else:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                elif self.lse == 'lse':\n",
    "                    # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu\n",
    "                llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, left_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # RIGHT CHILD\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "\n",
    "            Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "            llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv\n",
    "            llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, right_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "            return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "    def updatePartialSums(self, leaf_position, decoded_bits, partial_llrs):\n",
    "\n",
    "        u = decoded_bits.clone()\n",
    "        u[:, leaf_position+1:] = 0\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            partial_llrs[:, d] = u\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        partial_llrs[:, self.n] = u\n",
    "        return partial_llrs\n",
    "\n",
    "    def sc_decode_new(self, corrupted_codewords, snr, use_gt = None, channel = 'awgn'):\n",
    "\n",
    "        assert channel in ['awgn', 'bsc']\n",
    "\n",
    "        if channel == 'awgn':\n",
    "            noise_sigma = snr_db2sigma(snr)\n",
    "            llrs = (2/noise_sigma**2)*corrupted_codewords\n",
    "        elif channel == 'bsc':\n",
    "            # snr refers to transition prob\n",
    "            p = (torch.ones(1)*(snr + 1e-9)).to(corrupted_codewords.device)\n",
    "            llrs = (torch.clip(torch.log((1 - p) / p), -10000, 10000) * (corrupted_codewords + 1) - torch.clip(torch.log(p / (1-p)), -10000, 10000) * (corrupted_codewords - 1))/2\n",
    "\n",
    "        # step-wise implementation using updateLLR and updatePartialSums\n",
    "\n",
    "        priors = torch.zeros(self.N)\n",
    "        priors[self.frozen_positions] = self.infty\n",
    "\n",
    "        u_hat = torch.zeros(corrupted_codewords.shape[0], self.N, device=corrupted_codewords.device)\n",
    "        llr_array, partial_llrs = self.define_partial_arrays(llrs)\n",
    "        for ii in range(self.N):\n",
    "            #start = time.time()\n",
    "            llr_array , decoded_bits = self.updateLLR(ii, llr_array.clone(), partial_llrs, priors)\n",
    "            #print('SC update : {}'.format(time.time() - start), corrupted_codewords.shape[0])\n",
    "            if use_gt is None:\n",
    "                u_hat[:, ii] = torch.sign(llr_array[:, 0, ii])\n",
    "            else:\n",
    "                u_hat[:, ii] = use_gt[:, ii]\n",
    "            #start = time.time()\n",
    "            partial_llrs = self.updatePartialSums(ii, u_hat, partial_llrs)\n",
    "            #print('SC partial: {}s, {}', time.time() - start, 'frozen' if ii in self.frozen_positions else 'info')\n",
    "        decoded_bits = u_hat[:, self.info_positions]\n",
    "        return llr_array[:, 0, :].clone(), decoded_bits\n",
    "\n",
    "    def get_CRC(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # inout message should be int\n",
    "\n",
    "        padded_bits = torch.cat([message, torch.zeros(self.CRC_len).int().to(message.device)])\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + self.CRC_len + 1] = padded_bits[cur_shift: cur_shift + self.CRC_len + 1] ^ self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        return padded_bits[self.K_minus_CRC:]\n",
    "\n",
    "    def CRC_check(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # input message should be int\n",
    "\n",
    "        padded_bits = message\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + polar.CRC_len + 1] ^= self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        if padded_bits[self.K_minus_CRC:].sum()>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def encode_with_crc(self, message, CRC_len):\n",
    "        self.CRC_len = CRC_len\n",
    "        self.K_minus_CRC = self.K - CRC_len\n",
    "\n",
    "        if CRC_len == 0:\n",
    "            return self.encode_plotkin(message)\n",
    "        else:\n",
    "            crcs = 1-2*torch.vstack([self.get_CRC((0.5+0.5*message[jj]).int()) for jj in range(message.shape[0])])\n",
    "            encoded = self.encode_plotkin(torch.cat([message, crcs], 1))\n",
    "\n",
    "            return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6d51",
   "metadata": {},
   "source": [
    "# Part 3: DeepPolar Class and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b3d92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        for i in range(n - self.degree):\n",
    "            active_batches = result[:, i] == 1\n",
    "            if torch.any(active_batches):\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPolar(PolarCode):\n",
    "    def __init__(self, device, N, K, ell = 2, infty = 1000., depth_map : defaultdict = None):\n",
    "\n",
    "        # rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        # Frozen = np.argsort(rmweight)[:-K]\n",
    "        # Frozen.sort()\n",
    "\n",
    "        #self.args = args\n",
    "        Fr = get_frozen(N, K, rate_profile)\n",
    "        super().__init__(n = int(np.log2(N)), K = K, Fr=Fr,  infty = infty)\n",
    "        self.N = N\n",
    "\n",
    "        if depth_map is not None:\n",
    "            # depth map is a dict, product of values should be equal to N\n",
    "            assert np.prod(list(depth_map.values())) == N\n",
    "            # assert that keys od depth map start from one and go continuosly till some point \n",
    "            assert min(list(depth_map.keys())) == 1\n",
    "            assert max(list(depth_map.keys())) <= int(np.log2(N))\n",
    "            self.ell = None\n",
    "            self.n_ell = len(depth_map.keys())\n",
    "            assert max(list(depth_map.keys())) == self.n_ell\n",
    "\n",
    "            self.depth_map = depth_map\n",
    "        else:\n",
    "            self.ell = ell\n",
    "            self.n_ell = int(np.log(N)/np.log(self.ell))\n",
    "\n",
    "            self.depth_map = defaultdict(int)\n",
    "            for d in range(1, self.n_ell+1):\n",
    "                self.depth_map[d] = self.ell\n",
    "            assert np.prod(list(self.depth_map.values())) == N\n",
    "\n",
    "        self.device = device\n",
    "        self.fnet_dict = None\n",
    "        self.gnet_dict = None\n",
    "\n",
    "        self.infty = infty\n",
    "\n",
    "    @staticmethod\n",
    "    def get_onehot(actions):\n",
    "        inds = (0.5 + 0.5*actions).long()\n",
    "        if len(actions.shape) == 2:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)\n",
    "        elif len(actions.shape) == 3:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], actions.shape[1], -1)\n",
    "\n",
    "    def define_kernel_nns(self, ell, unfrozen = None, fnet = 'KO', gnet = 'KO', shared = False):\n",
    "\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "        #dec_hidden_size = dec_hidden_size\n",
    "        #enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        depth = 1\n",
    "        assert len(unfrozen) > 0, \"No unfrozen bits!\"\n",
    "\n",
    "        self.fnet_dict[depth] = {}\n",
    "\n",
    "        if fnet == 'KO_parallel' or fnet == 'KO_last_parallel':\n",
    "            bit_position = 0\n",
    "                   \n",
    "            self.fnet_dict[depth][bit_position] = {}\n",
    "            # input_size = self.N if depth == self.n_ell else self.N // int(np.prod([self.depth_map[d] for d in range(depth+1, self.n_ell+1)]))\n",
    "            input_size = ell             \n",
    "            # For curriculum, only for lowest depth.\n",
    "            output_size = ell#len(unfrozen)\n",
    "            self.fnet_dict[depth][bit_position] = f_Full(input_size, dec_hidden_size, output_size, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    " \n",
    "        elif 'KO' in fnet:\n",
    "            if shared:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for current_position in range(ell):\n",
    "                    self.fnet_dict[depth][current_position] = f_Full(ell + current_position, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                for current_position in unfrozen:\n",
    "                    if not self.fnet_dict[depth].get(bit_position):\n",
    "                        self.fnet_dict[depth][bit_position] = {}\n",
    "                    input_size = ell + (int(onehot)+1)*current_position\n",
    "                    self.fnet_dict[depth][bit_position][current_position] = f_Full(input_size, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "                \n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict[depth] = {}\n",
    "            if shared:\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth][bit_position] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "\n",
    "    def define_and_load_nns(self, ell, kernel_load_path=None, fnet='KO', gnet='KO', shared=True, dataparallel=False):\n",
    "        # Initialize decoder and encoder dictionaries\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "\n",
    "        # Loop through each depth level\n",
    "        for depth in range(self.n_ell, 0, -1):\n",
    "            if depth in polar_depths:\n",
    "                continue\n",
    "\n",
    "            ell = self.depth_map[depth]\n",
    "            proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "            # Handle parallel decoder case\n",
    "            if fnet == 'KO_last_parallel' and depth == 1:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for bit_position in range(self.N // proj_size):\n",
    "                    proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                    get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                    num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                    subproj_len = len(proj) // ell\n",
    "                    subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                    num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                    unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                    input_size = ell             \n",
    "                    output_size = ell\n",
    "\n",
    "                    # Use attention-enhanced decoder for parallel case\n",
    "                    self.fnet_dict[depth][bit_position] = f_Full(\n",
    "                        input_size=input_size,\n",
    "                        hidden_size=dec_hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        activation=dec_activation,\n",
    "                        dropout_p=dropout_p,\n",
    "                        depth=f_depth,\n",
    "                        use_norm=use_norm\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    # Load pretrained weights if available\n",
    "                    if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                        try:\n",
    "                            ckpt = torch.load(os.path.join(kernel_load_path + '_parallel', f'{ell}_{len(unfrozen)}.pt'))\n",
    "                            self.fnet_dict[depth][bit_position].load_state_dict(ckpt[0][1][0].state_dict())\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"Parallel File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                            pass\n",
    "\n",
    "                    if dataparallel:\n",
    "                        self.fnet_dict[depth][bit_position] = nn.DataParallel(self.fnet_dict[depth][bit_position])\n",
    "\n",
    "            # Handle sequential decoder case\n",
    "            elif 'KO' in fnet:\n",
    "                self.fnet_dict[depth] = {}\n",
    "\n",
    "                if shared:\n",
    "                    # Shared decoder network for all positions\n",
    "                    for current_position in range(ell):\n",
    "                        self.fnet_dict[depth][current_position] = f_Full(\n",
    "                            input_size=ell + current_position,\n",
    "                            hidden_size=dec_hidden_size,\n",
    "                            output_size=1,\n",
    "                            activation=dec_activation,\n",
    "                            dropout_p=dropout_p,\n",
    "                            depth=f_depth,\n",
    "                            use_norm=use_norm\n",
    "                        ).to(self.device)\n",
    "\n",
    "                        if dataparallel:\n",
    "                            self.fnet_dict[depth][current_position] = nn.DataParallel(self.fnet_dict[depth][current_position])\n",
    "\n",
    "                else:\n",
    "                    # Individual decoder networks for each position\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                        num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                        subproj_len = len(proj) // ell\n",
    "                        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                        unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                        # Load pretrained weights if available\n",
    "                        ckpt_exists = False\n",
    "                        if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                            try:\n",
    "                                ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                ckpt_exists = True\n",
    "                            except FileNotFoundError:\n",
    "                                print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                pass\n",
    "\n",
    "                        # Create decoders for unfrozen positions\n",
    "                        for current_position in unfrozen:\n",
    "                            if not self.fnet_dict[depth].get(bit_position):\n",
    "                                self.fnet_dict[depth][bit_position] = {}\n",
    "\n",
    "                            input_size = ell + (int(onehot)+1)*current_position\n",
    "                            output_size = 1\n",
    "\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = f_Full(\n",
    "                                input_size=input_size,\n",
    "                                hidden_size=dec_hidden_size,\n",
    "                                output_size=output_size,\n",
    "                                activation=dec_activation,\n",
    "                                dropout_p=dropout_p,\n",
    "                                depth=f_depth,\n",
    "                                use_norm=use_norm\n",
    "                            ).to(self.device)\n",
    "\n",
    "                            if ckpt_exists:\n",
    "                                try:\n",
    "                                    f_ckpt = ckpt[0][1][0][current_position].state_dict()\n",
    "                                    self.fnet_dict[depth][bit_position][current_position].load_state_dict(f_ckpt)\n",
    "                                except:\n",
    "                                    print(f\"Warning: Could not load weights for position {current_position}\")\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.fnet_dict[depth][bit_position][current_position] = nn.DataParallel(\n",
    "                                    self.fnet_dict[depth][bit_position][current_position]\n",
    "                                )\n",
    "\n",
    "            # Handle encoder network\n",
    "            if 'KO' in gnet:\n",
    "                self.gnet_dict[depth] = {}\n",
    "                if shared:\n",
    "                    if gnet == 'KO':\n",
    "                        if not dataparallel:\n",
    "                            self.gnet_dict[depth] = g_Full(\n",
    "                                ell, enc_hidden_size, ell-1,\n",
    "                                depth=g_depth,\n",
    "                                skip_depth=g_skip_depth,\n",
    "                                skip_layer=g_skip_layer,\n",
    "                                ell=ell,\n",
    "                                use_skip=use_skip\n",
    "                            ).to(self.device)\n",
    "                        else:\n",
    "                            self.gnet_dict[depth] = nn.DataParallel(\n",
    "                                g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    use_skip=use_skip\n",
    "                                )\n",
    "                            ).to(self.device)\n",
    "                else:\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        num_info_in_proj = sum([int(x in self.info_positions) for x in proj])\n",
    "\n",
    "                        if num_info_in_proj > 0:\n",
    "                            if gnet == 'KO':\n",
    "                                self.gnet_dict[depth][bit_position] = g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    activation=enc_activation,\n",
    "                                    use_skip=use_skip\n",
    "                                ).to(self.device)\n",
    "\n",
    "                            # Load pretrained weights if available\n",
    "                            if kernel_load_path is not None:\n",
    "                                try:\n",
    "                                    ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                    self.gnet_dict[depth][bit_position].load_state_dict(ckpt[1][1][0].state_dict())\n",
    "                                except FileNotFoundError:\n",
    "                                    print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                    pass\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.gnet_dict[depth][bit_position] = nn.DataParallel(self.gnet_dict[depth][bit_position])\n",
    "\n",
    "        if kernel_load_path is not None:\n",
    "            print(\"Loaded kernel from \", kernel_load_path)\n",
    "\n",
    "    def load_nns(self, fnet_dict, gnet_dict = None, shared = False):\n",
    "        self.fnet_dict = fnet_dict\n",
    "        self.gnet_dict = gnet_dict\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if self.fnet_dict is not None:\n",
    "                for bit_position in self.fnet_dict[depth].keys():\n",
    "                    if not isinstance(self.fnet_dict[depth][bit_position], dict):#shared or decoder_type == 'KO_parallel' or decoder_type == 'KO_RNN':\n",
    "                        self.fnet_dict[depth][bit_position].to(self.device)\n",
    "                    else:\n",
    "                        for current_position in self.fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "            if gnet_dict is not None:\n",
    "                if shared:\n",
    "                    self.gnet_dict[depth].to(self.device)\n",
    "                else:\n",
    "                    for bit_position in self.gnet_dict[depth].keys():\n",
    "                        self.gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def load_partial_nns(self, fnet_dict, gnet_dict = None):\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if fnet_dict is not None:\n",
    "                for bit_position in fnet_dict[depth].keys():\n",
    "                    if isinstance(fnet_dict[depth][bit_position], dict):\n",
    "                        for current_position in fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "                    else:\n",
    "                        self.fnet_dict[depth][bit_position] = fnet_dict[depth][bit_position].to(self.device)\n",
    "\n",
    "            if gnet_dict is not None:\n",
    "                for bit_position in gnet_dict[depth].keys():\n",
    "                    self.gnet_dict[depth][bit_position] = gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def kernel_encode(self, ell, gnet, msg_bits, info_positions, binary = False):\n",
    "        input_shape = msg_bits.shape[-1]\n",
    "        assert input_shape <= ell\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, info_positions] = msg_bits\n",
    "        output =torch.cat([gnet(u.unsqueeze(1)).squeeze(1), u[:, -1:]], 1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(output)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def deeppolar_encode(self, msg_bits, binary = False):\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, self.info_positions] = msg_bits\n",
    "        for d in range(1, self.n_ell+1):\n",
    "            # num_bits = self.ell**(d-1)\n",
    "            num_bits = np.prod([self.depth_map[dd] for dd in range(1, d)]) if d > 1 else 1\n",
    "            # proj_size = self.ell**(d)\n",
    "            proj_size = np.prod([self.depth_map[dd] for dd in range(1, d+1)])\n",
    "            ell = self.depth_map[d]\n",
    "            for bit_position, i in enumerate(np.arange(0, self.N, ell*num_bits)):\n",
    "\n",
    "                # [u v] encoded to [(u xor v),v)]\n",
    "                proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                subproj_len = len(proj) // ell\n",
    "                subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "                \n",
    "                if num_info_in_proj > 0:\n",
    "                    info_bits_present = True          \n",
    "                else:\n",
    "                    info_bits_present = False         \n",
    "                if d in polar_depths:\n",
    "                    info_bits_present = False\n",
    "\n",
    "                enc_chunks = []\n",
    "                ell = self.depth_map[d]\n",
    "                for j in range(ell):\n",
    "                    chunk = u[:, i + j*num_bits:i + (j+1)*num_bits].unsqueeze(2).clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[d](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        output = torch.cat([self.gnet_dict[d][bit_position](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(msg_bits.shape[0], -1, 1).squeeze(2)\n",
    "\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                u = torch.cat((u[:, :i], output, u[:, i + ell*num_bits:]), dim=1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(u)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def power_constraint(self, codewords):\n",
    "        return F.normalize(codewords, p=2, dim=1)*np.sqrt(self.N)\n",
    "\n",
    "    def encode_chunks_plotkin(self, enc_chunks, ell = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "\n",
    "        # to change for other kernels\n",
    "\n",
    "        if ell is None:\n",
    "            ell = self.ell\n",
    "        assert len(enc_chunks) == ell\n",
    "        chunk_size = enc_chunks[0].shape[1]\n",
    "        batch_size = enc_chunks[0].shape[0]\n",
    "\n",
    "        u = torch.cat(enc_chunks, 1).squeeze(2)\n",
    "        n = int(np.log2(ell))\n",
    "\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d * chunk_size\n",
    "            for i in np.arange(0, chunk_size*ell, 2*num_bits):\n",
    "                # [u v] encoded to [(u,v) xor v]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        return u\n",
    "            \n",
    "    def deeppolar_parallel_decode(self, noisy_code):\n",
    "        # Successive cancellation decoder for polar codes\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "        decoded_llrs  = self.KO_parallel_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "\n",
    "    def deeppolar_parallel_decode_depth(self, llrs, depth, bit_position, decoded_llrs):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        dec_chunks = torch.cat([llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "        Lu = self.fnet_dict[depth][bit_position](dec_chunks)\n",
    "\n",
    "        if depth == 1:\n",
    "            u = torch.tanh(Lu/2)\n",
    "            decoded_llrs[:, left_bit_position + unfrozen] = Lu.squeeze(1)\n",
    "        else:\n",
    "            for index, current_position in enumerate(unfrozen):\n",
    "                bit_position_offset = left_bit_position + current_position                \n",
    "                decoded_llrs = self.deeppolar_parallel_decode_depth(Lu[:, :, index:index+1], depth-1, bit_position_offset, decoded_llrs)\n",
    "\n",
    "        return decoded_llrs\n",
    "            \n",
    "    def deeppolar_decode(self, noisy_code):\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        \n",
    "        # don't want to go into useless frozen subtrees.\n",
    "        partial_sums = torch.ones(noisy_code.shape[0], self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "\n",
    "        decoded_llrs, partial_sums = self.deeppolar_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs, partial_sums)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "    \n",
    "    def deeppolar_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        # size of the projection of tht subtree\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        # This chunk - finds infrozen positions in this kernel.\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        if num_nonzero_subproj > 0:\n",
    "            info_bits_present = True      \n",
    "        else:\n",
    "            info_bits_present = False \n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "                \n",
    "        # This will be input to decoder\n",
    "        dec_chunks = [llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            if decoder_type == 'KO_last_parallel':\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                Lu = self.fnet_dict[depth][bit_position](concatenated_chunks)[:, 0, unfrozen]\n",
    "                u_hat = torch.tanh(Lu/2)\n",
    "                decoded_llrs[:, left_bit_position + unfrozen] = Lu\n",
    "                partial_sums[:, depth-1, left_bit_position + unfrozen] = u_hat\n",
    "\n",
    "            else:\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    if current_position > 0:\n",
    "                        # I am adding previously decoded bits . (either onehot or normal)\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "\n",
    "                    if bit_position_offset in self.frozen_positions: # frozen \n",
    "                        # don't update decoded llrs. It already has ones*prior.\n",
    "                        # actually don't need this. can skip.\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, depth-1, bit_position_offset])\n",
    "                    else: # information bit\n",
    "                        # This is the decoding.\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](concatenated_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "\n",
    "                        u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                        decoded_llrs[:, bit_position_offset] = Lu.squeeze(2).squeeze(1)\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = u_hat.squeeze(1)\n",
    "\n",
    "            # Encoding back the decoded bits - for higher layers.\n",
    "            # # Compute decoded codeword\n",
    "            i = left_bit_position * half_index\n",
    "            # num_bits = self.ell**(depth-1)\n",
    "            num_bits = 1\n",
    "\n",
    "            enc_chunks = []\n",
    "            for j in range(ell):\n",
    "                chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                enc_chunks.append(chunk)\n",
    "            if info_bits_present:\n",
    "                concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                if 'KO' in encoder_type:\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        # bit position of the previous depth.\n",
    "                        output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            else:\n",
    "                output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "            \n",
    "            return decoded_llrs, partial_sums\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "\n",
    "                if current_position in unfrozen:\n",
    "                    # General decoding ....\n",
    "                    # add the decoded bit here\n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](concatenated_chunks).squeeze(2)\n",
    "                    else:\n",
    "                        # if current_position == 0:\n",
    "                        #     Lu = self.fnet_dict[depth][bit_position][current_position](llrs)\n",
    "                        # else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "                    decoded_llrs, partial_sums = self.deeppolar_decode_depth(Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums)\n",
    "                else:\n",
    "                    Lu = self.infty*torch.ones_like(llrs)\n",
    "\n",
    "\n",
    "            # Compute decoded codeword\n",
    "            if depth < self.n_ell :\n",
    "                i = left_bit_position * half_index\n",
    "                # num_bits = self.ell**(depth-1)\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        else:\n",
    "                            # bit position of the previous depth.\n",
    "                            output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "\n",
    "                return decoded_llrs, partial_sums\n",
    "            else: # encoding not required for last level - we have already decoded all bits.\n",
    "                return decoded_llrs, partial_sums\n",
    "\n",
    "\n",
    "    def kernel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = [noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "\n",
    "        for current_position in range(ell):\n",
    "            if current_position > 0:\n",
    "                if onehot:\n",
    "                    prev_decoded = get_onehot(u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone().sign()).detach().clone()\n",
    "                else:\n",
    "                    prev_decoded = u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                dec_chunks.append(prev_decoded)\n",
    "            if current_position in info_positions:\n",
    "                if current_position in info_positions:\n",
    "                    concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                    Lu = fnet_dict[current_position](concatenated_chunks)\n",
    "                    decoded_llrs[:, current_position] = Lu.squeeze(2).squeeze(1)\n",
    "                    u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                    u[:, current_position] = u_hat.squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "\n",
    "    def kernel_parallel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = torch.cat([noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "\n",
    "        decoded_llrs = fnet_dict(dec_chunks).squeeze(1)\n",
    "        u = torch.tanh(decoded_llrs/2).squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "    \n",
    "\n",
    "    def deeppolar_list_decode(self, noisy_code, L, crc=None):\n",
    "        \"\"\"\n",
    "        List decoding implementation for DeepPolar with CRC checking\n",
    "        Args:\n",
    "            noisy_code: Input received codeword\n",
    "            L: List size\n",
    "            crc: CRC object for checking decoded messages\n",
    "        \"\"\"\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "        batch_size = noisy_code.shape[0]\n",
    "        depth = self.n_ell\n",
    "\n",
    "        # Initialize L copies of path metrics \n",
    "        PML = 1000*torch.ones(batch_size, L, device=noisy_code.device)\n",
    "        PML[:, 0] = 0\n",
    "\n",
    "        # Initialize L copies of LLRs and partial sums\n",
    "        decoded_llrs = self.infty * torch.ones(batch_size, L, self.N, device=noisy_code.device)\n",
    "        partial_sums = torch.ones(batch_size, L, self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # Expand noisy_code for L paths\n",
    "        noisy_code_expanded = noisy_code.unsqueeze(1).repeat(1, L, 1)\n",
    "\n",
    "        decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "            noisy_code_expanded.unsqueeze(3), depth, 0, decoded_llrs, partial_sums, PML, L)\n",
    "\n",
    "        # Extract information bits for all paths\n",
    "        info_llrs = decoded_llrs[:, :, self.info_positions]\n",
    "        decisions = torch.sign(info_llrs)\n",
    "\n",
    "        # Convert decoded bits to proper format for CRC checking\n",
    "        #decoded_bits = ((1 - decisions) / 2).to(torch.int64)  # Convert from {-1,1} to {1,0}\n",
    "        decoded_bits =decisions\n",
    "        \n",
    "        if crc is not None:\n",
    "            # Check CRC for each path in the list\n",
    "            valid_paths = crc.check_batch(decoded_bits.view(-1, decoded_bits.shape[-1]))\n",
    "            valid_paths = valid_paths.view(batch_size, L)\n",
    "\n",
    "            # For each batch, find first valid path or use first path if none valid\n",
    "            selected_paths = torch.zeros(batch_size, dtype=torch.long, device=decoded_bits.device)\n",
    "            for b in range(batch_size):\n",
    "                valid_indices = torch.where(valid_paths[b])[0]\n",
    "                if len(valid_indices) > 0:\n",
    "                    # Use first valid path\n",
    "                    selected_paths[b] = valid_indices[0]\n",
    "                else:\n",
    "                    # If no valid paths, use path with best metric (index 0)\n",
    "                    selected_paths[b] = 0\n",
    "\n",
    "            # Gather selected paths\n",
    "            batch_indices = torch.arange(batch_size, device=decoded_bits.device)\n",
    "            final_decisions = decisions[batch_indices, selected_paths]\n",
    "        else:\n",
    "            # If no CRC, just return first path\n",
    "            final_decisions = decisions[:, 0]\n",
    "\n",
    "        return final_decisions, info_llrs, PML\n",
    "\n",
    "    def deeppolar_list_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums, PML, L):\n",
    "        \"\"\"\n",
    "        Recursive list decoding implementation for DeepPolar decoder\n",
    "        Args:\n",
    "            llrs: Input LLRs [batch_size, L, N, 1]\n",
    "            depth: Current depth in the decoding tree\n",
    "            bit_position: Current bit position\n",
    "            decoded_llrs: Running decoded LLRs [batch_size, L, N]\n",
    "            partial_sums: Running partial sums [batch_size, L, n_ell+1, N]\n",
    "            PML: Path metrics for each path [batch_size, L]\n",
    "        \"\"\"\n",
    "        batch_size = llrs.shape[0]\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] * bit_position\n",
    "\n",
    "        # Calculate projection information\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj: sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj: [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        info_bits_present = num_nonzero_subproj > 0\n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "\n",
    "        # Initialize decoder chunks\n",
    "        dec_chunks = [llrs[:, :, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        \n",
    "        if depth == 1:  # Base case\n",
    "            if decoder_type != 'KO_last_parallel':\n",
    "            \n",
    "                # Sequential decoding of each position\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    \n",
    "\n",
    "                    if current_position > 0:\n",
    "                        # Add previously decoded bits\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "                    \n",
    "                     \n",
    "                    \n",
    "                    if bit_position_offset in self.frozen_positions:\n",
    "                        # Handle frozen bits\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, :, depth-1, bit_position_offset])\n",
    "                        DM = decoded_llrs[:, :, bit_position_offset]\n",
    "                        # Update path metrics for frozen bits\n",
    "                        PML = PML + torch.abs(DM) * (DM < 0).float()\n",
    "\n",
    "                    else:  # Information bit case\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                        orig_shape = concatenated_chunks.shape\n",
    "                        reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "\n",
    "                        # Get decoder output\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](reshaped_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                        Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "\n",
    "                        # Store LLRs and get decisions\n",
    "                        decoded_llrs[:,:, bit_position_offset] = Lu.squeeze(3).squeeze(2)\n",
    "                        DM = Lu.squeeze(3).squeeze(2)\n",
    "                        dec = (DM < 0).float()\n",
    "                        dec = 1-2*dec\n",
    "\n",
    "                        # Compute path metrics for both decisions\n",
    "                        PM2 = torch.cat([PML, PML + torch.abs(DM)], dim=1)  # [batch_size, 2L]\n",
    "\n",
    "                        # Select best L paths\n",
    "                        PML, pos = torch.topk(PM2, L, dim=1, largest=False)  \n",
    "\n",
    "                        # Update decisions and states\n",
    "                        pos_dec = pos.clone()\n",
    "                        pos_dec[pos >= L] = pos_dec[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "                        dec = torch.gather(dec, 1, pos_dec)  # Gather decisions for selected paths\n",
    "                        dec = torch.where(pos >= L, -dec, dec)  # Flip decisions for paths from second half\n",
    "\n",
    "                        # Update states with gathered indices\n",
    "                        # First adjust pos for gathering from L-sized tensors\n",
    "                        pos_adj = pos.clone()\n",
    "                        pos_adj[pos >= L] = pos_adj[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "\n",
    "                        # For decoded_llrs\n",
    "                        pos_expand = pos_adj.unsqueeze(-1).expand(-1, -1, decoded_llrs.shape[-1])\n",
    "                        decoded_llrs = torch.gather(decoded_llrs, 1, pos_expand)\n",
    "\n",
    "                        # For partial_sums \n",
    "                        pos_expand_sums = pos_adj.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, partial_sums.shape[2], partial_sums.shape[3])\n",
    "                        partial_sums = torch.gather(partial_sums, 1, pos_expand_sums)\n",
    "\n",
    "\n",
    "                        # Store updated decisions\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = dec\n",
    "\n",
    "                        \n",
    "                       \n",
    "                 \n",
    "\n",
    "            # Encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = 1\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        else:  # General case for deeper levels\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                #print(concatenated_chunks.shape)\n",
    "                orig_shape = concatenated_chunks.shape\n",
    "                reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                if current_position in unfrozen:\n",
    "                    \n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](reshaped_chunks).squeeze(3)\n",
    "                    else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                    Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "                    \n",
    "                    # Recursive call for each path\n",
    "                    decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "                        Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums, PML, L)\n",
    "                else:\n",
    "                    Lu = self.infty * torch.ones_like(llrs)\n",
    "\n",
    "            # Handle encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                        \n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        return decoded_llrs, partial_sums, PML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e848578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen(N, K, rate_profile, target_K = None):\n",
    "    n = int(np.log2(N))\n",
    "    if rate_profile == 'polar':\n",
    "        # computed for SNR = 0\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "\n",
    "            # for RM :(\n",
    "            # rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 3, 5, 8, 4, 2, 1, 0])\n",
    "\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "        elif n<9:\n",
    "            rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "        else:\n",
    "            rs = np.array([1023, 1022, 1021, 1019, 1015, 1007, 1020,  991, 1018, 1017, 1014,\n",
    "       1006,  895, 1013, 1011,  959, 1005,  990, 1003,  989,  767, 1016,\n",
    "        999, 1012,  987,  958,  983,  957, 1010, 1004,  955, 1009,  894,\n",
    "        975,  893, 1002,  951, 1001,  988,  511,  766,  998,  891,  943,\n",
    "        986,  997,  985,  887,  956,  765,  995,  927,  982,  981,  879,\n",
    "        954,  974,  763,  953,  979,  510, 1008,  759,  863,  950,  892,\n",
    "       1000,  973,  949,  509,  890,  971,  996,  942,  751,  984,  889,\n",
    "        507,  947,  831,  886,  967,  941,  764,  926,  980,  994,  939,\n",
    "        885,  993,  735,  878,  925,  503,  762,  883,  978,  935,  703,\n",
    "        495,  952,  877,  761,  972,  923,  977,  948,  758,  862,  875,\n",
    "        919,  970,  757,  861,  508,  969,  750,  946,  479,  888,  639,\n",
    "        871,  911,  830,  940,  859,  755,  966,  945,  749,  506,  884,\n",
    "        938,  965,  829,  734,  924,  855,  505,  747,  963,  937,  882,\n",
    "        934,  827,  733,  447,  992,  847,  876,  501,  921,  702,  494,\n",
    "        881,  760,  743,  933,  502,  918,  874,  922,  823,  731,  499,\n",
    "        860,  756,  931,  701,  873,  493,  727,  917,  870,  976,  815,\n",
    "        910,  383,  968,  478,  858,  754,  699,  491,  869,  944,  748,\n",
    "        638,  915,  477,  719,  909,  964,  255,  799,  504,  857,  854,\n",
    "        753,  828,  746,  695,  487,  907,  637,  867,  853,  475,  936,\n",
    "        962,  446,  732,  826,  745,  846,  500,  825,  903,  687,  932,\n",
    "        635,  471,  445,  742,  880,  498,  730,  851,  822,  382,  920,\n",
    "        845,  741,  443,  700,  729,  631,  492,  872,  961,  726,  821,\n",
    "        930,  497,  381,  843,  463,  916,  739,  671,  623,  490,  929,\n",
    "        439,  814,  819,  868,  752,  914,  698,  725,  839,  856,  476,\n",
    "        813,  718,  908,  486,  723,  866,  489,  607,  431,  697,  379,\n",
    "        811,  798,  913,  575,  717,  254,  694,  636,  474,  807,  715,\n",
    "        906,  797,  693,  865,  960,  852,  744,  634,  473,  795,  905,\n",
    "        485,  415,  483,  470,  444,  375,  850,  740,  686,  902,  824,\n",
    "        691,  253,  711,  633,  844,  685,  630,  901,  367,  791,  928,\n",
    "        728,  820,  849,  783,  670,  899,  738,  842,  683,  247,  469,\n",
    "        441,  442,  462,  251,  737,  438,  467,  351,  629,  841,  724,\n",
    "        679,  669,  496,  461,  818,  380,  437,  627,  622,  459,  378,\n",
    "        239,  488,  667,  838,  430,  484,  812,  621,  319,  817,  435,\n",
    "        377,  696,  722,  912,  606,  810,  864,  716,  837,  721,  714,\n",
    "        809,  796,  455,  472,  619,  835,  692,  663,  223,  414,  904,\n",
    "        427,  806,  482,  632,  713,  690,  848,  605,  373,  252,  794,\n",
    "        429,  710,  684,  615,  805,  900,  655,  468,  366,  603,  413,\n",
    "        574,  481,  371,  250,  793,  466,  423,  374,  689,  628,  440,\n",
    "        365,  709,  789,  803,  411,  573,  682,  249,  460,  790,  668,\n",
    "        599,  350,  707,  246,  681,  465,  571,  626,  436,  407,  782,\n",
    "        191,  127,  363,  620,  666,  458,  245,  349,  677,  434,  678,\n",
    "        591,  787,  399,  457,  359,  238,  625,  840,  567,  736,  665,\n",
    "        428,  376,  781,  898,  618,  675,  318,  454,  662,  243,  897,\n",
    "        347,  836,  816,  720,  433,  604,  617,  779,  808,  661,  834,\n",
    "        712,  804,  833,  559,  237,  453,  426,  222,  317,  775,  372,\n",
    "        343,  412,  235,  543,  614,  451,  425,  422,  613,  370,  221,\n",
    "        315,  480,  335,  659,  654,  364,  190,  369,  248,  653,  688,\n",
    "        231,  410,  602,  611,  802,  792,  421,  651,  601,  598,  708,\n",
    "        311,  219,  572,  597,  788,  570,  409,  590,  362,  801,  680,\n",
    "        464,  406,  419,  348,  647,  786,  215,  589,  706,  361,  676,\n",
    "        566,  189,  595,  244,  569,  303,  405,  358,  456,  346,  398,\n",
    "        565,  242,  126,  705,  780,  587,  624,  664,  236,  187,  357,\n",
    "        432,  785,  558,  674,  207,  403,  397,  452,  345,  563,  778,\n",
    "        241,  316,  342,  616,  660,  557,  125,  234,  183,  287,  355,\n",
    "        583,  673,  395,  424,  314,  220,  777,  341,  612,  658,  123,\n",
    "        175,  774,  555,  233,  334,  542,  450,  313,  391,  230,  652,\n",
    "        368,  218,  339,  600,  119,  333,  657,  610,  773,  541,  310,\n",
    "        420,  159,  229,  650,  551,  596,  609,  408,  217,  449,  188,\n",
    "        309,  214,  331,  111,  539,  360,  771,  649,  302,  418,  594,\n",
    "        896,  227,  404,  646,  186,  588,  832,  568,  213,  417,  301,\n",
    "        307,  356,  402,  800,  564,  327,   95,  206,  240,  535,  593,\n",
    "        645,  586,  344,  396,  185,  401,  211,  354,  299,  585,  286,\n",
    "        562,  643,  182,  205,  124,  232,  285,  295,  181,  556,  582,\n",
    "        527,  394,  340,   63,  203,  561,  353,  448,  122,  283,  393,\n",
    "        581,  554,  174,  390,  704,  312,  338,  228,  179,  784,  199,\n",
    "        553,  121,  173,  389,  540,  579,  332,  118,  672,  550,  337,\n",
    "        158,  279,  271,  416,  216,  308,  387,  538,  549,  226,  330,\n",
    "        776,  171,  212,  117,  110,  329,  656,  157,  772,  306,  326,\n",
    "        225,  167,  115,  537,  534,  184,  109,  300,  547,  305,  210,\n",
    "        155,  533,  325,  352,  608,  400,  298,  204,   94,  648,  284,\n",
    "        209,  151,  180,  107,  770,  297,  392,  323,  592,  202,  644,\n",
    "         93,  294,  178,  103,  143,  282,   62,  336,  201,  120,  172,\n",
    "        198,  769,  584,   91,  388,  293,  177,  526,  278,  281,  642,\n",
    "        525,  531,   61,  170,  116,  197,   87,  156,  277,  114,  560,\n",
    "        169,   59,  291,  580,  275,  523,  641,  270,  195,  552,  519,\n",
    "        166,  224,  578,  108,  269,   79,  154,  113,  548,  577,  536,\n",
    "        328,   55,  106,  165,  153,  150,  386,  208,  324,  546,  385,\n",
    "        267,   47,   92,  163,  296,  304,  105,  102,  149,  263,  532,\n",
    "        322,  292,  545,   90,  200,   31,  321,  530,  142,  176,  147,\n",
    "        101,  141,  196,  524,  529,  290,   89,  280,   60,   86,   99,\n",
    "        139,  168,   58,  522,  276,   85,  194,  289,   78,  135,  112,\n",
    "        521,   57,   83,   54,  518,  274,  268,  768,  164,   77,  152,\n",
    "        193,   53,  162,  104,  517,  273,  266,   75,   46,  148,   51,\n",
    "        640,  100,   45,  576,  161,  265,  262,   71,  146,   30,  140,\n",
    "         88,  515,   98,   43,   29,  261,  145,  138,   84,  259,   39,\n",
    "         97,   27,   56,   82,  137,   76,  384,  134,   23,   52,  133,\n",
    "        320,   15,   73,   50,   81,  131,   44,   70,  544,  192,  528,\n",
    "        288,  520,  160,  272,   74,   49,  516,   42,   69,   28,  144,\n",
    "         41,   67,   96,  514,   38,  264,  260,  136,   22,   25,   37,\n",
    "         80,  513,   26,  258,   35,  132,   21,  257,   72,   14,   48,\n",
    "         13,   19,  130,   68,   40,   11,  512,   66,  129,    7,   36,\n",
    "         24,   34,  256,   20,   65,   33,   12,  128,   18,   10,   17,\n",
    "          6,    9,   64,    5,    3,   32,   16,    8,    4,    2,    1,\n",
    "          0])\n",
    "        rs = rs[rs<N]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'RM':\n",
    "        rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        Fr = np.argsort(rmweight)[:-K]\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted_last':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds[::-1]\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'rev_polar':\n",
    "\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:target_K].copy()\n",
    "        rs[:target_K] = first_inds[::-1]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    return Fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(codebook):\n",
    "    \"\"\"Calculate pairwise distances between codewords\"\"\"\n",
    "    dists = []\n",
    "    for row1, row2 in combinations(codebook, 2):\n",
    "        distance = (row1-row2).pow(2).sum()\n",
    "        dists.append(np.sqrt(distance.item()))\n",
    "    return dists, np.min(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54073b6",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2a9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_original_path):\n",
    "    plt.figure()\n",
    "    plt.plot(bers_enc, label='BER')\n",
    "    plt.plot(moving_average(bers_enc, n=10), label='BER moving avg')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Training BER ENC')\n",
    "    plt.savefig(os.path.join(results_save_original_path, 'training_ber_enc.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Similar plots for losses_enc, bers_dec, losses_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96d3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save models\n",
    "def save_model(polar, iter, results_save_original_path, best=False):\n",
    "    torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map], \n",
    "               os.path.join(results_save_original_path, f'Models/fnet_gnet_{iter}.pt'))\n",
    "    if iter > 1:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt'))\n",
    "    if best:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e6cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        # Convert to binary if needed\n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        # Initialize result tensor\n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        \n",
    "        # Prepare dividend for all batches at once\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        \n",
    "        # Perform batch polynomial division\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        \n",
    "        # Combine message and remainder\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        # Convert back to float if needed\n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "            \n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        \"\"\"Check if received messages pass CRC in batch.\"\"\"\n",
    "        # Convert to binary if needed\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "            \n",
    "        # Perform polynomial division on all messages at once\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        \n",
    "        # Check if all remainder bits are zero for each message\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    \n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        \"\"\"Perform polynomial division in batch using vectorized operations.\"\"\"\n",
    "        # Make copy to avoid modifying input\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        # Find positions of 1s for all batches\n",
    "        for i in range(n - self.degree):\n",
    "            # Find batches where current bit is 1\n",
    "            active_batches = result[:, i] == 1\n",
    "            \n",
    "            if torch.any(active_batches):\n",
    "                # XOR with polynomial for active batches\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        \n",
    "        # Return last degree bits (remainder) for all batches\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b167a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crc = CRC(crc_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4986216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n"
     ]
    }
   ],
   "source": [
    "if anomaly:\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "#ID = str(np.random.randint(100000, 999999)) if id is None else id\n",
    "#ID = 207515\n",
    "\n",
    "\n",
    "###############\n",
    "### Polar code\n",
    "##############\n",
    "\n",
    "### Encoder\n",
    "\n",
    "if last_ell is not None:\n",
    "    depth_map = defaultdict(int)\n",
    "    n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "    for d in range(1, n+1):\n",
    "        depth_map[d] = kernel_size\n",
    "    depth_map[n+1] = last_ell\n",
    "    assert np.prod(list(depth_map.values())) == N\n",
    "    polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "else:\n",
    "    polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "info_inds = polar.info_positions\n",
    "frozen_inds = polar.frozen_positions\n",
    "\n",
    "print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "##############\n",
    "### Neural networks\n",
    "##############\n",
    "ell = kernel_size\n",
    "if N == ell: # Kernel pre-training\n",
    "    polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "elif N > ell: # Initialize full network with pretrained kernels\n",
    "    polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "if binary:\n",
    "    load_path = os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt')\n",
    "    assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "    results_save_original_path = os.path.join(results_save_original_path, 'Binary')\n",
    "    os.makedirs(results_save_original_path, exist_ok=True)\n",
    "    os.makedirs(results_save_original_path +'/Models', exist_ok=True)\n",
    "\n",
    "if load_path is not None:\n",
    "    if test:\n",
    "        if test_load_path is None:\n",
    "            print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "    else:\n",
    "        checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "        fnet_dict = checkpoint1[0]\n",
    "        gnet_dict = checkpoint1[1]\n",
    "\n",
    "        polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "        print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "if 'KO' in decoder_type:\n",
    "    dec_params = []\n",
    "    for i in polar.fnet_dict.keys():\n",
    "        for j in polar.fnet_dict[i].keys():\n",
    "            if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                for k in polar.fnet_dict[i][j].keys():\n",
    "                    dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "            else:\n",
    "                dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "elif decoder_type == 'RNN':\n",
    "    dec_params = polar.fnet_dict.parameters()\n",
    "else:\n",
    "    dec_train_iters = 0\n",
    "\n",
    "if 'KO' in encoder_type:\n",
    "    enc_params = []\n",
    "    if shared:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            enc_params += list(polar.gnet_dict[i].parameters())\n",
    "    else:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            for j in polar.gnet_dict[i].keys():\n",
    "                enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "elif encoder_type == 'scaled':\n",
    "    enc_params = [polar.a]\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "else:\n",
    "    enc_train_iters = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'BCE' in loss_type:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'L1':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_type == 'huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "info_positions = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d5c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053eafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__0.0_Encoder_KO_-2.0_Decoder/epochs_500_batchsize_20000'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_save_original_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e6b672b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "Checkpoint Loaded\n",
      "NN weights loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "times = []\n",
    "results_load_path = results_save_original_path\n",
    "\n",
    "\n",
    "\n",
    "checkpoint1 = torch.load(results_load_path +'/Models/fnet_gnet_final.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "fnet_dict = checkpoint1[0]\n",
    "gnet_dict = checkpoint1[1]\n",
    "print('Checkpoint Loaded')\n",
    "\n",
    "polar.load_nns(fnet_dict, gnet_dict, shared = shared)\n",
    "\n",
    "if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "    snr_range = [test_snr_start]\n",
    "else:\n",
    "    snrs_interval = (test_snr_end - test_snr_start)* 1.0 /  (snr_points-1)\n",
    "    snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# For polar code testing.\n",
    "\n",
    "ell = 2\n",
    "Frozen = get_frozen(N, K, rate_profile)\n",
    "Frozen.sort()\n",
    "polar_l_2 = PolarCode(int(np.log2(N)), K, Fr=Frozen, infty = infty, hard_decision=hard_decision)\n",
    "\n",
    "\n",
    "if pairwise:\n",
    "    codebook_size = 1000\n",
    "    all_msg_bits = 2 * (torch.rand(codebook_size, K, device = device) < 0.5).float() - 1\n",
    "    deeppolar_codebook = polar.deeppolar_encode(all_msg_bits)\n",
    "    polar_codebook = polar_l_2.encode_plotkin(all_msg_bits)\n",
    "    gaussian_codebook = F.normalize(torch.randn(codebook_size, N), p=2, dim=1)*np.sqrt(N)\n",
    "\n",
    "    from scipy import stats\n",
    "    w_statistic_deeppolar, p_value_deeppolar = stats.shapiro(deeppolar_codebook.detach().cpu().numpy())\n",
    "    w_statistic_gaussian, p_value_gaussian = stats.shapiro(gaussian_codebook.detach().cpu().numpy())\n",
    "    w_statistic_polar, p_value_polar = stats.shapiro(polar_codebook.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Deeppolar Shapiro test W = {w_statistic_deeppolar}, p-value = {p_value_deeppolar}\")\n",
    "    print(f\"Gaussian Shapiro test W = {w_statistic_gaussian}, p-value = {p_value_gaussian}\")\n",
    "    print(f\"Polar Shapiro test W = {w_statistic_polar}, p-value = {p_value_polar}\")\n",
    "\n",
    "    dists_deeppolar, md_deeppolar = pairwise_distances(deeppolar_codebook)\n",
    "    dists_polar, md_polar = pairwise_distances(polar_codebook)\n",
    "    dists_gaussian, md_gaussian = pairwise_distances(gaussian_codebook)\n",
    "\n",
    "    # Function to calculate and plot PDF\n",
    "    def plot_pdf(data, label, bins=30, alpha=0.5, color=None, linewidth=1.0):\n",
    "        counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, counts, label=label, alpha=alpha, \n",
    "                 color=color, linewidth=linewidth)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Larger figure size\n",
    "\n",
    "    # Define better colors\n",
    "    colors = ['#e74c3c', '#3498db']  # Red and Blue\n",
    "    linewidth = 2.5\n",
    "\n",
    "    # Plot with enhanced styling\n",
    "    plot_pdf(dists_deeppolar, 'DeepPolar', bins=300, color=colors[0], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "    plot_pdf(dists_gaussian, 'Gaussian', bins=300, color=colors[1], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "\n",
    "    # Enhance grid - both major and minor\n",
    "    plt.grid(True, which='major', linestyle='-', alpha=0.5)\n",
    "    plt.grid(True, which='minor', linestyle=':', alpha=0.3)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    # Enhance labels and title\n",
    "    plt.xlabel('Pairwise Distance', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Probability Density', fontsize=16, fontweight='bold')\n",
    "    #plt.title(f'Pairwise Distances Distribution (N={N}, K={K})', \n",
    "    #          fontsize=16, fontweight='bold', pad=15)\n",
    "\n",
    "    # Enhance legend\n",
    "    plt.legend(fontsize=16, frameon=True, fancybox=True, \n",
    "              shadow=True, loc='upper left')\n",
    "\n",
    "    # Enhance ticks\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save with high DPI for better quality\n",
    "    plt.savefig(os.path.join(results_save_original_path, f\"hists_N{N}_K{K}_{id}_2.pdf\"), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(f'dists_deeppolar: {dists_deeppolar}')\n",
    "    print(f'dists_gaussian: {dists_gaussian}')\n",
    "if epos:\n",
    "    from collections import OrderedDict, Counter\n",
    "\n",
    "    def get_epos(k1, k2):\n",
    "        # return counter for bit ocations of first-errors\n",
    "        bb = torch.ne(k1.cpu().sign(), k2.cpu().sign())\n",
    "        # inds = torch.nonzero(bb)[:, 1].numpy()\n",
    "        idx = []\n",
    "        for ii in range(bb.shape[0]):\n",
    "            try:\n",
    "                iii = list(bb.cpu().float().numpy()[ii]).index(1)\n",
    "                idx.append(iii)\n",
    "            except:\n",
    "                pass\n",
    "        counter = Counter(idx)\n",
    "        ordered_counter = OrderedDict(sorted(counter.items()))\n",
    "        return ordered_counter\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (k, msg_bits) in enumerate(Test_Data_Generator):\n",
    "            msg_bits = msg_bits.to(device)\n",
    "            polar_code = polar_l_2.encode_plotkin(msg_bits)\n",
    "            noisy_code = polar.channel(polar_code, dec_train_snr)\n",
    "            noise = noisy_code - polar_code\n",
    "            deeppolar_code = polar.deeppolar_encode(msg_bits)\n",
    "            noisy_deeppolar_code = deeppolar_code + noise\n",
    "            SC_llrs, decoded_SC_msg_bits = polar_l_2.sc_decode_new(noisy_code, dec_train_snr)\n",
    "            deeppolar_llrs, decoded_deeppolar_msg_bits = polar.deeppolar_decode(noisy_deeppolar_code)\n",
    "\n",
    "            if k == 0:\n",
    "                epos_deeppolar = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "            else:\n",
    "                epos_deeppolar1 = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC1 = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "                epos_deeppolar = epos_deeppolar + epos_deeppolar1\n",
    "                epos_SC = epos_SC + epos_SC1\n",
    "\n",
    "        print(f\"epos_deeppolar: {epos_deeppolar}\")\n",
    "        print(f\"EPOS_SC: {epos_SC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ada1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeppolar_example_test(polar, KO, snr_range, device, info_positions, binary=False, num_examples=10**6, noise_type='awgn', L=8, crc=crc):\n",
    "    bers_KO_test = [0. for _ in snr_range]\n",
    "    blers_KO_test = [0. for _ in snr_range]\n",
    "    bers_SC_test = [0. for _ in snr_range]\n",
    "    blers_SC_test = [0. for _ in snr_range]\n",
    "\n",
    "    kernel = N == KO.ell\n",
    "    num_batches = num_examples // test_batch_size\n",
    "\n",
    "    print(f\"TESTING for {num_examples} examples ({num_batches} batches)\")\n",
    "    for snr_ind, snr in enumerate(snr_range):\n",
    "        total_block_errors_SC = 0\n",
    "        total_block_errors_KO = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        sigma = snr_db2sigma(snr)\n",
    "\n",
    "        try:\n",
    "            for _ in range(num_batches):\n",
    "                msg_bits = 2 * (torch.rand(test_batch_size, K-crc_len) < 0.5).float() - 1\n",
    "                msg_bits = msg_bits.to(device)\n",
    "                \n",
    "                msg_bits_with_crc = crc.encode(msg_bits)\n",
    "                \n",
    "                polar_code = polar.encode_plotkin(msg_bits_with_crc)\n",
    "\n",
    "                if 'KO' in encoder_type:\n",
    "                    if kernel:\n",
    "                        KO_polar_code = KO.kernel_encode(kernel_size, KO.gnet_dict[1][0], msg_bits_with_crc, info_positions, binary=binary)\n",
    "                    else:\n",
    "                        KO_polar_code = KO.deeppolar_encode(msg_bits_with_crc, binary=binary)\n",
    "\n",
    "                noisy_code = polar.channel(polar_code, snr, noise_type)\n",
    "                \n",
    "                noisy_KO_code = polar.channel(KO_polar_code, snr, noise_type) if 'KO' in encoder_type else noisy_code\n",
    "\n",
    "                SC_llrs, decoded_SC_msg_bits_with_crc = polar.sc_decode_new(noisy_code, snr)\n",
    "                decoded_SC_msg_bits = decoded_SC_msg_bits_with_crc[:,:K-crc_len]\n",
    "                ber_SC = errors_ber(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                bler_SC = errors_bler(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                total_block_errors_SC += int(bler_SC*test_batch_size)\n",
    "\n",
    "                \n",
    "                final_decisions, info_llrs, PML = KO.deeppolar_list_decode(noisy_KO_code, L, crc)\n",
    "                decoded_KO_msg_bits = final_decisions[:,:K-crc_len]\n",
    "                ber_KO = errors_ber(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                bler_KO = errors_bler(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                total_block_errors_KO += int(bler_KO*test_batch_size)\n",
    "\n",
    "                batches_processed += 1\n",
    "\n",
    "                # Update accumulative results\n",
    "                bers_KO_test[snr_ind] += ber_KO\n",
    "                bers_SC_test[snr_ind] += ber_SC\n",
    "                blers_KO_test[snr_ind] += bler_KO\n",
    "                blers_SC_test[snr_ind] += bler_SC\n",
    "\n",
    "                # Progress logging\n",
    "                if batches_processed % 10 == 0:  # Print every 10 batches\n",
    "                    print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, Progress: {batches_processed}/{num_batches} batches\", end='\\r')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        # Normalize by actual number of batches processed\n",
    "        bers_KO_test[snr_ind] /= batches_processed\n",
    "        bers_SC_test[snr_ind] /= batches_processed\n",
    "        blers_KO_test[snr_ind] /= batches_processed\n",
    "        blers_SC_test[snr_ind] /= batches_processed\n",
    "\n",
    "        print(f\"\\nSNR: {snr} dB, Sigma: {sigma:.5f}\")\n",
    "        print(f\"SC   - BER: {bers_SC_test[snr_ind]:.6f}, BLER: {blers_SC_test[snr_ind]:.6f}\")\n",
    "        print(f\"Deep - BER: {bers_KO_test[snr_ind]:.6f}, BLER: {blers_KO_test[snr_ind]:.6f}\")\n",
    "\n",
    "    return bers_SC_test, blers_SC_test, bers_KO_test, blers_KO_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "645cc944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "TESTING for 1000000 examples (1000 batches)\n",
      "SNR: -5.0 dB, Sigma: 1.77828, Progress: 1000/1000 batches\n",
      "SNR: -5.0 dB, Sigma: 1.77828\n",
      "SC   - BER: 0.166732, BLER: 0.435796\n",
      "Deep - BER: 0.129534, BLER: 0.460450\n",
      "SNR: -4.0 dB, Sigma: 1.58489, Progress: 1000/1000 batches\n",
      "SNR: -4.0 dB, Sigma: 1.58489\n",
      "SC   - BER: 0.072305, BLER: 0.196391\n",
      "Deep - BER: 0.046149, BLER: 0.190078\n",
      "SNR: -3.0 dB, Sigma: 1.41254, Progress: 1000/1000 batches\n",
      "SNR: -3.0 dB, Sigma: 1.41254\n",
      "SC   - BER: 0.020044, BLER: 0.055956\n",
      "Deep - BER: 0.009531, BLER: 0.046650\n",
      "SNR: -2.0 dB, Sigma: 1.25893, Progress: 1000/1000 batches\n",
      "SNR: -2.0 dB, Sigma: 1.25893\n",
      "SC   - BER: 0.003003, BLER: 0.008492\n",
      "Deep - BER: 0.001045, BLER: 0.006504\n",
      "SNR: -1.0 dB, Sigma: 1.12202, Progress: 1000/1000 batches\n",
      "SNR: -1.0 dB, Sigma: 1.12202\n",
      "SC   - BER: 0.000211, BLER: 0.000596\n",
      "Deep - BER: 0.000057, BLER: 0.000490\n",
      "Test SNRs : [-5.0, -4.0, -3.0, -2.0, -1.0]\n",
      "\n",
      "Test Sigmas : [1.7782794100389228, 1.5848931924611136, 1.4125375446227544, 1.2589254117941673, 1.1220184543019633]\n",
      "\n",
      "BERs of DeepPolar: [0.12953370602428912, 0.04614902944862843, 0.009531411760952324, 0.0010450000036107668, 5.6764705761452203e-05]\n",
      "BERs of SC decoding: [0.16673238214850425, 0.07230508836731314, 0.020044176478870215, 0.003003058826652705, 0.00021067647132258572]\n",
      "BLERs of DeepPolar: [0.4604500000000001, 0.19007799999999986, 0.04664999999999987, 0.0065039999999999525, 0.0004900000000000004]\n",
      "BLERs of SC decoding: [0.43579599999999935, 0.19639099999999973, 0.05595599999999983, 0.008491999999999954, 0.0005960000000000004]\n",
      "time = 366.0259726405144 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "\n",
    "start = time.time()\n",
    "bers_SC_test, blers_SC_test, bers_deeppolar_test, blers_deeppolar_test = deeppolar_example_test(polar_l_2, polar, snr_range, device, info_positions, binary = binary, num_examples=10**6, noise_type = noise_type, L=L, crc=crc)\n",
    "print(\"Test SNRs : {}\\n\".format(snr_range))\n",
    "print(f\"Test Sigmas : {[snr_db2sigma(s) for s in snr_range]}\\n\")\n",
    "print(\"BERs of DeepPolar: {0}\".format(bers_deeppolar_test))\n",
    "print(\"BERs of SC decoding: {0}\".format(bers_SC_test))\n",
    "print(\"BLERs of DeepPolar: {0}\".format(blers_deeppolar_test))\n",
    "print(\"BLERs of SC decoding: {0}\".format(blers_SC_test))\n",
    "print(f\"time = {(time.time() - start)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f42683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BER\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "ok = 0\n",
    "plt.semilogy(snr_range, bers_deeppolar_test, label=\"DeepPolar SC List\", marker='*', linewidth=1.5)\n",
    "\n",
    "plt.semilogy(snr_range, bers_SC_test, label=\"SC decoder\", marker='^', linewidth=1.5)\n",
    "\n",
    "## BLER\n",
    "plt.semilogy(snr_range, blers_deeppolar_test, label=\"DeepPolar SC List BLER)\", marker='*', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.semilogy(snr_range, blers_SC_test, label=\"SC decoder (BLER)\", marker='^', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=16)\n",
    "plt.ylabel(\"Error Rate\", fontsize=16)\n",
    "\n",
    "plt.legend(prop={'size': 15})\n",
    "if test_load_path is not None:\n",
    "    os.makedirs('Polar_Results/figures', exist_ok=True)\n",
    "    fig_save_path = results_save_path + 'Polar_Results/figures/SCListDeepPolar.pdf'\n",
    "else:\n",
    "    fig_save_path = results_save_path + f\"/SCList_Step{model_iters if model_iters is not None else 'final'}{'_binary' if binary else ''}.pdf\"\n",
    "if not no_fig:\n",
    "    plt.savefig(fig_save_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
