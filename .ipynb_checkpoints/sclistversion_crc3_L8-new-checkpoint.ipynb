{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8752b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc45a",
   "metadata": {},
   "source": [
    "# Configuration variables (previously args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b957ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # Block length\n",
    "K = 37   # Message size\n",
    "kernel_size = 16  # Kernel size (ell)\n",
    "rate_profile = 'polar'  # Rate profiling; choices=['RM', 'polar', 'sorted', 'last', 'rev_polar', 'custom']\n",
    "infty = 1000.  # Infinity value for frozen position LLR in polar dec\n",
    "lse = 'minsum'  # LSE function; choices=['minsum', 'lse']\n",
    "hard_decision = False  # Polar code sc decoding hard decision?\n",
    "\n",
    "# DeepPolar parameters\n",
    "encoder_type = 'KO'  # Type of encoding; choices=['KO', 'scaled', 'polar']\n",
    "decoder_type = 'KO'  # Type of decoding; choices=['KO', 'SC', 'KO_parallel', 'KO_last_parallel']\n",
    "enc_activation = 'selu'  # Activation function\n",
    "dec_activation = 'selu'  # Activation function\n",
    "dropout_p = 0.\n",
    "dec_hidden_size = 128  # Neural network size\n",
    "enc_hidden_size = 64   # Neural network size\n",
    "f_depth = 3  # Decoder neural network depth\n",
    "g_depth = 3  # Encoder neural network depth\n",
    "g_skip_depth = 1  # Encoder neural network skip depth\n",
    "g_skip_layer = 1  # Encoder neural network skip layer\n",
    "onehot = False  # Use onehot representation of prev_decoded_bits\n",
    "shared = False  # Share weights across depth\n",
    "use_skip = True  # Use skip connections\n",
    "use_norm = False  # Use normalization\n",
    "binary = False  # Use binary quantization\n",
    "\n",
    "# Infrastructure parameters\n",
    "id = None  # Optional ID for multiple runs\n",
    "test = False  # Testing mode flag\n",
    "pairwise = False  # Plot codeword pairwise distances\n",
    "epos = False  # Plot error positions\n",
    "seed = None  # Random seed\n",
    "anomaly = False  # Enable anomaly detection\n",
    "dataparallel = False  # Use dataparallel\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture parameters\n",
    "polar_depths = []  # List of depths to use polar encoding/decoding\n",
    "last_ell = None  # Use kernel last_ell last layer\n",
    "\n",
    "\n",
    "# Channel parameters\n",
    "radar_power = None  # Radar power parameter\n",
    "radar_prob = 0.1  # Radar probability parameter\n",
    "\n",
    "# Training parameters\n",
    "full_iters = 500  # Full iterations\n",
    "enc_train_iters = 30  # Encoder iterations\n",
    "dec_train_iters = 300  # Decoder iterations\n",
    "enc_train_snr = 0.  # SNR at which encoder is trained\n",
    "dec_train_snr = -2.  # SNR at which decoder is trained\n",
    "weight_decay = 0.0\n",
    "dec_lr = 0.001  # Decoder Learning rate\n",
    "enc_lr = 0.001  # Encoder Learning rate\n",
    "batch_size = 20000  # Size of batches\n",
    "small_batch_size = 5000  # Size of small batches\n",
    "noise_type = 'awgn'  # Noise type; choices=['fading', 'awgn', 'radar']\n",
    "regularizer = None  # Regularizer type; choices=['std', 'max_deviation','polar']\n",
    "regularizer_weight = 0.001\n",
    "loss_type = 'BCE' # loss function; choices=['MSE', 'BCE', 'BCE_reg', 'L1', 'huber', 'focal', 'BCE_bler']\n",
    "initialization = 'random'  # Initialization type; choices=['random', 'zeros']\n",
    "optim_name = 'Adam'  # Optimizer type; choices=['Adam', 'RMS', 'SGD', 'AdamW']\n",
    "\n",
    "# Testing parameters\n",
    "test_batch_size = 500  # Size of test batches\n",
    "num_errors = 100  # Test until _ block errors\n",
    "test_snr_start = -5.  # Testing SNR start\n",
    "test_snr_end = -1.   # Testing SNR end\n",
    "snr_points = 5       # Testing SNR num points\n",
    "\n",
    "\n",
    "\n",
    "# Model saving/loading parameters\n",
    "model_save_per = 100  # Model save frequency\n",
    "model_iters = None  # Option to load specific model iteration\n",
    "test_load_path = None  # Path to load test model\n",
    "\n",
    "load_path = None  # Load path \n",
    "kernel_load_path = 'Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new'   # Kernel load path\n",
    "no_fig = False  # Plot figure option\n",
    "\n",
    "\n",
    "# Scheduler parameters\n",
    "scheduler = 'cosine' # choices = ['reduce', '1cycle', 'cosine']\n",
    "scheduler_patience = None  # Scheduler patience\n",
    "batch_schedule = False  # Use batch scheduler\n",
    "batch_patience = 50  # Batch scheduler patience \n",
    "batch_factor = 2  # Batch multiplication factor\n",
    "min_batch_size = 500  # Minimum batch size\n",
    "max_batch_size = 50000  # Maximum batch size\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117821f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab1d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "crc_len = 3  # CRC length \n",
    "# Initialize CRC\n",
    "crc_poly = [1, 0, 1, 1]  # CRC polynomial\n",
    "L=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc384a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_original_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}/{encoder_type}__{enc_train_snr}_Encoder_{decoder_type}_{dec_train_snr}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e40922",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}_SClist_L_{L}_crc_{crc_poly}/{encoder_type}_Encoder_{decoder_type}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0c3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path +'/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e521",
   "metadata": {},
   "source": [
    "# Part 1: Core Utilities and Model Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_db2sigma(train_snr):\n",
    "    return 10**(-train_snr*1.0/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a23a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2bb73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a smoother version using product of bit probabilities\n",
    "def soft_bler_loss(logits, targets):\n",
    "    bit_probs = torch.sigmoid(logits)  # For correct bits\n",
    "    bit_probs = torch.where(targets == 1., bit_probs, 1 - bit_probs)\n",
    "    block_probs = torch.prod(bit_probs, dim=1)  # Probability of whole block being correct\n",
    "    return -torch.mean(torch.log(block_probs + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b989d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_ber(y_true, y_pred, mask=None):\n",
    "    if mask == None:\n",
    "        mask=torch.ones(y_true.size(),device=y_true.device)\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "    mask = mask.view(mask.shape[0], -1, 1)\n",
    "    myOtherTensor = (mask*torch.ne(torch.round(y_true), torch.round(y_pred))).float()\n",
    "    res = sum(sum(myOtherTensor))/(torch.sum(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_bler(y_true, y_pred, get_pos = False):\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "\n",
    "    decoded_bits = torch.round(y_pred).cpu()\n",
    "    X_test = torch.round(y_true).cpu()\n",
    "    tp0 = (abs(decoded_bits-X_test)).view([X_test.shape[0],X_test.shape[1]])\n",
    "    tp0 = tp0.detach().cpu().numpy()\n",
    "    bler_err_rate = sum(np.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
    "\n",
    "    if not get_pos:\n",
    "        return bler_err_rate\n",
    "    else:\n",
    "        err_pos = list(np.nonzero((np.sum(tp0,axis=1)>0).astype(int))[0])\n",
    "        return bler_err_rate, err_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92df8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_signal(input_signal, sigma = 1.0, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 0.05):\n",
    "    data_shape = input_signal.shape\n",
    "    device = input_signal.device\n",
    "    if noise_type == 'awgn':\n",
    "        dist = torch.distributions.Normal(torch.tensor([0.0], device=device), torch.tensor([sigma], device=device))\n",
    "        noise = dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 'fading':\n",
    "        fading_h = torch.sqrt(torch.randn_like(input_signal)**2 + torch.randn_like(input_signal)**2)/np.sqrt(3.14/2.0)\n",
    "        noise = sigma * torch.randn_like(input_signal)\n",
    "        corrupted_signal = fading_h *(input_signal) + noise\n",
    "\n",
    "    elif noise_type == 'radar':\n",
    "        add_pos = np.random.choice([0.0, 1.0], data_shape, p=[1 - radar_prob, radar_prob])\n",
    "        corrupted_signal = radar_power* np.random.standard_normal(size=data_shape) * add_pos\n",
    "        noise = sigma * torch.randn_like(input_signal) +\\\n",
    "                    torch.from_numpy(corrupted_signal).float().to(input_signal.device)\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 't-dist':\n",
    "        dist = torch.distributions.StudentT(torch.tensor([vv], device=device))\n",
    "        noise = sigma* dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    return corrupted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e97bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp(x, y):\n",
    "    log_sum_ms = torch.min(torch.abs(x), torch.abs(y))*torch.sign(x)*torch.sign(y)\n",
    "    return log_sum_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5937279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp_4(x_1, x_2, x_3, x_4):\n",
    "    return min_sum_log_sum_exp(min_sum_log_sum_exp(x_1, x_2), min_sum_log_sum_exp(x_3, x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c239bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, y):\n",
    "    def log_sum_exp_(LLR_vector):\n",
    "        sum_vector = LLR_vector.sum(dim=1, keepdim=True)\n",
    "        sum_concat = torch.cat([sum_vector, torch.zeros_like(sum_vector)], dim=1)\n",
    "        return torch.logsumexp(sum_concat, dim=1)- torch.logsumexp(LLR_vector, dim=1) \n",
    "\n",
    "    Lv = log_sum_exp_(torch.cat([x.unsqueeze(2), y.unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "    return Lv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655fe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bitarray(in_number, bit_width):\n",
    "    binary_string = bin(in_number)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(bit_width, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[bit_width-i-1] = int(binary_string[length-i-1])\n",
    "    return bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a081f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSetBits(n):\n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, enc_quantize_level = 2, enc_value_limit = 1.0, enc_grad_limit = 0.01, enc_clipping = 'both'):\n",
    "        ctx.save_for_backward(inputs)\n",
    "        assert enc_clipping in ['both', 'inputs']\n",
    "        ctx.enc_clipping = enc_clipping\n",
    "        ctx.enc_value_limit = enc_value_limit\n",
    "        ctx.enc_quantize_level = enc_quantize_level\n",
    "        ctx.enc_grad_limit = enc_grad_limit\n",
    "\n",
    "        x_lim_abs = enc_value_limit\n",
    "        x_lim_range = 2.0 * x_lim_abs\n",
    "        x_input_norm = torch.clamp(inputs, -x_lim_abs, x_lim_abs)\n",
    "\n",
    "        if enc_quantize_level == 2:\n",
    "            outputs_int = torch.sign(x_input_norm)\n",
    "        else:\n",
    "            outputs_int = torch.round((x_input_norm +x_lim_abs) * ((enc_quantize_level - 1.0)/x_lim_range)) * x_lim_range/(enc_quantize_level - 1.0) - x_lim_abs\n",
    "\n",
    "        return outputs_int\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.enc_clipping in ['inputs', 'both']:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input>ctx.enc_value_limit]=0\n",
    "            grad_output[input<-ctx.enc_value_limit]=0\n",
    "\n",
    "        if ctx.enc_clipping in ['gradient', 'both']:\n",
    "            grad_output = torch.clamp(grad_output, -ctx.enc_grad_limit, ctx.enc_grad_limit)\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d695a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'tanh':\n",
    "        return F.tanh\n",
    "    elif activation == 'elu':\n",
    "        return F.elu\n",
    "    elif activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'selu':\n",
    "        return F.selu\n",
    "    elif activation == 'sigmoid':\n",
    "        return F.sigmoid\n",
    "    elif activation == 'gelu':\n",
    "        return F.gelu\n",
    "    elif activation == 'silu':\n",
    "        return F.silu\n",
    "    elif activation == 'mish':\n",
    "        return F.mish\n",
    "    elif activation == 'linear':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Activation function {activation} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth=3, skip_depth=1, skip_layer=1, ell=2, activation='selu', use_skip=False, augment=False):\n",
    "        super(g_Full, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.ell = ell\n",
    "        self.ell_input_size = input_size//self.ell\n",
    "        self.augment = augment\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "        self.skip_depth = skip_depth\n",
    "        self.skip_layer = skip_layer\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        if self.use_skip:\n",
    "            self.skip = nn.ModuleList([nn.Linear(self.input_size + self.output_size, self.hidden_size, bias=True)])\n",
    "            self.skip.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.skip_depth)])\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        self.linears.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.depth)])\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_augment(msg, ell):\n",
    "        u = msg.clone()\n",
    "        n = int(np.log2(ell))\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, ell, 2*num_bits):\n",
    "                if len(u.shape) == 2:\n",
    "                    u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                elif len(u.shape) == 3:\n",
    "                    u = torch.cat((u[:, :, :i], u[:, :, i:i+num_bits].clone() * u[:, :, i+num_bits: i+2*num_bits], u[:, :, i+num_bits:]), dim=2)\n",
    "\n",
    "        if len(u.shape) == 3:\n",
    "            return u[:, :, :-1]\n",
    "        elif len(u.shape) == 2:\n",
    "            return u[:, :-1]\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y.clone()\n",
    "        for ii, layer in enumerate(self.linears):\n",
    "            if ii != self.depth:\n",
    "                x = self.activation_fn(layer(x))\n",
    "                if self.use_skip and ii == self.skip_layer:\n",
    "                    if len(x.shape) == 3:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=2)\n",
    "                    elif len(x.shape) == 2:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=1)\n",
    "                    for jj, skip_layer in enumerate(self.skip):\n",
    "                        skip_input = self.activation_fn(skip_layer(skip_input))\n",
    "                    x = x + skip_input\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if self.augment:\n",
    "                    x = x + g_Full.get_augment(y, self.ell)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d72065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape should be: (batch_size, seq_len, hidden_dim)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class f_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0., activation='selu', depth=3, use_norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.use_norm = use_norm\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "\n",
    "        # Initial layers same as original f_Full\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        if self.use_norm:\n",
    "            self.norms = nn.ModuleList([nn.LayerNorm(self.hidden_size)])\n",
    "        \n",
    "        # Attention layer after first linear\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,  # Reduced number of heads\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Remaining layers same as original\n",
    "        for ii in range(1, self.depth):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size, bias=True))\n",
    "            if self.use_norm:\n",
    "                self.norms.append(nn.LayerNorm(self.hidden_size))\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    def forward(self, y, aug=None):\n",
    "        x = y.clone()\n",
    "        \n",
    "        # First linear layer\n",
    "        x = self.linears[0](x)\n",
    "        if self.use_norm:\n",
    "            x = self.norms[0](x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        # Reshape for attention: [batch, seq_len, hidden]\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = attn_out if len(y.shape) == 3 else attn_out.squeeze(1)\n",
    "        \n",
    "        # Remaining layers\n",
    "        for ii in range(1, len(self.linears)):\n",
    "            if ii != self.depth:\n",
    "                x = self.linears[ii](x)\n",
    "                if self.use_norm:\n",
    "                    x = self.norms[ii](x)\n",
    "                x = self.activation_fn(x)\n",
    "            else:\n",
    "                x = self.linears[ii](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10845154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        try:\n",
    "            m.bias.data.fill_(0.)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e38e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(actions):\n",
    "    inds = (0.5 + 0.5*actions).long()\n",
    "    return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594f46",
   "metadata": {},
   "source": [
    "# Part 2: Core PolarCode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarCode:\n",
    "\n",
    "    def __init__(self, n, K, Fr = None, rs = None, use_cuda = True, infty = 1000., hard_decision = False, lse = 'lse'):\n",
    "\n",
    "        assert n>=1\n",
    "        self.n = n\n",
    "        self.N = 2**n\n",
    "        self.K = K\n",
    "        self.G2 = np.array([[1,1],[0,1]])\n",
    "        self.G = np.array([1])\n",
    "        for i in range(n):\n",
    "            self.G = np.kron(self.G, self.G2)\n",
    "        self.G = torch.from_numpy(self.G).float()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.infty = infty\n",
    "        self.hard_decision = hard_decision\n",
    "        self.lse = lse\n",
    "\n",
    "        if Fr is not None:\n",
    "            assert len(Fr) == self.N - self.K\n",
    "            self.frozen_positions = Fr\n",
    "            self.unsorted_frozen_positions = self.frozen_positions\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "            self.info_positions = np.array(list(set(self.frozen_positions) ^ set(np.arange(self.N))))\n",
    "            self.unsorted_info_positions = self.info_positions\n",
    "            self.info_positions.sort()\n",
    "            \n",
    "        else:\n",
    "            if rs is None:\n",
    "                # in increasing order of reliability\n",
    "                self.reliability_seq = np.arange(1023, -1, -1)\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "            else:\n",
    "                self.reliability_seq = rs\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "\n",
    "                assert len(self.rs) == self.N\n",
    "            # best K bits\n",
    "            self.info_positions = self.rs[:self.K]\n",
    "            self.unsorted_info_positions = self.reliability_seq[self.reliability_seq<self.N][:self.K]\n",
    "            self.info_positions.sort()\n",
    "            self.unsorted_info_positions=np.flip(self.unsorted_info_positions)\n",
    "            # worst N-K bits\n",
    "            self.frozen_positions = self.rs[self.K:]\n",
    "            self.unsorted_frozen_positions = self.rs[self.K:]\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "\n",
    "            self.CRC_polynomials = {\n",
    "            3: torch.Tensor([1, 0, 1, 1]).int(),\n",
    "            8: torch.Tensor([1, 1, 1, 0, 1, 0, 1, 0, 1]).int(),\n",
    "            16: torch.Tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]).int(),\n",
    "                                    }\n",
    "\n",
    "    def get_G(self, ell):\n",
    "        n = int(np.log2(ell))\n",
    "        G = np.array([1])\n",
    "        for i in range(n):\n",
    "            G = np.kron(G, self.G2)\n",
    "        return G\n",
    "\n",
    "    def encode_plotkin(self, message, scaling = None, custom_info_positions = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "        if custom_info_positions is not None:\n",
    "            info_positions = custom_info_positions\n",
    "        else:\n",
    "            info_positions = self.info_positions\n",
    "        u = torch.ones(message.shape[0], self.N, dtype=torch.float).to(message.device)\n",
    "        u[:, info_positions] = message\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                # u[:, i:i+num_bits] = u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits].clone\n",
    "        if scaling is not None:\n",
    "            u = (scaling * np.sqrt(self.N)*u)/torch.norm(scaling)\n",
    "        return u\n",
    "    \n",
    "    def channel(self, code, snr, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 5e-2):\n",
    "        if noise_type != \"bsc\":\n",
    "            sigma = snr_db2sigma(snr)\n",
    "        else:\n",
    "            sigma = snr\n",
    "\n",
    "        r = corrupt_signal(code, sigma, noise_type, vv, radar_power, radar_prob)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def define_partial_arrays(self, llrs):\n",
    "        # Initialize arrays to store llrs and partial_sums useful to compute the partial successive cancellation process.\n",
    "        llr_array = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        llr_array[:, self.n] = llrs\n",
    "        partial_sums = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        return llr_array, partial_sums\n",
    "\n",
    "\n",
    "    def updateLLR(self, leaf_position, llrs, partial_llrs = None, prior = None):\n",
    "\n",
    "        #START\n",
    "        depth = self.n\n",
    "        decoded_bits = partial_llrs[:,0].clone()\n",
    "        if prior is None:\n",
    "            prior = torch.zeros(self.N) #priors\n",
    "        llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth, 0, leaf_position, prior, decoded_bits)\n",
    "        return llrs, decoded_bits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def partial_decode(self, llrs, partial_llrs, depth, bit_position, leaf_position, prior, decoded_bits=None):\n",
    "        # Function to call recursively, for partial SC decoder.\n",
    "        # We are assuming that u_0, u_1, .... , u_{leaf_position -1} bits are known.\n",
    "        # Partial sums computes the sums got through Plotkin encoding operations of known bits, to avoid recomputation.\n",
    "        # this function is implemented for rate 1 (not accounting for frozen bits in polar SC decoding)\n",
    "\n",
    "        # print(\"DEPTH = {}, bit_position = {}\".format(depth, bit_position))\n",
    "        half_index = 2 ** (depth - 1)\n",
    "        leaf_position_at_depth = leaf_position // 2**(depth-1) # will tell us whether left_child or right_child\n",
    "\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            # Left child\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position:left_bit_position+1]\n",
    "            elif leaf_position_at_depth == left_bit_position:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                elif self.lse == 'lse':\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                #print(Lu.device, prior.device, torch.ones_like(Lu).device)\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu + prior[left_bit_position]*torch.ones_like(Lu)\n",
    "                if self.hard_decision:\n",
    "                    u_hat = torch.sign(Lu)\n",
    "                else:\n",
    "                    u_hat = torch.tanh(Lu/2)\n",
    "\n",
    "                decoded_bits[:, left_bit_position] = u_hat.squeeze(1)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # Right child\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "            if leaf_position_at_depth > right_bit_position:\n",
    "                pass\n",
    "            elif leaf_position_at_depth == right_bit_position:\n",
    "                Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "                llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv + prior[right_bit_position] * torch.ones_like(Lv)\n",
    "                if self.hard_decision:\n",
    "                    v_hat = torch.sign(Lv)\n",
    "                else:\n",
    "                    v_hat = torch.tanh(Lv/2)\n",
    "                decoded_bits[:, right_bit_position] = v_hat.squeeze(1)\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            # LEFT CHILD\n",
    "            # Find likelihood of (u xor v) xor (v) = u\n",
    "            # Lu = log_sum_exp(torch.cat([llrs[:, :half_index].unsqueeze(2), llrs[:, half_index:].unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                Lu = llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "            else:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                elif self.lse == 'lse':\n",
    "                    # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu\n",
    "                llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, left_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # RIGHT CHILD\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "\n",
    "            Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "            llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv\n",
    "            llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, right_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "            return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "    def updatePartialSums(self, leaf_position, decoded_bits, partial_llrs):\n",
    "\n",
    "        u = decoded_bits.clone()\n",
    "        u[:, leaf_position+1:] = 0\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            partial_llrs[:, d] = u\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        partial_llrs[:, self.n] = u\n",
    "        return partial_llrs\n",
    "\n",
    "    def sc_decode_new(self, corrupted_codewords, snr, use_gt = None, channel = 'awgn'):\n",
    "\n",
    "        assert channel in ['awgn', 'bsc']\n",
    "\n",
    "        if channel == 'awgn':\n",
    "            noise_sigma = snr_db2sigma(snr)\n",
    "            llrs = (2/noise_sigma**2)*corrupted_codewords\n",
    "        elif channel == 'bsc':\n",
    "            # snr refers to transition prob\n",
    "            p = (torch.ones(1)*(snr + 1e-9)).to(corrupted_codewords.device)\n",
    "            llrs = (torch.clip(torch.log((1 - p) / p), -10000, 10000) * (corrupted_codewords + 1) - torch.clip(torch.log(p / (1-p)), -10000, 10000) * (corrupted_codewords - 1))/2\n",
    "\n",
    "        # step-wise implementation using updateLLR and updatePartialSums\n",
    "\n",
    "        priors = torch.zeros(self.N)\n",
    "        priors[self.frozen_positions] = self.infty\n",
    "\n",
    "        u_hat = torch.zeros(corrupted_codewords.shape[0], self.N, device=corrupted_codewords.device)\n",
    "        llr_array, partial_llrs = self.define_partial_arrays(llrs)\n",
    "        for ii in range(self.N):\n",
    "            #start = time.time()\n",
    "            llr_array , decoded_bits = self.updateLLR(ii, llr_array.clone(), partial_llrs, priors)\n",
    "            #print('SC update : {}'.format(time.time() - start), corrupted_codewords.shape[0])\n",
    "            if use_gt is None:\n",
    "                u_hat[:, ii] = torch.sign(llr_array[:, 0, ii])\n",
    "            else:\n",
    "                u_hat[:, ii] = use_gt[:, ii]\n",
    "            #start = time.time()\n",
    "            partial_llrs = self.updatePartialSums(ii, u_hat, partial_llrs)\n",
    "            #print('SC partial: {}s, {}', time.time() - start, 'frozen' if ii in self.frozen_positions else 'info')\n",
    "        decoded_bits = u_hat[:, self.info_positions]\n",
    "        return llr_array[:, 0, :].clone(), decoded_bits\n",
    "\n",
    "    def get_CRC(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # inout message should be int\n",
    "\n",
    "        padded_bits = torch.cat([message, torch.zeros(self.CRC_len).int().to(message.device)])\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + self.CRC_len + 1] = padded_bits[cur_shift: cur_shift + self.CRC_len + 1] ^ self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        return padded_bits[self.K_minus_CRC:]\n",
    "\n",
    "    def CRC_check(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # input message should be int\n",
    "\n",
    "        padded_bits = message\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + polar.CRC_len + 1] ^= self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        if padded_bits[self.K_minus_CRC:].sum()>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def encode_with_crc(self, message, CRC_len):\n",
    "        self.CRC_len = CRC_len\n",
    "        self.K_minus_CRC = self.K - CRC_len\n",
    "\n",
    "        if CRC_len == 0:\n",
    "            return self.encode_plotkin(message)\n",
    "        else:\n",
    "            crcs = 1-2*torch.vstack([self.get_CRC((0.5+0.5*message[jj]).int()) for jj in range(message.shape[0])])\n",
    "            encoded = self.encode_plotkin(torch.cat([message, crcs], 1))\n",
    "\n",
    "            return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6d51",
   "metadata": {},
   "source": [
    "# Part 3: DeepPolar Class and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b3d92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        for i in range(n - self.degree):\n",
    "            active_batches = result[:, i] == 1\n",
    "            if torch.any(active_batches):\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPolar(PolarCode):\n",
    "    def __init__(self, device, N, K, ell = 2, infty = 1000., depth_map : defaultdict = None):\n",
    "\n",
    "        # rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        # Frozen = np.argsort(rmweight)[:-K]\n",
    "        # Frozen.sort()\n",
    "\n",
    "        #self.args = args\n",
    "        Fr = get_frozen(N, K, rate_profile)\n",
    "        super().__init__(n = int(np.log2(N)), K = K, Fr=Fr,  infty = infty)\n",
    "        self.N = N\n",
    "\n",
    "        if depth_map is not None:\n",
    "            # depth map is a dict, product of values should be equal to N\n",
    "            assert np.prod(list(depth_map.values())) == N\n",
    "            # assert that keys od depth map start from one and go continuosly till some point \n",
    "            assert min(list(depth_map.keys())) == 1\n",
    "            assert max(list(depth_map.keys())) <= int(np.log2(N))\n",
    "            self.ell = None\n",
    "            self.n_ell = len(depth_map.keys())\n",
    "            assert max(list(depth_map.keys())) == self.n_ell\n",
    "\n",
    "            self.depth_map = depth_map\n",
    "        else:\n",
    "            self.ell = ell\n",
    "            self.n_ell = int(np.log(N)/np.log(self.ell))\n",
    "\n",
    "            self.depth_map = defaultdict(int)\n",
    "            for d in range(1, self.n_ell+1):\n",
    "                self.depth_map[d] = self.ell\n",
    "            assert np.prod(list(self.depth_map.values())) == N\n",
    "\n",
    "        self.device = device\n",
    "        self.fnet_dict = None\n",
    "        self.gnet_dict = None\n",
    "\n",
    "        self.infty = infty\n",
    "\n",
    "    @staticmethod\n",
    "    def get_onehot(actions):\n",
    "        inds = (0.5 + 0.5*actions).long()\n",
    "        if len(actions.shape) == 2:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)\n",
    "        elif len(actions.shape) == 3:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], actions.shape[1], -1)\n",
    "\n",
    "    def define_kernel_nns(self, ell, unfrozen = None, fnet = 'KO', gnet = 'KO', shared = False):\n",
    "\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "        #dec_hidden_size = dec_hidden_size\n",
    "        #enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        depth = 1\n",
    "        assert len(unfrozen) > 0, \"No unfrozen bits!\"\n",
    "\n",
    "        self.fnet_dict[depth] = {}\n",
    "\n",
    "        if fnet == 'KO_parallel' or fnet == 'KO_last_parallel':\n",
    "            bit_position = 0\n",
    "                   \n",
    "            self.fnet_dict[depth][bit_position] = {}\n",
    "            # input_size = self.N if depth == self.n_ell else self.N // int(np.prod([self.depth_map[d] for d in range(depth+1, self.n_ell+1)]))\n",
    "            input_size = ell             \n",
    "            # For curriculum, only for lowest depth.\n",
    "            output_size = ell#len(unfrozen)\n",
    "            self.fnet_dict[depth][bit_position] = f_Full(input_size, dec_hidden_size, output_size, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    " \n",
    "        elif 'KO' in fnet:\n",
    "            if shared:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for current_position in range(ell):\n",
    "                    self.fnet_dict[depth][current_position] = f_Full(ell + current_position, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                for current_position in unfrozen:\n",
    "                    if not self.fnet_dict[depth].get(bit_position):\n",
    "                        self.fnet_dict[depth][bit_position] = {}\n",
    "                    input_size = ell + (int(onehot)+1)*current_position\n",
    "                    self.fnet_dict[depth][bit_position][current_position] = f_Full(input_size, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "                \n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict[depth] = {}\n",
    "            if shared:\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth][bit_position] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "\n",
    "    def define_and_load_nns(self, ell, kernel_load_path=None, fnet='KO', gnet='KO', shared=True, dataparallel=False):\n",
    "        # Initialize decoder and encoder dictionaries\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "\n",
    "        # Loop through each depth level\n",
    "        for depth in range(self.n_ell, 0, -1):\n",
    "            if depth in polar_depths:\n",
    "                continue\n",
    "\n",
    "            ell = self.depth_map[depth]\n",
    "            proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "            # Handle parallel decoder case\n",
    "            if fnet == 'KO_last_parallel' and depth == 1:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for bit_position in range(self.N // proj_size):\n",
    "                    proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                    get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                    num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                    subproj_len = len(proj) // ell\n",
    "                    subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                    num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                    unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                    input_size = ell             \n",
    "                    output_size = ell\n",
    "\n",
    "                    # Use attention-enhanced decoder for parallel case\n",
    "                    self.fnet_dict[depth][bit_position] = f_Full(\n",
    "                        input_size=input_size,\n",
    "                        hidden_size=dec_hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        activation=dec_activation,\n",
    "                        dropout_p=dropout_p,\n",
    "                        depth=f_depth,\n",
    "                        use_norm=use_norm\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    # Load pretrained weights if available\n",
    "                    if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                        try:\n",
    "                            ckpt = torch.load(os.path.join(kernel_load_path + '_parallel', f'{ell}_{len(unfrozen)}.pt'))\n",
    "                            self.fnet_dict[depth][bit_position].load_state_dict(ckpt[0][1][0].state_dict())\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"Parallel File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                            pass\n",
    "\n",
    "                    if dataparallel:\n",
    "                        self.fnet_dict[depth][bit_position] = nn.DataParallel(self.fnet_dict[depth][bit_position])\n",
    "\n",
    "            # Handle sequential decoder case\n",
    "            elif 'KO' in fnet:\n",
    "                self.fnet_dict[depth] = {}\n",
    "\n",
    "                if shared:\n",
    "                    # Shared decoder network for all positions\n",
    "                    for current_position in range(ell):\n",
    "                        self.fnet_dict[depth][current_position] = f_Full(\n",
    "                            input_size=ell + current_position,\n",
    "                            hidden_size=dec_hidden_size,\n",
    "                            output_size=1,\n",
    "                            activation=dec_activation,\n",
    "                            dropout_p=dropout_p,\n",
    "                            depth=f_depth,\n",
    "                            use_norm=use_norm\n",
    "                        ).to(self.device)\n",
    "\n",
    "                        if dataparallel:\n",
    "                            self.fnet_dict[depth][current_position] = nn.DataParallel(self.fnet_dict[depth][current_position])\n",
    "\n",
    "                else:\n",
    "                    # Individual decoder networks for each position\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                        num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                        subproj_len = len(proj) // ell\n",
    "                        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                        unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                        # Load pretrained weights if available\n",
    "                        ckpt_exists = False\n",
    "                        if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                            try:\n",
    "                                ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                ckpt_exists = True\n",
    "                            except FileNotFoundError:\n",
    "                                print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                pass\n",
    "\n",
    "                        # Create decoders for unfrozen positions\n",
    "                        for current_position in unfrozen:\n",
    "                            if not self.fnet_dict[depth].get(bit_position):\n",
    "                                self.fnet_dict[depth][bit_position] = {}\n",
    "\n",
    "                            input_size = ell + (int(onehot)+1)*current_position\n",
    "                            output_size = 1\n",
    "\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = f_Full(\n",
    "                                input_size=input_size,\n",
    "                                hidden_size=dec_hidden_size,\n",
    "                                output_size=output_size,\n",
    "                                activation=dec_activation,\n",
    "                                dropout_p=dropout_p,\n",
    "                                depth=f_depth,\n",
    "                                use_norm=use_norm\n",
    "                            ).to(self.device)\n",
    "\n",
    "                            if ckpt_exists:\n",
    "                                try:\n",
    "                                    f_ckpt = ckpt[0][1][0][current_position].state_dict()\n",
    "                                    self.fnet_dict[depth][bit_position][current_position].load_state_dict(f_ckpt)\n",
    "                                except:\n",
    "                                    print(f\"Warning: Could not load weights for position {current_position}\")\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.fnet_dict[depth][bit_position][current_position] = nn.DataParallel(\n",
    "                                    self.fnet_dict[depth][bit_position][current_position]\n",
    "                                )\n",
    "\n",
    "            # Handle encoder network\n",
    "            if 'KO' in gnet:\n",
    "                self.gnet_dict[depth] = {}\n",
    "                if shared:\n",
    "                    if gnet == 'KO':\n",
    "                        if not dataparallel:\n",
    "                            self.gnet_dict[depth] = g_Full(\n",
    "                                ell, enc_hidden_size, ell-1,\n",
    "                                depth=g_depth,\n",
    "                                skip_depth=g_skip_depth,\n",
    "                                skip_layer=g_skip_layer,\n",
    "                                ell=ell,\n",
    "                                use_skip=use_skip\n",
    "                            ).to(self.device)\n",
    "                        else:\n",
    "                            self.gnet_dict[depth] = nn.DataParallel(\n",
    "                                g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    use_skip=use_skip\n",
    "                                )\n",
    "                            ).to(self.device)\n",
    "                else:\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        num_info_in_proj = sum([int(x in self.info_positions) for x in proj])\n",
    "\n",
    "                        if num_info_in_proj > 0:\n",
    "                            if gnet == 'KO':\n",
    "                                self.gnet_dict[depth][bit_position] = g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    activation=enc_activation,\n",
    "                                    use_skip=use_skip\n",
    "                                ).to(self.device)\n",
    "\n",
    "                            # Load pretrained weights if available\n",
    "                            if kernel_load_path is not None:\n",
    "                                try:\n",
    "                                    ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                    self.gnet_dict[depth][bit_position].load_state_dict(ckpt[1][1][0].state_dict())\n",
    "                                except FileNotFoundError:\n",
    "                                    print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                    pass\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.gnet_dict[depth][bit_position] = nn.DataParallel(self.gnet_dict[depth][bit_position])\n",
    "\n",
    "        if kernel_load_path is not None:\n",
    "            print(\"Loaded kernel from \", kernel_load_path)\n",
    "\n",
    "    def load_nns(self, fnet_dict, gnet_dict = None, shared = False):\n",
    "        self.fnet_dict = fnet_dict\n",
    "        self.gnet_dict = gnet_dict\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if self.fnet_dict is not None:\n",
    "                for bit_position in self.fnet_dict[depth].keys():\n",
    "                    if not isinstance(self.fnet_dict[depth][bit_position], dict):#shared or decoder_type == 'KO_parallel' or decoder_type == 'KO_RNN':\n",
    "                        self.fnet_dict[depth][bit_position].to(self.device)\n",
    "                    else:\n",
    "                        for current_position in self.fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "            if gnet_dict is not None:\n",
    "                if shared:\n",
    "                    self.gnet_dict[depth].to(self.device)\n",
    "                else:\n",
    "                    for bit_position in self.gnet_dict[depth].keys():\n",
    "                        self.gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def load_partial_nns(self, fnet_dict, gnet_dict = None):\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if fnet_dict is not None:\n",
    "                for bit_position in fnet_dict[depth].keys():\n",
    "                    if isinstance(fnet_dict[depth][bit_position], dict):\n",
    "                        for current_position in fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "                    else:\n",
    "                        self.fnet_dict[depth][bit_position] = fnet_dict[depth][bit_position].to(self.device)\n",
    "\n",
    "            if gnet_dict is not None:\n",
    "                for bit_position in gnet_dict[depth].keys():\n",
    "                    self.gnet_dict[depth][bit_position] = gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def kernel_encode(self, ell, gnet, msg_bits, info_positions, binary = False):\n",
    "        input_shape = msg_bits.shape[-1]\n",
    "        assert input_shape <= ell\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, info_positions] = msg_bits\n",
    "        output =torch.cat([gnet(u.unsqueeze(1)).squeeze(1), u[:, -1:]], 1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(output)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def deeppolar_encode(self, msg_bits, binary = False):\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, self.info_positions] = msg_bits\n",
    "        for d in range(1, self.n_ell+1):\n",
    "            # num_bits = self.ell**(d-1)\n",
    "            num_bits = np.prod([self.depth_map[dd] for dd in range(1, d)]) if d > 1 else 1\n",
    "            # proj_size = self.ell**(d)\n",
    "            proj_size = np.prod([self.depth_map[dd] for dd in range(1, d+1)])\n",
    "            ell = self.depth_map[d]\n",
    "            for bit_position, i in enumerate(np.arange(0, self.N, ell*num_bits)):\n",
    "\n",
    "                # [u v] encoded to [(u xor v),v)]\n",
    "                proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                subproj_len = len(proj) // ell\n",
    "                subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "                \n",
    "                if num_info_in_proj > 0:\n",
    "                    info_bits_present = True          \n",
    "                else:\n",
    "                    info_bits_present = False         \n",
    "                if d in polar_depths:\n",
    "                    info_bits_present = False\n",
    "\n",
    "                enc_chunks = []\n",
    "                ell = self.depth_map[d]\n",
    "                for j in range(ell):\n",
    "                    chunk = u[:, i + j*num_bits:i + (j+1)*num_bits].unsqueeze(2).clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[d](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        output = torch.cat([self.gnet_dict[d][bit_position](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(msg_bits.shape[0], -1, 1).squeeze(2)\n",
    "\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                u = torch.cat((u[:, :i], output, u[:, i + ell*num_bits:]), dim=1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(u)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def power_constraint(self, codewords):\n",
    "        return F.normalize(codewords, p=2, dim=1)*np.sqrt(self.N)\n",
    "\n",
    "    def encode_chunks_plotkin(self, enc_chunks, ell = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "\n",
    "        # to change for other kernels\n",
    "\n",
    "        if ell is None:\n",
    "            ell = self.ell\n",
    "        assert len(enc_chunks) == ell\n",
    "        chunk_size = enc_chunks[0].shape[1]\n",
    "        batch_size = enc_chunks[0].shape[0]\n",
    "\n",
    "        u = torch.cat(enc_chunks, 1).squeeze(2)\n",
    "        n = int(np.log2(ell))\n",
    "\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d * chunk_size\n",
    "            for i in np.arange(0, chunk_size*ell, 2*num_bits):\n",
    "                # [u v] encoded to [(u,v) xor v]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        return u\n",
    "            \n",
    "    def deeppolar_parallel_decode(self, noisy_code):\n",
    "        # Successive cancellation decoder for polar codes\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "        decoded_llrs  = self.KO_parallel_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "\n",
    "    def deeppolar_parallel_decode_depth(self, llrs, depth, bit_position, decoded_llrs):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        dec_chunks = torch.cat([llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "        Lu = self.fnet_dict[depth][bit_position](dec_chunks)\n",
    "\n",
    "        if depth == 1:\n",
    "            u = torch.tanh(Lu/2)\n",
    "            decoded_llrs[:, left_bit_position + unfrozen] = Lu.squeeze(1)\n",
    "        else:\n",
    "            for index, current_position in enumerate(unfrozen):\n",
    "                bit_position_offset = left_bit_position + current_position                \n",
    "                decoded_llrs = self.deeppolar_parallel_decode_depth(Lu[:, :, index:index+1], depth-1, bit_position_offset, decoded_llrs)\n",
    "\n",
    "        return decoded_llrs\n",
    "            \n",
    "    def deeppolar_decode(self, noisy_code):\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        \n",
    "        # don't want to go into useless frozen subtrees.\n",
    "        partial_sums = torch.ones(noisy_code.shape[0], self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "\n",
    "        decoded_llrs, partial_sums = self.deeppolar_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs, partial_sums)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "    \n",
    "    def deeppolar_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        # size of the projection of tht subtree\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        # This chunk - finds infrozen positions in this kernel.\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        if num_nonzero_subproj > 0:\n",
    "            info_bits_present = True      \n",
    "        else:\n",
    "            info_bits_present = False \n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "                \n",
    "        # This will be input to decoder\n",
    "        dec_chunks = [llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            if decoder_type == 'KO_last_parallel':\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                Lu = self.fnet_dict[depth][bit_position](concatenated_chunks)[:, 0, unfrozen]\n",
    "                u_hat = torch.tanh(Lu/2)\n",
    "                decoded_llrs[:, left_bit_position + unfrozen] = Lu\n",
    "                partial_sums[:, depth-1, left_bit_position + unfrozen] = u_hat\n",
    "\n",
    "            else:\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    if current_position > 0:\n",
    "                        # I am adding previously decoded bits . (either onehot or normal)\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "\n",
    "                    if bit_position_offset in self.frozen_positions: # frozen \n",
    "                        # don't update decoded llrs. It already has ones*prior.\n",
    "                        # actually don't need this. can skip.\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, depth-1, bit_position_offset])\n",
    "                    else: # information bit\n",
    "                        # This is the decoding.\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](concatenated_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "\n",
    "                        u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                        decoded_llrs[:, bit_position_offset] = Lu.squeeze(2).squeeze(1)\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = u_hat.squeeze(1)\n",
    "\n",
    "            # Encoding back the decoded bits - for higher layers.\n",
    "            # # Compute decoded codeword\n",
    "            i = left_bit_position * half_index\n",
    "            # num_bits = self.ell**(depth-1)\n",
    "            num_bits = 1\n",
    "\n",
    "            enc_chunks = []\n",
    "            for j in range(ell):\n",
    "                chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                enc_chunks.append(chunk)\n",
    "            if info_bits_present:\n",
    "                concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                if 'KO' in encoder_type:\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        # bit position of the previous depth.\n",
    "                        output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            else:\n",
    "                output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "            \n",
    "            return decoded_llrs, partial_sums\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "\n",
    "                if current_position in unfrozen:\n",
    "                    # General decoding ....\n",
    "                    # add the decoded bit here\n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](concatenated_chunks).squeeze(2)\n",
    "                    else:\n",
    "                        # if current_position == 0:\n",
    "                        #     Lu = self.fnet_dict[depth][bit_position][current_position](llrs)\n",
    "                        # else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "                    decoded_llrs, partial_sums = self.deeppolar_decode_depth(Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums)\n",
    "                else:\n",
    "                    Lu = self.infty*torch.ones_like(llrs)\n",
    "\n",
    "\n",
    "            # Compute decoded codeword\n",
    "            if depth < self.n_ell :\n",
    "                i = left_bit_position * half_index\n",
    "                # num_bits = self.ell**(depth-1)\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        else:\n",
    "                            # bit position of the previous depth.\n",
    "                            output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "\n",
    "                return decoded_llrs, partial_sums\n",
    "            else: # encoding not required for last level - we have already decoded all bits.\n",
    "                return decoded_llrs, partial_sums\n",
    "\n",
    "\n",
    "    def kernel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = [noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "\n",
    "        for current_position in range(ell):\n",
    "            if current_position > 0:\n",
    "                if onehot:\n",
    "                    prev_decoded = get_onehot(u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone().sign()).detach().clone()\n",
    "                else:\n",
    "                    prev_decoded = u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                dec_chunks.append(prev_decoded)\n",
    "            if current_position in info_positions:\n",
    "                if current_position in info_positions:\n",
    "                    concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                    Lu = fnet_dict[current_position](concatenated_chunks)\n",
    "                    decoded_llrs[:, current_position] = Lu.squeeze(2).squeeze(1)\n",
    "                    u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                    u[:, current_position] = u_hat.squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "\n",
    "    def kernel_parallel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = torch.cat([noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "\n",
    "        decoded_llrs = fnet_dict(dec_chunks).squeeze(1)\n",
    "        u = torch.tanh(decoded_llrs/2).squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "    \n",
    "\n",
    "    def deeppolar_list_decode(self, noisy_code, L, crc=None):\n",
    "        \"\"\"\n",
    "        List decoding implementation for DeepPolar with CRC checking\n",
    "        Args:\n",
    "            noisy_code: Input received codeword\n",
    "            L: List size\n",
    "            crc: CRC object for checking decoded messages\n",
    "        \"\"\"\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "        batch_size = noisy_code.shape[0]\n",
    "        depth = self.n_ell\n",
    "\n",
    "        # Initialize L copies of path metrics \n",
    "        PML = 1000*torch.ones(batch_size, L, device=noisy_code.device)\n",
    "        PML[:, 0] = 0\n",
    "\n",
    "        # Initialize L copies of LLRs and partial sums\n",
    "        decoded_llrs = self.infty * torch.ones(batch_size, L, self.N, device=noisy_code.device)\n",
    "        partial_sums = torch.ones(batch_size, L, self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # Expand noisy_code for L paths\n",
    "        noisy_code_expanded = noisy_code.unsqueeze(1).repeat(1, L, 1)\n",
    "\n",
    "        decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "            noisy_code_expanded.unsqueeze(3), depth, 0, decoded_llrs, partial_sums, PML, L)\n",
    "\n",
    "        # Extract information bits for all paths\n",
    "        info_llrs = decoded_llrs[:, :, self.info_positions]\n",
    "        decisions = torch.sign(info_llrs)\n",
    "\n",
    "        # Convert decoded bits to proper format for CRC checking\n",
    "        decoded_bits = ((1 - decisions) / 2).to(torch.int64)  # Convert from {-1,1} to {1,0}\n",
    "\n",
    "        if crc is not None:\n",
    "            # Check CRC for each path in the list\n",
    "            valid_paths = crc.check_batch(decoded_bits.view(-1, decoded_bits.shape[-1]))\n",
    "            valid_paths = valid_paths.view(batch_size, L)\n",
    "\n",
    "            # For each batch, find first valid path or use first path if none valid\n",
    "            selected_paths = torch.zeros(batch_size, dtype=torch.long, device=decoded_bits.device)\n",
    "            for b in range(batch_size):\n",
    "                valid_indices = torch.where(valid_paths[b])[0]\n",
    "                if len(valid_indices) > 0:\n",
    "                    # Use first valid path\n",
    "                    selected_paths[b] = valid_indices[0]\n",
    "                else:\n",
    "                    # If no valid paths, use path with best metric (index 0)\n",
    "                    selected_paths[b] = 0\n",
    "\n",
    "            # Gather selected paths\n",
    "            batch_indices = torch.arange(batch_size, device=decoded_bits.device)\n",
    "            final_decisions = decisions[batch_indices, selected_paths]\n",
    "        else:\n",
    "            # If no CRC, just return first path\n",
    "            final_decisions = decisions[:, 0]\n",
    "\n",
    "        return final_decisions, info_llrs, PML\n",
    "\n",
    "    def deeppolar_list_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums, PML, L):\n",
    "        \"\"\"\n",
    "        Recursive list decoding implementation for DeepPolar decoder\n",
    "        Args:\n",
    "            llrs: Input LLRs [batch_size, L, N, 1]\n",
    "            depth: Current depth in the decoding tree\n",
    "            bit_position: Current bit position\n",
    "            decoded_llrs: Running decoded LLRs [batch_size, L, N]\n",
    "            partial_sums: Running partial sums [batch_size, L, n_ell+1, N]\n",
    "            PML: Path metrics for each path [batch_size, L]\n",
    "        \"\"\"\n",
    "        batch_size = llrs.shape[0]\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] * bit_position\n",
    "\n",
    "        # Calculate projection information\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj: sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj: [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        info_bits_present = num_nonzero_subproj > 0\n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "\n",
    "        # Initialize decoder chunks\n",
    "        dec_chunks = [llrs[:, :, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        \n",
    "        if depth == 1:  # Base case\n",
    "            if decoder_type != 'KO_last_parallel':\n",
    "            \n",
    "                # Sequential decoding of each position\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    \n",
    "\n",
    "                    if current_position > 0:\n",
    "                        # Add previously decoded bits\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "                    \n",
    "                     \n",
    "                    \n",
    "                    if bit_position_offset in self.frozen_positions:\n",
    "                        # Handle frozen bits\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, :, depth-1, bit_position_offset])\n",
    "                        DM = decoded_llrs[:, :, bit_position_offset]\n",
    "                        # Update path metrics for frozen bits\n",
    "                        PML = PML + torch.abs(DM) * (DM < 0).float()\n",
    "\n",
    "                    else:  # Information bit case\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                        orig_shape = concatenated_chunks.shape\n",
    "                        reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "\n",
    "                        # Get decoder output\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](reshaped_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                        Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "\n",
    "                        # Store LLRs and get decisions\n",
    "                        decoded_llrs[:,:, bit_position_offset] = Lu.squeeze(3).squeeze(2)\n",
    "                        DM = Lu.squeeze(3).squeeze(2)\n",
    "                        dec = (DM < 0).float()\n",
    "                        dec = 1-2*dec\n",
    "\n",
    "                        # Compute path metrics for both decisions\n",
    "                        PM2 = torch.cat([PML, PML + torch.abs(DM)], dim=1)  # [batch_size, 2L]\n",
    "\n",
    "                        # Select best L paths\n",
    "                        PML, pos = torch.topk(PM2, L, dim=1, largest=False)  \n",
    "\n",
    "                        # Update decisions and states\n",
    "                        pos_dec = pos.clone()\n",
    "                        pos_dec[pos >= L] = pos_dec[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "                        dec = torch.gather(dec, 1, pos_dec)  # Gather decisions for selected paths\n",
    "                        dec = torch.where(pos >= L, -dec, dec)  # Flip decisions for paths from second half\n",
    "\n",
    "                        # Update states with gathered indices\n",
    "                        # First adjust pos for gathering from L-sized tensors\n",
    "                        pos_adj = pos.clone()\n",
    "                        pos_adj[pos >= L] = pos_adj[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "\n",
    "                        # For decoded_llrs\n",
    "                        pos_expand = pos_adj.unsqueeze(-1).expand(-1, -1, decoded_llrs.shape[-1])\n",
    "                        decoded_llrs = torch.gather(decoded_llrs, 1, pos_expand)\n",
    "\n",
    "                        # For partial_sums \n",
    "                        pos_expand_sums = pos_adj.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, partial_sums.shape[2], partial_sums.shape[3])\n",
    "                        partial_sums = torch.gather(partial_sums, 1, pos_expand_sums)\n",
    "\n",
    "\n",
    "                        # Store updated decisions\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = dec\n",
    "\n",
    "                        \n",
    "                       \n",
    "                 \n",
    "\n",
    "            # Encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = 1\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        else:  # General case for deeper levels\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                #print(concatenated_chunks.shape)\n",
    "                orig_shape = concatenated_chunks.shape\n",
    "                reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                if current_position in unfrozen:\n",
    "                    \n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](reshaped_chunks).squeeze(3)\n",
    "                    else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                    Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "                    \n",
    "                    # Recursive call for each path\n",
    "                    decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "                        Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums, PML, L)\n",
    "                else:\n",
    "                    Lu = self.infty * torch.ones_like(llrs)\n",
    "\n",
    "            # Handle encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                        \n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        return decoded_llrs, partial_sums, PML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e848578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen(N, K, rate_profile, target_K = None):\n",
    "    n = int(np.log2(N))\n",
    "    if rate_profile == 'polar':\n",
    "        # computed for SNR = 0\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "\n",
    "            # for RM :(\n",
    "            # rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 3, 5, 8, 4, 2, 1, 0])\n",
    "\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "        elif n<9:\n",
    "            rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "        else:\n",
    "            rs = np.array([1023, 1022, 1021, 1019, 1015, 1007, 1020,  991, 1018, 1017, 1014,\n",
    "       1006,  895, 1013, 1011,  959, 1005,  990, 1003,  989,  767, 1016,\n",
    "        999, 1012,  987,  958,  983,  957, 1010, 1004,  955, 1009,  894,\n",
    "        975,  893, 1002,  951, 1001,  988,  511,  766,  998,  891,  943,\n",
    "        986,  997,  985,  887,  956,  765,  995,  927,  982,  981,  879,\n",
    "        954,  974,  763,  953,  979,  510, 1008,  759,  863,  950,  892,\n",
    "       1000,  973,  949,  509,  890,  971,  996,  942,  751,  984,  889,\n",
    "        507,  947,  831,  886,  967,  941,  764,  926,  980,  994,  939,\n",
    "        885,  993,  735,  878,  925,  503,  762,  883,  978,  935,  703,\n",
    "        495,  952,  877,  761,  972,  923,  977,  948,  758,  862,  875,\n",
    "        919,  970,  757,  861,  508,  969,  750,  946,  479,  888,  639,\n",
    "        871,  911,  830,  940,  859,  755,  966,  945,  749,  506,  884,\n",
    "        938,  965,  829,  734,  924,  855,  505,  747,  963,  937,  882,\n",
    "        934,  827,  733,  447,  992,  847,  876,  501,  921,  702,  494,\n",
    "        881,  760,  743,  933,  502,  918,  874,  922,  823,  731,  499,\n",
    "        860,  756,  931,  701,  873,  493,  727,  917,  870,  976,  815,\n",
    "        910,  383,  968,  478,  858,  754,  699,  491,  869,  944,  748,\n",
    "        638,  915,  477,  719,  909,  964,  255,  799,  504,  857,  854,\n",
    "        753,  828,  746,  695,  487,  907,  637,  867,  853,  475,  936,\n",
    "        962,  446,  732,  826,  745,  846,  500,  825,  903,  687,  932,\n",
    "        635,  471,  445,  742,  880,  498,  730,  851,  822,  382,  920,\n",
    "        845,  741,  443,  700,  729,  631,  492,  872,  961,  726,  821,\n",
    "        930,  497,  381,  843,  463,  916,  739,  671,  623,  490,  929,\n",
    "        439,  814,  819,  868,  752,  914,  698,  725,  839,  856,  476,\n",
    "        813,  718,  908,  486,  723,  866,  489,  607,  431,  697,  379,\n",
    "        811,  798,  913,  575,  717,  254,  694,  636,  474,  807,  715,\n",
    "        906,  797,  693,  865,  960,  852,  744,  634,  473,  795,  905,\n",
    "        485,  415,  483,  470,  444,  375,  850,  740,  686,  902,  824,\n",
    "        691,  253,  711,  633,  844,  685,  630,  901,  367,  791,  928,\n",
    "        728,  820,  849,  783,  670,  899,  738,  842,  683,  247,  469,\n",
    "        441,  442,  462,  251,  737,  438,  467,  351,  629,  841,  724,\n",
    "        679,  669,  496,  461,  818,  380,  437,  627,  622,  459,  378,\n",
    "        239,  488,  667,  838,  430,  484,  812,  621,  319,  817,  435,\n",
    "        377,  696,  722,  912,  606,  810,  864,  716,  837,  721,  714,\n",
    "        809,  796,  455,  472,  619,  835,  692,  663,  223,  414,  904,\n",
    "        427,  806,  482,  632,  713,  690,  848,  605,  373,  252,  794,\n",
    "        429,  710,  684,  615,  805,  900,  655,  468,  366,  603,  413,\n",
    "        574,  481,  371,  250,  793,  466,  423,  374,  689,  628,  440,\n",
    "        365,  709,  789,  803,  411,  573,  682,  249,  460,  790,  668,\n",
    "        599,  350,  707,  246,  681,  465,  571,  626,  436,  407,  782,\n",
    "        191,  127,  363,  620,  666,  458,  245,  349,  677,  434,  678,\n",
    "        591,  787,  399,  457,  359,  238,  625,  840,  567,  736,  665,\n",
    "        428,  376,  781,  898,  618,  675,  318,  454,  662,  243,  897,\n",
    "        347,  836,  816,  720,  433,  604,  617,  779,  808,  661,  834,\n",
    "        712,  804,  833,  559,  237,  453,  426,  222,  317,  775,  372,\n",
    "        343,  412,  235,  543,  614,  451,  425,  422,  613,  370,  221,\n",
    "        315,  480,  335,  659,  654,  364,  190,  369,  248,  653,  688,\n",
    "        231,  410,  602,  611,  802,  792,  421,  651,  601,  598,  708,\n",
    "        311,  219,  572,  597,  788,  570,  409,  590,  362,  801,  680,\n",
    "        464,  406,  419,  348,  647,  786,  215,  589,  706,  361,  676,\n",
    "        566,  189,  595,  244,  569,  303,  405,  358,  456,  346,  398,\n",
    "        565,  242,  126,  705,  780,  587,  624,  664,  236,  187,  357,\n",
    "        432,  785,  558,  674,  207,  403,  397,  452,  345,  563,  778,\n",
    "        241,  316,  342,  616,  660,  557,  125,  234,  183,  287,  355,\n",
    "        583,  673,  395,  424,  314,  220,  777,  341,  612,  658,  123,\n",
    "        175,  774,  555,  233,  334,  542,  450,  313,  391,  230,  652,\n",
    "        368,  218,  339,  600,  119,  333,  657,  610,  773,  541,  310,\n",
    "        420,  159,  229,  650,  551,  596,  609,  408,  217,  449,  188,\n",
    "        309,  214,  331,  111,  539,  360,  771,  649,  302,  418,  594,\n",
    "        896,  227,  404,  646,  186,  588,  832,  568,  213,  417,  301,\n",
    "        307,  356,  402,  800,  564,  327,   95,  206,  240,  535,  593,\n",
    "        645,  586,  344,  396,  185,  401,  211,  354,  299,  585,  286,\n",
    "        562,  643,  182,  205,  124,  232,  285,  295,  181,  556,  582,\n",
    "        527,  394,  340,   63,  203,  561,  353,  448,  122,  283,  393,\n",
    "        581,  554,  174,  390,  704,  312,  338,  228,  179,  784,  199,\n",
    "        553,  121,  173,  389,  540,  579,  332,  118,  672,  550,  337,\n",
    "        158,  279,  271,  416,  216,  308,  387,  538,  549,  226,  330,\n",
    "        776,  171,  212,  117,  110,  329,  656,  157,  772,  306,  326,\n",
    "        225,  167,  115,  537,  534,  184,  109,  300,  547,  305,  210,\n",
    "        155,  533,  325,  352,  608,  400,  298,  204,   94,  648,  284,\n",
    "        209,  151,  180,  107,  770,  297,  392,  323,  592,  202,  644,\n",
    "         93,  294,  178,  103,  143,  282,   62,  336,  201,  120,  172,\n",
    "        198,  769,  584,   91,  388,  293,  177,  526,  278,  281,  642,\n",
    "        525,  531,   61,  170,  116,  197,   87,  156,  277,  114,  560,\n",
    "        169,   59,  291,  580,  275,  523,  641,  270,  195,  552,  519,\n",
    "        166,  224,  578,  108,  269,   79,  154,  113,  548,  577,  536,\n",
    "        328,   55,  106,  165,  153,  150,  386,  208,  324,  546,  385,\n",
    "        267,   47,   92,  163,  296,  304,  105,  102,  149,  263,  532,\n",
    "        322,  292,  545,   90,  200,   31,  321,  530,  142,  176,  147,\n",
    "        101,  141,  196,  524,  529,  290,   89,  280,   60,   86,   99,\n",
    "        139,  168,   58,  522,  276,   85,  194,  289,   78,  135,  112,\n",
    "        521,   57,   83,   54,  518,  274,  268,  768,  164,   77,  152,\n",
    "        193,   53,  162,  104,  517,  273,  266,   75,   46,  148,   51,\n",
    "        640,  100,   45,  576,  161,  265,  262,   71,  146,   30,  140,\n",
    "         88,  515,   98,   43,   29,  261,  145,  138,   84,  259,   39,\n",
    "         97,   27,   56,   82,  137,   76,  384,  134,   23,   52,  133,\n",
    "        320,   15,   73,   50,   81,  131,   44,   70,  544,  192,  528,\n",
    "        288,  520,  160,  272,   74,   49,  516,   42,   69,   28,  144,\n",
    "         41,   67,   96,  514,   38,  264,  260,  136,   22,   25,   37,\n",
    "         80,  513,   26,  258,   35,  132,   21,  257,   72,   14,   48,\n",
    "         13,   19,  130,   68,   40,   11,  512,   66,  129,    7,   36,\n",
    "         24,   34,  256,   20,   65,   33,   12,  128,   18,   10,   17,\n",
    "          6,    9,   64,    5,    3,   32,   16,    8,    4,    2,    1,\n",
    "          0])\n",
    "        rs = rs[rs<N]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'RM':\n",
    "        rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        Fr = np.argsort(rmweight)[:-K]\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted_last':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds[::-1]\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'rev_polar':\n",
    "\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:target_K].copy()\n",
    "        rs[:target_K] = first_inds[::-1]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    return Fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(codebook):\n",
    "    \"\"\"Calculate pairwise distances between codewords\"\"\"\n",
    "    dists = []\n",
    "    for row1, row2 in combinations(codebook, 2):\n",
    "        distance = (row1-row2).pow(2).sum()\n",
    "        dists.append(np.sqrt(distance.item()))\n",
    "    return dists, np.min(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54073b6",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2a9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_original_path):\n",
    "    plt.figure()\n",
    "    plt.plot(bers_enc, label='BER')\n",
    "    plt.plot(moving_average(bers_enc, n=10), label='BER moving avg')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Training BER ENC')\n",
    "    plt.savefig(os.path.join(results_save_original_path, 'training_ber_enc.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Similar plots for losses_enc, bers_dec, losses_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96d3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save models\n",
    "def save_model(polar, iter, results_save_original_path, best=False):\n",
    "    torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map], \n",
    "               os.path.join(results_save_original_path, f'Models/fnet_gnet_{iter}.pt'))\n",
    "    if iter > 1:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt'))\n",
    "    if best:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e6cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        # Convert to binary if needed\n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        # Initialize result tensor\n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        \n",
    "        # Prepare dividend for all batches at once\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        \n",
    "        # Perform batch polynomial division\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        \n",
    "        # Combine message and remainder\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        # Convert back to float if needed\n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "            \n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        \"\"\"Check if received messages pass CRC in batch.\"\"\"\n",
    "        # Convert to binary if needed\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "            \n",
    "        # Perform polynomial division on all messages at once\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        \n",
    "        # Check if all remainder bits are zero for each message\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    \n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        \"\"\"Perform polynomial division in batch using vectorized operations.\"\"\"\n",
    "        # Make copy to avoid modifying input\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        # Find positions of 1s for all batches\n",
    "        for i in range(n - self.degree):\n",
    "            # Find batches where current bit is 1\n",
    "            active_batches = result[:, i] == 1\n",
    "            \n",
    "            if torch.any(active_batches):\n",
    "                # XOR with polynomial for active batches\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        \n",
    "        # Return last degree bits (remainder) for all batches\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b167a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crc = CRC(crc_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4986216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n"
     ]
    }
   ],
   "source": [
    "if anomaly:\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "#ID = str(np.random.randint(100000, 999999)) if id is None else id\n",
    "#ID = 207515\n",
    "\n",
    "\n",
    "###############\n",
    "### Polar code\n",
    "##############\n",
    "\n",
    "### Encoder\n",
    "\n",
    "if last_ell is not None:\n",
    "    depth_map = defaultdict(int)\n",
    "    n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "    for d in range(1, n+1):\n",
    "        depth_map[d] = kernel_size\n",
    "    depth_map[n+1] = last_ell\n",
    "    assert np.prod(list(depth_map.values())) == N\n",
    "    polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "else:\n",
    "    polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "info_inds = polar.info_positions\n",
    "frozen_inds = polar.frozen_positions\n",
    "\n",
    "print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "##############\n",
    "### Neural networks\n",
    "##############\n",
    "ell = kernel_size\n",
    "if N == ell: # Kernel pre-training\n",
    "    polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "elif N > ell: # Initialize full network with pretrained kernels\n",
    "    polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "if binary:\n",
    "    load_path = os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt')\n",
    "    assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "    results_save_original_path = os.path.join(results_save_original_path, 'Binary')\n",
    "    os.makedirs(results_save_original_path, exist_ok=True)\n",
    "    os.makedirs(results_save_original_path +'/Models', exist_ok=True)\n",
    "\n",
    "if load_path is not None:\n",
    "    if test:\n",
    "        if test_load_path is None:\n",
    "            print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "    else:\n",
    "        checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "        fnet_dict = checkpoint1[0]\n",
    "        gnet_dict = checkpoint1[1]\n",
    "\n",
    "        polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "        print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "if 'KO' in decoder_type:\n",
    "    dec_params = []\n",
    "    for i in polar.fnet_dict.keys():\n",
    "        for j in polar.fnet_dict[i].keys():\n",
    "            if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                for k in polar.fnet_dict[i][j].keys():\n",
    "                    dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "            else:\n",
    "                dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "elif decoder_type == 'RNN':\n",
    "    dec_params = polar.fnet_dict.parameters()\n",
    "else:\n",
    "    dec_train_iters = 0\n",
    "\n",
    "if 'KO' in encoder_type:\n",
    "    enc_params = []\n",
    "    if shared:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            enc_params += list(polar.gnet_dict[i].parameters())\n",
    "    else:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            for j in polar.gnet_dict[i].keys():\n",
    "                enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "elif encoder_type == 'scaled':\n",
    "    enc_params = [polar.a]\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "else:\n",
    "    enc_train_iters = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'BCE' in loss_type:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'L1':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_type == 'huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "info_positions = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d5c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053eafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__0.0_Encoder_KO_-2.0_Decoder/epochs_500_batchsize_20000'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_save_original_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e6b672b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "Checkpoint Loaded\n",
      "NN weights loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "times = []\n",
    "results_load_path = results_save_original_path\n",
    "\n",
    "\n",
    "\n",
    "checkpoint1 = torch.load(results_load_path +'/Models/fnet_gnet_final.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "fnet_dict = checkpoint1[0]\n",
    "gnet_dict = checkpoint1[1]\n",
    "print('Checkpoint Loaded')\n",
    "\n",
    "polar.load_nns(fnet_dict, gnet_dict, shared = shared)\n",
    "\n",
    "if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "    snr_range = [test_snr_start]\n",
    "else:\n",
    "    snrs_interval = (test_snr_end - test_snr_start)* 1.0 /  (snr_points-1)\n",
    "    snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# For polar code testing.\n",
    "\n",
    "ell = 2\n",
    "Frozen = get_frozen(N, K, rate_profile)\n",
    "Frozen.sort()\n",
    "polar_l_2 = PolarCode(int(np.log2(N)), K, Fr=Frozen, infty = infty, hard_decision=hard_decision)\n",
    "\n",
    "\n",
    "if pairwise:\n",
    "    codebook_size = 1000\n",
    "    all_msg_bits = 2 * (torch.rand(codebook_size, K, device = device) < 0.5).float() - 1\n",
    "    deeppolar_codebook = polar.deeppolar_encode(all_msg_bits)\n",
    "    polar_codebook = polar_l_2.encode_plotkin(all_msg_bits)\n",
    "    gaussian_codebook = F.normalize(torch.randn(codebook_size, N), p=2, dim=1)*np.sqrt(N)\n",
    "\n",
    "    from scipy import stats\n",
    "    w_statistic_deeppolar, p_value_deeppolar = stats.shapiro(deeppolar_codebook.detach().cpu().numpy())\n",
    "    w_statistic_gaussian, p_value_gaussian = stats.shapiro(gaussian_codebook.detach().cpu().numpy())\n",
    "    w_statistic_polar, p_value_polar = stats.shapiro(polar_codebook.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Deeppolar Shapiro test W = {w_statistic_deeppolar}, p-value = {p_value_deeppolar}\")\n",
    "    print(f\"Gaussian Shapiro test W = {w_statistic_gaussian}, p-value = {p_value_gaussian}\")\n",
    "    print(f\"Polar Shapiro test W = {w_statistic_polar}, p-value = {p_value_polar}\")\n",
    "\n",
    "    dists_deeppolar, md_deeppolar = pairwise_distances(deeppolar_codebook)\n",
    "    dists_polar, md_polar = pairwise_distances(polar_codebook)\n",
    "    dists_gaussian, md_gaussian = pairwise_distances(gaussian_codebook)\n",
    "\n",
    "    # Function to calculate and plot PDF\n",
    "    def plot_pdf(data, label, bins=30, alpha=0.5, color=None, linewidth=1.0):\n",
    "        counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, counts, label=label, alpha=alpha, \n",
    "                 color=color, linewidth=linewidth)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Larger figure size\n",
    "\n",
    "    # Define better colors\n",
    "    colors = ['#e74c3c', '#3498db']  # Red and Blue\n",
    "    linewidth = 2.5\n",
    "\n",
    "    # Plot with enhanced styling\n",
    "    plot_pdf(dists_deeppolar, 'DeepPolar', bins=300, color=colors[0], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "    plot_pdf(dists_gaussian, 'Gaussian', bins=300, color=colors[1], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "\n",
    "    # Enhance grid - both major and minor\n",
    "    plt.grid(True, which='major', linestyle='-', alpha=0.5)\n",
    "    plt.grid(True, which='minor', linestyle=':', alpha=0.3)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    # Enhance labels and title\n",
    "    plt.xlabel('Pairwise Distance', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Probability Density', fontsize=16, fontweight='bold')\n",
    "    #plt.title(f'Pairwise Distances Distribution (N={N}, K={K})', \n",
    "    #          fontsize=16, fontweight='bold', pad=15)\n",
    "\n",
    "    # Enhance legend\n",
    "    plt.legend(fontsize=16, frameon=True, fancybox=True, \n",
    "              shadow=True, loc='upper left')\n",
    "\n",
    "    # Enhance ticks\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save with high DPI for better quality\n",
    "    plt.savefig(os.path.join(results_save_original_path, f\"hists_N{N}_K{K}_{id}_2.pdf\"), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(f'dists_deeppolar: {dists_deeppolar}')\n",
    "    print(f'dists_gaussian: {dists_gaussian}')\n",
    "if epos:\n",
    "    from collections import OrderedDict, Counter\n",
    "\n",
    "    def get_epos(k1, k2):\n",
    "        # return counter for bit ocations of first-errors\n",
    "        bb = torch.ne(k1.cpu().sign(), k2.cpu().sign())\n",
    "        # inds = torch.nonzero(bb)[:, 1].numpy()\n",
    "        idx = []\n",
    "        for ii in range(bb.shape[0]):\n",
    "            try:\n",
    "                iii = list(bb.cpu().float().numpy()[ii]).index(1)\n",
    "                idx.append(iii)\n",
    "            except:\n",
    "                pass\n",
    "        counter = Counter(idx)\n",
    "        ordered_counter = OrderedDict(sorted(counter.items()))\n",
    "        return ordered_counter\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (k, msg_bits) in enumerate(Test_Data_Generator):\n",
    "            msg_bits = msg_bits.to(device)\n",
    "            polar_code = polar_l_2.encode_plotkin(msg_bits)\n",
    "            noisy_code = polar.channel(polar_code, dec_train_snr)\n",
    "            noise = noisy_code - polar_code\n",
    "            deeppolar_code = polar.deeppolar_encode(msg_bits)\n",
    "            noisy_deeppolar_code = deeppolar_code + noise\n",
    "            SC_llrs, decoded_SC_msg_bits = polar_l_2.sc_decode_new(noisy_code, dec_train_snr)\n",
    "            deeppolar_llrs, decoded_deeppolar_msg_bits = polar.deeppolar_decode(noisy_deeppolar_code)\n",
    "\n",
    "            if k == 0:\n",
    "                epos_deeppolar = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "            else:\n",
    "                epos_deeppolar1 = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC1 = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "                epos_deeppolar = epos_deeppolar + epos_deeppolar1\n",
    "                epos_SC = epos_SC + epos_SC1\n",
    "\n",
    "        print(f\"epos_deeppolar: {epos_deeppolar}\")\n",
    "        print(f\"EPOS_SC: {epos_SC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ada1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeppolar_example_test(polar, KO, snr_range, device, info_positions, binary=False, num_examples=10**6, noise_type='awgn', L=8, crc=crc):\n",
    "    bers_KO_test = [0. for _ in snr_range]\n",
    "    blers_KO_test = [0. for _ in snr_range]\n",
    "    bers_SC_test = [0. for _ in snr_range]\n",
    "    blers_SC_test = [0. for _ in snr_range]\n",
    "\n",
    "    kernel = N == KO.ell\n",
    "    num_batches = num_examples // test_batch_size\n",
    "\n",
    "    print(f\"TESTING for {num_examples} examples ({num_batches} batches)\")\n",
    "    for snr_ind, snr in enumerate(snr_range):\n",
    "        total_block_errors_SC = 0\n",
    "        total_block_errors_KO = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        sigma = snr_db2sigma(snr)\n",
    "\n",
    "        try:\n",
    "            for _ in range(num_batches):\n",
    "                msg_bits = 2 * (torch.rand(test_batch_size, K-crc_len) < 0.5).float() - 1\n",
    "                msg_bits = msg_bits.to(device)\n",
    "                \n",
    "                msg_bits_with_crc = crc.encode(msg_bits)\n",
    "                \n",
    "                polar_code = polar.encode_plotkin(msg_bits_with_crc)\n",
    "\n",
    "                if 'KO' in encoder_type:\n",
    "                    if kernel:\n",
    "                        KO_polar_code = KO.kernel_encode(kernel_size, KO.gnet_dict[1][0], msg_bits_with_crc, info_positions, binary=binary)\n",
    "                    else:\n",
    "                        KO_polar_code = KO.deeppolar_encode(msg_bits_with_crc, binary=binary)\n",
    "\n",
    "                noisy_code = polar.channel(polar_code, snr, noise_type)\n",
    "                \n",
    "                noisy_KO_code = polar.channel(KO_polar_code, snr, noise_type) if 'KO' in encoder_type else noisy_code\n",
    "\n",
    "                SC_llrs, decoded_SC_msg_bits_with_crc = polar.sc_decode_new(noisy_code, snr)\n",
    "                decoded_SC_msg_bits = decoded_SC_msg_bits_with_crc[:,:K-crc_len]\n",
    "                ber_SC = errors_ber(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                bler_SC = errors_bler(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                total_block_errors_SC += int(bler_SC*test_batch_size)\n",
    "\n",
    "                \n",
    "                final_decisions, info_llrs, PML = KO.deeppolar_list_decode(noisy_KO_code, L, crc)\n",
    "                decoded_KO_msg_bits = final_decisions[:,:K-crc_len]\n",
    "                ber_KO = errors_ber(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                bler_KO = errors_bler(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                total_block_errors_KO += int(bler_KO*test_batch_size)\n",
    "\n",
    "                batches_processed += 1\n",
    "\n",
    "                # Update accumulative results\n",
    "                bers_KO_test[snr_ind] += ber_KO\n",
    "                bers_SC_test[snr_ind] += ber_SC\n",
    "                blers_KO_test[snr_ind] += bler_KO\n",
    "                blers_SC_test[snr_ind] += bler_SC\n",
    "\n",
    "                # Progress logging\n",
    "                if batches_processed % 10 == 0:  # Print every 10 batches\n",
    "                    print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, Progress: {batches_processed}/{num_batches} batches\", end='\\r')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        # Normalize by actual number of batches processed\n",
    "        bers_KO_test[snr_ind] /= batches_processed\n",
    "        bers_SC_test[snr_ind] /= batches_processed\n",
    "        blers_KO_test[snr_ind] /= batches_processed\n",
    "        blers_SC_test[snr_ind] /= batches_processed\n",
    "\n",
    "        print(f\"\\nSNR: {snr} dB, Sigma: {sigma:.5f}\")\n",
    "        print(f\"SC   - BER: {bers_SC_test[snr_ind]:.6f}, BLER: {blers_SC_test[snr_ind]:.6f}\")\n",
    "        print(f\"Deep - BER: {bers_KO_test[snr_ind]:.6f}, BLER: {blers_KO_test[snr_ind]:.6f}\")\n",
    "\n",
    "    return bers_SC_test, blers_SC_test, bers_KO_test, blers_KO_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "645cc944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "TESTING for 1000000 examples (2000 batches)\n",
      "SNR: -5.0 dB, Sigma: 1.77828, Progress: 2000/2000 batches\n",
      "SNR: -5.0 dB, Sigma: 1.77828\n",
      "SC   - BER: 0.166141, BLER: 0.434499\n",
      "Deep - BER: 0.132742, BLER: 0.460969\n",
      "SNR: -4.0 dB, Sigma: 1.58489, Progress: 2000/2000 batches\n",
      "SNR: -4.0 dB, Sigma: 1.58489\n",
      "SC   - BER: 0.072355, BLER: 0.196469\n",
      "Deep - BER: 0.047913, BLER: 0.190398\n",
      "SNR: -3.0 dB, Sigma: 1.41254, Progress: 2000/2000 batches\n",
      "SNR: -3.0 dB, Sigma: 1.41254\n",
      "SC   - BER: 0.020034, BLER: 0.055618\n",
      "Deep - BER: 0.010045, BLER: 0.047107\n",
      "SNR: -2.0 dB, Sigma: 1.25893, Progress: 2000/2000 batches\n",
      "SNR: -2.0 dB, Sigma: 1.25893\n",
      "SC   - BER: 0.003010, BLER: 0.008493\n",
      "Deep - BER: 0.001168, BLER: 0.006497\n",
      "SNR: -1.0 dB, Sigma: 1.12202, Progress: 2000/2000 batches\n",
      "SNR: -1.0 dB, Sigma: 1.12202\n",
      "SC   - BER: 0.000196, BLER: 0.000572\n",
      "Deep - BER: 0.000072, BLER: 0.000491\n",
      "Test SNRs : [-5.0, -4.0, -3.0, -2.0, -1.0]\n",
      "\n",
      "Test Sigmas : [1.7782794100389228, 1.5848931924611136, 1.4125375446227544, 1.2589254117941673, 1.1220184543019633]\n",
      "\n",
      "BERs of DeepPolar: [0.1327416177839041, 0.0479128529606387, 0.010044500006595626, 0.0011681470595231076, 7.217647035395203e-05]\n",
      "BERs of SC decoding: [0.16614126458019018, 0.07235461766645312, 0.020034176440909504, 0.0030100882418973925, 0.0001961764708503324]\n",
      "BLERs of DeepPolar: [0.4609690000000017, 0.19039799999999957, 0.04710700000000041, 0.006496999999999897, 0.0004910000000000003]\n",
      "BLERs of SC decoding: [0.4344990000000016, 0.1964690000000001, 0.055618000000000334, 0.008492999999999888, 0.0005720000000000004]\n",
      "time = 697.6589717904727 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "\n",
    "start = time.time()\n",
    "bers_SC_test, blers_SC_test, bers_deeppolar_test, blers_deeppolar_test = deeppolar_example_test(polar_l_2, polar, snr_range, device, info_positions, binary = binary, num_examples=10**6, noise_type = noise_type, L=L, crc=crc)\n",
    "print(\"Test SNRs : {}\\n\".format(snr_range))\n",
    "print(f\"Test Sigmas : {[snr_db2sigma(s) for s in snr_range]}\\n\")\n",
    "print(\"BERs of DeepPolar: {0}\".format(bers_deeppolar_test))\n",
    "print(\"BERs of SC decoding: {0}\".format(bers_SC_test))\n",
    "print(\"BLERs of DeepPolar: {0}\".format(blers_deeppolar_test))\n",
    "print(\"BLERs of SC decoding: {0}\".format(blers_SC_test))\n",
    "print(f\"time = {(time.time() - start)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f42683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BER\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "ok = 0\n",
    "plt.semilogy(snr_range, bers_deeppolar_test, label=\"DeepPolar SC List\", marker='*', linewidth=1.5)\n",
    "\n",
    "plt.semilogy(snr_range, bers_SC_test, label=\"SC decoder\", marker='^', linewidth=1.5)\n",
    "\n",
    "## BLER\n",
    "plt.semilogy(snr_range, blers_deeppolar_test, label=\"DeepPolar SC List BLER)\", marker='*', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.semilogy(snr_range, blers_SC_test, label=\"SC decoder (BLER)\", marker='^', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=16)\n",
    "plt.ylabel(\"Error Rate\", fontsize=16)\n",
    "\n",
    "plt.legend(prop={'size': 15})\n",
    "if test_load_path is not None:\n",
    "    os.makedirs('Polar_Results/figures', exist_ok=True)\n",
    "    fig_save_path = results_save_path + 'Polar_Results/figures/SCListDeepPolar.pdf'\n",
    "else:\n",
    "    fig_save_path = results_save_path + f\"/SCList_Step{model_iters if model_iters is not None else 'final'}{'_binary' if binary else ''}.pdf\"\n",
    "if not no_fig:\n",
    "    plt.savefig(fig_save_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
