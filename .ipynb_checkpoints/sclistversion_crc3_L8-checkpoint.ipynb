{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8752b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc45a",
   "metadata": {},
   "source": [
    "# Configuration variables (previously args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b957ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # Block length\n",
    "K = 37   # Message size\n",
    "kernel_size = 16  # Kernel size (ell)\n",
    "rate_profile = 'polar'  # Rate profiling; choices=['RM', 'polar', 'sorted', 'last', 'rev_polar', 'custom']\n",
    "infty = 1000.  # Infinity value for frozen position LLR in polar dec\n",
    "lse = 'minsum'  # LSE function; choices=['minsum', 'lse']\n",
    "hard_decision = False  # Polar code sc decoding hard decision?\n",
    "\n",
    "# DeepPolar parameters\n",
    "encoder_type = 'KO'  # Type of encoding; choices=['KO', 'scaled', 'polar']\n",
    "decoder_type = 'KO'  # Type of decoding; choices=['KO', 'SC', 'KO_parallel', 'KO_last_parallel']\n",
    "enc_activation = 'selu'  # Activation function\n",
    "dec_activation = 'selu'  # Activation function\n",
    "dropout_p = 0.\n",
    "dec_hidden_size = 128  # Neural network size\n",
    "enc_hidden_size = 64   # Neural network size\n",
    "f_depth = 3  # Decoder neural network depth\n",
    "g_depth = 3  # Encoder neural network depth\n",
    "g_skip_depth = 1  # Encoder neural network skip depth\n",
    "g_skip_layer = 1  # Encoder neural network skip layer\n",
    "onehot = False  # Use onehot representation of prev_decoded_bits\n",
    "shared = False  # Share weights across depth\n",
    "use_skip = True  # Use skip connections\n",
    "use_norm = False  # Use normalization\n",
    "binary = False  # Use binary quantization\n",
    "\n",
    "# Infrastructure parameters\n",
    "id = None  # Optional ID for multiple runs\n",
    "test = False  # Testing mode flag\n",
    "pairwise = False  # Plot codeword pairwise distances\n",
    "epos = False  # Plot error positions\n",
    "seed = None  # Random seed\n",
    "anomaly = False  # Enable anomaly detection\n",
    "dataparallel = False  # Use dataparallel\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture parameters\n",
    "polar_depths = []  # List of depths to use polar encoding/decoding\n",
    "last_ell = None  # Use kernel last_ell last layer\n",
    "\n",
    "\n",
    "# Channel parameters\n",
    "radar_power = None  # Radar power parameter\n",
    "radar_prob = 0.1  # Radar probability parameter\n",
    "\n",
    "# Training parameters\n",
    "full_iters = 500  # Full iterations\n",
    "enc_train_iters = 30  # Encoder iterations\n",
    "dec_train_iters = 300  # Decoder iterations\n",
    "enc_train_snr = 0.  # SNR at which encoder is trained\n",
    "dec_train_snr = -2.  # SNR at which decoder is trained\n",
    "weight_decay = 0.0\n",
    "dec_lr = 0.001  # Decoder Learning rate\n",
    "enc_lr = 0.001  # Encoder Learning rate\n",
    "batch_size = 20000  # Size of batches\n",
    "small_batch_size = 5000  # Size of small batches\n",
    "noise_type = 'awgn'  # Noise type; choices=['fading', 'awgn', 'radar']\n",
    "regularizer = None  # Regularizer type; choices=['std', 'max_deviation','polar']\n",
    "regularizer_weight = 0.001\n",
    "loss_type = 'BCE' # loss function; choices=['MSE', 'BCE', 'BCE_reg', 'L1', 'huber', 'focal', 'BCE_bler']\n",
    "initialization = 'random'  # Initialization type; choices=['random', 'zeros']\n",
    "optim_name = 'Adam'  # Optimizer type; choices=['Adam', 'RMS', 'SGD', 'AdamW']\n",
    "\n",
    "# Testing parameters\n",
    "test_batch_size = 500  # Size of test batches\n",
    "num_errors = 100  # Test until _ block errors\n",
    "test_snr_start = -5.  # Testing SNR start\n",
    "test_snr_end = -1.   # Testing SNR end\n",
    "snr_points = 5       # Testing SNR num points\n",
    "\n",
    "\n",
    "\n",
    "# Model saving/loading parameters\n",
    "model_save_per = 100  # Model save frequency\n",
    "model_iters = None  # Option to load specific model iteration\n",
    "test_load_path = None  # Path to load test model\n",
    "\n",
    "load_path = None  # Load path \n",
    "kernel_load_path = 'Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new'   # Kernel load path\n",
    "no_fig = False  # Plot figure option\n",
    "\n",
    "\n",
    "# Scheduler parameters\n",
    "scheduler = 'cosine' # choices = ['reduce', '1cycle', 'cosine']\n",
    "scheduler_patience = None  # Scheduler patience\n",
    "batch_schedule = False  # Use batch scheduler\n",
    "batch_patience = 50  # Batch scheduler patience \n",
    "batch_factor = 2  # Batch multiplication factor\n",
    "min_batch_size = 500  # Minimum batch size\n",
    "max_batch_size = 50000  # Maximum batch size\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117821f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab1d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "crc_len = 8  # CRC length \n",
    "# Initialize CRC\n",
    "crc_poly = [1, 1, 1, 0, 1, 0, 1, 0, 1]  # CRC polynomial\n",
    "L=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc384a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_original_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}/{encoder_type}__{enc_train_snr}_Encoder_{decoder_type}_{dec_train_snr}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e40922",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}_SClist_L_{L}_crc_{crc_poly}/{encoder_type}_Encoder_{decoder_type}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0c3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path +'/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e521",
   "metadata": {},
   "source": [
    "# Part 1: Core Utilities and Model Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_db2sigma(train_snr):\n",
    "    return 10**(-train_snr*1.0/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a23a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2bb73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a smoother version using product of bit probabilities\n",
    "def soft_bler_loss(logits, targets):\n",
    "    bit_probs = torch.sigmoid(logits)  # For correct bits\n",
    "    bit_probs = torch.where(targets == 1., bit_probs, 1 - bit_probs)\n",
    "    block_probs = torch.prod(bit_probs, dim=1)  # Probability of whole block being correct\n",
    "    return -torch.mean(torch.log(block_probs + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b989d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_ber(y_true, y_pred, mask=None):\n",
    "    if mask == None:\n",
    "        mask=torch.ones(y_true.size(),device=y_true.device)\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "    mask = mask.view(mask.shape[0], -1, 1)\n",
    "    myOtherTensor = (mask*torch.ne(torch.round(y_true), torch.round(y_pred))).float()\n",
    "    res = sum(sum(myOtherTensor))/(torch.sum(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_bler(y_true, y_pred, get_pos = False):\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "\n",
    "    decoded_bits = torch.round(y_pred).cpu()\n",
    "    X_test = torch.round(y_true).cpu()\n",
    "    tp0 = (abs(decoded_bits-X_test)).view([X_test.shape[0],X_test.shape[1]])\n",
    "    tp0 = tp0.detach().cpu().numpy()\n",
    "    bler_err_rate = sum(np.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
    "\n",
    "    if not get_pos:\n",
    "        return bler_err_rate\n",
    "    else:\n",
    "        err_pos = list(np.nonzero((np.sum(tp0,axis=1)>0).astype(int))[0])\n",
    "        return bler_err_rate, err_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92df8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_signal(input_signal, sigma = 1.0, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 0.05):\n",
    "    data_shape = input_signal.shape\n",
    "    device = input_signal.device\n",
    "    if noise_type == 'awgn':\n",
    "        dist = torch.distributions.Normal(torch.tensor([0.0], device=device), torch.tensor([sigma], device=device))\n",
    "        noise = dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 'fading':\n",
    "        fading_h = torch.sqrt(torch.randn_like(input_signal)**2 + torch.randn_like(input_signal)**2)/np.sqrt(3.14/2.0)\n",
    "        noise = sigma * torch.randn_like(input_signal)\n",
    "        corrupted_signal = fading_h *(input_signal) + noise\n",
    "\n",
    "    elif noise_type == 'radar':\n",
    "        add_pos = np.random.choice([0.0, 1.0], data_shape, p=[1 - radar_prob, radar_prob])\n",
    "        corrupted_signal = radar_power* np.random.standard_normal(size=data_shape) * add_pos\n",
    "        noise = sigma * torch.randn_like(input_signal) +\\\n",
    "                    torch.from_numpy(corrupted_signal).float().to(input_signal.device)\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 't-dist':\n",
    "        dist = torch.distributions.StudentT(torch.tensor([vv], device=device))\n",
    "        noise = sigma* dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    return corrupted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e97bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp(x, y):\n",
    "    log_sum_ms = torch.min(torch.abs(x), torch.abs(y))*torch.sign(x)*torch.sign(y)\n",
    "    return log_sum_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5937279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp_4(x_1, x_2, x_3, x_4):\n",
    "    return min_sum_log_sum_exp(min_sum_log_sum_exp(x_1, x_2), min_sum_log_sum_exp(x_3, x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c239bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, y):\n",
    "    def log_sum_exp_(LLR_vector):\n",
    "        sum_vector = LLR_vector.sum(dim=1, keepdim=True)\n",
    "        sum_concat = torch.cat([sum_vector, torch.zeros_like(sum_vector)], dim=1)\n",
    "        return torch.logsumexp(sum_concat, dim=1)- torch.logsumexp(LLR_vector, dim=1) \n",
    "\n",
    "    Lv = log_sum_exp_(torch.cat([x.unsqueeze(2), y.unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "    return Lv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655fe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bitarray(in_number, bit_width):\n",
    "    binary_string = bin(in_number)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(bit_width, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[bit_width-i-1] = int(binary_string[length-i-1])\n",
    "    return bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a081f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSetBits(n):\n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, enc_quantize_level = 2, enc_value_limit = 1.0, enc_grad_limit = 0.01, enc_clipping = 'both'):\n",
    "        ctx.save_for_backward(inputs)\n",
    "        assert enc_clipping in ['both', 'inputs']\n",
    "        ctx.enc_clipping = enc_clipping\n",
    "        ctx.enc_value_limit = enc_value_limit\n",
    "        ctx.enc_quantize_level = enc_quantize_level\n",
    "        ctx.enc_grad_limit = enc_grad_limit\n",
    "\n",
    "        x_lim_abs = enc_value_limit\n",
    "        x_lim_range = 2.0 * x_lim_abs\n",
    "        x_input_norm = torch.clamp(inputs, -x_lim_abs, x_lim_abs)\n",
    "\n",
    "        if enc_quantize_level == 2:\n",
    "            outputs_int = torch.sign(x_input_norm)\n",
    "        else:\n",
    "            outputs_int = torch.round((x_input_norm +x_lim_abs) * ((enc_quantize_level - 1.0)/x_lim_range)) * x_lim_range/(enc_quantize_level - 1.0) - x_lim_abs\n",
    "\n",
    "        return outputs_int\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.enc_clipping in ['inputs', 'both']:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input>ctx.enc_value_limit]=0\n",
    "            grad_output[input<-ctx.enc_value_limit]=0\n",
    "\n",
    "        if ctx.enc_clipping in ['gradient', 'both']:\n",
    "            grad_output = torch.clamp(grad_output, -ctx.enc_grad_limit, ctx.enc_grad_limit)\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d695a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'tanh':\n",
    "        return F.tanh\n",
    "    elif activation == 'elu':\n",
    "        return F.elu\n",
    "    elif activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'selu':\n",
    "        return F.selu\n",
    "    elif activation == 'sigmoid':\n",
    "        return F.sigmoid\n",
    "    elif activation == 'gelu':\n",
    "        return F.gelu\n",
    "    elif activation == 'silu':\n",
    "        return F.silu\n",
    "    elif activation == 'mish':\n",
    "        return F.mish\n",
    "    elif activation == 'linear':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Activation function {activation} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth=3, skip_depth=1, skip_layer=1, ell=2, activation='selu', use_skip=False, augment=False):\n",
    "        super(g_Full, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.ell = ell\n",
    "        self.ell_input_size = input_size//self.ell\n",
    "        self.augment = augment\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "        self.skip_depth = skip_depth\n",
    "        self.skip_layer = skip_layer\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        if self.use_skip:\n",
    "            self.skip = nn.ModuleList([nn.Linear(self.input_size + self.output_size, self.hidden_size, bias=True)])\n",
    "            self.skip.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.skip_depth)])\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        self.linears.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.depth)])\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_augment(msg, ell):\n",
    "        u = msg.clone()\n",
    "        n = int(np.log2(ell))\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, ell, 2*num_bits):\n",
    "                if len(u.shape) == 2:\n",
    "                    u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                elif len(u.shape) == 3:\n",
    "                    u = torch.cat((u[:, :, :i], u[:, :, i:i+num_bits].clone() * u[:, :, i+num_bits: i+2*num_bits], u[:, :, i+num_bits:]), dim=2)\n",
    "\n",
    "        if len(u.shape) == 3:\n",
    "            return u[:, :, :-1]\n",
    "        elif len(u.shape) == 2:\n",
    "            return u[:, :-1]\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y.clone()\n",
    "        for ii, layer in enumerate(self.linears):\n",
    "            if ii != self.depth:\n",
    "                x = self.activation_fn(layer(x))\n",
    "                if self.use_skip and ii == self.skip_layer:\n",
    "                    if len(x.shape) == 3:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=2)\n",
    "                    elif len(x.shape) == 2:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=1)\n",
    "                    for jj, skip_layer in enumerate(self.skip):\n",
    "                        skip_input = self.activation_fn(skip_layer(skip_input))\n",
    "                    x = x + skip_input\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if self.augment:\n",
    "                    x = x + g_Full.get_augment(y, self.ell)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d72065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape should be: (batch_size, seq_len, hidden_dim)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class f_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0., activation='selu', depth=3, use_norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.use_norm = use_norm\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "\n",
    "        # Initial layers same as original f_Full\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        if self.use_norm:\n",
    "            self.norms = nn.ModuleList([nn.LayerNorm(self.hidden_size)])\n",
    "        \n",
    "        # Attention layer after first linear\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,  # Reduced number of heads\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Remaining layers same as original\n",
    "        for ii in range(1, self.depth):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size, bias=True))\n",
    "            if self.use_norm:\n",
    "                self.norms.append(nn.LayerNorm(self.hidden_size))\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    def forward(self, y, aug=None):\n",
    "        x = y.clone()\n",
    "        \n",
    "        # First linear layer\n",
    "        x = self.linears[0](x)\n",
    "        if self.use_norm:\n",
    "            x = self.norms[0](x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        # Reshape for attention: [batch, seq_len, hidden]\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = attn_out if len(y.shape) == 3 else attn_out.squeeze(1)\n",
    "        \n",
    "        # Remaining layers\n",
    "        for ii in range(1, len(self.linears)):\n",
    "            if ii != self.depth:\n",
    "                x = self.linears[ii](x)\n",
    "                if self.use_norm:\n",
    "                    x = self.norms[ii](x)\n",
    "                x = self.activation_fn(x)\n",
    "            else:\n",
    "                x = self.linears[ii](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10845154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        try:\n",
    "            m.bias.data.fill_(0.)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e38e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(actions):\n",
    "    inds = (0.5 + 0.5*actions).long()\n",
    "    return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594f46",
   "metadata": {},
   "source": [
    "# Part 2: Core PolarCode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarCode:\n",
    "\n",
    "    def __init__(self, n, K, Fr = None, rs = None, use_cuda = True, infty = 1000., hard_decision = False, lse = 'lse'):\n",
    "\n",
    "        assert n>=1\n",
    "        self.n = n\n",
    "        self.N = 2**n\n",
    "        self.K = K\n",
    "        self.G2 = np.array([[1,1],[0,1]])\n",
    "        self.G = np.array([1])\n",
    "        for i in range(n):\n",
    "            self.G = np.kron(self.G, self.G2)\n",
    "        self.G = torch.from_numpy(self.G).float()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.infty = infty\n",
    "        self.hard_decision = hard_decision\n",
    "        self.lse = lse\n",
    "\n",
    "        if Fr is not None:\n",
    "            assert len(Fr) == self.N - self.K\n",
    "            self.frozen_positions = Fr\n",
    "            self.unsorted_frozen_positions = self.frozen_positions\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "            self.info_positions = np.array(list(set(self.frozen_positions) ^ set(np.arange(self.N))))\n",
    "            self.unsorted_info_positions = self.info_positions\n",
    "            self.info_positions.sort()\n",
    "            \n",
    "        else:\n",
    "            if rs is None:\n",
    "                # in increasing order of reliability\n",
    "                self.reliability_seq = np.arange(1023, -1, -1)\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "            else:\n",
    "                self.reliability_seq = rs\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "\n",
    "                assert len(self.rs) == self.N\n",
    "            # best K bits\n",
    "            self.info_positions = self.rs[:self.K]\n",
    "            self.unsorted_info_positions = self.reliability_seq[self.reliability_seq<self.N][:self.K]\n",
    "            self.info_positions.sort()\n",
    "            self.unsorted_info_positions=np.flip(self.unsorted_info_positions)\n",
    "            # worst N-K bits\n",
    "            self.frozen_positions = self.rs[self.K:]\n",
    "            self.unsorted_frozen_positions = self.rs[self.K:]\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "\n",
    "            self.CRC_polynomials = {\n",
    "            3: torch.Tensor([1, 0, 1, 1]).int(),\n",
    "            8: torch.Tensor([1, 1, 1, 0, 1, 0, 1, 0, 1]).int(),\n",
    "            16: torch.Tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]).int(),\n",
    "                                    }\n",
    "\n",
    "    def get_G(self, ell):\n",
    "        n = int(np.log2(ell))\n",
    "        G = np.array([1])\n",
    "        for i in range(n):\n",
    "            G = np.kron(G, self.G2)\n",
    "        return G\n",
    "\n",
    "    def encode_plotkin(self, message, scaling = None, custom_info_positions = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "        if custom_info_positions is not None:\n",
    "            info_positions = custom_info_positions\n",
    "        else:\n",
    "            info_positions = self.info_positions\n",
    "        u = torch.ones(message.shape[0], self.N, dtype=torch.float).to(message.device)\n",
    "        u[:, info_positions] = message\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                # u[:, i:i+num_bits] = u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits].clone\n",
    "        if scaling is not None:\n",
    "            u = (scaling * np.sqrt(self.N)*u)/torch.norm(scaling)\n",
    "        return u\n",
    "    \n",
    "    def channel(self, code, snr, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 5e-2):\n",
    "        if noise_type != \"bsc\":\n",
    "            sigma = snr_db2sigma(snr)\n",
    "        else:\n",
    "            sigma = snr\n",
    "\n",
    "        r = corrupt_signal(code, sigma, noise_type, vv, radar_power, radar_prob)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def define_partial_arrays(self, llrs):\n",
    "        # Initialize arrays to store llrs and partial_sums useful to compute the partial successive cancellation process.\n",
    "        llr_array = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        llr_array[:, self.n] = llrs\n",
    "        partial_sums = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        return llr_array, partial_sums\n",
    "\n",
    "\n",
    "    def updateLLR(self, leaf_position, llrs, partial_llrs = None, prior = None):\n",
    "\n",
    "        #START\n",
    "        depth = self.n\n",
    "        decoded_bits = partial_llrs[:,0].clone()\n",
    "        if prior is None:\n",
    "            prior = torch.zeros(self.N) #priors\n",
    "        llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth, 0, leaf_position, prior, decoded_bits)\n",
    "        return llrs, decoded_bits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def partial_decode(self, llrs, partial_llrs, depth, bit_position, leaf_position, prior, decoded_bits=None):\n",
    "        # Function to call recursively, for partial SC decoder.\n",
    "        # We are assuming that u_0, u_1, .... , u_{leaf_position -1} bits are known.\n",
    "        # Partial sums computes the sums got through Plotkin encoding operations of known bits, to avoid recomputation.\n",
    "        # this function is implemented for rate 1 (not accounting for frozen bits in polar SC decoding)\n",
    "\n",
    "        # print(\"DEPTH = {}, bit_position = {}\".format(depth, bit_position))\n",
    "        half_index = 2 ** (depth - 1)\n",
    "        leaf_position_at_depth = leaf_position // 2**(depth-1) # will tell us whether left_child or right_child\n",
    "\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            # Left child\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position:left_bit_position+1]\n",
    "            elif leaf_position_at_depth == left_bit_position:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                elif self.lse == 'lse':\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                #print(Lu.device, prior.device, torch.ones_like(Lu).device)\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu + prior[left_bit_position]*torch.ones_like(Lu)\n",
    "                if self.hard_decision:\n",
    "                    u_hat = torch.sign(Lu)\n",
    "                else:\n",
    "                    u_hat = torch.tanh(Lu/2)\n",
    "\n",
    "                decoded_bits[:, left_bit_position] = u_hat.squeeze(1)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # Right child\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "            if leaf_position_at_depth > right_bit_position:\n",
    "                pass\n",
    "            elif leaf_position_at_depth == right_bit_position:\n",
    "                Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "                llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv + prior[right_bit_position] * torch.ones_like(Lv)\n",
    "                if self.hard_decision:\n",
    "                    v_hat = torch.sign(Lv)\n",
    "                else:\n",
    "                    v_hat = torch.tanh(Lv/2)\n",
    "                decoded_bits[:, right_bit_position] = v_hat.squeeze(1)\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            # LEFT CHILD\n",
    "            # Find likelihood of (u xor v) xor (v) = u\n",
    "            # Lu = log_sum_exp(torch.cat([llrs[:, :half_index].unsqueeze(2), llrs[:, half_index:].unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                Lu = llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "            else:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                elif self.lse == 'lse':\n",
    "                    # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu\n",
    "                llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, left_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # RIGHT CHILD\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "\n",
    "            Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "            llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv\n",
    "            llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, right_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "            return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "    def updatePartialSums(self, leaf_position, decoded_bits, partial_llrs):\n",
    "\n",
    "        u = decoded_bits.clone()\n",
    "        u[:, leaf_position+1:] = 0\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            partial_llrs[:, d] = u\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        partial_llrs[:, self.n] = u\n",
    "        return partial_llrs\n",
    "\n",
    "    def sc_decode_new(self, corrupted_codewords, snr, use_gt = None, channel = 'awgn'):\n",
    "\n",
    "        assert channel in ['awgn', 'bsc']\n",
    "\n",
    "        if channel == 'awgn':\n",
    "            noise_sigma = snr_db2sigma(snr)\n",
    "            llrs = (2/noise_sigma**2)*corrupted_codewords\n",
    "        elif channel == 'bsc':\n",
    "            # snr refers to transition prob\n",
    "            p = (torch.ones(1)*(snr + 1e-9)).to(corrupted_codewords.device)\n",
    "            llrs = (torch.clip(torch.log((1 - p) / p), -10000, 10000) * (corrupted_codewords + 1) - torch.clip(torch.log(p / (1-p)), -10000, 10000) * (corrupted_codewords - 1))/2\n",
    "\n",
    "        # step-wise implementation using updateLLR and updatePartialSums\n",
    "\n",
    "        priors = torch.zeros(self.N)\n",
    "        priors[self.frozen_positions] = self.infty\n",
    "\n",
    "        u_hat = torch.zeros(corrupted_codewords.shape[0], self.N, device=corrupted_codewords.device)\n",
    "        llr_array, partial_llrs = self.define_partial_arrays(llrs)\n",
    "        for ii in range(self.N):\n",
    "            #start = time.time()\n",
    "            llr_array , decoded_bits = self.updateLLR(ii, llr_array.clone(), partial_llrs, priors)\n",
    "            #print('SC update : {}'.format(time.time() - start), corrupted_codewords.shape[0])\n",
    "            if use_gt is None:\n",
    "                u_hat[:, ii] = torch.sign(llr_array[:, 0, ii])\n",
    "            else:\n",
    "                u_hat[:, ii] = use_gt[:, ii]\n",
    "            #start = time.time()\n",
    "            partial_llrs = self.updatePartialSums(ii, u_hat, partial_llrs)\n",
    "            #print('SC partial: {}s, {}', time.time() - start, 'frozen' if ii in self.frozen_positions else 'info')\n",
    "        decoded_bits = u_hat[:, self.info_positions]\n",
    "        return llr_array[:, 0, :].clone(), decoded_bits\n",
    "\n",
    "    def get_CRC(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # inout message should be int\n",
    "\n",
    "        padded_bits = torch.cat([message, torch.zeros(self.CRC_len).int().to(message.device)])\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + self.CRC_len + 1] = padded_bits[cur_shift: cur_shift + self.CRC_len + 1] ^ self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        return padded_bits[self.K_minus_CRC:]\n",
    "\n",
    "    def CRC_check(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # input message should be int\n",
    "\n",
    "        padded_bits = message\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + polar.CRC_len + 1] ^= self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        if padded_bits[self.K_minus_CRC:].sum()>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def encode_with_crc(self, message, CRC_len):\n",
    "        self.CRC_len = CRC_len\n",
    "        self.K_minus_CRC = self.K - CRC_len\n",
    "\n",
    "        if CRC_len == 0:\n",
    "            return self.encode_plotkin(message)\n",
    "        else:\n",
    "            crcs = 1-2*torch.vstack([self.get_CRC((0.5+0.5*message[jj]).int()) for jj in range(message.shape[0])])\n",
    "            encoded = self.encode_plotkin(torch.cat([message, crcs], 1))\n",
    "\n",
    "            return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6d51",
   "metadata": {},
   "source": [
    "# Part 3: DeepPolar Class and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b3d92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        for i in range(n - self.degree):\n",
    "            active_batches = result[:, i] == 1\n",
    "            if torch.any(active_batches):\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPolar(PolarCode):\n",
    "    def __init__(self, device, N, K, ell = 2, infty = 1000., depth_map : defaultdict = None):\n",
    "\n",
    "        # rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        # Frozen = np.argsort(rmweight)[:-K]\n",
    "        # Frozen.sort()\n",
    "\n",
    "        #self.args = args\n",
    "        Fr = get_frozen(N, K, rate_profile)\n",
    "        super().__init__(n = int(np.log2(N)), K = K, Fr=Fr,  infty = infty)\n",
    "        self.N = N\n",
    "\n",
    "        if depth_map is not None:\n",
    "            # depth map is a dict, product of values should be equal to N\n",
    "            assert np.prod(list(depth_map.values())) == N\n",
    "            # assert that keys od depth map start from one and go continuosly till some point \n",
    "            assert min(list(depth_map.keys())) == 1\n",
    "            assert max(list(depth_map.keys())) <= int(np.log2(N))\n",
    "            self.ell = None\n",
    "            self.n_ell = len(depth_map.keys())\n",
    "            assert max(list(depth_map.keys())) == self.n_ell\n",
    "\n",
    "            self.depth_map = depth_map\n",
    "        else:\n",
    "            self.ell = ell\n",
    "            self.n_ell = int(np.log(N)/np.log(self.ell))\n",
    "\n",
    "            self.depth_map = defaultdict(int)\n",
    "            for d in range(1, self.n_ell+1):\n",
    "                self.depth_map[d] = self.ell\n",
    "            assert np.prod(list(self.depth_map.values())) == N\n",
    "\n",
    "        self.device = device\n",
    "        self.fnet_dict = None\n",
    "        self.gnet_dict = None\n",
    "\n",
    "        self.infty = infty\n",
    "\n",
    "    @staticmethod\n",
    "    def get_onehot(actions):\n",
    "        inds = (0.5 + 0.5*actions).long()\n",
    "        if len(actions.shape) == 2:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)\n",
    "        elif len(actions.shape) == 3:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], actions.shape[1], -1)\n",
    "\n",
    "    def define_kernel_nns(self, ell, unfrozen = None, fnet = 'KO', gnet = 'KO', shared = False):\n",
    "\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "        #dec_hidden_size = dec_hidden_size\n",
    "        #enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        depth = 1\n",
    "        assert len(unfrozen) > 0, \"No unfrozen bits!\"\n",
    "\n",
    "        self.fnet_dict[depth] = {}\n",
    "\n",
    "        if fnet == 'KO_parallel' or fnet == 'KO_last_parallel':\n",
    "            bit_position = 0\n",
    "                   \n",
    "            self.fnet_dict[depth][bit_position] = {}\n",
    "            # input_size = self.N if depth == self.n_ell else self.N // int(np.prod([self.depth_map[d] for d in range(depth+1, self.n_ell+1)]))\n",
    "            input_size = ell             \n",
    "            # For curriculum, only for lowest depth.\n",
    "            output_size = ell#len(unfrozen)\n",
    "            self.fnet_dict[depth][bit_position] = f_Full(input_size, dec_hidden_size, output_size, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    " \n",
    "        elif 'KO' in fnet:\n",
    "            if shared:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for current_position in range(ell):\n",
    "                    self.fnet_dict[depth][current_position] = f_Full(ell + current_position, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                for current_position in unfrozen:\n",
    "                    if not self.fnet_dict[depth].get(bit_position):\n",
    "                        self.fnet_dict[depth][bit_position] = {}\n",
    "                    input_size = ell + (int(onehot)+1)*current_position\n",
    "                    self.fnet_dict[depth][bit_position][current_position] = f_Full(input_size, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "                \n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict[depth] = {}\n",
    "            if shared:\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth][bit_position] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "\n",
    "    def define_and_load_nns(self, ell, kernel_load_path=None, fnet='KO', gnet='KO', shared=True, dataparallel=False):\n",
    "        # Initialize decoder and encoder dictionaries\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "\n",
    "        # Loop through each depth level\n",
    "        for depth in range(self.n_ell, 0, -1):\n",
    "            if depth in polar_depths:\n",
    "                continue\n",
    "\n",
    "            ell = self.depth_map[depth]\n",
    "            proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "            # Handle parallel decoder case\n",
    "            if fnet == 'KO_last_parallel' and depth == 1:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for bit_position in range(self.N // proj_size):\n",
    "                    proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                    get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                    num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                    subproj_len = len(proj) // ell\n",
    "                    subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                    num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                    unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                    input_size = ell             \n",
    "                    output_size = ell\n",
    "\n",
    "                    # Use attention-enhanced decoder for parallel case\n",
    "                    self.fnet_dict[depth][bit_position] = f_Full(\n",
    "                        input_size=input_size,\n",
    "                        hidden_size=dec_hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        activation=dec_activation,\n",
    "                        dropout_p=dropout_p,\n",
    "                        depth=f_depth,\n",
    "                        use_norm=use_norm\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    # Load pretrained weights if available\n",
    "                    if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                        try:\n",
    "                            ckpt = torch.load(os.path.join(kernel_load_path + '_parallel', f'{ell}_{len(unfrozen)}.pt'))\n",
    "                            self.fnet_dict[depth][bit_position].load_state_dict(ckpt[0][1][0].state_dict())\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"Parallel File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                            pass\n",
    "\n",
    "                    if dataparallel:\n",
    "                        self.fnet_dict[depth][bit_position] = nn.DataParallel(self.fnet_dict[depth][bit_position])\n",
    "\n",
    "            # Handle sequential decoder case\n",
    "            elif 'KO' in fnet:\n",
    "                self.fnet_dict[depth] = {}\n",
    "\n",
    "                if shared:\n",
    "                    # Shared decoder network for all positions\n",
    "                    for current_position in range(ell):\n",
    "                        self.fnet_dict[depth][current_position] = f_Full(\n",
    "                            input_size=ell + current_position,\n",
    "                            hidden_size=dec_hidden_size,\n",
    "                            output_size=1,\n",
    "                            activation=dec_activation,\n",
    "                            dropout_p=dropout_p,\n",
    "                            depth=f_depth,\n",
    "                            use_norm=use_norm\n",
    "                        ).to(self.device)\n",
    "\n",
    "                        if dataparallel:\n",
    "                            self.fnet_dict[depth][current_position] = nn.DataParallel(self.fnet_dict[depth][current_position])\n",
    "\n",
    "                else:\n",
    "                    # Individual decoder networks for each position\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                        num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                        subproj_len = len(proj) // ell\n",
    "                        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                        unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                        # Load pretrained weights if available\n",
    "                        ckpt_exists = False\n",
    "                        if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                            try:\n",
    "                                ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                ckpt_exists = True\n",
    "                            except FileNotFoundError:\n",
    "                                print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                pass\n",
    "\n",
    "                        # Create decoders for unfrozen positions\n",
    "                        for current_position in unfrozen:\n",
    "                            if not self.fnet_dict[depth].get(bit_position):\n",
    "                                self.fnet_dict[depth][bit_position] = {}\n",
    "\n",
    "                            input_size = ell + (int(onehot)+1)*current_position\n",
    "                            output_size = 1\n",
    "\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = f_Full(\n",
    "                                input_size=input_size,\n",
    "                                hidden_size=dec_hidden_size,\n",
    "                                output_size=output_size,\n",
    "                                activation=dec_activation,\n",
    "                                dropout_p=dropout_p,\n",
    "                                depth=f_depth,\n",
    "                                use_norm=use_norm\n",
    "                            ).to(self.device)\n",
    "\n",
    "                            if ckpt_exists:\n",
    "                                try:\n",
    "                                    f_ckpt = ckpt[0][1][0][current_position].state_dict()\n",
    "                                    self.fnet_dict[depth][bit_position][current_position].load_state_dict(f_ckpt)\n",
    "                                except:\n",
    "                                    print(f\"Warning: Could not load weights for position {current_position}\")\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.fnet_dict[depth][bit_position][current_position] = nn.DataParallel(\n",
    "                                    self.fnet_dict[depth][bit_position][current_position]\n",
    "                                )\n",
    "\n",
    "            # Handle encoder network\n",
    "            if 'KO' in gnet:\n",
    "                self.gnet_dict[depth] = {}\n",
    "                if shared:\n",
    "                    if gnet == 'KO':\n",
    "                        if not dataparallel:\n",
    "                            self.gnet_dict[depth] = g_Full(\n",
    "                                ell, enc_hidden_size, ell-1,\n",
    "                                depth=g_depth,\n",
    "                                skip_depth=g_skip_depth,\n",
    "                                skip_layer=g_skip_layer,\n",
    "                                ell=ell,\n",
    "                                use_skip=use_skip\n",
    "                            ).to(self.device)\n",
    "                        else:\n",
    "                            self.gnet_dict[depth] = nn.DataParallel(\n",
    "                                g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    use_skip=use_skip\n",
    "                                )\n",
    "                            ).to(self.device)\n",
    "                else:\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        num_info_in_proj = sum([int(x in self.info_positions) for x in proj])\n",
    "\n",
    "                        if num_info_in_proj > 0:\n",
    "                            if gnet == 'KO':\n",
    "                                self.gnet_dict[depth][bit_position] = g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    activation=enc_activation,\n",
    "                                    use_skip=use_skip\n",
    "                                ).to(self.device)\n",
    "\n",
    "                            # Load pretrained weights if available\n",
    "                            if kernel_load_path is not None:\n",
    "                                try:\n",
    "                                    ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                    self.gnet_dict[depth][bit_position].load_state_dict(ckpt[1][1][0].state_dict())\n",
    "                                except FileNotFoundError:\n",
    "                                    print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                    pass\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.gnet_dict[depth][bit_position] = nn.DataParallel(self.gnet_dict[depth][bit_position])\n",
    "\n",
    "        if kernel_load_path is not None:\n",
    "            print(\"Loaded kernel from \", kernel_load_path)\n",
    "\n",
    "    def load_nns(self, fnet_dict, gnet_dict = None, shared = False):\n",
    "        self.fnet_dict = fnet_dict\n",
    "        self.gnet_dict = gnet_dict\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if self.fnet_dict is not None:\n",
    "                for bit_position in self.fnet_dict[depth].keys():\n",
    "                    if not isinstance(self.fnet_dict[depth][bit_position], dict):#shared or decoder_type == 'KO_parallel' or decoder_type == 'KO_RNN':\n",
    "                        self.fnet_dict[depth][bit_position].to(self.device)\n",
    "                    else:\n",
    "                        for current_position in self.fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "            if gnet_dict is not None:\n",
    "                if shared:\n",
    "                    self.gnet_dict[depth].to(self.device)\n",
    "                else:\n",
    "                    for bit_position in self.gnet_dict[depth].keys():\n",
    "                        self.gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def load_partial_nns(self, fnet_dict, gnet_dict = None):\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if fnet_dict is not None:\n",
    "                for bit_position in fnet_dict[depth].keys():\n",
    "                    if isinstance(fnet_dict[depth][bit_position], dict):\n",
    "                        for current_position in fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "                    else:\n",
    "                        self.fnet_dict[depth][bit_position] = fnet_dict[depth][bit_position].to(self.device)\n",
    "\n",
    "            if gnet_dict is not None:\n",
    "                for bit_position in gnet_dict[depth].keys():\n",
    "                    self.gnet_dict[depth][bit_position] = gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def kernel_encode(self, ell, gnet, msg_bits, info_positions, binary = False):\n",
    "        input_shape = msg_bits.shape[-1]\n",
    "        assert input_shape <= ell\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, info_positions] = msg_bits\n",
    "        output =torch.cat([gnet(u.unsqueeze(1)).squeeze(1), u[:, -1:]], 1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(output)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def deeppolar_encode(self, msg_bits, binary = False):\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, self.info_positions] = msg_bits\n",
    "        for d in range(1, self.n_ell+1):\n",
    "            # num_bits = self.ell**(d-1)\n",
    "            num_bits = np.prod([self.depth_map[dd] for dd in range(1, d)]) if d > 1 else 1\n",
    "            # proj_size = self.ell**(d)\n",
    "            proj_size = np.prod([self.depth_map[dd] for dd in range(1, d+1)])\n",
    "            ell = self.depth_map[d]\n",
    "            for bit_position, i in enumerate(np.arange(0, self.N, ell*num_bits)):\n",
    "\n",
    "                # [u v] encoded to [(u xor v),v)]\n",
    "                proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                subproj_len = len(proj) // ell\n",
    "                subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "                \n",
    "                if num_info_in_proj > 0:\n",
    "                    info_bits_present = True          \n",
    "                else:\n",
    "                    info_bits_present = False         \n",
    "                if d in polar_depths:\n",
    "                    info_bits_present = False\n",
    "\n",
    "                enc_chunks = []\n",
    "                ell = self.depth_map[d]\n",
    "                for j in range(ell):\n",
    "                    chunk = u[:, i + j*num_bits:i + (j+1)*num_bits].unsqueeze(2).clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[d](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        output = torch.cat([self.gnet_dict[d][bit_position](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(msg_bits.shape[0], -1, 1).squeeze(2)\n",
    "\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                u = torch.cat((u[:, :i], output, u[:, i + ell*num_bits:]), dim=1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(u)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def power_constraint(self, codewords):\n",
    "        return F.normalize(codewords, p=2, dim=1)*np.sqrt(self.N)\n",
    "\n",
    "    def encode_chunks_plotkin(self, enc_chunks, ell = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "\n",
    "        # to change for other kernels\n",
    "\n",
    "        if ell is None:\n",
    "            ell = self.ell\n",
    "        assert len(enc_chunks) == ell\n",
    "        chunk_size = enc_chunks[0].shape[1]\n",
    "        batch_size = enc_chunks[0].shape[0]\n",
    "\n",
    "        u = torch.cat(enc_chunks, 1).squeeze(2)\n",
    "        n = int(np.log2(ell))\n",
    "\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d * chunk_size\n",
    "            for i in np.arange(0, chunk_size*ell, 2*num_bits):\n",
    "                # [u v] encoded to [(u,v) xor v]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        return u\n",
    "            \n",
    "    def deeppolar_parallel_decode(self, noisy_code):\n",
    "        # Successive cancellation decoder for polar codes\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "        decoded_llrs  = self.KO_parallel_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "\n",
    "    def deeppolar_parallel_decode_depth(self, llrs, depth, bit_position, decoded_llrs):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        dec_chunks = torch.cat([llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "        Lu = self.fnet_dict[depth][bit_position](dec_chunks)\n",
    "\n",
    "        if depth == 1:\n",
    "            u = torch.tanh(Lu/2)\n",
    "            decoded_llrs[:, left_bit_position + unfrozen] = Lu.squeeze(1)\n",
    "        else:\n",
    "            for index, current_position in enumerate(unfrozen):\n",
    "                bit_position_offset = left_bit_position + current_position                \n",
    "                decoded_llrs = self.deeppolar_parallel_decode_depth(Lu[:, :, index:index+1], depth-1, bit_position_offset, decoded_llrs)\n",
    "\n",
    "        return decoded_llrs\n",
    "            \n",
    "    def deeppolar_decode(self, noisy_code):\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        \n",
    "        # don't want to go into useless frozen subtrees.\n",
    "        partial_sums = torch.ones(noisy_code.shape[0], self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "\n",
    "        decoded_llrs, partial_sums = self.deeppolar_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs, partial_sums)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "    \n",
    "    def deeppolar_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        # size of the projection of tht subtree\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        # This chunk - finds infrozen positions in this kernel.\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        if num_nonzero_subproj > 0:\n",
    "            info_bits_present = True      \n",
    "        else:\n",
    "            info_bits_present = False \n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "                \n",
    "        # This will be input to decoder\n",
    "        dec_chunks = [llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            if decoder_type == 'KO_last_parallel':\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                Lu = self.fnet_dict[depth][bit_position](concatenated_chunks)[:, 0, unfrozen]\n",
    "                u_hat = torch.tanh(Lu/2)\n",
    "                decoded_llrs[:, left_bit_position + unfrozen] = Lu\n",
    "                partial_sums[:, depth-1, left_bit_position + unfrozen] = u_hat\n",
    "\n",
    "            else:\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    if current_position > 0:\n",
    "                        # I am adding previously decoded bits . (either onehot or normal)\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "\n",
    "                    if bit_position_offset in self.frozen_positions: # frozen \n",
    "                        # don't update decoded llrs. It already has ones*prior.\n",
    "                        # actually don't need this. can skip.\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, depth-1, bit_position_offset])\n",
    "                    else: # information bit\n",
    "                        # This is the decoding.\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](concatenated_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "\n",
    "                        u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                        decoded_llrs[:, bit_position_offset] = Lu.squeeze(2).squeeze(1)\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = u_hat.squeeze(1)\n",
    "\n",
    "            # Encoding back the decoded bits - for higher layers.\n",
    "            # # Compute decoded codeword\n",
    "            i = left_bit_position * half_index\n",
    "            # num_bits = self.ell**(depth-1)\n",
    "            num_bits = 1\n",
    "\n",
    "            enc_chunks = []\n",
    "            for j in range(ell):\n",
    "                chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                enc_chunks.append(chunk)\n",
    "            if info_bits_present:\n",
    "                concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                if 'KO' in encoder_type:\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        # bit position of the previous depth.\n",
    "                        output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            else:\n",
    "                output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "            \n",
    "            return decoded_llrs, partial_sums\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "\n",
    "                if current_position in unfrozen:\n",
    "                    # General decoding ....\n",
    "                    # add the decoded bit here\n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](concatenated_chunks).squeeze(2)\n",
    "                    else:\n",
    "                        # if current_position == 0:\n",
    "                        #     Lu = self.fnet_dict[depth][bit_position][current_position](llrs)\n",
    "                        # else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "                    decoded_llrs, partial_sums = self.deeppolar_decode_depth(Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums)\n",
    "                else:\n",
    "                    Lu = self.infty*torch.ones_like(llrs)\n",
    "\n",
    "\n",
    "            # Compute decoded codeword\n",
    "            if depth < self.n_ell :\n",
    "                i = left_bit_position * half_index\n",
    "                # num_bits = self.ell**(depth-1)\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        else:\n",
    "                            # bit position of the previous depth.\n",
    "                            output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "\n",
    "                return decoded_llrs, partial_sums\n",
    "            else: # encoding not required for last level - we have already decoded all bits.\n",
    "                return decoded_llrs, partial_sums\n",
    "\n",
    "\n",
    "    def kernel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = [noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "\n",
    "        for current_position in range(ell):\n",
    "            if current_position > 0:\n",
    "                if onehot:\n",
    "                    prev_decoded = get_onehot(u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone().sign()).detach().clone()\n",
    "                else:\n",
    "                    prev_decoded = u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                dec_chunks.append(prev_decoded)\n",
    "            if current_position in info_positions:\n",
    "                if current_position in info_positions:\n",
    "                    concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                    Lu = fnet_dict[current_position](concatenated_chunks)\n",
    "                    decoded_llrs[:, current_position] = Lu.squeeze(2).squeeze(1)\n",
    "                    u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                    u[:, current_position] = u_hat.squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "\n",
    "    def kernel_parallel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = torch.cat([noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "\n",
    "        decoded_llrs = fnet_dict(dec_chunks).squeeze(1)\n",
    "        u = torch.tanh(decoded_llrs/2).squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "    \n",
    "\n",
    "    def deeppolar_list_decode(self, noisy_code, L, crc=None):\n",
    "        \"\"\"\n",
    "        List decoding implementation for DeepPolar with CRC checking\n",
    "        Args:\n",
    "            noisy_code: Input received codeword\n",
    "            L: List size\n",
    "            crc: CRC object for checking decoded messages\n",
    "        \"\"\"\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "        batch_size = noisy_code.shape[0]\n",
    "        depth = self.n_ell\n",
    "\n",
    "        # Initialize L copies of path metrics \n",
    "        PML = 1000*torch.ones(batch_size, L, device=noisy_code.device)\n",
    "        PML[:, 0] = 0\n",
    "\n",
    "        # Initialize L copies of LLRs and partial sums\n",
    "        decoded_llrs = self.infty * torch.ones(batch_size, L, self.N, device=noisy_code.device)\n",
    "        partial_sums = torch.ones(batch_size, L, self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # Expand noisy_code for L paths\n",
    "        noisy_code_expanded = noisy_code.unsqueeze(1).repeat(1, L, 1)\n",
    "\n",
    "        decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "            noisy_code_expanded.unsqueeze(3), depth, 0, decoded_llrs, partial_sums, PML, L)\n",
    "\n",
    "        # Extract information bits for all paths\n",
    "        info_llrs = decoded_llrs[:, :, self.info_positions]\n",
    "        decisions = torch.sign(info_llrs)\n",
    "\n",
    "        # Convert decoded bits to proper format for CRC checking\n",
    "        decoded_bits = ((1 - decisions) / 2).to(torch.int64)  # Convert from {-1,1} to {1,0}\n",
    "\n",
    "        if crc is not None:\n",
    "            # Check CRC for each path in the list\n",
    "            valid_paths = crc.check_batch(decoded_bits.view(-1, decoded_bits.shape[-1]))\n",
    "            valid_paths = valid_paths.view(batch_size, L)\n",
    "\n",
    "            # For each batch, find first valid path or use first path if none valid\n",
    "            selected_paths = torch.zeros(batch_size, dtype=torch.long, device=decoded_bits.device)\n",
    "            for b in range(batch_size):\n",
    "                valid_indices = torch.where(valid_paths[b])[0]\n",
    "                if len(valid_indices) > 0:\n",
    "                    # Use first valid path\n",
    "                    selected_paths[b] = valid_indices[0]\n",
    "                else:\n",
    "                    # If no valid paths, use path with best metric (index 0)\n",
    "                    selected_paths[b] = 0\n",
    "\n",
    "            # Gather selected paths\n",
    "            batch_indices = torch.arange(batch_size, device=decoded_bits.device)\n",
    "            final_decisions = decisions[batch_indices, selected_paths]\n",
    "        else:\n",
    "            # If no CRC, just return first path\n",
    "            final_decisions = decisions[:, 0]\n",
    "\n",
    "        return final_decisions, info_llrs, PML\n",
    "\n",
    "    def deeppolar_list_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums, PML, L):\n",
    "        \"\"\"\n",
    "        Recursive list decoding implementation for DeepPolar decoder\n",
    "        Args:\n",
    "            llrs: Input LLRs [batch_size, L, N, 1]\n",
    "            depth: Current depth in the decoding tree\n",
    "            bit_position: Current bit position\n",
    "            decoded_llrs: Running decoded LLRs [batch_size, L, N]\n",
    "            partial_sums: Running partial sums [batch_size, L, n_ell+1, N]\n",
    "            PML: Path metrics for each path [batch_size, L]\n",
    "        \"\"\"\n",
    "        batch_size = llrs.shape[0]\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] * bit_position\n",
    "\n",
    "        # Calculate projection information\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj: sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj: [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        info_bits_present = num_nonzero_subproj > 0\n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "\n",
    "        # Initialize decoder chunks\n",
    "        dec_chunks = [llrs[:, :, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        \n",
    "        if depth == 1:  # Base case\n",
    "            if decoder_type != 'KO_last_parallel':\n",
    "            \n",
    "                # Sequential decoding of each position\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    \n",
    "\n",
    "                    if current_position > 0:\n",
    "                        # Add previously decoded bits\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "                    \n",
    "                     \n",
    "                    \n",
    "                    if bit_position_offset in self.frozen_positions:\n",
    "                        # Handle frozen bits\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, :, depth-1, bit_position_offset])\n",
    "                        DM = decoded_llrs[:, :, bit_position_offset]\n",
    "                        # Update path metrics for frozen bits\n",
    "                        PML = PML + torch.abs(DM) * (DM < 0).float()\n",
    "\n",
    "                    else:  # Information bit case\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                        orig_shape = concatenated_chunks.shape\n",
    "                        reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "\n",
    "                        # Get decoder output\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](reshaped_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                        Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "\n",
    "                        # Store LLRs and get decisions\n",
    "                        decoded_llrs[:,:, bit_position_offset] = Lu.squeeze(3).squeeze(2)\n",
    "                        DM = Lu.squeeze(3).squeeze(2)\n",
    "                        dec = (DM < 0).float()\n",
    "                        dec = 1-2*dec\n",
    "\n",
    "                        # Compute path metrics for both decisions\n",
    "                        PM2 = torch.cat([PML, PML + torch.abs(DM)], dim=1)  # [batch_size, 2L]\n",
    "\n",
    "                        # Select best L paths\n",
    "                        PML, pos = torch.topk(PM2, L, dim=1, largest=False)  \n",
    "\n",
    "                        # Update decisions and states\n",
    "                        pos_dec = pos.clone()\n",
    "                        pos_dec[pos >= L] = pos_dec[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "                        dec = torch.gather(dec, 1, pos_dec)  # Gather decisions for selected paths\n",
    "                        dec = torch.where(pos >= L, -dec, dec)  # Flip decisions for paths from second half\n",
    "\n",
    "                        # Update states with gathered indices\n",
    "                        # First adjust pos for gathering from L-sized tensors\n",
    "                        pos_adj = pos.clone()\n",
    "                        pos_adj[pos >= L] = pos_adj[pos >= L] - L  # Map indices from L to 2L-1 back to 0 to L-1\n",
    "\n",
    "                        # For decoded_llrs\n",
    "                        pos_expand = pos_adj.unsqueeze(-1).expand(-1, -1, decoded_llrs.shape[-1])\n",
    "                        decoded_llrs = torch.gather(decoded_llrs, 1, pos_expand)\n",
    "\n",
    "                        # For partial_sums \n",
    "                        pos_expand_sums = pos_adj.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, partial_sums.shape[2], partial_sums.shape[3])\n",
    "                        partial_sums = torch.gather(partial_sums, 1, pos_expand_sums)\n",
    "\n",
    "\n",
    "                        # Store updated decisions\n",
    "                        partial_sums[:, :, depth-1, bit_position_offset] = dec\n",
    "\n",
    "                        \n",
    "                       \n",
    "                 \n",
    "\n",
    "            # Encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = 1\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        else:  # General case for deeper levels\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, :, depth-1, (current_position-1)*half_index:(current_position)*half_index].unsqueeze(3).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 3)\n",
    "                #print(concatenated_chunks.shape)\n",
    "                orig_shape = concatenated_chunks.shape\n",
    "                reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                if current_position in unfrozen:\n",
    "                    \n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](reshaped_chunks).squeeze(3)\n",
    "                    else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](reshaped_chunks)\n",
    "                    Lu = Lu.view(batch_size, L, *Lu.shape[1:])\n",
    "                    \n",
    "                    # Recursive call for each path\n",
    "                    decoded_llrs, partial_sums, PML = self.deeppolar_list_decode_depth(\n",
    "                        Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums, PML, L)\n",
    "                else:\n",
    "                    Lu = self.infty * torch.ones_like(llrs)\n",
    "\n",
    "            # Handle encoding for higher layers\n",
    "            if depth < self.n_ell:\n",
    "                i = left_bit_position * half_index\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, :, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(3).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 3)\n",
    "                    orig_shape = concatenated_chunks.shape\n",
    "                    reshaped_chunks = concatenated_chunks.view(batch_size * L, *orig_shape[2:])\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            temp = self.gnet_dict[depth](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        else:\n",
    "                            temp = self.gnet_dict[depth][bit_position](reshaped_chunks)\n",
    "                            temp = temp.view(batch_size, L, *temp.shape[1:])\n",
    "                            output = torch.cat([temp,\n",
    "                                             partial_sums[:, :, depth-1, i + (ell-1)*num_bits:i + ell*num_bits].unsqueeze(3)], dim=3)\n",
    "                            \n",
    "                        output = output.permute(0, 1, 3, 2).reshape(llrs.shape[0], L, -1, 1).squeeze(3)\n",
    "                        \n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "\n",
    "                partial_sums[:, :, depth, i:i + num_bits*ell] = output.clone()\n",
    "\n",
    "        return decoded_llrs, partial_sums, PML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e848578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen(N, K, rate_profile, target_K = None):\n",
    "    n = int(np.log2(N))\n",
    "    if rate_profile == 'polar':\n",
    "        # computed for SNR = 0\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "\n",
    "            # for RM :(\n",
    "            # rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 3, 5, 8, 4, 2, 1, 0])\n",
    "\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "        elif n<9:\n",
    "            rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "        else:\n",
    "            rs = np.array([1023, 1022, 1021, 1019, 1015, 1007, 1020,  991, 1018, 1017, 1014,\n",
    "       1006,  895, 1013, 1011,  959, 1005,  990, 1003,  989,  767, 1016,\n",
    "        999, 1012,  987,  958,  983,  957, 1010, 1004,  955, 1009,  894,\n",
    "        975,  893, 1002,  951, 1001,  988,  511,  766,  998,  891,  943,\n",
    "        986,  997,  985,  887,  956,  765,  995,  927,  982,  981,  879,\n",
    "        954,  974,  763,  953,  979,  510, 1008,  759,  863,  950,  892,\n",
    "       1000,  973,  949,  509,  890,  971,  996,  942,  751,  984,  889,\n",
    "        507,  947,  831,  886,  967,  941,  764,  926,  980,  994,  939,\n",
    "        885,  993,  735,  878,  925,  503,  762,  883,  978,  935,  703,\n",
    "        495,  952,  877,  761,  972,  923,  977,  948,  758,  862,  875,\n",
    "        919,  970,  757,  861,  508,  969,  750,  946,  479,  888,  639,\n",
    "        871,  911,  830,  940,  859,  755,  966,  945,  749,  506,  884,\n",
    "        938,  965,  829,  734,  924,  855,  505,  747,  963,  937,  882,\n",
    "        934,  827,  733,  447,  992,  847,  876,  501,  921,  702,  494,\n",
    "        881,  760,  743,  933,  502,  918,  874,  922,  823,  731,  499,\n",
    "        860,  756,  931,  701,  873,  493,  727,  917,  870,  976,  815,\n",
    "        910,  383,  968,  478,  858,  754,  699,  491,  869,  944,  748,\n",
    "        638,  915,  477,  719,  909,  964,  255,  799,  504,  857,  854,\n",
    "        753,  828,  746,  695,  487,  907,  637,  867,  853,  475,  936,\n",
    "        962,  446,  732,  826,  745,  846,  500,  825,  903,  687,  932,\n",
    "        635,  471,  445,  742,  880,  498,  730,  851,  822,  382,  920,\n",
    "        845,  741,  443,  700,  729,  631,  492,  872,  961,  726,  821,\n",
    "        930,  497,  381,  843,  463,  916,  739,  671,  623,  490,  929,\n",
    "        439,  814,  819,  868,  752,  914,  698,  725,  839,  856,  476,\n",
    "        813,  718,  908,  486,  723,  866,  489,  607,  431,  697,  379,\n",
    "        811,  798,  913,  575,  717,  254,  694,  636,  474,  807,  715,\n",
    "        906,  797,  693,  865,  960,  852,  744,  634,  473,  795,  905,\n",
    "        485,  415,  483,  470,  444,  375,  850,  740,  686,  902,  824,\n",
    "        691,  253,  711,  633,  844,  685,  630,  901,  367,  791,  928,\n",
    "        728,  820,  849,  783,  670,  899,  738,  842,  683,  247,  469,\n",
    "        441,  442,  462,  251,  737,  438,  467,  351,  629,  841,  724,\n",
    "        679,  669,  496,  461,  818,  380,  437,  627,  622,  459,  378,\n",
    "        239,  488,  667,  838,  430,  484,  812,  621,  319,  817,  435,\n",
    "        377,  696,  722,  912,  606,  810,  864,  716,  837,  721,  714,\n",
    "        809,  796,  455,  472,  619,  835,  692,  663,  223,  414,  904,\n",
    "        427,  806,  482,  632,  713,  690,  848,  605,  373,  252,  794,\n",
    "        429,  710,  684,  615,  805,  900,  655,  468,  366,  603,  413,\n",
    "        574,  481,  371,  250,  793,  466,  423,  374,  689,  628,  440,\n",
    "        365,  709,  789,  803,  411,  573,  682,  249,  460,  790,  668,\n",
    "        599,  350,  707,  246,  681,  465,  571,  626,  436,  407,  782,\n",
    "        191,  127,  363,  620,  666,  458,  245,  349,  677,  434,  678,\n",
    "        591,  787,  399,  457,  359,  238,  625,  840,  567,  736,  665,\n",
    "        428,  376,  781,  898,  618,  675,  318,  454,  662,  243,  897,\n",
    "        347,  836,  816,  720,  433,  604,  617,  779,  808,  661,  834,\n",
    "        712,  804,  833,  559,  237,  453,  426,  222,  317,  775,  372,\n",
    "        343,  412,  235,  543,  614,  451,  425,  422,  613,  370,  221,\n",
    "        315,  480,  335,  659,  654,  364,  190,  369,  248,  653,  688,\n",
    "        231,  410,  602,  611,  802,  792,  421,  651,  601,  598,  708,\n",
    "        311,  219,  572,  597,  788,  570,  409,  590,  362,  801,  680,\n",
    "        464,  406,  419,  348,  647,  786,  215,  589,  706,  361,  676,\n",
    "        566,  189,  595,  244,  569,  303,  405,  358,  456,  346,  398,\n",
    "        565,  242,  126,  705,  780,  587,  624,  664,  236,  187,  357,\n",
    "        432,  785,  558,  674,  207,  403,  397,  452,  345,  563,  778,\n",
    "        241,  316,  342,  616,  660,  557,  125,  234,  183,  287,  355,\n",
    "        583,  673,  395,  424,  314,  220,  777,  341,  612,  658,  123,\n",
    "        175,  774,  555,  233,  334,  542,  450,  313,  391,  230,  652,\n",
    "        368,  218,  339,  600,  119,  333,  657,  610,  773,  541,  310,\n",
    "        420,  159,  229,  650,  551,  596,  609,  408,  217,  449,  188,\n",
    "        309,  214,  331,  111,  539,  360,  771,  649,  302,  418,  594,\n",
    "        896,  227,  404,  646,  186,  588,  832,  568,  213,  417,  301,\n",
    "        307,  356,  402,  800,  564,  327,   95,  206,  240,  535,  593,\n",
    "        645,  586,  344,  396,  185,  401,  211,  354,  299,  585,  286,\n",
    "        562,  643,  182,  205,  124,  232,  285,  295,  181,  556,  582,\n",
    "        527,  394,  340,   63,  203,  561,  353,  448,  122,  283,  393,\n",
    "        581,  554,  174,  390,  704,  312,  338,  228,  179,  784,  199,\n",
    "        553,  121,  173,  389,  540,  579,  332,  118,  672,  550,  337,\n",
    "        158,  279,  271,  416,  216,  308,  387,  538,  549,  226,  330,\n",
    "        776,  171,  212,  117,  110,  329,  656,  157,  772,  306,  326,\n",
    "        225,  167,  115,  537,  534,  184,  109,  300,  547,  305,  210,\n",
    "        155,  533,  325,  352,  608,  400,  298,  204,   94,  648,  284,\n",
    "        209,  151,  180,  107,  770,  297,  392,  323,  592,  202,  644,\n",
    "         93,  294,  178,  103,  143,  282,   62,  336,  201,  120,  172,\n",
    "        198,  769,  584,   91,  388,  293,  177,  526,  278,  281,  642,\n",
    "        525,  531,   61,  170,  116,  197,   87,  156,  277,  114,  560,\n",
    "        169,   59,  291,  580,  275,  523,  641,  270,  195,  552,  519,\n",
    "        166,  224,  578,  108,  269,   79,  154,  113,  548,  577,  536,\n",
    "        328,   55,  106,  165,  153,  150,  386,  208,  324,  546,  385,\n",
    "        267,   47,   92,  163,  296,  304,  105,  102,  149,  263,  532,\n",
    "        322,  292,  545,   90,  200,   31,  321,  530,  142,  176,  147,\n",
    "        101,  141,  196,  524,  529,  290,   89,  280,   60,   86,   99,\n",
    "        139,  168,   58,  522,  276,   85,  194,  289,   78,  135,  112,\n",
    "        521,   57,   83,   54,  518,  274,  268,  768,  164,   77,  152,\n",
    "        193,   53,  162,  104,  517,  273,  266,   75,   46,  148,   51,\n",
    "        640,  100,   45,  576,  161,  265,  262,   71,  146,   30,  140,\n",
    "         88,  515,   98,   43,   29,  261,  145,  138,   84,  259,   39,\n",
    "         97,   27,   56,   82,  137,   76,  384,  134,   23,   52,  133,\n",
    "        320,   15,   73,   50,   81,  131,   44,   70,  544,  192,  528,\n",
    "        288,  520,  160,  272,   74,   49,  516,   42,   69,   28,  144,\n",
    "         41,   67,   96,  514,   38,  264,  260,  136,   22,   25,   37,\n",
    "         80,  513,   26,  258,   35,  132,   21,  257,   72,   14,   48,\n",
    "         13,   19,  130,   68,   40,   11,  512,   66,  129,    7,   36,\n",
    "         24,   34,  256,   20,   65,   33,   12,  128,   18,   10,   17,\n",
    "          6,    9,   64,    5,    3,   32,   16,    8,    4,    2,    1,\n",
    "          0])\n",
    "        rs = rs[rs<N]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'RM':\n",
    "        rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        Fr = np.argsort(rmweight)[:-K]\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted_last':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds[::-1]\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'rev_polar':\n",
    "\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:target_K].copy()\n",
    "        rs[:target_K] = first_inds[::-1]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    return Fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(codebook):\n",
    "    \"\"\"Calculate pairwise distances between codewords\"\"\"\n",
    "    dists = []\n",
    "    for row1, row2 in combinations(codebook, 2):\n",
    "        distance = (row1-row2).pow(2).sum()\n",
    "        dists.append(np.sqrt(distance.item()))\n",
    "    return dists, np.min(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54073b6",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2a9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_original_path):\n",
    "    plt.figure()\n",
    "    plt.plot(bers_enc, label='BER')\n",
    "    plt.plot(moving_average(bers_enc, n=10), label='BER moving avg')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Training BER ENC')\n",
    "    plt.savefig(os.path.join(results_save_original_path, 'training_ber_enc.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Similar plots for losses_enc, bers_dec, losses_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96d3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save models\n",
    "def save_model(polar, iter, results_save_original_path, best=False):\n",
    "    torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map], \n",
    "               os.path.join(results_save_original_path, f'Models/fnet_gnet_{iter}.pt'))\n",
    "    if iter > 1:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt'))\n",
    "    if best:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_original_path, 'Models/fnet_gnet_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e6cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        # Convert to binary if needed\n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        # Initialize result tensor\n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        \n",
    "        # Prepare dividend for all batches at once\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        \n",
    "        # Perform batch polynomial division\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        \n",
    "        # Combine message and remainder\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        # Convert back to float if needed\n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "            \n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        \"\"\"Check if received messages pass CRC in batch.\"\"\"\n",
    "        # Convert to binary if needed\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "            \n",
    "        # Perform polynomial division on all messages at once\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        \n",
    "        # Check if all remainder bits are zero for each message\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    \n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        \"\"\"Perform polynomial division in batch using vectorized operations.\"\"\"\n",
    "        # Make copy to avoid modifying input\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        # Find positions of 1s for all batches\n",
    "        for i in range(n - self.degree):\n",
    "            # Find batches where current bit is 1\n",
    "            active_batches = result[:, i] == 1\n",
    "            \n",
    "            if torch.any(active_batches):\n",
    "                # XOR with polynomial for active batches\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        \n",
    "        # Return last degree bits (remainder) for all batches\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b167a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crc = CRC(crc_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4986216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n"
     ]
    }
   ],
   "source": [
    "if anomaly:\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "#ID = str(np.random.randint(100000, 999999)) if id is None else id\n",
    "#ID = 207515\n",
    "\n",
    "\n",
    "###############\n",
    "### Polar code\n",
    "##############\n",
    "\n",
    "### Encoder\n",
    "\n",
    "if last_ell is not None:\n",
    "    depth_map = defaultdict(int)\n",
    "    n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "    for d in range(1, n+1):\n",
    "        depth_map[d] = kernel_size\n",
    "    depth_map[n+1] = last_ell\n",
    "    assert np.prod(list(depth_map.values())) == N\n",
    "    polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "else:\n",
    "    polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "info_inds = polar.info_positions\n",
    "frozen_inds = polar.frozen_positions\n",
    "\n",
    "print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "##############\n",
    "### Neural networks\n",
    "##############\n",
    "ell = kernel_size\n",
    "if N == ell: # Kernel pre-training\n",
    "    polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "elif N > ell: # Initialize full network with pretrained kernels\n",
    "    polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "if binary:\n",
    "    load_path = os.path.join(results_save_original_path, 'Models/fnet_gnet_final.pt')\n",
    "    assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "    results_save_original_path = os.path.join(results_save_original_path, 'Binary')\n",
    "    os.makedirs(results_save_original_path, exist_ok=True)\n",
    "    os.makedirs(results_save_original_path +'/Models', exist_ok=True)\n",
    "\n",
    "if load_path is not None:\n",
    "    if test:\n",
    "        if test_load_path is None:\n",
    "            print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "    else:\n",
    "        checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "        fnet_dict = checkpoint1[0]\n",
    "        gnet_dict = checkpoint1[1]\n",
    "\n",
    "        polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "        print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "if 'KO' in decoder_type:\n",
    "    dec_params = []\n",
    "    for i in polar.fnet_dict.keys():\n",
    "        for j in polar.fnet_dict[i].keys():\n",
    "            if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                for k in polar.fnet_dict[i][j].keys():\n",
    "                    dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "            else:\n",
    "                dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "elif decoder_type == 'RNN':\n",
    "    dec_params = polar.fnet_dict.parameters()\n",
    "else:\n",
    "    dec_train_iters = 0\n",
    "\n",
    "if 'KO' in encoder_type:\n",
    "    enc_params = []\n",
    "    if shared:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            enc_params += list(polar.gnet_dict[i].parameters())\n",
    "    else:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            for j in polar.gnet_dict[i].keys():\n",
    "                enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "elif encoder_type == 'scaled':\n",
    "    enc_params = [polar.a]\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "else:\n",
    "    enc_train_iters = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'BCE' in loss_type:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'L1':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_type == 'huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "info_positions = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d5c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053eafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__0.0_Encoder_KO_-2.0_Decoder/epochs_500_batchsize_20000'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_save_original_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e6b672b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "Checkpoint Loaded\n",
      "NN weights loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "times = []\n",
    "results_load_path = results_save_original_path\n",
    "\n",
    "\n",
    "\n",
    "checkpoint1 = torch.load(results_load_path +'/Models/fnet_gnet_final.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "fnet_dict = checkpoint1[0]\n",
    "gnet_dict = checkpoint1[1]\n",
    "print('Checkpoint Loaded')\n",
    "\n",
    "polar.load_nns(fnet_dict, gnet_dict, shared = shared)\n",
    "\n",
    "if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "    snr_range = [test_snr_start]\n",
    "else:\n",
    "    snrs_interval = (test_snr_end - test_snr_start)* 1.0 /  (snr_points-1)\n",
    "    snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# For polar code testing.\n",
    "\n",
    "ell = 2\n",
    "Frozen = get_frozen(N, K, rate_profile)\n",
    "Frozen.sort()\n",
    "polar_l_2 = PolarCode(int(np.log2(N)), K, Fr=Frozen, infty = infty, hard_decision=hard_decision)\n",
    "\n",
    "\n",
    "if pairwise:\n",
    "    codebook_size = 1000\n",
    "    all_msg_bits = 2 * (torch.rand(codebook_size, K, device = device) < 0.5).float() - 1\n",
    "    deeppolar_codebook = polar.deeppolar_encode(all_msg_bits)\n",
    "    polar_codebook = polar_l_2.encode_plotkin(all_msg_bits)\n",
    "    gaussian_codebook = F.normalize(torch.randn(codebook_size, N), p=2, dim=1)*np.sqrt(N)\n",
    "\n",
    "    from scipy import stats\n",
    "    w_statistic_deeppolar, p_value_deeppolar = stats.shapiro(deeppolar_codebook.detach().cpu().numpy())\n",
    "    w_statistic_gaussian, p_value_gaussian = stats.shapiro(gaussian_codebook.detach().cpu().numpy())\n",
    "    w_statistic_polar, p_value_polar = stats.shapiro(polar_codebook.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Deeppolar Shapiro test W = {w_statistic_deeppolar}, p-value = {p_value_deeppolar}\")\n",
    "    print(f\"Gaussian Shapiro test W = {w_statistic_gaussian}, p-value = {p_value_gaussian}\")\n",
    "    print(f\"Polar Shapiro test W = {w_statistic_polar}, p-value = {p_value_polar}\")\n",
    "\n",
    "    dists_deeppolar, md_deeppolar = pairwise_distances(deeppolar_codebook)\n",
    "    dists_polar, md_polar = pairwise_distances(polar_codebook)\n",
    "    dists_gaussian, md_gaussian = pairwise_distances(gaussian_codebook)\n",
    "\n",
    "    # Function to calculate and plot PDF\n",
    "    def plot_pdf(data, label, bins=30, alpha=0.5, color=None, linewidth=1.0):\n",
    "        counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, counts, label=label, alpha=alpha, \n",
    "                 color=color, linewidth=linewidth)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Larger figure size\n",
    "\n",
    "    # Define better colors\n",
    "    colors = ['#e74c3c', '#3498db']  # Red and Blue\n",
    "    linewidth = 2.5\n",
    "\n",
    "    # Plot with enhanced styling\n",
    "    plot_pdf(dists_deeppolar, 'DeepPolar', bins=300, color=colors[0], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "    plot_pdf(dists_gaussian, 'Gaussian', bins=300, color=colors[1], \n",
    "             linewidth=linewidth, alpha=0.8)\n",
    "\n",
    "    # Enhance grid - both major and minor\n",
    "    plt.grid(True, which='major', linestyle='-', alpha=0.5)\n",
    "    plt.grid(True, which='minor', linestyle=':', alpha=0.3)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    # Enhance labels and title\n",
    "    plt.xlabel('Pairwise Distance', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Probability Density', fontsize=16, fontweight='bold')\n",
    "    #plt.title(f'Pairwise Distances Distribution (N={N}, K={K})', \n",
    "    #          fontsize=16, fontweight='bold', pad=15)\n",
    "\n",
    "    # Enhance legend\n",
    "    plt.legend(fontsize=16, frameon=True, fancybox=True, \n",
    "              shadow=True, loc='upper left')\n",
    "\n",
    "    # Enhance ticks\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save with high DPI for better quality\n",
    "    plt.savefig(os.path.join(results_save_original_path, f\"hists_N{N}_K{K}_{id}_2.pdf\"), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(f'dists_deeppolar: {dists_deeppolar}')\n",
    "    print(f'dists_gaussian: {dists_gaussian}')\n",
    "if epos:\n",
    "    from collections import OrderedDict, Counter\n",
    "\n",
    "    def get_epos(k1, k2):\n",
    "        # return counter for bit ocations of first-errors\n",
    "        bb = torch.ne(k1.cpu().sign(), k2.cpu().sign())\n",
    "        # inds = torch.nonzero(bb)[:, 1].numpy()\n",
    "        idx = []\n",
    "        for ii in range(bb.shape[0]):\n",
    "            try:\n",
    "                iii = list(bb.cpu().float().numpy()[ii]).index(1)\n",
    "                idx.append(iii)\n",
    "            except:\n",
    "                pass\n",
    "        counter = Counter(idx)\n",
    "        ordered_counter = OrderedDict(sorted(counter.items()))\n",
    "        return ordered_counter\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (k, msg_bits) in enumerate(Test_Data_Generator):\n",
    "            msg_bits = msg_bits.to(device)\n",
    "            polar_code = polar_l_2.encode_plotkin(msg_bits)\n",
    "            noisy_code = polar.channel(polar_code, dec_train_snr)\n",
    "            noise = noisy_code - polar_code\n",
    "            deeppolar_code = polar.deeppolar_encode(msg_bits)\n",
    "            noisy_deeppolar_code = deeppolar_code + noise\n",
    "            SC_llrs, decoded_SC_msg_bits = polar_l_2.sc_decode_new(noisy_code, dec_train_snr)\n",
    "            deeppolar_llrs, decoded_deeppolar_msg_bits = polar.deeppolar_decode(noisy_deeppolar_code)\n",
    "\n",
    "            if k == 0:\n",
    "                epos_deeppolar = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "            else:\n",
    "                epos_deeppolar1 = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC1 = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "                epos_deeppolar = epos_deeppolar + epos_deeppolar1\n",
    "                epos_SC = epos_SC + epos_SC1\n",
    "\n",
    "        print(f\"epos_deeppolar: {epos_deeppolar}\")\n",
    "        print(f\"EPOS_SC: {epos_SC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ada1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeppolar_example_test(polar, KO, snr_range, device, info_positions, binary=False, num_examples=10**6, noise_type='awgn', L=8, crc=crc):\n",
    "    bers_KO_test = [0. for _ in snr_range]\n",
    "    blers_KO_test = [0. for _ in snr_range]\n",
    "    bers_SC_test = [0. for _ in snr_range]\n",
    "    blers_SC_test = [0. for _ in snr_range]\n",
    "\n",
    "    kernel = N == KO.ell\n",
    "    num_batches = num_examples // test_batch_size\n",
    "\n",
    "    print(f\"TESTING for {num_examples} examples ({num_batches} batches)\")\n",
    "    for snr_ind, snr in enumerate(snr_range):\n",
    "        total_block_errors_SC = 0\n",
    "        total_block_errors_KO = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        sigma = snr_db2sigma(snr)\n",
    "\n",
    "        try:\n",
    "            for _ in range(num_batches):\n",
    "                msg_bits = 2 * (torch.rand(test_batch_size, K-crc_len) < 0.5).float() - 1\n",
    "                msg_bits = msg_bits.to(device)\n",
    "                \n",
    "                msg_bits_with_crc = crc.encode(msg_bits)\n",
    "                \n",
    "                polar_code = polar.encode_plotkin(msg_bits_with_crc)\n",
    "\n",
    "                if 'KO' in encoder_type:\n",
    "                    if kernel:\n",
    "                        KO_polar_code = KO.kernel_encode(kernel_size, KO.gnet_dict[1][0], msg_bits_with_crc, info_positions, binary=binary)\n",
    "                    else:\n",
    "                        KO_polar_code = KO.deeppolar_encode(msg_bits_with_crc, binary=binary)\n",
    "\n",
    "                noisy_code = polar.channel(polar_code, snr, noise_type)\n",
    "                \n",
    "                noisy_KO_code = polar.channel(KO_polar_code, snr, noise_type) if 'KO' in encoder_type else noisy_code\n",
    "\n",
    "                SC_llrs, decoded_SC_msg_bits_with_crc = polar.sc_decode_new(noisy_code, snr)\n",
    "                decoded_SC_msg_bits = decoded_SC_msg_bits_with_crc[:,:K-crc_len]\n",
    "                ber_SC = errors_ber(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                bler_SC = errors_bler(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                total_block_errors_SC += int(bler_SC*test_batch_size)\n",
    "\n",
    "                \n",
    "                final_decisions, info_llrs, PML = KO.deeppolar_list_decode(noisy_KO_code, L, crc)\n",
    "                decoded_KO_msg_bits = final_decisions[:,:K-crc_len]\n",
    "                ber_KO = errors_ber(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                bler_KO = errors_bler(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                total_block_errors_KO += int(bler_KO*test_batch_size)\n",
    "\n",
    "                batches_processed += 1\n",
    "\n",
    "                # Update accumulative results\n",
    "                bers_KO_test[snr_ind] += ber_KO\n",
    "                bers_SC_test[snr_ind] += ber_SC\n",
    "                blers_KO_test[snr_ind] += bler_KO\n",
    "                blers_SC_test[snr_ind] += bler_SC\n",
    "\n",
    "                # Progress logging\n",
    "                if batches_processed % 10 == 0:  # Print every 10 batches\n",
    "                    print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, Progress: {batches_processed}/{num_batches} batches\", end='\\r')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        # Normalize by actual number of batches processed\n",
    "        bers_KO_test[snr_ind] /= batches_processed\n",
    "        bers_SC_test[snr_ind] /= batches_processed\n",
    "        blers_KO_test[snr_ind] /= batches_processed\n",
    "        blers_SC_test[snr_ind] /= batches_processed\n",
    "\n",
    "        print(f\"\\nSNR: {snr} dB, Sigma: {sigma:.5f}\")\n",
    "        print(f\"SC   - BER: {bers_SC_test[snr_ind]:.6f}, BLER: {blers_SC_test[snr_ind]:.6f}\")\n",
    "        print(f\"Deep - BER: {bers_KO_test[snr_ind]:.6f}, BLER: {blers_KO_test[snr_ind]:.6f}\")\n",
    "\n",
    "    return bers_SC_test, blers_SC_test, bers_KO_test, blers_KO_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "645cc944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "TESTING for 1000000 examples (2000 batches)\n",
      "SNR: -5.0 dB, Sigma: 1.77828, Progress: 2000/2000 batches\n",
      "SNR: -5.0 dB, Sigma: 1.77828\n",
      "SC   - BER: 0.161110, BLER: 0.434036\n",
      "Deep - BER: 0.118601, BLER: 0.454853\n",
      "SNR: -4.0 dB, Sigma: 1.58489, Progress: 2000/2000 batches\n",
      "SNR: -4.0 dB, Sigma: 1.58489\n",
      "SC   - BER: 0.069797, BLER: 0.195558\n",
      "Deep - BER: 0.041268, BLER: 0.186768\n",
      "SNR: -3.0 dB, Sigma: 1.41254, Progress: 2000/2000 batches\n",
      "SNR: -3.0 dB, Sigma: 1.41254\n",
      "SC   - BER: 0.019350, BLER: 0.055623\n",
      "Deep - BER: 0.008190, BLER: 0.045038\n",
      "SNR: -2.0 dB, Sigma: 1.25893, Progress: 2000/2000 batches\n",
      "SNR: -2.0 dB, Sigma: 1.25893\n",
      "SC   - BER: 0.002992, BLER: 0.008726\n",
      "Deep - BER: 0.000885, BLER: 0.006395\n",
      "SNR: -1.0 dB, Sigma: 1.12202, Progress: 2000/2000 batches\n",
      "SNR: -1.0 dB, Sigma: 1.12202\n",
      "SC   - BER: 0.000200, BLER: 0.000580\n",
      "Deep - BER: 0.000047, BLER: 0.000504\n",
      "Test SNRs : [-5.0, -4.0, -3.0, -2.0, -1.0]\n",
      "\n",
      "Test Sigmas : [1.7782794100389228, 1.5848931924611136, 1.4125375446227544, 1.2589254117941673, 1.1220184543019633]\n",
      "\n",
      "BERs of DeepPolar: [0.11860144818201661, 0.04126782758627087, 0.008189965524245054, 0.0008853103495748655, 4.706896684365347e-05]\n",
      "BERs of SC decoding: [0.16111044804751873, 0.06979713788814843, 0.0193504482768476, 0.0029916206913294446, 0.00019989655319659506]\n",
      "BLERs of DeepPolar: [0.4548530000000021, 0.1867680000000004, 0.045038000000000085, 0.006394999999999914, 0.0005040000000000003]\n",
      "BLERs of SC decoding: [0.43403600000000064, 0.19555800000000023, 0.05562300000000029, 0.008725999999999906, 0.0005800000000000004]\n",
      "time = 709.7362108747164 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "\n",
    "start = time.time()\n",
    "bers_SC_test, blers_SC_test, bers_deeppolar_test, blers_deeppolar_test = deeppolar_example_test(polar_l_2, polar, snr_range, device, info_positions, binary = binary, num_examples=10**6, noise_type = noise_type, L=L, crc=crc)\n",
    "print(\"Test SNRs : {}\\n\".format(snr_range))\n",
    "print(f\"Test Sigmas : {[snr_db2sigma(s) for s in snr_range]}\\n\")\n",
    "print(\"BERs of DeepPolar: {0}\".format(bers_deeppolar_test))\n",
    "print(\"BERs of SC decoding: {0}\".format(bers_SC_test))\n",
    "print(\"BLERs of DeepPolar: {0}\".format(blers_deeppolar_test))\n",
    "print(\"BLERs of SC decoding: {0}\".format(blers_SC_test))\n",
    "print(f\"time = {(time.time() - start)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f42683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BER\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "ok = 0\n",
    "plt.semilogy(snr_range, bers_deeppolar_test, label=\"DeepPolar SC List\", marker='*', linewidth=1.5)\n",
    "\n",
    "plt.semilogy(snr_range, bers_SC_test, label=\"SC decoder\", marker='^', linewidth=1.5)\n",
    "\n",
    "## BLER\n",
    "plt.semilogy(snr_range, blers_deeppolar_test, label=\"DeepPolar SC List BLER)\", marker='*', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.semilogy(snr_range, blers_SC_test, label=\"SC decoder (BLER)\", marker='^', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=16)\n",
    "plt.ylabel(\"Error Rate\", fontsize=16)\n",
    "\n",
    "plt.legend(prop={'size': 15})\n",
    "if test_load_path is not None:\n",
    "    os.makedirs('Polar_Results/figures', exist_ok=True)\n",
    "    fig_save_path = results_save_path + 'Polar_Results/figures/SCListDeepPolar.pdf'\n",
    "else:\n",
    "    fig_save_path = results_save_path + f\"/SCList_Step{model_iters if model_iters is not None else 'final'}{'_binary' if binary else ''}.pdf\"\n",
    "if not no_fig:\n",
    "    plt.savefig(fig_save_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
