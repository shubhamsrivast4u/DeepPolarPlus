{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8752b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc45a",
   "metadata": {},
   "source": [
    "# Configuration variables (previously args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b957ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # Block length\n",
    "K = 37   # Message size\n",
    "kernel_size = 16  # Kernel size (ell)\n",
    "rate_profile = 'polar'  # Rate profiling; choices=['RM', 'polar', 'sorted', 'last', 'rev_polar', 'custom']\n",
    "infty = 1000.  # Infinity value for frozen position LLR in polar dec\n",
    "lse = 'minsum'  # LSE function; choices=['minsum', 'lse']\n",
    "hard_decision = False  # Polar code sc decoding hard decision?\n",
    "\n",
    "# DeepPolar parameters\n",
    "encoder_type = 'KO'  # Type of encoding; choices=['KO', 'scaled', 'polar']\n",
    "decoder_type = 'KO'  # Type of decoding; choices=['KO', 'SC', 'KO_parallel', 'KO_last_parallel']\n",
    "enc_activation = 'selu'  # Activation function\n",
    "dec_activation = 'selu'  # Activation function\n",
    "dropout_p = 0.\n",
    "dec_hidden_size = 128  # Neural network size\n",
    "enc_hidden_size = 64   # Neural network size\n",
    "f_depth = 3  # Decoder neural network depth\n",
    "g_depth = 3  # Encoder neural network depth\n",
    "g_skip_depth = 1  # Encoder neural network skip depth\n",
    "g_skip_layer = 1  # Encoder neural network skip layer\n",
    "onehot = False  # Use onehot representation of prev_decoded_bits\n",
    "shared = False  # Share weights across depth\n",
    "use_skip = True  # Use skip connections\n",
    "use_norm = False  # Use normalization\n",
    "binary = False  # Use binary quantization\n",
    "\n",
    "# Infrastructure parameters\n",
    "id = None  # Optional ID for multiple runs\n",
    "test = False  # Testing mode flag\n",
    "pairwise = True  # Plot codeword pairwise distances\n",
    "epos = False  # Plot error positions\n",
    "seed = None  # Random seed\n",
    "anomaly = False  # Enable anomaly detection\n",
    "dataparallel = False  # Use dataparallel\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture parameters\n",
    "polar_depths = []  # List of depths to use polar encoding/decoding\n",
    "last_ell = None  # Use kernel last_ell last layer\n",
    "\n",
    "\n",
    "# Channel parameters\n",
    "radar_power = None  # Radar power parameter\n",
    "radar_prob = 0.1  # Radar probability parameter\n",
    "\n",
    "# Training parameters\n",
    "full_iters = 300  # Full iterations\n",
    "enc_train_iters = 30  # Encoder iterations\n",
    "dec_train_iters = 300  # Decoder iterations\n",
    "enc_train_snr = 0.  # SNR at which encoder is trained\n",
    "dec_train_snr = -2.  # SNR at which decoder is trained\n",
    "weight_decay = 0.0\n",
    "dec_lr = 0.0005  # Decoder Learning rate\n",
    "enc_lr = 0.0005  # Encoder Learning rate\n",
    "batch_size = 20000  # Size of batches\n",
    "small_batch_size = 5000  # Size of small batches\n",
    "noise_type = 'awgn'  # Noise type; choices=['fading', 'awgn', 'radar']\n",
    "regularizer = None  # Regularizer type; choices=['std', 'max_deviation','polar']\n",
    "regularizer_weight = 0.001\n",
    "loss_type = 'BCE' # loss function; choices=['MSE', 'BCE', 'BCE_reg', 'L1', 'huber', 'focal', 'BCE_bler']\n",
    "initialization = 'random'  # Initialization type; choices=['random', 'zeros']\n",
    "optim_name = 'Adam'  # Optimizer type; choices=['Adam', 'RMS', 'SGD', 'AdamW']\n",
    "\n",
    "# Testing parameters\n",
    "test_batch_size = 500  # Size of test batches\n",
    "num_errors = 100  # Test until _ block errors\n",
    "test_snr_start = -5.  # Testing SNR start\n",
    "test_snr_end = -1.   # Testing SNR end\n",
    "snr_points = 5       # Testing SNR num points\n",
    "\n",
    "\n",
    "\n",
    "# Model saving/loading parameters\n",
    "model_save_per = 100  # Model save frequency\n",
    "model_iters = None  # Option to load specific model iteration\n",
    "test_load_path = None  # Path to load test model\n",
    "\n",
    "load_path = None  # Load path \n",
    "kernel_load_path = 'Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new'   # Kernel load path\n",
    "no_fig = False  # Plot figure option\n",
    "\n",
    "\n",
    "# Scheduler parameters\n",
    "scheduler = 'cosine' # choices = ['reduce', '1cycle', 'cosine']\n",
    "scheduler_patience = None  # Scheduler patience\n",
    "batch_schedule = False  # Use batch scheduler\n",
    "batch_patience = 50  # Batch scheduler patience \n",
    "batch_factor = 2  # Batch multiplication factor\n",
    "min_batch_size = 500  # Minimum batch size\n",
    "max_batch_size = 50000  # Maximum batch size\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117821f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1dc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the CRC parameters and models to load\n",
    "crc_polynomial = [1, 0, 1, 1] # Example CRC-3 polynomial\n",
    "\n",
    "msg_len = 34  # Original message length (37-3 for CRC bits)\n",
    "\n",
    "# Define SNR points where models were trained\n",
    "trained_snrs = [(0., -2.),(-1., -3.),(-3.,-5.),(1.,-1.),(-2.,-4.)]  # (enc_snr, dec_snr) pairs\n",
    "default_snr = (0.,-2.)  # Default model to use if no CRC check passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da887ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = f\"DeepPolar_Results/snrlist_attention_Polar_{kernel_size}({N},{K})/tsnr{trained_snrs}_dsnr_{default_snr}_crc_{crc_polynomial}_Scheme_{rate_profile}/{encoder_type}_Encoder_{decoder_type}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0c3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path +'/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e521",
   "metadata": {},
   "source": [
    "# Part 1: Core Utilities and Model Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_db2sigma(train_snr):\n",
    "    return 10**(-train_snr*1.0/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a23a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2bb73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a smoother version using product of bit probabilities\n",
    "def soft_bler_loss(logits, targets):\n",
    "    bit_probs = torch.sigmoid(logits)  # For correct bits\n",
    "    bit_probs = torch.where(targets == 1., bit_probs, 1 - bit_probs)\n",
    "    block_probs = torch.prod(bit_probs, dim=1)  # Probability of whole block being correct\n",
    "    return -torch.mean(torch.log(block_probs + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b989d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_ber(y_true, y_pred, mask=None):\n",
    "    if mask == None:\n",
    "        mask=torch.ones(y_true.size(),device=y_true.device)\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "    mask = mask.view(mask.shape[0], -1, 1)\n",
    "    myOtherTensor = (mask*torch.ne(torch.round(y_true), torch.round(y_pred))).float()\n",
    "    res = sum(sum(myOtherTensor))/(torch.sum(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_bler(y_true, y_pred, get_pos = False):\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "\n",
    "    decoded_bits = torch.round(y_pred).cpu()\n",
    "    X_test = torch.round(y_true).cpu()\n",
    "    tp0 = (abs(decoded_bits-X_test)).view([X_test.shape[0],X_test.shape[1]])\n",
    "    tp0 = tp0.detach().cpu().numpy()\n",
    "    bler_err_rate = sum(np.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
    "\n",
    "    if not get_pos:\n",
    "        return bler_err_rate\n",
    "    else:\n",
    "        err_pos = list(np.nonzero((np.sum(tp0,axis=1)>0).astype(int))[0])\n",
    "        return bler_err_rate, err_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92df8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_signal(input_signal, sigma = 1.0, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 0.05):\n",
    "    data_shape = input_signal.shape\n",
    "    device = input_signal.device\n",
    "    if noise_type == 'awgn':\n",
    "        dist = torch.distributions.Normal(torch.tensor([0.0], device=device), torch.tensor([sigma], device=device))\n",
    "        noise = dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 'fading':\n",
    "        fading_h = torch.sqrt(torch.randn_like(input_signal)**2 + torch.randn_like(input_signal)**2)/np.sqrt(3.14/2.0)\n",
    "        noise = sigma * torch.randn_like(input_signal)\n",
    "        corrupted_signal = fading_h *(input_signal) + noise\n",
    "\n",
    "    elif noise_type == 'radar':\n",
    "        add_pos = np.random.choice([0.0, 1.0], data_shape, p=[1 - radar_prob, radar_prob])\n",
    "        corrupted_signal = radar_power* np.random.standard_normal(size=data_shape) * add_pos\n",
    "        noise = sigma * torch.randn_like(input_signal) +\\\n",
    "                    torch.from_numpy(corrupted_signal).float().to(input_signal.device)\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 't-dist':\n",
    "        dist = torch.distributions.StudentT(torch.tensor([vv], device=device))\n",
    "        noise = sigma* dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    return corrupted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e97bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp(x, y):\n",
    "    log_sum_ms = torch.min(torch.abs(x), torch.abs(y))*torch.sign(x)*torch.sign(y)\n",
    "    return log_sum_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5937279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp_4(x_1, x_2, x_3, x_4):\n",
    "    return min_sum_log_sum_exp(min_sum_log_sum_exp(x_1, x_2), min_sum_log_sum_exp(x_3, x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c239bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, y):\n",
    "    def log_sum_exp_(LLR_vector):\n",
    "        sum_vector = LLR_vector.sum(dim=1, keepdim=True)\n",
    "        sum_concat = torch.cat([sum_vector, torch.zeros_like(sum_vector)], dim=1)\n",
    "        return torch.logsumexp(sum_concat, dim=1)- torch.logsumexp(LLR_vector, dim=1) \n",
    "\n",
    "    Lv = log_sum_exp_(torch.cat([x.unsqueeze(2), y.unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "    return Lv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655fe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bitarray(in_number, bit_width):\n",
    "    binary_string = bin(in_number)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(bit_width, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[bit_width-i-1] = int(binary_string[length-i-1])\n",
    "    return bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a081f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSetBits(n):\n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, enc_quantize_level = 2, enc_value_limit = 1.0, enc_grad_limit = 0.01, enc_clipping = 'both'):\n",
    "        ctx.save_for_backward(inputs)\n",
    "        assert enc_clipping in ['both', 'inputs']\n",
    "        ctx.enc_clipping = enc_clipping\n",
    "        ctx.enc_value_limit = enc_value_limit\n",
    "        ctx.enc_quantize_level = enc_quantize_level\n",
    "        ctx.enc_grad_limit = enc_grad_limit\n",
    "\n",
    "        x_lim_abs = enc_value_limit\n",
    "        x_lim_range = 2.0 * x_lim_abs\n",
    "        x_input_norm = torch.clamp(inputs, -x_lim_abs, x_lim_abs)\n",
    "\n",
    "        if enc_quantize_level == 2:\n",
    "            outputs_int = torch.sign(x_input_norm)\n",
    "        else:\n",
    "            outputs_int = torch.round((x_input_norm +x_lim_abs) * ((enc_quantize_level - 1.0)/x_lim_range)) * x_lim_range/(enc_quantize_level - 1.0) - x_lim_abs\n",
    "\n",
    "        return outputs_int\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.enc_clipping in ['inputs', 'both']:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input>ctx.enc_value_limit]=0\n",
    "            grad_output[input<-ctx.enc_value_limit]=0\n",
    "\n",
    "        if ctx.enc_clipping in ['gradient', 'both']:\n",
    "            grad_output = torch.clamp(grad_output, -ctx.enc_grad_limit, ctx.enc_grad_limit)\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d695a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'tanh':\n",
    "        return F.tanh\n",
    "    elif activation == 'elu':\n",
    "        return F.elu\n",
    "    elif activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'selu':\n",
    "        return F.selu\n",
    "    elif activation == 'sigmoid':\n",
    "        return F.sigmoid\n",
    "    elif activation == 'gelu':\n",
    "        return F.gelu\n",
    "    elif activation == 'silu':\n",
    "        return F.silu\n",
    "    elif activation == 'mish':\n",
    "        return F.mish\n",
    "    elif activation == 'linear':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Activation function {activation} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c2096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth=3, skip_depth=1, skip_layer=1, ell=2, activation='selu', use_skip=False, augment=False):\n",
    "        super(g_Full, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.ell = ell\n",
    "        self.ell_input_size = input_size//self.ell\n",
    "        self.augment = augment\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "        self.skip_depth = skip_depth\n",
    "        self.skip_layer = skip_layer\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        if self.use_skip:\n",
    "            self.skip = nn.ModuleList([nn.Linear(self.input_size + self.output_size, self.hidden_size, bias=True)])\n",
    "            self.skip.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.skip_depth)])\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        self.linears.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.depth)])\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_augment(msg, ell):\n",
    "        u = msg.clone()\n",
    "        n = int(np.log2(ell))\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, ell, 2*num_bits):\n",
    "                if len(u.shape) == 2:\n",
    "                    u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                elif len(u.shape) == 3:\n",
    "                    u = torch.cat((u[:, :, :i], u[:, :, i:i+num_bits].clone() * u[:, :, i+num_bits: i+2*num_bits], u[:, :, i+num_bits:]), dim=2)\n",
    "\n",
    "        if len(u.shape) == 3:\n",
    "            return u[:, :, :-1]\n",
    "        elif len(u.shape) == 2:\n",
    "            return u[:, :-1]\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y.clone()\n",
    "        for ii, layer in enumerate(self.linears):\n",
    "            if ii != self.depth:\n",
    "                x = self.activation_fn(layer(x))\n",
    "                if self.use_skip and ii == self.skip_layer:\n",
    "                    if len(x.shape) == 3:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=2)\n",
    "                    elif len(x.shape) == 2:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=1)\n",
    "                    for jj, skip_layer in enumerate(self.skip):\n",
    "                        skip_input = self.activation_fn(skip_layer(skip_input))\n",
    "                    x = x + skip_input\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if self.augment:\n",
    "                    x = x + g_Full.get_augment(y, self.ell)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa9d5bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRC:\n",
    "    def __init__(self, polynomial_coeffs):\n",
    "        \"\"\"Initialize with polynomial coefficients in binary form.\"\"\"\n",
    "        self.polynomial = torch.tensor(polynomial_coeffs, dtype=torch.int64)\n",
    "        self.degree = len(polynomial_coeffs) - 1\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"Add CRC bits to message in batch.\"\"\"\n",
    "        batch_size = message.shape[0]\n",
    "        msg_len = message.shape[1]\n",
    "        \n",
    "        # Convert to binary if needed\n",
    "        if message.dtype == torch.float:\n",
    "            message_binary = ((1 - message)/2).to(torch.int64)\n",
    "        else:\n",
    "            message_binary = message.to(torch.int64)\n",
    "            \n",
    "        # Initialize result tensor\n",
    "        encoded = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                            dtype=torch.int64, \n",
    "                            device=message.device)\n",
    "        \n",
    "        # Prepare dividend for all batches at once\n",
    "        dividend = torch.zeros((batch_size, msg_len + self.degree), \n",
    "                             dtype=torch.int64,\n",
    "                             device=message.device)\n",
    "        dividend[:, :msg_len] = message_binary\n",
    "        \n",
    "        # Perform batch polynomial division\n",
    "        remainder = self.polynomial_division_batch(dividend)\n",
    "        \n",
    "        # Combine message and remainder\n",
    "        encoded[:, :msg_len] = message_binary\n",
    "        encoded[:, msg_len:] = remainder\n",
    "        \n",
    "        # Convert back to float if needed\n",
    "        if message.dtype == torch.float:\n",
    "            encoded = (1 - 2*encoded).float()\n",
    "            \n",
    "        return encoded\n",
    "\n",
    "    def check_batch(self, received):\n",
    "        \"\"\"Check if received messages pass CRC in batch.\"\"\"\n",
    "        # Convert to binary if needed\n",
    "        if received.dtype == torch.float:\n",
    "            received_binary = ((1 - received)/2).to(torch.int64)\n",
    "        else:\n",
    "            received_binary = received.to(torch.int64)\n",
    "            \n",
    "        # Perform polynomial division on all messages at once\n",
    "        remainder = self.polynomial_division_batch(received_binary)\n",
    "        \n",
    "        # Check if all remainder bits are zero for each message\n",
    "        valid = torch.all(remainder == 0, dim=1)\n",
    "        return valid\n",
    "\n",
    "    def check(self, received):\n",
    "        \"\"\"Maintain backward compatibility\"\"\"\n",
    "        return self.check_batch(received.unsqueeze(0) if received.dim() == 1 else received)\n",
    "\n",
    "    def polynomial_division_batch(self, dividend):\n",
    "        \"\"\"Perform polynomial division in batch using vectorized operations.\"\"\"\n",
    "        # Make copy to avoid modifying input\n",
    "        result = dividend.clone()\n",
    "        n = dividend.shape[1]\n",
    "        \n",
    "        # Find positions of 1s for all batches\n",
    "        for i in range(n - self.degree):\n",
    "            # Find batches where current bit is 1\n",
    "            active_batches = result[:, i] == 1\n",
    "            \n",
    "            if torch.any(active_batches):\n",
    "                # XOR with polynomial for active batches\n",
    "                for j in range(self.degree + 1):\n",
    "                    result[active_batches, i + j] ^= self.polynomial[j]\n",
    "        \n",
    "        # Return last degree bits (remainder) for all batches\n",
    "        return result[:, -self.degree:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1d08da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crc_encoder = CRC(crc_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68d72065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape should be: (batch_size, seq_len, hidden_dim)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class f_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0., activation='selu', depth=3, use_norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.use_norm = use_norm\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "\n",
    "        # Initial layers same as original f_Full\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        if self.use_norm:\n",
    "            self.norms = nn.ModuleList([nn.LayerNorm(self.hidden_size)])\n",
    "        \n",
    "        # Attention layer after first linear\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,  # Reduced number of heads\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Remaining layers same as original\n",
    "        for ii in range(1, self.depth):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size, bias=True))\n",
    "            if self.use_norm:\n",
    "                self.norms.append(nn.LayerNorm(self.hidden_size))\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    def forward(self, y, aug=None):\n",
    "        x = y.clone()\n",
    "        \n",
    "        # First linear layer\n",
    "        x = self.linears[0](x)\n",
    "        if self.use_norm:\n",
    "            x = self.norms[0](x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        # Reshape for attention: [batch, seq_len, hidden]\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = attn_out if len(y.shape) == 3 else attn_out.squeeze(1)\n",
    "        \n",
    "        # Remaining layers\n",
    "        for ii in range(1, len(self.linears)):\n",
    "            if ii != self.depth:\n",
    "                x = self.linears[ii](x)\n",
    "                if self.use_norm:\n",
    "                    x = self.norms[ii](x)\n",
    "                x = self.activation_fn(x)\n",
    "            else:\n",
    "                x = self.linears[ii](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10845154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        try:\n",
    "            m.bias.data.fill_(0.)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(actions):\n",
    "    inds = (0.5 + 0.5*actions).long()\n",
    "    return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594f46",
   "metadata": {},
   "source": [
    "# Part 2: Core PolarCode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9da23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarCode:\n",
    "\n",
    "    def __init__(self, n, K, Fr = None, rs = None, use_cuda = True, infty = 1000., hard_decision = False, lse = 'lse'):\n",
    "\n",
    "        assert n>=1\n",
    "        self.n = n\n",
    "        self.N = 2**n\n",
    "        self.K = K\n",
    "        self.G2 = np.array([[1,1],[0,1]])\n",
    "        self.G = np.array([1])\n",
    "        for i in range(n):\n",
    "            self.G = np.kron(self.G, self.G2)\n",
    "        self.G = torch.from_numpy(self.G).float()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.infty = infty\n",
    "        self.hard_decision = hard_decision\n",
    "        self.lse = lse\n",
    "\n",
    "        if Fr is not None:\n",
    "            assert len(Fr) == self.N - self.K\n",
    "            self.frozen_positions = Fr\n",
    "            self.unsorted_frozen_positions = self.frozen_positions\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "            self.info_positions = np.array(list(set(self.frozen_positions) ^ set(np.arange(self.N))))\n",
    "            self.unsorted_info_positions = self.info_positions\n",
    "            self.info_positions.sort()\n",
    "            \n",
    "        else:\n",
    "            if rs is None:\n",
    "                # in increasing order of reliability\n",
    "                self.reliability_seq = np.arange(1023, -1, -1)\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "            else:\n",
    "                self.reliability_seq = rs\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "\n",
    "                assert len(self.rs) == self.N\n",
    "            # best K bits\n",
    "            self.info_positions = self.rs[:self.K]\n",
    "            self.unsorted_info_positions = self.reliability_seq[self.reliability_seq<self.N][:self.K]\n",
    "            self.info_positions.sort()\n",
    "            self.unsorted_info_positions=np.flip(self.unsorted_info_positions)\n",
    "            # worst N-K bits\n",
    "            self.frozen_positions = self.rs[self.K:]\n",
    "            self.unsorted_frozen_positions = self.rs[self.K:]\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "\n",
    "            self.CRC_polynomials = {\n",
    "            3: torch.Tensor([1, 0, 1, 1]).int(),\n",
    "            8: torch.Tensor([1, 1, 1, 0, 1, 0, 1, 0, 1]).int(),\n",
    "            16: torch.Tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]).int(),\n",
    "                                    }\n",
    "\n",
    "    def get_G(self, ell):\n",
    "        n = int(np.log2(ell))\n",
    "        G = np.array([1])\n",
    "        for i in range(n):\n",
    "            G = np.kron(G, self.G2)\n",
    "        return G\n",
    "\n",
    "    def encode_plotkin(self, message, scaling = None, custom_info_positions = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "        if custom_info_positions is not None:\n",
    "            info_positions = custom_info_positions\n",
    "        else:\n",
    "            info_positions = self.info_positions\n",
    "        u = torch.ones(message.shape[0], self.N, dtype=torch.float).to(message.device)\n",
    "        u[:, info_positions] = message\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                # u[:, i:i+num_bits] = u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits].clone\n",
    "        if scaling is not None:\n",
    "            u = (scaling * np.sqrt(self.N)*u)/torch.norm(scaling)\n",
    "        return u\n",
    "    \n",
    "    def channel(self, code, snr, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 5e-2):\n",
    "        if noise_type != \"bsc\":\n",
    "            sigma = snr_db2sigma(snr)\n",
    "        else:\n",
    "            sigma = snr\n",
    "\n",
    "        r = corrupt_signal(code, sigma, noise_type, vv, radar_power, radar_prob)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def define_partial_arrays(self, llrs):\n",
    "        # Initialize arrays to store llrs and partial_sums useful to compute the partial successive cancellation process.\n",
    "        llr_array = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        llr_array[:, self.n] = llrs\n",
    "        partial_sums = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        return llr_array, partial_sums\n",
    "\n",
    "\n",
    "    def updateLLR(self, leaf_position, llrs, partial_llrs = None, prior = None):\n",
    "\n",
    "        #START\n",
    "        depth = self.n\n",
    "        decoded_bits = partial_llrs[:,0].clone()\n",
    "        if prior is None:\n",
    "            prior = torch.zeros(self.N) #priors\n",
    "        llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth, 0, leaf_position, prior, decoded_bits)\n",
    "        return llrs, decoded_bits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def partial_decode(self, llrs, partial_llrs, depth, bit_position, leaf_position, prior, decoded_bits=None):\n",
    "        # Function to call recursively, for partial SC decoder.\n",
    "        # We are assuming that u_0, u_1, .... , u_{leaf_position -1} bits are known.\n",
    "        # Partial sums computes the sums got through Plotkin encoding operations of known bits, to avoid recomputation.\n",
    "        # this function is implemented for rate 1 (not accounting for frozen bits in polar SC decoding)\n",
    "\n",
    "        # print(\"DEPTH = {}, bit_position = {}\".format(depth, bit_position))\n",
    "        half_index = 2 ** (depth - 1)\n",
    "        leaf_position_at_depth = leaf_position // 2**(depth-1) # will tell us whether left_child or right_child\n",
    "\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            # Left child\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position:left_bit_position+1]\n",
    "            elif leaf_position_at_depth == left_bit_position:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                elif self.lse == 'lse':\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                #print(Lu.device, prior.device, torch.ones_like(Lu).device)\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu + prior[left_bit_position]*torch.ones_like(Lu)\n",
    "                if self.hard_decision:\n",
    "                    u_hat = torch.sign(Lu)\n",
    "                else:\n",
    "                    u_hat = torch.tanh(Lu/2)\n",
    "\n",
    "                decoded_bits[:, left_bit_position] = u_hat.squeeze(1)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # Right child\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "            if leaf_position_at_depth > right_bit_position:\n",
    "                pass\n",
    "            elif leaf_position_at_depth == right_bit_position:\n",
    "                Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "                llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv + prior[right_bit_position] * torch.ones_like(Lv)\n",
    "                if self.hard_decision:\n",
    "                    v_hat = torch.sign(Lv)\n",
    "                else:\n",
    "                    v_hat = torch.tanh(Lv/2)\n",
    "                decoded_bits[:, right_bit_position] = v_hat.squeeze(1)\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            # LEFT CHILD\n",
    "            # Find likelihood of (u xor v) xor (v) = u\n",
    "            # Lu = log_sum_exp(torch.cat([llrs[:, :half_index].unsqueeze(2), llrs[:, half_index:].unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                Lu = llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "            else:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                elif self.lse == 'lse':\n",
    "                    # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu\n",
    "                llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, left_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # RIGHT CHILD\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "\n",
    "            Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "            llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv\n",
    "            llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, right_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "            return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "    def updatePartialSums(self, leaf_position, decoded_bits, partial_llrs):\n",
    "\n",
    "        u = decoded_bits.clone()\n",
    "        u[:, leaf_position+1:] = 0\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            partial_llrs[:, d] = u\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        partial_llrs[:, self.n] = u\n",
    "        return partial_llrs\n",
    "\n",
    "    def sc_decode_new(self, corrupted_codewords, snr, use_gt = None, channel = 'awgn'):\n",
    "\n",
    "        assert channel in ['awgn', 'bsc']\n",
    "\n",
    "        if channel == 'awgn':\n",
    "            noise_sigma = snr_db2sigma(snr)\n",
    "            llrs = (2/noise_sigma**2)*corrupted_codewords\n",
    "        elif channel == 'bsc':\n",
    "            # snr refers to transition prob\n",
    "            p = (torch.ones(1)*(snr + 1e-9)).to(corrupted_codewords.device)\n",
    "            llrs = (torch.clip(torch.log((1 - p) / p), -10000, 10000) * (corrupted_codewords + 1) - torch.clip(torch.log(p / (1-p)), -10000, 10000) * (corrupted_codewords - 1))/2\n",
    "\n",
    "        # step-wise implementation using updateLLR and updatePartialSums\n",
    "\n",
    "        priors = torch.zeros(self.N)\n",
    "        priors[self.frozen_positions] = self.infty\n",
    "\n",
    "        u_hat = torch.zeros(corrupted_codewords.shape[0], self.N, device=corrupted_codewords.device)\n",
    "        llr_array, partial_llrs = self.define_partial_arrays(llrs)\n",
    "        for ii in range(self.N):\n",
    "            #start = time.time()\n",
    "            llr_array , decoded_bits = self.updateLLR(ii, llr_array.clone(), partial_llrs, priors)\n",
    "            #print('SC update : {}'.format(time.time() - start), corrupted_codewords.shape[0])\n",
    "            if use_gt is None:\n",
    "                u_hat[:, ii] = torch.sign(llr_array[:, 0, ii])\n",
    "            else:\n",
    "                u_hat[:, ii] = use_gt[:, ii]\n",
    "            #start = time.time()\n",
    "            partial_llrs = self.updatePartialSums(ii, u_hat, partial_llrs)\n",
    "            #print('SC partial: {}s, {}', time.time() - start, 'frozen' if ii in self.frozen_positions else 'info')\n",
    "        decoded_bits = u_hat[:, self.info_positions]\n",
    "        return llr_array[:, 0, :].clone(), decoded_bits\n",
    "\n",
    "    def get_CRC(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # inout message should be int\n",
    "\n",
    "        padded_bits = torch.cat([message, torch.zeros(self.CRC_len).int().to(message.device)])\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + self.CRC_len + 1] = padded_bits[cur_shift: cur_shift + self.CRC_len + 1] ^ self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        return padded_bits[self.K_minus_CRC:]\n",
    "\n",
    "    def CRC_check(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # input message should be int\n",
    "\n",
    "        padded_bits = message\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + polar.CRC_len + 1] ^= self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        if padded_bits[self.K_minus_CRC:].sum()>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def encode_with_crc(self, message, CRC_len):\n",
    "        self.CRC_len = CRC_len\n",
    "        self.K_minus_CRC = self.K - CRC_len\n",
    "\n",
    "        if CRC_len == 0:\n",
    "            return self.encode_plotkin(message)\n",
    "        else:\n",
    "            crcs = 1-2*torch.vstack([self.get_CRC((0.5+0.5*message[jj]).int()) for jj in range(message.shape[0])])\n",
    "            encoded = self.encode_plotkin(torch.cat([message, crcs], 1))\n",
    "\n",
    "            return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6d51",
   "metadata": {},
   "source": [
    "# Part 3: DeepPolar Class and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPolar(PolarCode):\n",
    "    def __init__(self, device, N, K, ell = 2, infty = 1000., depth_map : defaultdict = None):\n",
    "\n",
    "        # rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        # Frozen = np.argsort(rmweight)[:-K]\n",
    "        # Frozen.sort()\n",
    "\n",
    "        #self.args = args\n",
    "        Fr = get_frozen(N, K, rate_profile)\n",
    "        super().__init__(n = int(np.log2(N)), K = K, Fr=Fr,  infty = infty)\n",
    "        self.N = N\n",
    "\n",
    "        if depth_map is not None:\n",
    "            # depth map is a dict, product of values should be equal to N\n",
    "            assert np.prod(list(depth_map.values())) == N\n",
    "            # assert that keys od depth map start from one and go continuosly till some point \n",
    "            assert min(list(depth_map.keys())) == 1\n",
    "            assert max(list(depth_map.keys())) <= int(np.log2(N))\n",
    "            self.ell = None\n",
    "            self.n_ell = len(depth_map.keys())\n",
    "            assert max(list(depth_map.keys())) == self.n_ell\n",
    "\n",
    "            self.depth_map = depth_map\n",
    "        else:\n",
    "            self.ell = ell\n",
    "            self.n_ell = int(np.log(N)/np.log(self.ell))\n",
    "\n",
    "            self.depth_map = defaultdict(int)\n",
    "            for d in range(1, self.n_ell+1):\n",
    "                self.depth_map[d] = self.ell\n",
    "            assert np.prod(list(self.depth_map.values())) == N\n",
    "\n",
    "        self.device = device\n",
    "        self.fnet_dict = None\n",
    "        self.gnet_dict = None\n",
    "\n",
    "        self.infty = infty\n",
    "\n",
    "    @staticmethod\n",
    "    def get_onehot(actions):\n",
    "        inds = (0.5 + 0.5*actions).long()\n",
    "        if len(actions.shape) == 2:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)\n",
    "        elif len(actions.shape) == 3:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], actions.shape[1], -1)\n",
    "\n",
    "    def define_kernel_nns(self, ell, unfrozen = None, fnet = 'KO', gnet = 'KO', shared = False):\n",
    "\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "        #dec_hidden_size = dec_hidden_size\n",
    "        #enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        depth = 1\n",
    "        assert len(unfrozen) > 0, \"No unfrozen bits!\"\n",
    "\n",
    "        self.fnet_dict[depth] = {}\n",
    "\n",
    "        if fnet == 'KO_parallel' or fnet == 'KO_last_parallel':\n",
    "            bit_position = 0\n",
    "                   \n",
    "            self.fnet_dict[depth][bit_position] = {}\n",
    "            # input_size = self.N if depth == self.n_ell else self.N // int(np.prod([self.depth_map[d] for d in range(depth+1, self.n_ell+1)]))\n",
    "            input_size = ell             \n",
    "            # For curriculum, only for lowest depth.\n",
    "            output_size = ell#len(unfrozen)\n",
    "            self.fnet_dict[depth][bit_position] = f_Full(input_size, dec_hidden_size, output_size, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    " \n",
    "        elif 'KO' in fnet:\n",
    "            if shared:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for current_position in range(ell):\n",
    "                    self.fnet_dict[depth][current_position] = f_Full(ell + current_position, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                for current_position in unfrozen:\n",
    "                    if not self.fnet_dict[depth].get(bit_position):\n",
    "                        self.fnet_dict[depth][bit_position] = {}\n",
    "                    input_size = ell + (int(onehot)+1)*current_position\n",
    "                    self.fnet_dict[depth][bit_position][current_position] = f_Full(input_size, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "                \n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict[depth] = {}\n",
    "            if shared:\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth][bit_position] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "\n",
    "    def define_and_load_nns(self, ell, kernel_load_path=None, fnet='KO', gnet='KO', shared=True, dataparallel=False):\n",
    "        # Initialize decoder and encoder dictionaries\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "\n",
    "        # Loop through each depth level\n",
    "        for depth in range(self.n_ell, 0, -1):\n",
    "            if depth in polar_depths:\n",
    "                continue\n",
    "\n",
    "            ell = self.depth_map[depth]\n",
    "            proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "            # Handle parallel decoder case\n",
    "            if fnet == 'KO_last_parallel' and depth == 1:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for bit_position in range(self.N // proj_size):\n",
    "                    proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                    get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                    num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                    subproj_len = len(proj) // ell\n",
    "                    subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                    num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                    unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                    input_size = ell             \n",
    "                    output_size = ell\n",
    "\n",
    "                    # Use attention-enhanced decoder for parallel case\n",
    "                    self.fnet_dict[depth][bit_position] = f_Full(\n",
    "                        input_size=input_size,\n",
    "                        hidden_size=dec_hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        activation=dec_activation,\n",
    "                        dropout_p=dropout_p,\n",
    "                        depth=f_depth,\n",
    "                        use_norm=use_norm\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    # Load pretrained weights if available\n",
    "                    if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                        try:\n",
    "                            ckpt = torch.load(os.path.join(kernel_load_path + '_parallel', f'{ell}_{len(unfrozen)}.pt'))\n",
    "                            self.fnet_dict[depth][bit_position].load_state_dict(ckpt[0][1][0].state_dict())\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"Parallel File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                            pass\n",
    "\n",
    "                    if dataparallel:\n",
    "                        self.fnet_dict[depth][bit_position] = nn.DataParallel(self.fnet_dict[depth][bit_position])\n",
    "\n",
    "            # Handle sequential decoder case\n",
    "            elif 'KO' in fnet:\n",
    "                self.fnet_dict[depth] = {}\n",
    "\n",
    "                if shared:\n",
    "                    # Shared decoder network for all positions\n",
    "                    for current_position in range(ell):\n",
    "                        self.fnet_dict[depth][current_position] = f_Full(\n",
    "                            input_size=ell + current_position,\n",
    "                            hidden_size=dec_hidden_size,\n",
    "                            output_size=1,\n",
    "                            activation=dec_activation,\n",
    "                            dropout_p=dropout_p,\n",
    "                            depth=f_depth,\n",
    "                            use_norm=use_norm\n",
    "                        ).to(self.device)\n",
    "\n",
    "                        if dataparallel:\n",
    "                            self.fnet_dict[depth][current_position] = nn.DataParallel(self.fnet_dict[depth][current_position])\n",
    "\n",
    "                else:\n",
    "                    # Individual decoder networks for each position\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                        num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                        subproj_len = len(proj) // ell\n",
    "                        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                        unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                        # Load pretrained weights if available\n",
    "                        ckpt_exists = False\n",
    "                        if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                            try:\n",
    "                                ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                ckpt_exists = True\n",
    "                            except FileNotFoundError:\n",
    "                                print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                pass\n",
    "\n",
    "                        # Create decoders for unfrozen positions\n",
    "                        for current_position in unfrozen:\n",
    "                            if not self.fnet_dict[depth].get(bit_position):\n",
    "                                self.fnet_dict[depth][bit_position] = {}\n",
    "\n",
    "                            input_size = ell + (int(onehot)+1)*current_position\n",
    "                            output_size = 1\n",
    "\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = f_Full(\n",
    "                                input_size=input_size,\n",
    "                                hidden_size=dec_hidden_size,\n",
    "                                output_size=output_size,\n",
    "                                activation=dec_activation,\n",
    "                                dropout_p=dropout_p,\n",
    "                                depth=f_depth,\n",
    "                                use_norm=use_norm\n",
    "                            ).to(self.device)\n",
    "\n",
    "                            if ckpt_exists:\n",
    "                                try:\n",
    "                                    f_ckpt = ckpt[0][1][0][current_position].state_dict()\n",
    "                                    self.fnet_dict[depth][bit_position][current_position].load_state_dict(f_ckpt)\n",
    "                                except:\n",
    "                                    print(f\"Warning: Could not load weights for position {current_position}\")\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.fnet_dict[depth][bit_position][current_position] = nn.DataParallel(\n",
    "                                    self.fnet_dict[depth][bit_position][current_position]\n",
    "                                )\n",
    "\n",
    "            # Handle encoder network\n",
    "            if 'KO' in gnet:\n",
    "                self.gnet_dict[depth] = {}\n",
    "                if shared:\n",
    "                    if gnet == 'KO':\n",
    "                        if not dataparallel:\n",
    "                            self.gnet_dict[depth] = g_Full(\n",
    "                                ell, enc_hidden_size, ell-1,\n",
    "                                depth=g_depth,\n",
    "                                skip_depth=g_skip_depth,\n",
    "                                skip_layer=g_skip_layer,\n",
    "                                ell=ell,\n",
    "                                use_skip=use_skip\n",
    "                            ).to(self.device)\n",
    "                        else:\n",
    "                            self.gnet_dict[depth] = nn.DataParallel(\n",
    "                                g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    use_skip=use_skip\n",
    "                                )\n",
    "                            ).to(self.device)\n",
    "                else:\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        num_info_in_proj = sum([int(x in self.info_positions) for x in proj])\n",
    "\n",
    "                        if num_info_in_proj > 0:\n",
    "                            if gnet == 'KO':\n",
    "                                self.gnet_dict[depth][bit_position] = g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    activation=enc_activation,\n",
    "                                    use_skip=use_skip\n",
    "                                ).to(self.device)\n",
    "\n",
    "                            # Load pretrained weights if available\n",
    "                            if kernel_load_path is not None:\n",
    "                                try:\n",
    "                                    ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                    self.gnet_dict[depth][bit_position].load_state_dict(ckpt[1][1][0].state_dict())\n",
    "                                except FileNotFoundError:\n",
    "                                    print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                    pass\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.gnet_dict[depth][bit_position] = nn.DataParallel(self.gnet_dict[depth][bit_position])\n",
    "\n",
    "        if kernel_load_path is not None:\n",
    "            print(\"Loaded kernel from \", kernel_load_path)\n",
    "\n",
    "    def load_nns(self, fnet_dict, gnet_dict = None, shared = False):\n",
    "        self.fnet_dict = fnet_dict\n",
    "        self.gnet_dict = gnet_dict\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if self.fnet_dict is not None:\n",
    "                for bit_position in self.fnet_dict[depth].keys():\n",
    "                    if not isinstance(self.fnet_dict[depth][bit_position], dict):#shared or decoder_type == 'KO_parallel' or decoder_type == 'KO_RNN':\n",
    "                        self.fnet_dict[depth][bit_position].to(self.device)\n",
    "                    else:\n",
    "                        for current_position in self.fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "            if gnet_dict is not None:\n",
    "                if shared:\n",
    "                    self.gnet_dict[depth].to(self.device)\n",
    "                else:\n",
    "                    for bit_position in self.gnet_dict[depth].keys():\n",
    "                        self.gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def load_partial_nns(self, fnet_dict, gnet_dict = None):\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if fnet_dict is not None:\n",
    "                for bit_position in fnet_dict[depth].keys():\n",
    "                    if isinstance(fnet_dict[depth][bit_position], dict):\n",
    "                        for current_position in fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "                    else:\n",
    "                        self.fnet_dict[depth][bit_position] = fnet_dict[depth][bit_position].to(self.device)\n",
    "\n",
    "            if gnet_dict is not None:\n",
    "                for bit_position in gnet_dict[depth].keys():\n",
    "                    self.gnet_dict[depth][bit_position] = gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def kernel_encode(self, ell, gnet, msg_bits, info_positions, binary = False):\n",
    "        input_shape = msg_bits.shape[-1]\n",
    "        assert input_shape <= ell\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, info_positions] = msg_bits\n",
    "        output =torch.cat([gnet(u.unsqueeze(1)).squeeze(1), u[:, -1:]], 1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(output)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def deeppolar_encode(self, msg_bits, binary = False):\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, self.info_positions] = msg_bits\n",
    "        for d in range(1, self.n_ell+1):\n",
    "            # num_bits = self.ell**(d-1)\n",
    "            num_bits = np.prod([self.depth_map[dd] for dd in range(1, d)]) if d > 1 else 1\n",
    "            # proj_size = self.ell**(d)\n",
    "            proj_size = np.prod([self.depth_map[dd] for dd in range(1, d+1)])\n",
    "            ell = self.depth_map[d]\n",
    "            for bit_position, i in enumerate(np.arange(0, self.N, ell*num_bits)):\n",
    "\n",
    "                # [u v] encoded to [(u xor v),v)]\n",
    "                proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                subproj_len = len(proj) // ell\n",
    "                subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "                \n",
    "                if num_info_in_proj > 0:\n",
    "                    info_bits_present = True          \n",
    "                else:\n",
    "                    info_bits_present = False         \n",
    "                if d in polar_depths:\n",
    "                    info_bits_present = False\n",
    "\n",
    "                enc_chunks = []\n",
    "                ell = self.depth_map[d]\n",
    "                for j in range(ell):\n",
    "                    chunk = u[:, i + j*num_bits:i + (j+1)*num_bits].unsqueeze(2).clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[d](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        output = torch.cat([self.gnet_dict[d][bit_position](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(msg_bits.shape[0], -1, 1).squeeze(2)\n",
    "\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                u = torch.cat((u[:, :i], output, u[:, i + ell*num_bits:]), dim=1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(u)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def power_constraint(self, codewords):\n",
    "        return F.normalize(codewords, p=2, dim=1)*np.sqrt(self.N)\n",
    "\n",
    "    def encode_chunks_plotkin(self, enc_chunks, ell = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "\n",
    "        # to change for other kernels\n",
    "\n",
    "        if ell is None:\n",
    "            ell = self.ell\n",
    "        assert len(enc_chunks) == ell\n",
    "        chunk_size = enc_chunks[0].shape[1]\n",
    "        batch_size = enc_chunks[0].shape[0]\n",
    "\n",
    "        u = torch.cat(enc_chunks, 1).squeeze(2)\n",
    "        n = int(np.log2(ell))\n",
    "\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d * chunk_size\n",
    "            for i in np.arange(0, chunk_size*ell, 2*num_bits):\n",
    "                # [u v] encoded to [(u,v) xor v]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        return u\n",
    "            \n",
    "    def deeppolar_parallel_decode(self, noisy_code):\n",
    "        # Successive cancellation decoder for polar codes\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "        decoded_llrs  = self.KO_parallel_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "\n",
    "    def deeppolar_parallel_decode_depth(self, llrs, depth, bit_position, decoded_llrs):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        dec_chunks = torch.cat([llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "        Lu = self.fnet_dict[depth][bit_position](dec_chunks)\n",
    "\n",
    "        if depth == 1:\n",
    "            u = torch.tanh(Lu/2)\n",
    "            decoded_llrs[:, left_bit_position + unfrozen] = Lu.squeeze(1)\n",
    "        else:\n",
    "            for index, current_position in enumerate(unfrozen):\n",
    "                bit_position_offset = left_bit_position + current_position                \n",
    "                decoded_llrs = self.deeppolar_parallel_decode_depth(Lu[:, :, index:index+1], depth-1, bit_position_offset, decoded_llrs)\n",
    "\n",
    "        return decoded_llrs\n",
    "            \n",
    "    def deeppolar_decode(self, noisy_code):\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        \n",
    "        # don't want to go into useless frozen subtrees.\n",
    "        partial_sums = torch.ones(noisy_code.shape[0], self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "\n",
    "        decoded_llrs, partial_sums = self.deeppolar_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs, partial_sums)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "    \n",
    "    def deeppolar_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        # size of the projection of tht subtree\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        # This chunk - finds infrozen positions in this kernel.\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        if num_nonzero_subproj > 0:\n",
    "            info_bits_present = True      \n",
    "        else:\n",
    "            info_bits_present = False \n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "                \n",
    "        # This will be input to decoder\n",
    "        dec_chunks = [llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            if decoder_type == 'KO_last_parallel':\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                Lu = self.fnet_dict[depth][bit_position](concatenated_chunks)[:, 0, unfrozen]\n",
    "                u_hat = torch.tanh(Lu/2)\n",
    "                decoded_llrs[:, left_bit_position + unfrozen] = Lu\n",
    "                partial_sums[:, depth-1, left_bit_position + unfrozen] = u_hat\n",
    "\n",
    "            else:\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    if current_position > 0:\n",
    "                        # I am adding previously decoded bits . (either onehot or normal)\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "\n",
    "                    if bit_position_offset in self.frozen_positions: # frozen \n",
    "                        # don't update decoded llrs. It already has ones*prior.\n",
    "                        # actually don't need this. can skip.\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, depth-1, bit_position_offset])\n",
    "                    else: # information bit\n",
    "                        # This is the decoding.\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](concatenated_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "\n",
    "                        u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                        decoded_llrs[:, bit_position_offset] = Lu.squeeze(2).squeeze(1)\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = u_hat.squeeze(1)\n",
    "\n",
    "            # Encoding back the decoded bits - for higher layers.\n",
    "            # # Compute decoded codeword\n",
    "            i = left_bit_position * half_index\n",
    "            # num_bits = self.ell**(depth-1)\n",
    "            num_bits = 1\n",
    "\n",
    "            enc_chunks = []\n",
    "            for j in range(ell):\n",
    "                chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                enc_chunks.append(chunk)\n",
    "            if info_bits_present:\n",
    "                concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                if 'KO' in encoder_type:\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        # bit position of the previous depth.\n",
    "                        output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            else:\n",
    "                output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "            \n",
    "            return decoded_llrs, partial_sums\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "\n",
    "                if current_position in unfrozen:\n",
    "                    # General decoding ....\n",
    "                    # add the decoded bit here\n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](concatenated_chunks).squeeze(2)\n",
    "                    else:\n",
    "                        # if current_position == 0:\n",
    "                        #     Lu = self.fnet_dict[depth][bit_position][current_position](llrs)\n",
    "                        # else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "                    decoded_llrs, partial_sums = self.deeppolar_decode_depth(Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums)\n",
    "                else:\n",
    "                    Lu = self.infty*torch.ones_like(llrs)\n",
    "\n",
    "\n",
    "            # Compute decoded codeword\n",
    "            if depth < self.n_ell :\n",
    "                i = left_bit_position * half_index\n",
    "                # num_bits = self.ell**(depth-1)\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        else:\n",
    "                            # bit position of the previous depth.\n",
    "                            output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "\n",
    "                return decoded_llrs, partial_sums\n",
    "            else: # encoding not required for last level - we have already decoded all bits.\n",
    "                return decoded_llrs, partial_sums\n",
    "\n",
    "\n",
    "    def kernel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = [noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "\n",
    "        for current_position in range(ell):\n",
    "            if current_position > 0:\n",
    "                if onehot:\n",
    "                    prev_decoded = get_onehot(u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone().sign()).detach().clone()\n",
    "                else:\n",
    "                    prev_decoded = u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                dec_chunks.append(prev_decoded)\n",
    "            if current_position in info_positions:\n",
    "                if current_position in info_positions:\n",
    "                    concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                    Lu = fnet_dict[current_position](concatenated_chunks)\n",
    "                    decoded_llrs[:, current_position] = Lu.squeeze(2).squeeze(1)\n",
    "                    u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                    u[:, current_position] = u_hat.squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "\n",
    "    def kernel_parallel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = torch.cat([noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "\n",
    "        decoded_llrs = fnet_dict(dec_chunks).squeeze(1)\n",
    "        u = torch.tanh(decoded_llrs/2).squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96d749",
   "metadata": {},
   "source": [
    "# Part 4: Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e848578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen(N, K, rate_profile, target_K = None):\n",
    "    n = int(np.log2(N))\n",
    "    if rate_profile == 'polar':\n",
    "        # computed for SNR = 0\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "\n",
    "            # for RM :(\n",
    "            # rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 3, 5, 8, 4, 2, 1, 0])\n",
    "\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "        elif n<9:\n",
    "            rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "        else:\n",
    "            rs = np.array([1023, 1022, 1021, 1019, 1015, 1007, 1020,  991, 1018, 1017, 1014,\n",
    "       1006,  895, 1013, 1011,  959, 1005,  990, 1003,  989,  767, 1016,\n",
    "        999, 1012,  987,  958,  983,  957, 1010, 1004,  955, 1009,  894,\n",
    "        975,  893, 1002,  951, 1001,  988,  511,  766,  998,  891,  943,\n",
    "        986,  997,  985,  887,  956,  765,  995,  927,  982,  981,  879,\n",
    "        954,  974,  763,  953,  979,  510, 1008,  759,  863,  950,  892,\n",
    "       1000,  973,  949,  509,  890,  971,  996,  942,  751,  984,  889,\n",
    "        507,  947,  831,  886,  967,  941,  764,  926,  980,  994,  939,\n",
    "        885,  993,  735,  878,  925,  503,  762,  883,  978,  935,  703,\n",
    "        495,  952,  877,  761,  972,  923,  977,  948,  758,  862,  875,\n",
    "        919,  970,  757,  861,  508,  969,  750,  946,  479,  888,  639,\n",
    "        871,  911,  830,  940,  859,  755,  966,  945,  749,  506,  884,\n",
    "        938,  965,  829,  734,  924,  855,  505,  747,  963,  937,  882,\n",
    "        934,  827,  733,  447,  992,  847,  876,  501,  921,  702,  494,\n",
    "        881,  760,  743,  933,  502,  918,  874,  922,  823,  731,  499,\n",
    "        860,  756,  931,  701,  873,  493,  727,  917,  870,  976,  815,\n",
    "        910,  383,  968,  478,  858,  754,  699,  491,  869,  944,  748,\n",
    "        638,  915,  477,  719,  909,  964,  255,  799,  504,  857,  854,\n",
    "        753,  828,  746,  695,  487,  907,  637,  867,  853,  475,  936,\n",
    "        962,  446,  732,  826,  745,  846,  500,  825,  903,  687,  932,\n",
    "        635,  471,  445,  742,  880,  498,  730,  851,  822,  382,  920,\n",
    "        845,  741,  443,  700,  729,  631,  492,  872,  961,  726,  821,\n",
    "        930,  497,  381,  843,  463,  916,  739,  671,  623,  490,  929,\n",
    "        439,  814,  819,  868,  752,  914,  698,  725,  839,  856,  476,\n",
    "        813,  718,  908,  486,  723,  866,  489,  607,  431,  697,  379,\n",
    "        811,  798,  913,  575,  717,  254,  694,  636,  474,  807,  715,\n",
    "        906,  797,  693,  865,  960,  852,  744,  634,  473,  795,  905,\n",
    "        485,  415,  483,  470,  444,  375,  850,  740,  686,  902,  824,\n",
    "        691,  253,  711,  633,  844,  685,  630,  901,  367,  791,  928,\n",
    "        728,  820,  849,  783,  670,  899,  738,  842,  683,  247,  469,\n",
    "        441,  442,  462,  251,  737,  438,  467,  351,  629,  841,  724,\n",
    "        679,  669,  496,  461,  818,  380,  437,  627,  622,  459,  378,\n",
    "        239,  488,  667,  838,  430,  484,  812,  621,  319,  817,  435,\n",
    "        377,  696,  722,  912,  606,  810,  864,  716,  837,  721,  714,\n",
    "        809,  796,  455,  472,  619,  835,  692,  663,  223,  414,  904,\n",
    "        427,  806,  482,  632,  713,  690,  848,  605,  373,  252,  794,\n",
    "        429,  710,  684,  615,  805,  900,  655,  468,  366,  603,  413,\n",
    "        574,  481,  371,  250,  793,  466,  423,  374,  689,  628,  440,\n",
    "        365,  709,  789,  803,  411,  573,  682,  249,  460,  790,  668,\n",
    "        599,  350,  707,  246,  681,  465,  571,  626,  436,  407,  782,\n",
    "        191,  127,  363,  620,  666,  458,  245,  349,  677,  434,  678,\n",
    "        591,  787,  399,  457,  359,  238,  625,  840,  567,  736,  665,\n",
    "        428,  376,  781,  898,  618,  675,  318,  454,  662,  243,  897,\n",
    "        347,  836,  816,  720,  433,  604,  617,  779,  808,  661,  834,\n",
    "        712,  804,  833,  559,  237,  453,  426,  222,  317,  775,  372,\n",
    "        343,  412,  235,  543,  614,  451,  425,  422,  613,  370,  221,\n",
    "        315,  480,  335,  659,  654,  364,  190,  369,  248,  653,  688,\n",
    "        231,  410,  602,  611,  802,  792,  421,  651,  601,  598,  708,\n",
    "        311,  219,  572,  597,  788,  570,  409,  590,  362,  801,  680,\n",
    "        464,  406,  419,  348,  647,  786,  215,  589,  706,  361,  676,\n",
    "        566,  189,  595,  244,  569,  303,  405,  358,  456,  346,  398,\n",
    "        565,  242,  126,  705,  780,  587,  624,  664,  236,  187,  357,\n",
    "        432,  785,  558,  674,  207,  403,  397,  452,  345,  563,  778,\n",
    "        241,  316,  342,  616,  660,  557,  125,  234,  183,  287,  355,\n",
    "        583,  673,  395,  424,  314,  220,  777,  341,  612,  658,  123,\n",
    "        175,  774,  555,  233,  334,  542,  450,  313,  391,  230,  652,\n",
    "        368,  218,  339,  600,  119,  333,  657,  610,  773,  541,  310,\n",
    "        420,  159,  229,  650,  551,  596,  609,  408,  217,  449,  188,\n",
    "        309,  214,  331,  111,  539,  360,  771,  649,  302,  418,  594,\n",
    "        896,  227,  404,  646,  186,  588,  832,  568,  213,  417,  301,\n",
    "        307,  356,  402,  800,  564,  327,   95,  206,  240,  535,  593,\n",
    "        645,  586,  344,  396,  185,  401,  211,  354,  299,  585,  286,\n",
    "        562,  643,  182,  205,  124,  232,  285,  295,  181,  556,  582,\n",
    "        527,  394,  340,   63,  203,  561,  353,  448,  122,  283,  393,\n",
    "        581,  554,  174,  390,  704,  312,  338,  228,  179,  784,  199,\n",
    "        553,  121,  173,  389,  540,  579,  332,  118,  672,  550,  337,\n",
    "        158,  279,  271,  416,  216,  308,  387,  538,  549,  226,  330,\n",
    "        776,  171,  212,  117,  110,  329,  656,  157,  772,  306,  326,\n",
    "        225,  167,  115,  537,  534,  184,  109,  300,  547,  305,  210,\n",
    "        155,  533,  325,  352,  608,  400,  298,  204,   94,  648,  284,\n",
    "        209,  151,  180,  107,  770,  297,  392,  323,  592,  202,  644,\n",
    "         93,  294,  178,  103,  143,  282,   62,  336,  201,  120,  172,\n",
    "        198,  769,  584,   91,  388,  293,  177,  526,  278,  281,  642,\n",
    "        525,  531,   61,  170,  116,  197,   87,  156,  277,  114,  560,\n",
    "        169,   59,  291,  580,  275,  523,  641,  270,  195,  552,  519,\n",
    "        166,  224,  578,  108,  269,   79,  154,  113,  548,  577,  536,\n",
    "        328,   55,  106,  165,  153,  150,  386,  208,  324,  546,  385,\n",
    "        267,   47,   92,  163,  296,  304,  105,  102,  149,  263,  532,\n",
    "        322,  292,  545,   90,  200,   31,  321,  530,  142,  176,  147,\n",
    "        101,  141,  196,  524,  529,  290,   89,  280,   60,   86,   99,\n",
    "        139,  168,   58,  522,  276,   85,  194,  289,   78,  135,  112,\n",
    "        521,   57,   83,   54,  518,  274,  268,  768,  164,   77,  152,\n",
    "        193,   53,  162,  104,  517,  273,  266,   75,   46,  148,   51,\n",
    "        640,  100,   45,  576,  161,  265,  262,   71,  146,   30,  140,\n",
    "         88,  515,   98,   43,   29,  261,  145,  138,   84,  259,   39,\n",
    "         97,   27,   56,   82,  137,   76,  384,  134,   23,   52,  133,\n",
    "        320,   15,   73,   50,   81,  131,   44,   70,  544,  192,  528,\n",
    "        288,  520,  160,  272,   74,   49,  516,   42,   69,   28,  144,\n",
    "         41,   67,   96,  514,   38,  264,  260,  136,   22,   25,   37,\n",
    "         80,  513,   26,  258,   35,  132,   21,  257,   72,   14,   48,\n",
    "         13,   19,  130,   68,   40,   11,  512,   66,  129,    7,   36,\n",
    "         24,   34,  256,   20,   65,   33,   12,  128,   18,   10,   17,\n",
    "          6,    9,   64,    5,    3,   32,   16,    8,    4,    2,    1,\n",
    "          0])\n",
    "        rs = rs[rs<N]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'RM':\n",
    "        rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        Fr = np.argsort(rmweight)[:-K]\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted_last':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds[::-1]\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'rev_polar':\n",
    "\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:target_K].copy()\n",
    "        rs[:target_K] = first_inds[::-1]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    return Fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(codebook):\n",
    "    \"\"\"Calculate pairwise distances between codewords\"\"\"\n",
    "    dists = []\n",
    "    for row1, row2 in combinations(codebook, 2):\n",
    "        distance = (row1-row2).pow(2).sum()\n",
    "        dists.append(np.sqrt(distance.item()))\n",
    "    return dists, np.min(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54073b6",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2a9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_path):\n",
    "    plt.figure()\n",
    "    plt.plot(bers_enc, label='BER')\n",
    "    plt.plot(moving_average(bers_enc, n=10), label='BER moving avg')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Training BER ENC')\n",
    "    plt.savefig(os.path.join(results_save_path, 'training_ber_enc.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Similar plots for losses_enc, bers_dec, losses_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96d3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save models\n",
    "def save_model(polar, iter, results_save_path, best=False):\n",
    "    torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map], \n",
    "               os.path.join(results_save_path, f'Models/fnet_gnet_{iter}.pt'))\n",
    "    if iter > 1:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_path, 'Models/fnet_gnet_final.pt'))\n",
    "    if best:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_path, 'Models/fnet_gnet_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6b82da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCosineAnnealingLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_max, T_warmup, eta_min=0, last_epoch=-1):\n",
    "        self.T_max = T_max\n",
    "        self.T_warmup = T_warmup\n",
    "        self.eta_min = eta_min\n",
    "        super(WarmUpCosineAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.T_warmup:\n",
    "            return [base_lr * self.last_epoch / self.T_warmup for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            k = 1 + math.cos(math.pi * (self.last_epoch - self.T_warmup) / (self.T_max - self.T_warmup))\n",
    "            return [self.eta_min + (base_lr - self.eta_min) * k / 2 for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4986216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n"
     ]
    }
   ],
   "source": [
    "if anomaly:\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "#ID = str(np.random.randint(100000, 999999)) if id is None else id\n",
    "#ID = 207515\n",
    "\n",
    "\n",
    "###############\n",
    "### Polar code\n",
    "##############\n",
    "\n",
    "### Encoder\n",
    "\n",
    "if last_ell is not None:\n",
    "    depth_map = defaultdict(int)\n",
    "    n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "    for d in range(1, n+1):\n",
    "        depth_map[d] = kernel_size\n",
    "    depth_map[n+1] = last_ell\n",
    "    assert np.prod(list(depth_map.values())) == N\n",
    "    polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "else:\n",
    "    polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "info_inds = polar.info_positions\n",
    "frozen_inds = polar.frozen_positions\n",
    "\n",
    "print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "##############\n",
    "### Neural networks\n",
    "##############\n",
    "ell = kernel_size\n",
    "if N == ell: # Kernel pre-training\n",
    "    polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "elif N > ell: # Initialize full network with pretrained kernels\n",
    "    polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "if binary:\n",
    "    load_path = os.path.join(results_save_path, 'Models/fnet_gnet_final.pt')\n",
    "    assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "    results_save_path = os.path.join(results_save_path, 'Binary')\n",
    "    os.makedirs(results_save_path, exist_ok=True)\n",
    "    os.makedirs(results_save_path +'/Models', exist_ok=True)\n",
    "\n",
    "if load_path is not None:\n",
    "    if test:\n",
    "        if test_load_path is None:\n",
    "            print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "    else:\n",
    "        checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "        fnet_dict = checkpoint1[0]\n",
    "        gnet_dict = checkpoint1[1]\n",
    "\n",
    "        polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "        print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "if 'KO' in decoder_type:\n",
    "    dec_params = []\n",
    "    for i in polar.fnet_dict.keys():\n",
    "        for j in polar.fnet_dict[i].keys():\n",
    "            if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                for k in polar.fnet_dict[i][j].keys():\n",
    "                    dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "            else:\n",
    "                dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "elif decoder_type == 'RNN':\n",
    "    dec_params = polar.fnet_dict.parameters()\n",
    "else:\n",
    "    dec_train_iters = 0\n",
    "\n",
    "if 'KO' in encoder_type:\n",
    "    enc_params = []\n",
    "    if shared:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            enc_params += list(polar.gnet_dict[i].parameters())\n",
    "    else:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            for j in polar.gnet_dict[i].keys():\n",
    "                enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "elif encoder_type == 'scaled':\n",
    "    enc_params = [polar.a]\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "else:\n",
    "    enc_train_iters = 0\n",
    "\n",
    "if dec_train_iters > 0:\n",
    "    if optim_name == 'Adam':\n",
    "        dec_optimizer = optim.Adam(dec_params, lr = dec_lr, weight_decay = weight_decay)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    elif optim_name == 'SGD':\n",
    "        dec_optimizer = optim.SGD(dec_params, lr = dec_lr, weight_decay = weight_decay)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    elif optim_name == 'RMS':\n",
    "        dec_optimizer = optim.RMSprop(dec_params, lr = dec_lr, weight_decay = weight_decay)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    if scheduler == 'reduce':\n",
    "        dec_scheduler = optim.lr_scheduler.ReduceLROnPlateau(dec_optimizer, 'min', patience = scheduler_patience)  \n",
    "    elif scheduler == '1cycle':\n",
    "        dec_scheduler = optim.lr_scheduler.OneCycleLR(dec_optimizer, max_lr = dec_lr, total_steps=dec_train_iters*full_iters)  \n",
    "    if scheduler == 'cosine':\n",
    "        dec_scheduler = WarmUpCosineAnnealingLR(optimizer=dec_optimizer,\n",
    "                                            T_max=full_iters,\n",
    "                                            T_warmup=50,\n",
    "                                            eta_min=1e-6)\n",
    "    else:\n",
    "        dec_scheduler = None\n",
    "\n",
    "if enc_train_iters > 0:\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    if scheduler == 'reduce':\n",
    "        enc_scheduler = optim.lr_scheduler.ReduceLROnPlateau(enc_optimizer, 'min', patience = scheduler_patience)  \n",
    "    elif scheduler == '1cycle':\n",
    "        enc_scheduler = optim.lr_scheduler.OneCycleLR(enc_optimizer, max_lr = enc_lr, total_steps=enc_train_iters*full_iters) \n",
    "    if scheduler == 'cosine':\n",
    "        enc_scheduler = WarmUpCosineAnnealingLR(optimizer=enc_optimizer,\n",
    "                                            T_max=full_iters,\n",
    "                                            T_warmup=50,\n",
    "                                            eta_min=1e-6)\n",
    "    else:\n",
    "        enc_scheduler = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'BCE' in loss_type:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'L1':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_type == 'huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "info_positions = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9cdc5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_snr:0.0\n",
      "loaded weights from : DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__0.0_Encoder_KO_-2.0_Decoder/epochs_500_batchsize_20000/Models/fnet_gnet_final.pt\n",
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n",
      "NN weights loaded!\n",
      "enc_snr:-1.0\n",
      "loaded weights from : DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__-1.0_Encoder_KO_-3.0_Decoder/epochs_300_batchsize_20000/Models/fnet_gnet_final.pt\n",
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n",
      "NN weights loaded!\n",
      "enc_snr:-3.0\n",
      "loaded weights from : DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__-3.0_Encoder_KO_-5.0_Decoder/epochs_300_batchsize_20000/Models/fnet_gnet_final.pt\n",
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n",
      "NN weights loaded!\n",
      "enc_snr:1.0\n",
      "loaded weights from : DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__1.0_Encoder_KO_-1.0_Decoder/epochs_300_batchsize_20000/Models/fnet_gnet_final.pt\n",
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n",
      "NN weights loaded!\n",
      "enc_snr:-2.0\n",
      "loaded weights from : DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO__-2.0_Encoder_KO_-4.0_Decoder/epochs_300_batchsize_20000/Models/fnet_gnet_final.pt\n",
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n",
      "NN weights loaded!\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store loaded models\n",
    "models = {}\n",
    "# Load all models\n",
    "for enc_snr, dec_snr in trained_snrs:\n",
    "    print(f'enc_snr:{enc_snr}')\n",
    "    \n",
    "    model_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}/{encoder_type}__{enc_snr}_Encoder_{decoder_type}_{dec_snr}_Decoder/epochs_{full_iters}_batchsize_{batch_size}/Models/fnet_gnet_final.pt\"\n",
    "    print (f'loaded weights from : {model_path}')\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    ## Encoder\n",
    "    if last_ell is not None:\n",
    "        depth_map = defaultdict(int)\n",
    "        n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "        for d in range(1, n+1):\n",
    "            depth_map[d] = kernel_size\n",
    "        depth_map[n+1] = last_ell\n",
    "        assert np.prod(list(depth_map.values())) == N\n",
    "        polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "    else:\n",
    "        polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "    info_inds = polar.info_positions\n",
    "    frozen_inds = polar.frozen_positions\n",
    "\n",
    "    print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "    ##############\n",
    "    ### Neural networks\n",
    "    ##############\n",
    "    ell = kernel_size\n",
    "    if N == ell: # Kernel pre-training\n",
    "        polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "    elif N > ell: # Initialize full network with pretrained kernels\n",
    "        polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "    if binary:\n",
    "        load_path = os.path.join(results_save_path, 'Models/fnet_gnet_final.pt')\n",
    "        assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "        results_save_path = os.path.join(results_save_path, 'Binary')\n",
    "        os.makedirs(results_save_path, exist_ok=True)\n",
    "        os.makedirs(results_save_path +'/Models', exist_ok=True)\n",
    "\n",
    "    if load_path is not None:\n",
    "        if test:\n",
    "            if test_load_path is None:\n",
    "                print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "        else:\n",
    "            checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "            fnet_dict = checkpoint1[0]\n",
    "            gnet_dict = checkpoint1[1]\n",
    "\n",
    "            polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "            print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "    if 'KO' in decoder_type:\n",
    "        dec_params = []\n",
    "        for i in polar.fnet_dict.keys():\n",
    "            for j in polar.fnet_dict[i].keys():\n",
    "                if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                    for k in polar.fnet_dict[i][j].keys():\n",
    "                        dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "                else:\n",
    "                    dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "    elif decoder_type == 'RNN':\n",
    "        dec_params = polar.fnet_dict.parameters()\n",
    "    else:\n",
    "        dec_train_iters = 0\n",
    "\n",
    "    if 'KO' in encoder_type:\n",
    "        enc_params = []\n",
    "        if shared:\n",
    "            for i in polar.gnet_dict.keys():\n",
    "                enc_params += list(polar.gnet_dict[i].parameters())\n",
    "        else:\n",
    "            for i in polar.gnet_dict.keys():\n",
    "                for j in polar.gnet_dict[i].keys():\n",
    "                    enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "    elif encoder_type == 'scaled':\n",
    "        enc_params = [polar.a]\n",
    "        enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "    else:\n",
    "        enc_train_iters = 0\n",
    "    \n",
    "    # Create and load model\n",
    "    model = polar\n",
    "    model.load_nns(checkpoint[0], checkpoint[1], shared=shared)\n",
    "    models[(enc_snr, dec_snr)] = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80ab8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_crc(total_examples = 10**6):\n",
    "    print(\"TESTING with CRC-aided decoding\")\n",
    "    times = []\n",
    "    \n",
    "    if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "        snr_range = [test_snr_start]\n",
    "    else:\n",
    "        snrs_interval = (test_snr_end - test_snr_start)* 1.0 / (snr_points-1)\n",
    "        snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # For polar code testing\n",
    "    ell = 2\n",
    "    Frozen = get_frozen(N, K, rate_profile)\n",
    "    Frozen.sort()\n",
    "    polar_l_2 = PolarCode(int(np.log2(N)), K, Fr=Frozen, infty=infty, hard_decision=hard_decision)\n",
    "    num_batches = total_examples // test_batch_size\n",
    "    bers_SC_test = []\n",
    "    blers_SC_test = [] \n",
    "    bers_deeppolar_test = []\n",
    "    blers_deeppolar_test = []\n",
    "    \n",
    "    for snr in snr_range:\n",
    "        batches_processed = 0\n",
    "        ber_SC = 0\n",
    "        bler_SC = 0\n",
    "        ber_deeppolar = 0\n",
    "        bler_deeppolar = 0\n",
    "        \n",
    "        for _ in range(num_batches):\n",
    "            # Generate random messages\n",
    "            msg_bits = 2 * (torch.rand(test_batch_size, msg_len) < 0.5).float() - 1\n",
    "            msg_bits = msg_bits.to(device)\n",
    "            \n",
    "            # Add CRC\n",
    "            msg_with_crc = crc_encoder.encode(msg_bits)\n",
    "            \n",
    "            # Encode\n",
    "            polar_code = polar_l_2.encode_plotkin(msg_with_crc)\n",
    "            deeppolar_code = models[default_snr].deeppolar_encode(msg_with_crc)\n",
    "            \n",
    "            # Add noise\n",
    "            noisy_polar = polar_l_2.channel(polar_code, snr, noise_type)\n",
    "            noisy_deeppolar = polar_l_2.channel(deeppolar_code, snr, noise_type)\n",
    "            \n",
    "            # Decode\n",
    "            _, decoded_SC = polar_l_2.sc_decode_new(noisy_polar, snr)\n",
    "            decoded_deeppolar = crc_aided_decode_batch(noisy_deeppolar, snr, models, crc_encoder, default_snr)\n",
    "            \n",
    "            # Calculate errors\n",
    "            ber_SC += errors_ber(msg_with_crc, decoded_SC.sign()).item() \n",
    "            bler_SC += errors_bler(msg_with_crc, decoded_SC.sign()).item()\n",
    "            ber_deeppolar += errors_ber(msg_with_crc, decoded_deeppolar.sign()).item() \n",
    "            bler_deeppolar += errors_bler(msg_with_crc, decoded_deeppolar.sign()).item()\n",
    "            \n",
    "            batches_processed += 1\n",
    "            \n",
    "            print(f\"SNR: {snr}dB, batches_processed: {batches_processed}/{num_batches}, SC BER: {ber_SC/batches_processed:.6f}, DeepPolar+ BER: {ber_deeppolar/batches_processed:.6f}\", end='\\r')\n",
    "        \n",
    "        # Store results\n",
    "        bers_SC_test.append(ber_SC/batches_processed)\n",
    "        blers_SC_test.append(bler_SC/batches_processed)\n",
    "        bers_deeppolar_test.append(ber_deeppolar/batches_processed)\n",
    "        blers_deeppolar_test.append(bler_deeppolar/batches_processed)\n",
    "        \n",
    "        print(f\"\\nSNR: {snr}dB Final Results:\")\n",
    "        print(f\"SC - BER: {bers_SC_test[-1]:.6f}, BLER: {blers_SC_test[-1]:.6f}\")\n",
    "        print(f\"DeepPolar+ - BER: {bers_deeppolar_test[-1]:.6f}, BLER: {blers_deeppolar_test[-1]:.6f}\")\n",
    "    \n",
    "    return bers_SC_test, blers_SC_test, bers_deeppolar_test, blers_deeppolar_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a46c77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "    snr_range = [test_snr_start]\n",
    "else:\n",
    "    snrs_interval = (test_snr_end - test_snr_start)* 1.0 / (snr_points-1)\n",
    "    snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfc7c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crc_aided_decode_batch(noisy_code, snr, models, crc_encoder, default_snr):\n",
    "    \"\"\"\n",
    "    Perform CRC-aided list decoding using multiple DeepPolar+ models with batch operations\n",
    "    \"\"\"\n",
    "    batch_size = noisy_code.shape[0]\n",
    "    \n",
    "    # Store all decoded candidates\n",
    "    candidates = []\n",
    "    decoded_bits_list = []\n",
    "    \n",
    "    # Decode with all models (including default)\n",
    "    for (enc_snr, dec_snr), model in models.items():\n",
    "        llrs, decoded_bits = model.deeppolar_decode(noisy_code)\n",
    "        decoded_bits_list.append(decoded_bits)\n",
    "        candidates.append((enc_snr, dec_snr))\n",
    "    \n",
    "    # Stack all decoded bits into a single tensor\n",
    "    # Shape: [num_models, batch_size, message_length]\n",
    "    all_decoded = torch.stack(decoded_bits_list)\n",
    "    \n",
    "    # Check CRC for all candidates in batch\n",
    "    # Shape: [num_models, batch_size]\n",
    "    valid_crc = torch.stack([crc_encoder.check_batch(decoded) for decoded in decoded_bits_list])\n",
    "    \n",
    "    # Find first valid CRC for each batch element\n",
    "    # Shape: [batch_size]\n",
    "    first_valid_indices = valid_crc.float().argmax(dim=0)\n",
    "    \n",
    "    # Create mask for cases where no valid CRC was found\n",
    "    # Shape: [batch_size]\n",
    "    no_valid_crc = ~valid_crc.any(dim=0)\n",
    "    \n",
    "    # Get default model's index\n",
    "    default_idx = candidates.index(default_snr)\n",
    "    \n",
    "    # Where no valid CRC found, use default model's output\n",
    "    first_valid_indices[no_valid_crc] = default_idx\n",
    "    \n",
    "    # Gather the appropriate decoded bits for each batch element\n",
    "    # Convert indices for gather operation\n",
    "    batch_indices = torch.arange(batch_size, device=noisy_code.device)\n",
    "    final_decoded = all_decoded[first_valid_indices, batch_indices]\n",
    "    \n",
    "    return final_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa055026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING with CRC-aided decoding\n",
      "SNR: -5.0dB, batches_processed: 2000/2000, SC BER: 0.166440, DeepPolar+ BER: 0.128481\n",
      "SNR: -5.0dB Final Results:\n",
      "SC - BER: 0.166440, BLER: 0.434553\n",
      "DeepPolar+ - BER: 0.128481, BLER: 0.424920\n",
      "SNR: -4.0dB, batches_processed: 2000/2000, SC BER: 0.072047, DeepPolar+ BER: 0.043735\n",
      "SNR: -4.0dB Final Results:\n",
      "SC - BER: 0.072047, BLER: 0.195569\n",
      "DeepPolar+ - BER: 0.043735, BLER: 0.163842\n",
      "SNR: -3.0dB, batches_processed: 2000/2000, SC BER: 0.020097, DeepPolar+ BER: 0.008103\n",
      "SNR: -3.0dB Final Results:\n",
      "SC - BER: 0.020097, BLER: 0.056018\n",
      "DeepPolar+ - BER: 0.008103, BLER: 0.035433\n",
      "SNR: -2.0dB, batches_processed: 2000/2000, SC BER: 0.003011, DeepPolar+ BER: 0.000757\n",
      "SNR: -2.0dB Final Results:\n",
      "SC - BER: 0.003011, BLER: 0.008527\n",
      "DeepPolar+ - BER: 0.000757, BLER: 0.004067\n",
      "SNR: -1.0dB, batches_processed: 2000/2000, SC BER: 0.000194, DeepPolar+ BER: 0.000032\n",
      "SNR: -1.0dB Final Results:\n",
      "SC - BER: 0.000194, BLER: 0.000561\n",
      "DeepPolar+ - BER: 0.000032, BLER: 0.000248\n"
     ]
    }
   ],
   "source": [
    "# Run the test\n",
    "bers_SC, blers_SC, bers_dp, blers_dp = test_with_crc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34f42683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BER\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "ok = 0\n",
    "plt.semilogy(snr_range, bers_dp, label=\"DeepPolar+ snrlist\", marker='*', linewidth=1.5)\n",
    "\n",
    "plt.semilogy(snr_range, bers_SC, label=\"SC decoder\", marker='^', linewidth=1.5)\n",
    "\n",
    "## BLER\n",
    "plt.semilogy(snr_range, blers_dp, label=\"DeepPolar+ (BLER)\", marker='*', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.semilogy(snr_range, blers_SC, label=\"SC decoder (BLER)\", marker='^', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=16)\n",
    "plt.ylabel(\"Error Rate\", fontsize=16)\n",
    "\n",
    "plt.legend(prop={'size': 15})\n",
    "if test_load_path is not None:\n",
    "    os.makedirs('Polar_Results/figures', exist_ok=True)\n",
    "    fig_save_path = f'Polar_Results/figures/snrlist_DeepPolar_tsnr{trained_snrs}_dsnr_{default_snr}.pdf'\n",
    "    plt.savefig(fig_save_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49ff45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test SNRs : [-5.0, -4.0, -3.0, -2.0, -1.0]\n",
      "\n",
      "Test Sigmas : [1.7782794100389228, 1.5848931924611136, 1.4125375446227544, 1.2589254117941673, 1.1220184543019633]\n",
      "\n",
      "BERs of DeepPolar: [0.12848132421821357, 0.04373478379845619, 0.008103054043545853, 0.0007567297315708856, 3.216216215332679e-05]\n",
      "BERs of SC decoding: [0.166440107986331, 0.07204686475545168, 0.02009710811288096, 0.003011054056827561, 0.00019386486523035272]\n",
      "BLERs of DeepPolar: [0.4249200000000009, 0.16384199999999938, 0.03543299999999987, 0.004066999999999904, 0.0002480000000000002]\n",
      "BLERs of SC decoding: [0.4345530000000016, 0.1955690000000002, 0.0560180000000002, 0.008526999999999903, 0.0005610000000000004]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test SNRs : {}\\n\".format(snr_range))\n",
    "print(f\"Test Sigmas : {[snr_db2sigma(s) for s in snr_range]}\\n\")\n",
    "print(\"BERs of DeepPolar: {0}\".format(bers_dp))\n",
    "print(\"BERs of SC decoding: {0}\".format(bers_SC))\n",
    "print(\"BLERs of DeepPolar: {0}\".format(blers_dp))\n",
    "print(\"BLERs of SC decoding: {0}\".format(blers_SC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c24bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
