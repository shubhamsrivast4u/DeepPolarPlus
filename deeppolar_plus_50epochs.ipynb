{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8752b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc45a",
   "metadata": {},
   "source": [
    "# Configuration variables (previously args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b957ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # Block length\n",
    "K = 37   # Message size\n",
    "kernel_size = 16  # Kernel size (ell)\n",
    "rate_profile = 'polar'  # Rate profiling; choices=['RM', 'polar', 'sorted', 'last', 'rev_polar', 'custom']\n",
    "infty = 1000.  # Infinity value for frozen position LLR in polar dec\n",
    "lse = 'minsum'  # LSE function; choices=['minsum', 'lse']\n",
    "hard_decision = False  # Polar code sc decoding hard decision?\n",
    "\n",
    "# DeepPolar parameters\n",
    "encoder_type = 'KO'  # Type of encoding; choices=['KO', 'scaled', 'polar']\n",
    "decoder_type = 'KO'  # Type of decoding; choices=['KO', 'SC', 'KO_parallel', 'KO_last_parallel']\n",
    "enc_activation = 'selu'  # Activation function\n",
    "dec_activation = 'selu'  # Activation function\n",
    "dropout_p = 0.\n",
    "dec_hidden_size = 128  # Neural network size\n",
    "enc_hidden_size = 64   # Neural network size\n",
    "f_depth = 3  # Decoder neural network depth\n",
    "g_depth = 3  # Encoder neural network depth\n",
    "g_skip_depth = 1  # Encoder neural network skip depth\n",
    "g_skip_layer = 1  # Encoder neural network skip layer\n",
    "onehot = False  # Use onehot representation of prev_decoded_bits\n",
    "shared = False  # Share weights across depth\n",
    "use_skip = True  # Use skip connections\n",
    "use_norm = False  # Use normalization\n",
    "binary = False  # Use binary quantization\n",
    "\n",
    "# Infrastructure parameters\n",
    "id = None  # Optional ID for multiple runs\n",
    "test = False  # Testing mode flag\n",
    "pairwise = False  # Plot codeword pairwise distances\n",
    "epos = False  # Plot error positions\n",
    "seed = None  # Random seed\n",
    "anomaly = False  # Enable anomaly detection\n",
    "dataparallel = False  # Use dataparallel\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture parameters\n",
    "polar_depths = []  # List of depths to use polar encoding/decoding\n",
    "last_ell = None  # Use kernel last_ell last layer\n",
    "\n",
    "\n",
    "# Channel parameters\n",
    "radar_power = None  # Radar power parameter\n",
    "radar_prob = 0.1  # Radar probability parameter\n",
    "\n",
    "# Training parameters\n",
    "full_iters = 50  # Full iterations\n",
    "enc_train_iters = 30  # Encoder iterations\n",
    "dec_train_iters = 300  # Decoder iterations\n",
    "enc_train_snr = 0.  # SNR at which encoder is trained\n",
    "dec_train_snr = -2.  # SNR at which decoder is trained\n",
    "weight_decay = 0.0\n",
    "dec_lr = 0.001  # Decoder Learning rate\n",
    "enc_lr = 0.001  # Encoder Learning rate\n",
    "batch_size = 20000  # Size of batches\n",
    "small_batch_size = 5000  # Size of small batches\n",
    "noise_type = 'awgn'  # Noise type; choices=['fading', 'awgn', 'radar']\n",
    "regularizer = None  # Regularizer type; choices=['std', 'max_deviation','polar']\n",
    "regularizer_weight = 0.001\n",
    "loss_type = 'BCE' # loss function; choices=['MSE', 'BCE', 'BCE_reg', 'L1', 'huber', 'focal', 'BCE_bler']\n",
    "initialization = 'random'  # Initialization type; choices=['random', 'zeros']\n",
    "optim_name = 'Adam'  # Optimizer type; choices=['Adam', 'RMS', 'SGD', 'AdamW']\n",
    "\n",
    "# Testing parameters\n",
    "test_batch_size = 1000  # Size of test batches\n",
    "num_errors = 100  # Test until _ block errors\n",
    "test_snr_start = -5.  # Testing SNR start\n",
    "test_snr_end = -1.   # Testing SNR end\n",
    "snr_points = 5       # Testing SNR num points\n",
    "\n",
    "\n",
    "\n",
    "# Model saving/loading parameters\n",
    "model_save_per = 100  # Model save frequency\n",
    "model_iters = None  # Option to load specific model iteration\n",
    "test_load_path = None  # Path to load test model\n",
    "\n",
    "load_path = None  # Load path \n",
    "kernel_load_path = 'Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new'   # Kernel load path\n",
    "no_fig = False  # Plot figure option\n",
    "\n",
    "\n",
    "# Scheduler parameters\n",
    "scheduler = 'cosine' # choices = ['reduce', '1cycle', 'cosine']\n",
    "scheduler_patience = None  # Scheduler patience\n",
    "batch_schedule = False  # Use batch scheduler\n",
    "batch_patience = 50  # Batch scheduler patience \n",
    "batch_factor = 2  # Batch multiplication factor\n",
    "min_batch_size = 500  # Minimum batch size\n",
    "max_batch_size = 50000  # Maximum batch size\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117821f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da887ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = f\"DeepPolar_Results/attention_Polar_{kernel_size}({N},{K})/Scheme_{rate_profile}/{encoder_type}_Encoder_{decoder_type}_Decoder/epochs_{full_iters}_batchsize_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8140b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path +'/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e521",
   "metadata": {},
   "source": [
    "# Part 1: Core Utilities and Model Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_db2sigma(train_snr):\n",
    "    return 10**(-train_snr*1.0/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a23a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2bb73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a smoother version using product of bit probabilities\n",
    "def soft_bler_loss(logits, targets):\n",
    "    bit_probs = torch.sigmoid(logits)  # For correct bits\n",
    "    bit_probs = torch.where(targets == 1., bit_probs, 1 - bit_probs)\n",
    "    block_probs = torch.prod(bit_probs, dim=1)  # Probability of whole block being correct\n",
    "    return -torch.mean(torch.log(block_probs + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b989d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_ber(y_true, y_pred, mask=None):\n",
    "    if mask == None:\n",
    "        mask=torch.ones(y_true.size(),device=y_true.device)\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "    mask = mask.view(mask.shape[0], -1, 1)\n",
    "    myOtherTensor = (mask*torch.ne(torch.round(y_true), torch.round(y_pred))).float()\n",
    "    res = sum(sum(myOtherTensor))/(torch.sum(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_bler(y_true, y_pred, get_pos = False):\n",
    "    y_true = y_true.view(y_true.shape[0], -1, 1)\n",
    "    y_pred = y_pred.view(y_pred.shape[0], -1, 1)\n",
    "\n",
    "    decoded_bits = torch.round(y_pred).cpu()\n",
    "    X_test = torch.round(y_true).cpu()\n",
    "    tp0 = (abs(decoded_bits-X_test)).view([X_test.shape[0],X_test.shape[1]])\n",
    "    tp0 = tp0.detach().cpu().numpy()\n",
    "    bler_err_rate = sum(np.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
    "\n",
    "    if not get_pos:\n",
    "        return bler_err_rate\n",
    "    else:\n",
    "        err_pos = list(np.nonzero((np.sum(tp0,axis=1)>0).astype(int))[0])\n",
    "        return bler_err_rate, err_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92df8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_signal(input_signal, sigma = 1.0, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 0.05):\n",
    "    data_shape = input_signal.shape\n",
    "    device = input_signal.device\n",
    "    if noise_type == 'awgn':\n",
    "        dist = torch.distributions.Normal(torch.tensor([0.0], device=device), torch.tensor([sigma], device=device))\n",
    "        noise = dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 'fading':\n",
    "        fading_h = torch.sqrt(torch.randn_like(input_signal)**2 + torch.randn_like(input_signal)**2)/np.sqrt(3.14/2.0)\n",
    "        noise = sigma * torch.randn_like(input_signal)\n",
    "        corrupted_signal = fading_h *(input_signal) + noise\n",
    "\n",
    "    elif noise_type == 'radar':\n",
    "        add_pos = np.random.choice([0.0, 1.0], data_shape, p=[1 - radar_prob, radar_prob])\n",
    "        corrupted_signal = radar_power* np.random.standard_normal(size=data_shape) * add_pos\n",
    "        noise = sigma * torch.randn_like(input_signal) +\\\n",
    "                    torch.from_numpy(corrupted_signal).float().to(input_signal.device)\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    elif noise_type == 't-dist':\n",
    "        dist = torch.distributions.StudentT(torch.tensor([vv], device=device))\n",
    "        noise = sigma* dist.sample(input_signal.shape).squeeze()\n",
    "        corrupted_signal = input_signal + noise\n",
    "\n",
    "    return corrupted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e97bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp(x, y):\n",
    "    log_sum_ms = torch.min(torch.abs(x), torch.abs(y))*torch.sign(x)*torch.sign(y)\n",
    "    return log_sum_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5937279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_log_sum_exp_4(x_1, x_2, x_3, x_4):\n",
    "    return min_sum_log_sum_exp(min_sum_log_sum_exp(x_1, x_2), min_sum_log_sum_exp(x_3, x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c239bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, y):\n",
    "    def log_sum_exp_(LLR_vector):\n",
    "        sum_vector = LLR_vector.sum(dim=1, keepdim=True)\n",
    "        sum_concat = torch.cat([sum_vector, torch.zeros_like(sum_vector)], dim=1)\n",
    "        return torch.logsumexp(sum_concat, dim=1)- torch.logsumexp(LLR_vector, dim=1) \n",
    "\n",
    "    Lv = log_sum_exp_(torch.cat([x.unsqueeze(2), y.unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "    return Lv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655fe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bitarray(in_number, bit_width):\n",
    "    binary_string = bin(in_number)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(bit_width, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[bit_width-i-1] = int(binary_string[length-i-1])\n",
    "    return bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a081f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSetBits(n):\n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c3a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, enc_quantize_level = 2, enc_value_limit = 1.0, enc_grad_limit = 0.01, enc_clipping = 'both'):\n",
    "        ctx.save_for_backward(inputs)\n",
    "        assert enc_clipping in ['both', 'inputs']\n",
    "        ctx.enc_clipping = enc_clipping\n",
    "        ctx.enc_value_limit = enc_value_limit\n",
    "        ctx.enc_quantize_level = enc_quantize_level\n",
    "        ctx.enc_grad_limit = enc_grad_limit\n",
    "\n",
    "        x_lim_abs = enc_value_limit\n",
    "        x_lim_range = 2.0 * x_lim_abs\n",
    "        x_input_norm = torch.clamp(inputs, -x_lim_abs, x_lim_abs)\n",
    "\n",
    "        if enc_quantize_level == 2:\n",
    "            outputs_int = torch.sign(x_input_norm)\n",
    "        else:\n",
    "            outputs_int = torch.round((x_input_norm +x_lim_abs) * ((enc_quantize_level - 1.0)/x_lim_range)) * x_lim_range/(enc_quantize_level - 1.0) - x_lim_abs\n",
    "\n",
    "        return outputs_int\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.enc_clipping in ['inputs', 'both']:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input>ctx.enc_value_limit]=0\n",
    "            grad_output[input<-ctx.enc_value_limit]=0\n",
    "\n",
    "        if ctx.enc_clipping in ['gradient', 'both']:\n",
    "            grad_output = torch.clamp(grad_output, -ctx.enc_grad_limit, ctx.enc_grad_limit)\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d695a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'tanh':\n",
    "        return F.tanh\n",
    "    elif activation == 'elu':\n",
    "        return F.elu\n",
    "    elif activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'selu':\n",
    "        return F.selu\n",
    "    elif activation == 'sigmoid':\n",
    "        return F.sigmoid\n",
    "    elif activation == 'gelu':\n",
    "        return F.gelu\n",
    "    elif activation == 'silu':\n",
    "        return F.silu\n",
    "    elif activation == 'mish':\n",
    "        return F.mish\n",
    "    elif activation == 'linear':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Activation function {activation} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c2096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth=3, skip_depth=1, skip_layer=1, ell=2, activation='selu', use_skip=False, augment=False):\n",
    "        super(g_Full, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.ell = ell\n",
    "        self.ell_input_size = input_size//self.ell\n",
    "        self.augment = augment\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "        self.skip_depth = skip_depth\n",
    "        self.skip_layer = skip_layer\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        if self.use_skip:\n",
    "            self.skip = nn.ModuleList([nn.Linear(self.input_size + self.output_size, self.hidden_size, bias=True)])\n",
    "            self.skip.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.skip_depth)])\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        self.linears.extend([nn.Linear(self.hidden_size, self.hidden_size, bias=True) for ii in range(1, self.depth)])\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_augment(msg, ell):\n",
    "        u = msg.clone()\n",
    "        n = int(np.log2(ell))\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, ell, 2*num_bits):\n",
    "                if len(u.shape) == 2:\n",
    "                    u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                elif len(u.shape) == 3:\n",
    "                    u = torch.cat((u[:, :, :i], u[:, :, i:i+num_bits].clone() * u[:, :, i+num_bits: i+2*num_bits], u[:, :, i+num_bits:]), dim=2)\n",
    "\n",
    "        if len(u.shape) == 3:\n",
    "            return u[:, :, :-1]\n",
    "        elif len(u.shape) == 2:\n",
    "            return u[:, :-1]\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y.clone()\n",
    "        for ii, layer in enumerate(self.linears):\n",
    "            if ii != self.depth:\n",
    "                x = self.activation_fn(layer(x))\n",
    "                if self.use_skip and ii == self.skip_layer:\n",
    "                    if len(x.shape) == 3:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=2)\n",
    "                    elif len(x.shape) == 2:\n",
    "                        skip_input = torch.cat([y, g_Full.get_augment(y, self.ell)], dim=1)\n",
    "                    for jj, skip_layer in enumerate(self.skip):\n",
    "                        skip_input = self.activation_fn(skip_layer(skip_input))\n",
    "                    x = x + skip_input\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if self.augment:\n",
    "                    x = x + g_Full.get_augment(y, self.ell)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68d72065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape should be: (batch_size, seq_len, hidden_dim)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class f_Full(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0., activation='selu', depth=3, use_norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.depth = depth\n",
    "        self.use_norm = use_norm\n",
    "        self.activation_fn = get_activation_fn(activation)\n",
    "\n",
    "        # Initial layers same as original f_Full\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input_size, self.hidden_size, bias=True)])\n",
    "        if self.use_norm:\n",
    "            self.norms = nn.ModuleList([nn.LayerNorm(self.hidden_size)])\n",
    "        \n",
    "        # Attention layer after first linear\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,  # Reduced number of heads\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Remaining layers same as original\n",
    "        for ii in range(1, self.depth):\n",
    "            self.linears.append(nn.Linear(self.hidden_size, self.hidden_size, bias=True))\n",
    "            if self.use_norm:\n",
    "                self.norms.append(nn.LayerNorm(self.hidden_size))\n",
    "        self.linears.append(nn.Linear(self.hidden_size, self.output_size, bias=True))\n",
    "\n",
    "    def forward(self, y, aug=None):\n",
    "        x = y.clone()\n",
    "        \n",
    "        # First linear layer\n",
    "        x = self.linears[0](x)\n",
    "        if self.use_norm:\n",
    "            x = self.norms[0](x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        # Reshape for attention: [batch, seq_len, hidden]\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = attn_out if len(y.shape) == 3 else attn_out.squeeze(1)\n",
    "        \n",
    "        # Remaining layers\n",
    "        for ii in range(1, len(self.linears)):\n",
    "            if ii != self.depth:\n",
    "                x = self.linears[ii](x)\n",
    "                if self.use_norm:\n",
    "                    x = self.norms[ii](x)\n",
    "                x = self.activation_fn(x)\n",
    "            else:\n",
    "                x = self.linears[ii](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10845154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        try:\n",
    "            m.bias.data.fill_(0.)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e38e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(actions):\n",
    "    inds = (0.5 + 0.5*actions).long()\n",
    "    return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594f46",
   "metadata": {},
   "source": [
    "# Part 2: Core PolarCode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9da23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarCode:\n",
    "\n",
    "    def __init__(self, n, K, Fr = None, rs = None, use_cuda = True, infty = 1000., hard_decision = False, lse = 'lse'):\n",
    "\n",
    "        assert n>=1\n",
    "        self.n = n\n",
    "        self.N = 2**n\n",
    "        self.K = K\n",
    "        self.G2 = np.array([[1,1],[0,1]])\n",
    "        self.G = np.array([1])\n",
    "        for i in range(n):\n",
    "            self.G = np.kron(self.G, self.G2)\n",
    "        self.G = torch.from_numpy(self.G).float()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.infty = infty\n",
    "        self.hard_decision = hard_decision\n",
    "        self.lse = lse\n",
    "\n",
    "        if Fr is not None:\n",
    "            assert len(Fr) == self.N - self.K\n",
    "            self.frozen_positions = Fr\n",
    "            self.unsorted_frozen_positions = self.frozen_positions\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "            self.info_positions = np.array(list(set(self.frozen_positions) ^ set(np.arange(self.N))))\n",
    "            self.unsorted_info_positions = self.info_positions\n",
    "            self.info_positions.sort()\n",
    "            \n",
    "        else:\n",
    "            if rs is None:\n",
    "                # in increasing order of reliability\n",
    "                self.reliability_seq = np.arange(1023, -1, -1)\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "            else:\n",
    "                self.reliability_seq = rs\n",
    "                self.rs = self.reliability_seq[self.reliability_seq<self.N]\n",
    "\n",
    "                assert len(self.rs) == self.N\n",
    "            # best K bits\n",
    "            self.info_positions = self.rs[:self.K]\n",
    "            self.unsorted_info_positions = self.reliability_seq[self.reliability_seq<self.N][:self.K]\n",
    "            self.info_positions.sort()\n",
    "            self.unsorted_info_positions=np.flip(self.unsorted_info_positions)\n",
    "            # worst N-K bits\n",
    "            self.frozen_positions = self.rs[self.K:]\n",
    "            self.unsorted_frozen_positions = self.rs[self.K:]\n",
    "            self.frozen_positions.sort()\n",
    "\n",
    "\n",
    "            self.CRC_polynomials = {\n",
    "            3: torch.Tensor([1, 0, 1, 1]).int(),\n",
    "            8: torch.Tensor([1, 1, 1, 0, 1, 0, 1, 0, 1]).int(),\n",
    "            16: torch.Tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]).int(),\n",
    "                                    }\n",
    "\n",
    "    def get_G(self, ell):\n",
    "        n = int(np.log2(ell))\n",
    "        G = np.array([1])\n",
    "        for i in range(n):\n",
    "            G = np.kron(G, self.G2)\n",
    "        return G\n",
    "\n",
    "    def encode_plotkin(self, message, scaling = None, custom_info_positions = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "        if custom_info_positions is not None:\n",
    "            info_positions = custom_info_positions\n",
    "        else:\n",
    "            info_positions = self.info_positions\n",
    "        u = torch.ones(message.shape[0], self.N, dtype=torch.float).to(message.device)\n",
    "        u[:, info_positions] = message\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "                # u[:, i:i+num_bits] = u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits].clone\n",
    "        if scaling is not None:\n",
    "            u = (scaling * np.sqrt(self.N)*u)/torch.norm(scaling)\n",
    "        return u\n",
    "    \n",
    "    def channel(self, code, snr, noise_type = 'awgn', vv =5.0, radar_power = 20.0, radar_prob = 5e-2):\n",
    "        if noise_type != \"bsc\":\n",
    "            sigma = snr_db2sigma(snr)\n",
    "        else:\n",
    "            sigma = snr\n",
    "\n",
    "        r = corrupt_signal(code, sigma, noise_type, vv, radar_power, radar_prob)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def define_partial_arrays(self, llrs):\n",
    "        # Initialize arrays to store llrs and partial_sums useful to compute the partial successive cancellation process.\n",
    "        llr_array = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        llr_array[:, self.n] = llrs\n",
    "        partial_sums = torch.zeros(llrs.shape[0], self.n+1, self.N, device=llrs.device)\n",
    "        return llr_array, partial_sums\n",
    "\n",
    "\n",
    "    def updateLLR(self, leaf_position, llrs, partial_llrs = None, prior = None):\n",
    "\n",
    "        #START\n",
    "        depth = self.n\n",
    "        decoded_bits = partial_llrs[:,0].clone()\n",
    "        if prior is None:\n",
    "            prior = torch.zeros(self.N) #priors\n",
    "        llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth, 0, leaf_position, prior, decoded_bits)\n",
    "        return llrs, decoded_bits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def partial_decode(self, llrs, partial_llrs, depth, bit_position, leaf_position, prior, decoded_bits=None):\n",
    "        # Function to call recursively, for partial SC decoder.\n",
    "        # We are assuming that u_0, u_1, .... , u_{leaf_position -1} bits are known.\n",
    "        # Partial sums computes the sums got through Plotkin encoding operations of known bits, to avoid recomputation.\n",
    "        # this function is implemented for rate 1 (not accounting for frozen bits in polar SC decoding)\n",
    "\n",
    "        # print(\"DEPTH = {}, bit_position = {}\".format(depth, bit_position))\n",
    "        half_index = 2 ** (depth - 1)\n",
    "        leaf_position_at_depth = leaf_position // 2**(depth-1) # will tell us whether left_child or right_child\n",
    "\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            # Left child\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position:left_bit_position+1]\n",
    "            elif leaf_position_at_depth == left_bit_position:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                elif self.lse == 'lse':\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]).sum(dim=1, keepdim=True)\n",
    "                #print(Lu.device, prior.device, torch.ones_like(Lu).device)\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu + prior[left_bit_position]*torch.ones_like(Lu)\n",
    "                if self.hard_decision:\n",
    "                    u_hat = torch.sign(Lu)\n",
    "                else:\n",
    "                    u_hat = torch.tanh(Lu/2)\n",
    "\n",
    "                decoded_bits[:, left_bit_position] = u_hat.squeeze(1)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # Right child\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "            if leaf_position_at_depth > right_bit_position:\n",
    "                pass\n",
    "            elif leaf_position_at_depth == right_bit_position:\n",
    "                Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "                llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv + prior[right_bit_position] * torch.ones_like(Lv)\n",
    "                if self.hard_decision:\n",
    "                    v_hat = torch.sign(Lv)\n",
    "                else:\n",
    "                    v_hat = torch.tanh(Lv/2)\n",
    "                decoded_bits[:, right_bit_position] = v_hat.squeeze(1)\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            # LEFT CHILD\n",
    "            # Find likelihood of (u xor v) xor (v) = u\n",
    "            # Lu = log_sum_exp(torch.cat([llrs[:, :half_index].unsqueeze(2), llrs[:, half_index:].unsqueeze(2)], dim=2).permute(0, 2, 1))\n",
    "\n",
    "            left_bit_position = 2*bit_position\n",
    "            if leaf_position_at_depth > left_bit_position:\n",
    "                Lu = llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "                u_hat = partial_llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index]\n",
    "            else:\n",
    "                if self.lse == 'minsum':\n",
    "                    Lu = min_sum_log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                elif self.lse == 'lse':\n",
    "                    # Lu = log_sum_avoid_zero_NaN(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "                    Lu = log_sum_exp(llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index], llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index])\n",
    "\n",
    "                llrs[:, depth-1, left_bit_position*half_index:(left_bit_position+1)*half_index] = Lu\n",
    "                llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, left_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "                return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "            # RIGHT CHILD\n",
    "            right_bit_position = 2*bit_position + 1\n",
    "\n",
    "            Lv = u_hat * llrs[:, depth, left_bit_position*half_index:(left_bit_position+1)*half_index] + llrs[:,depth, (left_bit_position+1)*half_index:(left_bit_position+2)*half_index]\n",
    "            llrs[:, depth-1, right_bit_position*half_index:(right_bit_position+1)*half_index] = Lv\n",
    "            llrs, partial_llrs, decoded_bits = self.partial_decode(llrs, partial_llrs, depth-1, right_bit_position, leaf_position, prior, decoded_bits)\n",
    "\n",
    "            return llrs, partial_llrs, decoded_bits\n",
    "\n",
    "    def updatePartialSums(self, leaf_position, decoded_bits, partial_llrs):\n",
    "\n",
    "        u = decoded_bits.clone()\n",
    "        u[:, leaf_position+1:] = 0\n",
    "\n",
    "        for d in range(0, self.n):\n",
    "            partial_llrs[:, d] = u\n",
    "            num_bits = 2**d\n",
    "            for i in np.arange(0, self.N, 2*num_bits):\n",
    "                # [u v] encoded to [u xor(u,v)]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        partial_llrs[:, self.n] = u\n",
    "        return partial_llrs\n",
    "\n",
    "    def sc_decode_new(self, corrupted_codewords, snr, use_gt = None, channel = 'awgn'):\n",
    "\n",
    "        assert channel in ['awgn', 'bsc']\n",
    "\n",
    "        if channel == 'awgn':\n",
    "            noise_sigma = snr_db2sigma(snr)\n",
    "            llrs = (2/noise_sigma**2)*corrupted_codewords\n",
    "        elif channel == 'bsc':\n",
    "            # snr refers to transition prob\n",
    "            p = (torch.ones(1)*(snr + 1e-9)).to(corrupted_codewords.device)\n",
    "            llrs = (torch.clip(torch.log((1 - p) / p), -10000, 10000) * (corrupted_codewords + 1) - torch.clip(torch.log(p / (1-p)), -10000, 10000) * (corrupted_codewords - 1))/2\n",
    "\n",
    "        # step-wise implementation using updateLLR and updatePartialSums\n",
    "\n",
    "        priors = torch.zeros(self.N)\n",
    "        priors[self.frozen_positions] = self.infty\n",
    "\n",
    "        u_hat = torch.zeros(corrupted_codewords.shape[0], self.N, device=corrupted_codewords.device)\n",
    "        llr_array, partial_llrs = self.define_partial_arrays(llrs)\n",
    "        for ii in range(self.N):\n",
    "            #start = time.time()\n",
    "            llr_array , decoded_bits = self.updateLLR(ii, llr_array.clone(), partial_llrs, priors)\n",
    "            #print('SC update : {}'.format(time.time() - start), corrupted_codewords.shape[0])\n",
    "            if use_gt is None:\n",
    "                u_hat[:, ii] = torch.sign(llr_array[:, 0, ii])\n",
    "            else:\n",
    "                u_hat[:, ii] = use_gt[:, ii]\n",
    "            #start = time.time()\n",
    "            partial_llrs = self.updatePartialSums(ii, u_hat, partial_llrs)\n",
    "            #print('SC partial: {}s, {}', time.time() - start, 'frozen' if ii in self.frozen_positions else 'info')\n",
    "        decoded_bits = u_hat[:, self.info_positions]\n",
    "        return llr_array[:, 0, :].clone(), decoded_bits\n",
    "\n",
    "    def get_CRC(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # inout message should be int\n",
    "\n",
    "        padded_bits = torch.cat([message, torch.zeros(self.CRC_len).int().to(message.device)])\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + self.CRC_len + 1] = padded_bits[cur_shift: cur_shift + self.CRC_len + 1] ^ self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        return padded_bits[self.K_minus_CRC:]\n",
    "\n",
    "    def CRC_check(self, message):\n",
    "\n",
    "        # need to optimize.\n",
    "        # input message should be int\n",
    "\n",
    "        padded_bits = message\n",
    "        while len(padded_bits[0:self.K_minus_CRC].nonzero()):\n",
    "            cur_shift = (padded_bits != 0).int().argmax(0)\n",
    "            padded_bits[cur_shift: cur_shift + polar.CRC_len + 1] ^= self.CRC_polynomials[self.CRC_len].to(message.device)\n",
    "\n",
    "        if padded_bits[self.K_minus_CRC:].sum()>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def encode_with_crc(self, message, CRC_len):\n",
    "        self.CRC_len = CRC_len\n",
    "        self.K_minus_CRC = self.K - CRC_len\n",
    "\n",
    "        if CRC_len == 0:\n",
    "            return self.encode_plotkin(message)\n",
    "        else:\n",
    "            crcs = 1-2*torch.vstack([self.get_CRC((0.5+0.5*message[jj]).int()) for jj in range(message.shape[0])])\n",
    "            encoded = self.encode_plotkin(torch.cat([message, crcs], 1))\n",
    "\n",
    "            return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6d51",
   "metadata": {},
   "source": [
    "# Part 3: DeepPolar Class and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c41f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPolar(PolarCode):\n",
    "    def __init__(self, device, N, K, ell = 2, infty = 1000., depth_map : defaultdict = None):\n",
    "\n",
    "        # rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        # Frozen = np.argsort(rmweight)[:-K]\n",
    "        # Frozen.sort()\n",
    "\n",
    "        #self.args = args\n",
    "        Fr = get_frozen(N, K, rate_profile)\n",
    "        super().__init__(n = int(np.log2(N)), K = K, Fr=Fr,  infty = infty)\n",
    "        self.N = N\n",
    "\n",
    "        if depth_map is not None:\n",
    "            # depth map is a dict, product of values should be equal to N\n",
    "            assert np.prod(list(depth_map.values())) == N\n",
    "            # assert that keys od depth map start from one and go continuosly till some point \n",
    "            assert min(list(depth_map.keys())) == 1\n",
    "            assert max(list(depth_map.keys())) <= int(np.log2(N))\n",
    "            self.ell = None\n",
    "            self.n_ell = len(depth_map.keys())\n",
    "            assert max(list(depth_map.keys())) == self.n_ell\n",
    "\n",
    "            self.depth_map = depth_map\n",
    "        else:\n",
    "            self.ell = ell\n",
    "            self.n_ell = int(np.log(N)/np.log(self.ell))\n",
    "\n",
    "            self.depth_map = defaultdict(int)\n",
    "            for d in range(1, self.n_ell+1):\n",
    "                self.depth_map[d] = self.ell\n",
    "            assert np.prod(list(self.depth_map.values())) == N\n",
    "\n",
    "        self.device = device\n",
    "        self.fnet_dict = None\n",
    "        self.gnet_dict = None\n",
    "\n",
    "        self.infty = infty\n",
    "\n",
    "    @staticmethod\n",
    "    def get_onehot(actions):\n",
    "        inds = (0.5 + 0.5*actions).long()\n",
    "        if len(actions.shape) == 2:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], -1)\n",
    "        elif len(actions.shape) == 3:\n",
    "            return torch.eye(2, device = inds.device)[inds].reshape(actions.shape[0], actions.shape[1], -1)\n",
    "\n",
    "    def define_kernel_nns(self, ell, unfrozen = None, fnet = 'KO', gnet = 'KO', shared = False):\n",
    "\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "        #dec_hidden_size = dec_hidden_size\n",
    "        #enc_hidden_size = enc_hidden_size\n",
    "\n",
    "        depth = 1\n",
    "        assert len(unfrozen) > 0, \"No unfrozen bits!\"\n",
    "\n",
    "        self.fnet_dict[depth] = {}\n",
    "\n",
    "        if fnet == 'KO_parallel' or fnet == 'KO_last_parallel':\n",
    "            bit_position = 0\n",
    "                   \n",
    "            self.fnet_dict[depth][bit_position] = {}\n",
    "            # input_size = self.N if depth == self.n_ell else self.N // int(np.prod([self.depth_map[d] for d in range(depth+1, self.n_ell+1)]))\n",
    "            input_size = ell             \n",
    "            # For curriculum, only for lowest depth.\n",
    "            output_size = ell#len(unfrozen)\n",
    "            self.fnet_dict[depth][bit_position] = f_Full(input_size, dec_hidden_size, output_size, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    " \n",
    "        elif 'KO' in fnet:\n",
    "            if shared:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for current_position in range(ell):\n",
    "                    self.fnet_dict[depth][current_position] = f_Full(ell + current_position, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                for current_position in unfrozen:\n",
    "                    if not self.fnet_dict[depth].get(bit_position):\n",
    "                        self.fnet_dict[depth][bit_position] = {}\n",
    "                    input_size = ell + (int(onehot)+1)*current_position\n",
    "                    self.fnet_dict[depth][bit_position][current_position] = f_Full(input_size, dec_hidden_size, 1, activation = dec_activation, dropout_p = dropout_p, depth = f_depth, use_norm = use_norm).to(self.device)\n",
    "                \n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict[depth] = {}\n",
    "            if shared:\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "            else:\n",
    "                bit_position = 0\n",
    "                if gnet == 'KO':\n",
    "                    self.gnet_dict[depth][bit_position] = g_Full(ell, enc_hidden_size, ell-1, depth = g_depth, skip_depth = g_skip_depth, skip_layer = g_skip_layer, ell = ell, activation = enc_activation, use_skip = use_skip).to(self.device)\n",
    "\n",
    "    def define_and_load_nns(self, ell, kernel_load_path=None, fnet='KO', gnet='KO', shared=True, dataparallel=False):\n",
    "        # Initialize decoder and encoder dictionaries\n",
    "        if 'KO' in fnet:\n",
    "            self.fnet_dict = {}\n",
    "        else:\n",
    "            self.fnet_dict = None\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if 'KO' in gnet:\n",
    "            self.gnet_dict = {}\n",
    "        else:\n",
    "            self.gnet_dict = None\n",
    "\n",
    "        # Loop through each depth level\n",
    "        for depth in range(self.n_ell, 0, -1):\n",
    "            if depth in polar_depths:\n",
    "                continue\n",
    "\n",
    "            ell = self.depth_map[depth]\n",
    "            proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "            # Handle parallel decoder case\n",
    "            if fnet == 'KO_last_parallel' and depth == 1:\n",
    "                self.fnet_dict[depth] = {}\n",
    "                for bit_position in range(self.N // proj_size):\n",
    "                    proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                    get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                    num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                    subproj_len = len(proj) // ell\n",
    "                    subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                    num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                    unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                    input_size = ell             \n",
    "                    output_size = ell\n",
    "\n",
    "                    # Use attention-enhanced decoder for parallel case\n",
    "                    self.fnet_dict[depth][bit_position] = f_Full(\n",
    "                        input_size=input_size,\n",
    "                        hidden_size=dec_hidden_size,\n",
    "                        output_size=output_size,\n",
    "                        activation=dec_activation,\n",
    "                        dropout_p=dropout_p,\n",
    "                        depth=f_depth,\n",
    "                        use_norm=use_norm\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    # Load pretrained weights if available\n",
    "                    if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                        try:\n",
    "                            ckpt = torch.load(os.path.join(kernel_load_path + '_parallel', f'{ell}_{len(unfrozen)}.pt'))\n",
    "                            self.fnet_dict[depth][bit_position].load_state_dict(ckpt[0][1][0].state_dict())\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"Parallel File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                            pass\n",
    "\n",
    "                    if dataparallel:\n",
    "                        self.fnet_dict[depth][bit_position] = nn.DataParallel(self.fnet_dict[depth][bit_position])\n",
    "\n",
    "            # Handle sequential decoder case\n",
    "            elif 'KO' in fnet:\n",
    "                self.fnet_dict[depth] = {}\n",
    "\n",
    "                if shared:\n",
    "                    # Shared decoder network for all positions\n",
    "                    for current_position in range(ell):\n",
    "                        self.fnet_dict[depth][current_position] = f_Full(\n",
    "                            input_size=ell + current_position,\n",
    "                            hidden_size=dec_hidden_size,\n",
    "                            output_size=1,\n",
    "                            activation=dec_activation,\n",
    "                            dropout_p=dropout_p,\n",
    "                            depth=f_depth,\n",
    "                            use_norm=use_norm\n",
    "                        ).to(self.device)\n",
    "\n",
    "                        if dataparallel:\n",
    "                            self.fnet_dict[depth][current_position] = nn.DataParallel(self.fnet_dict[depth][current_position])\n",
    "\n",
    "                else:\n",
    "                    # Individual decoder networks for each position\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                        num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                        subproj_len = len(proj) // ell\n",
    "                        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                        unfrozen = [i for i, x in enumerate(num_info_in_subproj) if x >= 1]\n",
    "\n",
    "                        # Load pretrained weights if available\n",
    "                        ckpt_exists = False\n",
    "                        if len(unfrozen) > 0 and kernel_load_path is not None:\n",
    "                            try:\n",
    "                                ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                ckpt_exists = True\n",
    "                            except FileNotFoundError:\n",
    "                                print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                pass\n",
    "\n",
    "                        # Create decoders for unfrozen positions\n",
    "                        for current_position in unfrozen:\n",
    "                            if not self.fnet_dict[depth].get(bit_position):\n",
    "                                self.fnet_dict[depth][bit_position] = {}\n",
    "\n",
    "                            input_size = ell + (int(onehot)+1)*current_position\n",
    "                            output_size = 1\n",
    "\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = f_Full(\n",
    "                                input_size=input_size,\n",
    "                                hidden_size=dec_hidden_size,\n",
    "                                output_size=output_size,\n",
    "                                activation=dec_activation,\n",
    "                                dropout_p=dropout_p,\n",
    "                                depth=f_depth,\n",
    "                                use_norm=use_norm\n",
    "                            ).to(self.device)\n",
    "\n",
    "                            if ckpt_exists:\n",
    "                                try:\n",
    "                                    f_ckpt = ckpt[0][1][0][current_position].state_dict()\n",
    "                                    self.fnet_dict[depth][bit_position][current_position].load_state_dict(f_ckpt)\n",
    "                                except:\n",
    "                                    print(f\"Warning: Could not load weights for position {current_position}\")\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.fnet_dict[depth][bit_position][current_position] = nn.DataParallel(\n",
    "                                    self.fnet_dict[depth][bit_position][current_position]\n",
    "                                )\n",
    "\n",
    "            # Handle encoder network\n",
    "            if 'KO' in gnet:\n",
    "                self.gnet_dict[depth] = {}\n",
    "                if shared:\n",
    "                    if gnet == 'KO':\n",
    "                        if not dataparallel:\n",
    "                            self.gnet_dict[depth] = g_Full(\n",
    "                                ell, enc_hidden_size, ell-1,\n",
    "                                depth=g_depth,\n",
    "                                skip_depth=g_skip_depth,\n",
    "                                skip_layer=g_skip_layer,\n",
    "                                ell=ell,\n",
    "                                use_skip=use_skip\n",
    "                            ).to(self.device)\n",
    "                        else:\n",
    "                            self.gnet_dict[depth] = nn.DataParallel(\n",
    "                                g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    use_skip=use_skip\n",
    "                                )\n",
    "                            ).to(self.device)\n",
    "                else:\n",
    "                    for bit_position in range(self.N // proj_size):\n",
    "                        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                        num_info_in_proj = sum([int(x in self.info_positions) for x in proj])\n",
    "\n",
    "                        if num_info_in_proj > 0:\n",
    "                            if gnet == 'KO':\n",
    "                                self.gnet_dict[depth][bit_position] = g_Full(\n",
    "                                    ell, enc_hidden_size, ell-1,\n",
    "                                    depth=g_depth,\n",
    "                                    skip_depth=g_skip_depth,\n",
    "                                    skip_layer=g_skip_layer,\n",
    "                                    ell=ell,\n",
    "                                    activation=enc_activation,\n",
    "                                    use_skip=use_skip\n",
    "                                ).to(self.device)\n",
    "\n",
    "                            # Load pretrained weights if available\n",
    "                            if kernel_load_path is not None:\n",
    "                                try:\n",
    "                                    ckpt = torch.load(os.path.join(kernel_load_path, f'{ell}_{len(unfrozen)}.pt'))\n",
    "                                    self.gnet_dict[depth][bit_position].load_state_dict(ckpt[1][1][0].state_dict())\n",
    "                                except FileNotFoundError:\n",
    "                                    print(f\"File not found for ell = {ell}, num_unfrozen = {len(unfrozen)}\")\n",
    "                                    pass\n",
    "\n",
    "                            if dataparallel:\n",
    "                                self.gnet_dict[depth][bit_position] = nn.DataParallel(self.gnet_dict[depth][bit_position])\n",
    "\n",
    "        if kernel_load_path is not None:\n",
    "            print(\"Loaded kernel from \", kernel_load_path)\n",
    "\n",
    "    def load_nns(self, fnet_dict, gnet_dict = None, shared = False):\n",
    "        self.fnet_dict = fnet_dict\n",
    "        self.gnet_dict = gnet_dict\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if self.fnet_dict is not None:\n",
    "                for bit_position in self.fnet_dict[depth].keys():\n",
    "                    if not isinstance(self.fnet_dict[depth][bit_position], dict):#shared or decoder_type == 'KO_parallel' or decoder_type == 'KO_RNN':\n",
    "                        self.fnet_dict[depth][bit_position].to(self.device)\n",
    "                    else:\n",
    "                        for current_position in self.fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "            if gnet_dict is not None:\n",
    "                if shared:\n",
    "                    self.gnet_dict[depth].to(self.device)\n",
    "                else:\n",
    "                    for bit_position in self.gnet_dict[depth].keys():\n",
    "                        self.gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def load_partial_nns(self, fnet_dict, gnet_dict = None):\n",
    "\n",
    "        for depth in fnet_dict.keys():\n",
    "            if fnet_dict is not None:\n",
    "                for bit_position in fnet_dict[depth].keys():\n",
    "                    if isinstance(fnet_dict[depth][bit_position], dict):\n",
    "                        for current_position in fnet_dict[depth][bit_position].keys():\n",
    "                            self.fnet_dict[depth][bit_position][current_position] = fnet_dict[depth][bit_position][current_position].to(self.device)\n",
    "                    else:\n",
    "                        self.fnet_dict[depth][bit_position] = fnet_dict[depth][bit_position].to(self.device)\n",
    "\n",
    "            if gnet_dict is not None:\n",
    "                for bit_position in gnet_dict[depth].keys():\n",
    "                    self.gnet_dict[depth][bit_position] = gnet_dict[depth][bit_position].to(self.device)\n",
    "        print(\"NN weights loaded!\")\n",
    "\n",
    "    def kernel_encode(self, ell, gnet, msg_bits, info_positions, binary = False):\n",
    "        input_shape = msg_bits.shape[-1]\n",
    "        assert input_shape <= ell\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, info_positions] = msg_bits\n",
    "        output =torch.cat([gnet(u.unsqueeze(1)).squeeze(1), u[:, -1:]], 1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(output)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def deeppolar_encode(self, msg_bits, binary = False):\n",
    "        u = torch.ones(msg_bits.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        u[:, self.info_positions] = msg_bits\n",
    "        for d in range(1, self.n_ell+1):\n",
    "            # num_bits = self.ell**(d-1)\n",
    "            num_bits = np.prod([self.depth_map[dd] for dd in range(1, d)]) if d > 1 else 1\n",
    "            # proj_size = self.ell**(d)\n",
    "            proj_size = np.prod([self.depth_map[dd] for dd in range(1, d+1)])\n",
    "            ell = self.depth_map[d]\n",
    "            for bit_position, i in enumerate(np.arange(0, self.N, ell*num_bits)):\n",
    "\n",
    "                # [u v] encoded to [(u xor v),v)]\n",
    "                proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "                get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "                num_info_in_proj = get_num_info_proj(proj)\n",
    "\n",
    "                subproj_len = len(proj) // ell\n",
    "                subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "                num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "                num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "                \n",
    "                if num_info_in_proj > 0:\n",
    "                    info_bits_present = True          \n",
    "                else:\n",
    "                    info_bits_present = False         \n",
    "                if d in polar_depths:\n",
    "                    info_bits_present = False\n",
    "\n",
    "                enc_chunks = []\n",
    "                ell = self.depth_map[d]\n",
    "                for j in range(ell):\n",
    "                    chunk = u[:, i + j*num_bits:i + (j+1)*num_bits].unsqueeze(2).clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[d](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        output = torch.cat([self.gnet_dict[d][bit_position](concatenated_chunks), u[:, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(msg_bits.shape[0], -1, 1).squeeze(2)\n",
    "\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                u = torch.cat((u[:, :i], output, u[:, i + ell*num_bits:]), dim=1)\n",
    "\n",
    "        power_constrained_u = self.power_constraint(u)\n",
    "        if binary:\n",
    "            stequantize = STEQuantize.apply\n",
    "            power_constrained_u = stequantize(power_constrained_u)\n",
    "        return power_constrained_u\n",
    "\n",
    "    def power_constraint(self, codewords):\n",
    "        return F.normalize(codewords, p=2, dim=1)*np.sqrt(self.N)\n",
    "\n",
    "    def encode_chunks_plotkin(self, enc_chunks, ell = None):\n",
    "\n",
    "        # message shape is (batch, k)\n",
    "        # BPSK convention : 0 -> +1, 1 -> -1\n",
    "        # Therefore, xor(a, b) = a*b\n",
    "\n",
    "        # to change for other kernels\n",
    "\n",
    "        if ell is None:\n",
    "            ell = self.ell\n",
    "        assert len(enc_chunks) == ell\n",
    "        chunk_size = enc_chunks[0].shape[1]\n",
    "        batch_size = enc_chunks[0].shape[0]\n",
    "\n",
    "        u = torch.cat(enc_chunks, 1).squeeze(2)\n",
    "        n = int(np.log2(ell))\n",
    "\n",
    "        for d in range(0, n):\n",
    "            num_bits = 2**d * chunk_size\n",
    "            for i in np.arange(0, chunk_size*ell, 2*num_bits):\n",
    "                # [u v] encoded to [(u,v) xor v]\n",
    "                u = torch.cat((u[:, :i], u[:, i:i+num_bits].clone() * u[:, i+num_bits: i+2*num_bits], u[:, i+num_bits:]), dim=1)\n",
    "        return u\n",
    "            \n",
    "    def deeppolar_parallel_decode(self, noisy_code):\n",
    "        # Successive cancellation decoder for polar codes\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "        decoded_llrs  = self.KO_parallel_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "\n",
    "    def deeppolar_parallel_decode_depth(self, llrs, depth, bit_position, decoded_llrs):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        dec_chunks = torch.cat([llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "        Lu = self.fnet_dict[depth][bit_position](dec_chunks)\n",
    "\n",
    "        if depth == 1:\n",
    "            u = torch.tanh(Lu/2)\n",
    "            decoded_llrs[:, left_bit_position + unfrozen] = Lu.squeeze(1)\n",
    "        else:\n",
    "            for index, current_position in enumerate(unfrozen):\n",
    "                bit_position_offset = left_bit_position + current_position                \n",
    "                decoded_llrs = self.deeppolar_parallel_decode_depth(Lu[:, :, index:index+1], depth-1, bit_position_offset, decoded_llrs)\n",
    "\n",
    "        return decoded_llrs\n",
    "            \n",
    "    def deeppolar_decode(self, noisy_code):\n",
    "        assert noisy_code.shape[1] == self.N\n",
    "\n",
    "        depth = self.n_ell\n",
    "\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        \n",
    "        # don't want to go into useless frozen subtrees.\n",
    "        partial_sums = torch.ones(noisy_code.shape[0], self.n_ell+1, self.N, device=noisy_code.device)\n",
    "\n",
    "        # function is recursively called (DFS)\n",
    "        # arguments: Beliefs at the input of node (LLRs at top node), depth of children, bit_position (zero at top node)\n",
    "\n",
    "        decoded_llrs, partial_sums = self.deeppolar_decode_depth(noisy_code.unsqueeze(2), depth, 0, decoded_llrs, partial_sums)\n",
    "        decoded_llrs = decoded_llrs[:, self.info_positions]\n",
    "\n",
    "        return decoded_llrs, torch.sign(decoded_llrs)\n",
    "    \n",
    "    def deeppolar_decode_depth(self, llrs, depth, bit_position, decoded_llrs, partial_sums):\n",
    "        # Function to call recursively, for SC decoder\n",
    "\n",
    "        # half_index = self.ell ** (depth - 1)\n",
    "        half_index = np.prod([self.depth_map[d] for d in range(1, depth)]) if depth > 1 else 1\n",
    "        ell = self.depth_map[depth]\n",
    "        left_bit_position = self.depth_map[depth] *  bit_position \n",
    "\n",
    "        # Check if >1 information bits are present in the current projection. If not, don't use NNs - use polar encoding and minsum SC decoding.\n",
    "        # proj_size = self.ell**(depth)\n",
    "        # size of the projection of tht subtree\n",
    "        proj_size = np.prod([self.depth_map[d] for d in range(1, depth+1)])\n",
    "\n",
    "        # This chunk - finds infrozen positions in this kernel.\n",
    "        proj = np.arange(bit_position*proj_size, (bit_position+1)*proj_size)\n",
    "        get_num_info_proj = lambda proj : sum([int(x in self.info_positions) for x in proj])\n",
    "        get_info_proj = lambda proj : [x for x in proj if x in self.info_positions]\n",
    "\n",
    "        num_info_in_proj = get_num_info_proj(proj)\n",
    "        info_in_proj = get_info_proj(proj)\n",
    "\n",
    "        subproj_len = len(proj) // ell\n",
    "        subproj = [proj[i:i+subproj_len] for i in range(0, len(proj), subproj_len)]\n",
    "        num_info_in_subproj = [get_num_info_proj(x) for x in subproj]\n",
    "        num_nonzero_subproj = sum([int(x != 0) for x in num_info_in_subproj])\n",
    "        unfrozen = np.array([i for i, x in enumerate(num_info_in_subproj) if x >= 1])\n",
    "\n",
    "        if num_nonzero_subproj > 0:\n",
    "            info_bits_present = True      \n",
    "        else:\n",
    "            info_bits_present = False \n",
    "\n",
    "        if depth in polar_depths:\n",
    "            info_bits_present = False\n",
    "                \n",
    "        # This will be input to decoder\n",
    "        dec_chunks = [llrs[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "        # n = 2 tree case\n",
    "        if depth == 1:\n",
    "            if decoder_type == 'KO_last_parallel':\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                Lu = self.fnet_dict[depth][bit_position](concatenated_chunks)[:, 0, unfrozen]\n",
    "                u_hat = torch.tanh(Lu/2)\n",
    "                decoded_llrs[:, left_bit_position + unfrozen] = Lu\n",
    "                partial_sums[:, depth-1, left_bit_position + unfrozen] = u_hat\n",
    "\n",
    "            else:\n",
    "                for current_position in range(ell):\n",
    "                    bit_position_offset = left_bit_position + current_position\n",
    "                    if current_position > 0:\n",
    "                        # I am adding previously decoded bits . (either onehot or normal)\n",
    "                        if onehot:\n",
    "                            prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                        else:\n",
    "                            prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                        dec_chunks.append(prev_decoded)\n",
    "\n",
    "                    if bit_position_offset in self.frozen_positions: # frozen \n",
    "                        # don't update decoded llrs. It already has ones*prior.\n",
    "                        # actually don't need this. can skip.\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = torch.ones_like(partial_sums[:, depth-1, bit_position_offset])\n",
    "                    else: # information bit\n",
    "                        # This is the decoding.\n",
    "                        concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                        if self.shared:\n",
    "                            Lu = self.fnet_dict[depth][current_position](concatenated_chunks)\n",
    "                        else:\n",
    "                            Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "\n",
    "                        u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                        decoded_llrs[:, bit_position_offset] = Lu.squeeze(2).squeeze(1)\n",
    "                        partial_sums[:, depth-1, bit_position_offset] = u_hat.squeeze(1)\n",
    "\n",
    "            # Encoding back the decoded bits - for higher layers.\n",
    "            # # Compute decoded codeword\n",
    "            i = left_bit_position * half_index\n",
    "            # num_bits = self.ell**(depth-1)\n",
    "            num_bits = 1\n",
    "\n",
    "            enc_chunks = []\n",
    "            for j in range(ell):\n",
    "                chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                enc_chunks.append(chunk)\n",
    "            if info_bits_present:\n",
    "                concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                if 'KO' in encoder_type:\n",
    "                    if self.shared:\n",
    "                        output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    else:\n",
    "                        # bit position of the previous depth.\n",
    "                        output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                    output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            else:\n",
    "                output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "            partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "            \n",
    "            return decoded_llrs, partial_sums\n",
    "\n",
    "        # General case\n",
    "        else:\n",
    "            for current_position in range(ell):\n",
    "                bit_position_offset = left_bit_position + current_position\n",
    "\n",
    "                if current_position > 0:\n",
    "                    if onehot:\n",
    "                        prev_decoded = get_onehot(partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).sign()).detach().clone()\n",
    "                    else:\n",
    "                        prev_decoded = partial_sums[:, depth-1, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                    dec_chunks.append(prev_decoded)\n",
    "                concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "\n",
    "                if current_position in unfrozen:\n",
    "                    # General decoding ....\n",
    "                    # add the decoded bit here\n",
    "                    if self.shared:\n",
    "                        Lu = self.fnet_dict[depth][current_position](concatenated_chunks).squeeze(2)\n",
    "                    else:\n",
    "                        # if current_position == 0:\n",
    "                        #     Lu = self.fnet_dict[depth][bit_position][current_position](llrs)\n",
    "                        # else:\n",
    "                        Lu = self.fnet_dict[depth][bit_position][current_position](concatenated_chunks)\n",
    "                    decoded_llrs, partial_sums = self.deeppolar_decode_depth(Lu, depth-1, bit_position_offset, decoded_llrs, partial_sums)\n",
    "                else:\n",
    "                    Lu = self.infty*torch.ones_like(llrs)\n",
    "\n",
    "\n",
    "            # Compute decoded codeword\n",
    "            if depth < self.n_ell :\n",
    "                i = left_bit_position * half_index\n",
    "                # num_bits = self.ell**(depth-1)\n",
    "                num_bits = np.prod([self.depth_map[d] for d in range(1, depth)])\n",
    "                enc_chunks = []\n",
    "                for j in range(ell):\n",
    "                    chunk = torch.sign(partial_sums[:, depth-1, i + j*num_bits:i + (j+1)*num_bits]).unsqueeze(2).detach().clone()\n",
    "                    enc_chunks.append(chunk)\n",
    "                if info_bits_present:\n",
    "                    concatenated_chunks = torch.cat(enc_chunks, 2)\n",
    "                    if 'KO' in encoder_type:\n",
    "                        if self.shared:\n",
    "                            output = torch.cat([self.gnet_dict[depth](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        else:\n",
    "                            # bit position of the previous depth.\n",
    "                            output = torch.cat([self.gnet_dict[depth][bit_position](concatenated_chunks), partial_sums[:, depth-1, i + (ell-1)*num_bits:i + (ell)*num_bits].unsqueeze(2)], dim=2)\n",
    "                        output = output.permute(0,2,1).reshape(llrs.shape[0], -1, 1).squeeze(2)\n",
    "                    else:\n",
    "                        output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                else:\n",
    "                    output = self.encode_chunks_plotkin(enc_chunks, ell)\n",
    "                partial_sums[:, depth, i : i + num_bits*ell] = output.clone()\n",
    "\n",
    "                return decoded_llrs, partial_sums\n",
    "            else: # encoding not required for last level - we have already decoded all bits.\n",
    "                return decoded_llrs, partial_sums\n",
    "\n",
    "\n",
    "    def kernel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = [noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)]\n",
    "\n",
    "        for current_position in range(ell):\n",
    "            if current_position > 0:\n",
    "                if onehot:\n",
    "                    prev_decoded = get_onehot(u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone().sign()).detach().clone()\n",
    "                else:\n",
    "                    prev_decoded = u[:, (current_position -1)*half_index:(current_position)*half_index].unsqueeze(2).clone()\n",
    "                dec_chunks.append(prev_decoded)\n",
    "            if current_position in info_positions:\n",
    "                if current_position in info_positions:\n",
    "                    concatenated_chunks = torch.cat(dec_chunks, 2)\n",
    "                    Lu = fnet_dict[current_position](concatenated_chunks)\n",
    "                    decoded_llrs[:, current_position] = Lu.squeeze(2).squeeze(1)\n",
    "                    u_hat = torch.tanh(Lu/2).squeeze(2)\n",
    "                    u[:, current_position] = u_hat.squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n",
    "\n",
    "    def kernel_parallel_decode(self, ell, fnet_dict, noisy_code, info_positions = None):\n",
    "        input_shape = noisy_code.shape[-1]\n",
    "        noisy_code = noisy_code.unsqueeze(2)\n",
    "        assert input_shape == ell\n",
    "        u = torch.ones(noisy_code.shape[0], self.N, dtype=torch.float).to(self.device)\n",
    "        decoded_llrs = self.infty*torch.ones(noisy_code.shape[0], self.N, device = noisy_code.device)\n",
    "        half_index = 1\n",
    "        dec_chunks = torch.cat([noisy_code[:, (j)*half_index:(j+1)*half_index].clone() for j in range(ell)], 2)\n",
    "\n",
    "        decoded_llrs = fnet_dict(dec_chunks).squeeze(1)\n",
    "        u = torch.tanh(decoded_llrs/2).squeeze(1)\n",
    "        return decoded_llrs[:, info_positions], u[:, info_positions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96d749",
   "metadata": {},
   "source": [
    "# Part 4: Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "279f4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(polar, optimizer, scheduler, batch_size, train_snr, train_iters, criterion, device, info_positions, binary = False, noise_type = 'awgn'):\n",
    "\n",
    "    if N == polar.ell:\n",
    "        assert len(info_positions) == K\n",
    "        kernel = True \n",
    "    else:\n",
    "        kernel = False\n",
    "\n",
    "    for iter in range(train_iters):\n",
    "#         if batch_size > small_batch_size:\n",
    "#             small_batch_size = small_batch_size \n",
    "#         else:\n",
    "#             small_batch_size = batch_size\n",
    "\n",
    "        num_batches = batch_size // small_batch_size\n",
    "        for ii in range(num_batches):\n",
    "            msg_bits = 1 - 2*(torch.rand(small_batch_size, K) > 0.5).float().to(device)\n",
    "            if encoder_type == 'polar':\n",
    "                codes = polar.encode_plotkin(msg_bits)\n",
    "            elif 'KO' in encoder_type:\n",
    "                if kernel:\n",
    "                    codes = polar.kernel_encode(kernel_size, polar.gnet_dict[1][0], msg_bits, info_positions, binary = binary)\n",
    "                else:\n",
    "                    codes = polar.deeppolar_encode(msg_bits, binary = binary)\n",
    "\n",
    "            noisy_codes = polar.channel(codes, train_snr, noise_type)\n",
    "\n",
    "            if 'KO' in decoder_type:\n",
    "                if kernel:\n",
    "                    if decoder_type == 'KO_parallel':\n",
    "                        decoded_llrs, decoded_bits = polar.kernel_parallel_decode(kernel_size, polar.fnet_dict[1][0], noisy_codes, info_positions)\n",
    "                    else:\n",
    "                        decoded_llrs, decoded_bits = polar.kernel_decode(kernel_size, polar.fnet_dict[1][0], noisy_codes, info_positions)\n",
    "                else:\n",
    "                    decoded_llrs, decoded_bits = polar.deeppolar_decode(noisy_codes)\n",
    "            elif decoder_type == 'SC':\n",
    "                decoded_llrs, decoded_bits = polar.sc_decode_new(noisy_codes, train_snr)\n",
    "\n",
    "#             if 'BCE' in loss_type or loss_type == 'focal':\n",
    "#                 loss = criterion(decoded_llrs, 0.5 * msg_bits.to(polar.device) + 0.5)\n",
    "#             else:\n",
    "#                 loss = criterion(torch.tanh(0.5*decoded_llrs), msg_bits.to(polar.device))\n",
    "            \n",
    "#             if regularizer == 'std':\n",
    "#                 if K == 1:\n",
    "#                     loss += regularizer_weight * torch.std(codes, dim=1).mean()\n",
    "#                 elif K == 2:\n",
    "#                     loss += regularizer_weight * (0.5*torch.std(codes[:, ::2], dim=1).mean() + .5*torch.std(codes[:, 1::2], dim=1).mean())\n",
    "#             elif regularizer == 'max_deviation':\n",
    "#                 if K == 1:\n",
    "#                     loss += regularizer_weight * torch.amax(torch.abs(codes - codes.mean(dim=1, keepdim=True)), dim=1).mean()\n",
    "#                 elif K == 2:\n",
    "#                     loss += regularizer_weight * (0.5*torch.amax(torch.abs(codes[:, ::2] - codes[:, ::2].mean(dim=1, keepdim=True)), dim=1).mean() + .5*torch.amax(torch.abs(codes[:, 1::2] - codes[:, 1::2].mean(dim=1, keepdim=True)), dim=1).mean())\n",
    "#             elif regularizer == 'polar':\n",
    "#                 loss += regularizer_weight * F.mse_loss(codes, polar.encode_plotkin(msg_bits))\n",
    "            loss = soft_bler_loss(decoded_llrs, 0.5 * msg_bits.to(polar.device)+0.5) + criterion(decoded_llrs, 0.5 * msg_bits.to(polar.device) + 0.5)\n",
    "            loss = loss/num_batches\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_ber = errors_ber(decoded_bits.sign(), msg_bits.to(polar.device)).item()\n",
    "    \n",
    "    return loss.item(), train_ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d79570aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeppolar_full_test(polar, KO, snr_range, device, info_positions, binary=False, num_errors=100, noise_type = 'awgn'):\n",
    "    bers_KO_test = [0. for _ in snr_range]\n",
    "    blers_KO_test = [0. for _ in snr_range]\n",
    "\n",
    "    bers_SC_test = [0. for _ in snr_range]\n",
    "    blers_SC_test = [0. for _ in snr_range]\n",
    "\n",
    "    kernel = N == KO.ell\n",
    "\n",
    "    print(f\"TESTING until {num_errors} block errors\")\n",
    "    for snr_ind, snr in enumerate(snr_range):\n",
    "        total_block_errors_SC = 0\n",
    "        total_block_errors_KO = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        sigma = snr_db2sigma(snr)  # Assuming SNR is given in dB and noise variance is derived from it\n",
    "\n",
    "        try:\n",
    "            while min(total_block_errors_SC, total_block_errors_KO) <= num_errors:\n",
    "                msg_bits = 2 * (torch.rand(test_batch_size, K) < 0.5).float() - 1\n",
    "                msg_bits = msg_bits.to(device)\n",
    "                polar_code = polar.encode_plotkin(msg_bits)\n",
    "\n",
    "                if 'KO' in encoder_type:\n",
    "                    if kernel:\n",
    "                        KO_polar_code = KO.kernel_encode(kernel_size, KO.gnet_dict[1][0], msg_bits, info_positions, binary=binary)\n",
    "                    else:\n",
    "                        KO_polar_code = KO.deeppolar_encode(msg_bits, binary=binary)\n",
    "\n",
    "                noisy_code = polar.channel(polar_code, snr, noise_type)\n",
    "                noise = noisy_code - polar_code\n",
    "                noisy_KO_code = KO_polar_code + noise if 'KO' in encoder_type else noisy_code\n",
    "\n",
    "                SC_llrs, decoded_SC_msg_bits = polar.sc_decode_new(noisy_code, snr)\n",
    "                ber_SC = errors_ber(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                bler_SC = errors_bler(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                total_block_errors_SC += int(bler_SC*test_batch_size)\n",
    "                if 'KO' in decoder_type:\n",
    "                    if kernel:\n",
    "                        if decoder_type == 'KO_parallel':\n",
    "                            KO_llrs, decoded_KO_msg_bits = KO.kernel_parallel_decode(kernel_size, KO.fnet_dict[1][0], noisy_KO_code, info_positions)\n",
    "                        else:\n",
    "                            KO_llrs, decoded_KO_msg_bits = KO.kernel_decode(kernel_size, KO.fnet_dict[1][0], noisy_KO_code, info_positions)\n",
    "                    else:\n",
    "                        KO_llrs, decoded_KO_msg_bits = KO.deeppolar_decode(noisy_KO_code)\n",
    "                else:  # if SC is also used for KO\n",
    "                    KO_llrs, decoded_KO_msg_bits = KO.sc_decode_new(noisy_KO_code, snr)\n",
    "\n",
    "                ber_KO = errors_ber(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                bler_KO = errors_bler(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                total_block_errors_KO += int(bler_KO*test_batch_size)\n",
    "\n",
    "                batches_processed += 1\n",
    "\n",
    "                # Update accumulative results for logging\n",
    "                bers_KO_test[snr_ind] += ber_KO\n",
    "                bers_SC_test[snr_ind] += ber_SC\n",
    "                blers_KO_test[snr_ind] += bler_KO\n",
    "                blers_SC_test[snr_ind] += bler_SC\n",
    "\n",
    "                # Real-time logging for progress, updating in-place\n",
    "                print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, SC_BER: {bers_SC_test[snr_ind]/batches_processed:.6f}, SC_BLER: {blers_SC_test[snr_ind]/batches_processed:.6f}, KO_BER: {bers_KO_test[snr_ind]/batches_processed:.6f}, KO_BLER: {blers_KO_test[snr_ind]/batches_processed:.6f}, Batches: {batches_processed}\", end='\\r')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            # print(\"\\nInterrupted by user. Finalizing current SNR...\")\n",
    "            pass\n",
    "\n",
    "        # Normalize cumulative metrics by the number of processed batches for accuracy\n",
    "        bers_KO_test[snr_ind] /= (batches_processed + 0.00000001)\n",
    "        bers_SC_test[snr_ind] /= (batches_processed + 0.00000001)\n",
    "        blers_KO_test[snr_ind] /= (batches_processed + 0.00000001)\n",
    "        blers_SC_test[snr_ind] /= (batches_processed + 0.00000001)\n",
    "        print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, SC_BER: {bers_SC_test[snr_ind]:.6f}, SC_BLER: {blers_SC_test[snr_ind]:.6f}, KO_BER: {bers_KO_test[snr_ind]:.6f}, KO_BLER: {blers_KO_test[snr_ind]:.6f}\")\n",
    "\n",
    "    return bers_SC_test, blers_SC_test, bers_KO_test, blers_KO_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e848578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frozen(N, K, rate_profile, target_K = None):\n",
    "    n = int(np.log2(N))\n",
    "    if rate_profile == 'polar':\n",
    "        # computed for SNR = 0\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "\n",
    "            # for RM :(\n",
    "            # rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 3, 5, 8, 4, 2, 1, 0])\n",
    "\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "        elif n<9:\n",
    "            rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "        else:\n",
    "            rs = np.array([1023, 1022, 1021, 1019, 1015, 1007, 1020,  991, 1018, 1017, 1014,\n",
    "       1006,  895, 1013, 1011,  959, 1005,  990, 1003,  989,  767, 1016,\n",
    "        999, 1012,  987,  958,  983,  957, 1010, 1004,  955, 1009,  894,\n",
    "        975,  893, 1002,  951, 1001,  988,  511,  766,  998,  891,  943,\n",
    "        986,  997,  985,  887,  956,  765,  995,  927,  982,  981,  879,\n",
    "        954,  974,  763,  953,  979,  510, 1008,  759,  863,  950,  892,\n",
    "       1000,  973,  949,  509,  890,  971,  996,  942,  751,  984,  889,\n",
    "        507,  947,  831,  886,  967,  941,  764,  926,  980,  994,  939,\n",
    "        885,  993,  735,  878,  925,  503,  762,  883,  978,  935,  703,\n",
    "        495,  952,  877,  761,  972,  923,  977,  948,  758,  862,  875,\n",
    "        919,  970,  757,  861,  508,  969,  750,  946,  479,  888,  639,\n",
    "        871,  911,  830,  940,  859,  755,  966,  945,  749,  506,  884,\n",
    "        938,  965,  829,  734,  924,  855,  505,  747,  963,  937,  882,\n",
    "        934,  827,  733,  447,  992,  847,  876,  501,  921,  702,  494,\n",
    "        881,  760,  743,  933,  502,  918,  874,  922,  823,  731,  499,\n",
    "        860,  756,  931,  701,  873,  493,  727,  917,  870,  976,  815,\n",
    "        910,  383,  968,  478,  858,  754,  699,  491,  869,  944,  748,\n",
    "        638,  915,  477,  719,  909,  964,  255,  799,  504,  857,  854,\n",
    "        753,  828,  746,  695,  487,  907,  637,  867,  853,  475,  936,\n",
    "        962,  446,  732,  826,  745,  846,  500,  825,  903,  687,  932,\n",
    "        635,  471,  445,  742,  880,  498,  730,  851,  822,  382,  920,\n",
    "        845,  741,  443,  700,  729,  631,  492,  872,  961,  726,  821,\n",
    "        930,  497,  381,  843,  463,  916,  739,  671,  623,  490,  929,\n",
    "        439,  814,  819,  868,  752,  914,  698,  725,  839,  856,  476,\n",
    "        813,  718,  908,  486,  723,  866,  489,  607,  431,  697,  379,\n",
    "        811,  798,  913,  575,  717,  254,  694,  636,  474,  807,  715,\n",
    "        906,  797,  693,  865,  960,  852,  744,  634,  473,  795,  905,\n",
    "        485,  415,  483,  470,  444,  375,  850,  740,  686,  902,  824,\n",
    "        691,  253,  711,  633,  844,  685,  630,  901,  367,  791,  928,\n",
    "        728,  820,  849,  783,  670,  899,  738,  842,  683,  247,  469,\n",
    "        441,  442,  462,  251,  737,  438,  467,  351,  629,  841,  724,\n",
    "        679,  669,  496,  461,  818,  380,  437,  627,  622,  459,  378,\n",
    "        239,  488,  667,  838,  430,  484,  812,  621,  319,  817,  435,\n",
    "        377,  696,  722,  912,  606,  810,  864,  716,  837,  721,  714,\n",
    "        809,  796,  455,  472,  619,  835,  692,  663,  223,  414,  904,\n",
    "        427,  806,  482,  632,  713,  690,  848,  605,  373,  252,  794,\n",
    "        429,  710,  684,  615,  805,  900,  655,  468,  366,  603,  413,\n",
    "        574,  481,  371,  250,  793,  466,  423,  374,  689,  628,  440,\n",
    "        365,  709,  789,  803,  411,  573,  682,  249,  460,  790,  668,\n",
    "        599,  350,  707,  246,  681,  465,  571,  626,  436,  407,  782,\n",
    "        191,  127,  363,  620,  666,  458,  245,  349,  677,  434,  678,\n",
    "        591,  787,  399,  457,  359,  238,  625,  840,  567,  736,  665,\n",
    "        428,  376,  781,  898,  618,  675,  318,  454,  662,  243,  897,\n",
    "        347,  836,  816,  720,  433,  604,  617,  779,  808,  661,  834,\n",
    "        712,  804,  833,  559,  237,  453,  426,  222,  317,  775,  372,\n",
    "        343,  412,  235,  543,  614,  451,  425,  422,  613,  370,  221,\n",
    "        315,  480,  335,  659,  654,  364,  190,  369,  248,  653,  688,\n",
    "        231,  410,  602,  611,  802,  792,  421,  651,  601,  598,  708,\n",
    "        311,  219,  572,  597,  788,  570,  409,  590,  362,  801,  680,\n",
    "        464,  406,  419,  348,  647,  786,  215,  589,  706,  361,  676,\n",
    "        566,  189,  595,  244,  569,  303,  405,  358,  456,  346,  398,\n",
    "        565,  242,  126,  705,  780,  587,  624,  664,  236,  187,  357,\n",
    "        432,  785,  558,  674,  207,  403,  397,  452,  345,  563,  778,\n",
    "        241,  316,  342,  616,  660,  557,  125,  234,  183,  287,  355,\n",
    "        583,  673,  395,  424,  314,  220,  777,  341,  612,  658,  123,\n",
    "        175,  774,  555,  233,  334,  542,  450,  313,  391,  230,  652,\n",
    "        368,  218,  339,  600,  119,  333,  657,  610,  773,  541,  310,\n",
    "        420,  159,  229,  650,  551,  596,  609,  408,  217,  449,  188,\n",
    "        309,  214,  331,  111,  539,  360,  771,  649,  302,  418,  594,\n",
    "        896,  227,  404,  646,  186,  588,  832,  568,  213,  417,  301,\n",
    "        307,  356,  402,  800,  564,  327,   95,  206,  240,  535,  593,\n",
    "        645,  586,  344,  396,  185,  401,  211,  354,  299,  585,  286,\n",
    "        562,  643,  182,  205,  124,  232,  285,  295,  181,  556,  582,\n",
    "        527,  394,  340,   63,  203,  561,  353,  448,  122,  283,  393,\n",
    "        581,  554,  174,  390,  704,  312,  338,  228,  179,  784,  199,\n",
    "        553,  121,  173,  389,  540,  579,  332,  118,  672,  550,  337,\n",
    "        158,  279,  271,  416,  216,  308,  387,  538,  549,  226,  330,\n",
    "        776,  171,  212,  117,  110,  329,  656,  157,  772,  306,  326,\n",
    "        225,  167,  115,  537,  534,  184,  109,  300,  547,  305,  210,\n",
    "        155,  533,  325,  352,  608,  400,  298,  204,   94,  648,  284,\n",
    "        209,  151,  180,  107,  770,  297,  392,  323,  592,  202,  644,\n",
    "         93,  294,  178,  103,  143,  282,   62,  336,  201,  120,  172,\n",
    "        198,  769,  584,   91,  388,  293,  177,  526,  278,  281,  642,\n",
    "        525,  531,   61,  170,  116,  197,   87,  156,  277,  114,  560,\n",
    "        169,   59,  291,  580,  275,  523,  641,  270,  195,  552,  519,\n",
    "        166,  224,  578,  108,  269,   79,  154,  113,  548,  577,  536,\n",
    "        328,   55,  106,  165,  153,  150,  386,  208,  324,  546,  385,\n",
    "        267,   47,   92,  163,  296,  304,  105,  102,  149,  263,  532,\n",
    "        322,  292,  545,   90,  200,   31,  321,  530,  142,  176,  147,\n",
    "        101,  141,  196,  524,  529,  290,   89,  280,   60,   86,   99,\n",
    "        139,  168,   58,  522,  276,   85,  194,  289,   78,  135,  112,\n",
    "        521,   57,   83,   54,  518,  274,  268,  768,  164,   77,  152,\n",
    "        193,   53,  162,  104,  517,  273,  266,   75,   46,  148,   51,\n",
    "        640,  100,   45,  576,  161,  265,  262,   71,  146,   30,  140,\n",
    "         88,  515,   98,   43,   29,  261,  145,  138,   84,  259,   39,\n",
    "         97,   27,   56,   82,  137,   76,  384,  134,   23,   52,  133,\n",
    "        320,   15,   73,   50,   81,  131,   44,   70,  544,  192,  528,\n",
    "        288,  520,  160,  272,   74,   49,  516,   42,   69,   28,  144,\n",
    "         41,   67,   96,  514,   38,  264,  260,  136,   22,   25,   37,\n",
    "         80,  513,   26,  258,   35,  132,   21,  257,   72,   14,   48,\n",
    "         13,   19,  130,   68,   40,   11,  512,   66,  129,    7,   36,\n",
    "         24,   34,  256,   20,   65,   33,   12,  128,   18,   10,   17,\n",
    "          6,    9,   64,    5,    3,   32,   16,    8,    4,    2,    1,\n",
    "          0])\n",
    "        rs = rs[rs<N]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'RM':\n",
    "        rmweight = np.array([countSetBits(i) for i in range(N)])\n",
    "        Fr = np.argsort(rmweight)[:-K]\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'sorted_last':\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:K].copy()\n",
    "        first_inds.sort()\n",
    "        rs[:K] = first_inds[::-1]\n",
    "\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    elif rate_profile == 'rev_polar':\n",
    "\n",
    "        if n == 5:\n",
    "            rs = np.array([31, 30, 29, 27, 23, 15, 28, 26, 25, 22, 21, 14, 19, 13, 11, 24,  7, 20, 18, 12, 17, 10,  9,  6,  5,  3, 16,  8,  4,  2,  1,  0])\n",
    "\n",
    "        elif n == 4:\n",
    "            rs = np.array([15, 14, 13, 11, 7, 12, 10, 9, 6, 5, 3, 8, 4, 2, 1, 0])\n",
    "        elif n == 3:\n",
    "            rs = np.array([7, 6, 5, 3, 4, 2, 1, 0])\n",
    "        elif n == 2:\n",
    "            rs = np.array([3, 2, 1, 0])\n",
    "\n",
    "        rs = np.array([256 ,255 ,252 ,254 ,248 ,224 ,240 ,192 ,128 ,253 ,244 ,251 ,250 ,239 ,238 ,247 ,246 ,223 ,222 ,232 ,216 ,236 ,220 ,188 ,208 ,184 ,191 ,190 ,176 ,127 ,126 ,124 ,120 ,249 ,245 ,243 ,242 ,160 ,231 ,230 ,237 ,235 ,234 ,112 ,228 ,221 ,219 ,218 ,212 ,215 ,214 ,189 ,187 ,96 ,186 ,207 ,206 ,183 ,182 ,204 ,180 ,200 ,64 ,175 ,174 ,172 ,125 ,123 ,122 ,119 ,159 ,118 ,158 ,168 ,241 ,116 ,111 ,233 ,156 ,110 ,229 ,227 ,217 ,108 ,213 ,152 ,226 ,95 ,211 ,94 ,205 ,185 ,104 ,210 ,203 ,181 ,92 ,144 ,202 ,179 ,199 ,173 ,178 ,63 ,198 ,121 ,171 ,88 ,62 ,117 ,170 ,196 ,157 ,167 ,60 ,115 ,155 ,109 ,166 ,80 ,114 ,154 ,107 ,56 ,225 ,151 ,164 ,106 ,93 ,150 ,209 ,103 ,91 ,143 ,201 ,102 ,48 ,148 ,177 ,90 ,142 ,197 ,87 ,100 ,61 ,169 ,195 ,140 ,86 ,59 ,32 ,165 ,194 ,113 ,79 ,58 ,153 ,84 ,136 ,55 ,163 ,78 ,105 ,149 ,162 ,54 ,76 ,101 ,47 ,147 ,89 ,52 ,141 ,99 ,46 ,146 ,72 ,85 ,139 ,98 ,31 ,44 ,193 ,138 ,57 ,83 ,30 ,135 ,77 ,40 ,82 ,134 ,161 ,28 ,53 ,75 ,132 ,24 ,51 ,74 ,45 ,145 ,71 ,50 ,16 ,97 ,70 ,43 ,137 ,68 ,42 ,29 ,39 ,81 ,27 ,133 ,38 ,26 ,36 ,131 ,23 ,73 ,22 ,130 ,49 ,15 ,20 ,69 ,14 ,12 ,67 ,41 ,8 ,66 ,37 ,25 ,35 ,34 ,21 ,129 ,19 ,13 ,18 ,11 ,10 ,7 ,65 ,6 ,4 ,33 ,17 ,9 ,5 ,3 ,2 ,1 ]) - 1\n",
    "\n",
    "        rs = rs[rs<N]\n",
    "        first_inds = rs[:target_K].copy()\n",
    "        rs[:target_K] = first_inds[::-1]\n",
    "        Fr = rs[K:].copy()\n",
    "        Fr.sort()\n",
    "\n",
    "    return Fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(codebook):\n",
    "    \"\"\"Calculate pairwise distances between codewords\"\"\"\n",
    "    dists = []\n",
    "    for row1, row2 in combinations(codebook, 2):\n",
    "        distance = (row1-row2).pow(2).sum()\n",
    "        dists.append(np.sqrt(distance.item()))\n",
    "    return dists, np.min(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54073b6",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2a9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_path):\n",
    "    plt.figure()\n",
    "    plt.plot(bers_enc, label='BER')\n",
    "    plt.plot(moving_average(bers_enc, n=10), label='BER moving avg')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Training BER ENC')\n",
    "    plt.savefig(os.path.join(results_save_path, 'training_ber_enc.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Similar plots for losses_enc, bers_dec, losses_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f96d3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save models\n",
    "def save_model(polar, iter, results_save_path, best=False):\n",
    "    torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map], \n",
    "               os.path.join(results_save_path, f'Models/fnet_gnet_{iter}.pt'))\n",
    "    if iter > 1:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_path, 'Models/fnet_gnet_final.pt'))\n",
    "    if best:\n",
    "        torch.save([polar.fnet_dict, polar.gnet_dict, polar.depth_map],\n",
    "                  os.path.join(results_save_path, 'Models/fnet_gnet_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6b82da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCosineAnnealingLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_max, T_warmup, eta_min=0, last_epoch=-1):\n",
    "        self.T_max = T_max\n",
    "        self.T_warmup = T_warmup\n",
    "        self.eta_min = eta_min\n",
    "        super(WarmUpCosineAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.T_warmup:\n",
    "            return [base_lr * self.last_epoch / self.T_warmup for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            k = 1 + math.cos(math.pi * (self.last_epoch - self.T_warmup) / (self.T_max - self.T_warmup))\n",
    "            return [self.eta_min + (base_lr - self.eta_min) * k / 2 for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4986216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen positions : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 124 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 176 177 178 179 180 181 182 184 185 186\n",
      " 188 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 208 209\n",
      " 210 211 212 213 214 216 217 218 220 224 225 226 227 228 229 230 232 233\n",
      " 234 236 240]\n",
      "Loaded kernel from  Polar_Results/curriculum/final_kernels/16_normal_polar_eh64_dh128_selu_new\n"
     ]
    }
   ],
   "source": [
    "if anomaly:\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "#ID = str(np.random.randint(100000, 999999)) if id is None else id\n",
    "#ID = 207515\n",
    "\n",
    "\n",
    "###############\n",
    "### Polar code\n",
    "##############\n",
    "\n",
    "### Encoder\n",
    "\n",
    "if last_ell is not None:\n",
    "    depth_map = defaultdict(int)\n",
    "    n = int(np.log2(N // last_ell) // np.log2(kernel_size))\n",
    "    for d in range(1, n+1):\n",
    "        depth_map[d] = kernel_size\n",
    "    depth_map[n+1] = last_ell\n",
    "    assert np.prod(list(depth_map.values())) == N\n",
    "    polar = DeepPolar(device, N, K, infty = infty, depth_map = depth_map)\n",
    "else:\n",
    "    polar = DeepPolar(device, N, K, kernel_size, infty)\n",
    "\n",
    "info_inds = polar.info_positions\n",
    "frozen_inds = polar.frozen_positions\n",
    "\n",
    "print(\"Frozen positions : {}\".format(frozen_inds))\n",
    "\n",
    "##############\n",
    "### Neural networks\n",
    "##############\n",
    "ell = kernel_size\n",
    "if N == ell: # Kernel pre-training\n",
    "    polar.define_kernel_nns(ell = kernel_size, unfrozen = polar.info_positions, fnet = decoder_type, gnet = encoder_type, shared = shared)\n",
    "elif N > ell: # Initialize full network with pretrained kernels\n",
    "    polar.define_and_load_nns(ell = kernel_size, kernel_load_path=kernel_load_path, fnet = decoder_type, gnet = encoder_type, shared = shared, dataparallel=dataparallel)\n",
    "\n",
    "if binary:\n",
    "    load_path = os.path.join(results_save_path, 'Models/fnet_gnet_final.pt')\n",
    "    assert os.path.exists(load_path), \"Model does not exist!!\"\n",
    "    results_save_path = os.path.join(results_save_path, 'Binary')\n",
    "    os.makedirs(results_save_path, exist_ok=True)\n",
    "    os.makedirs(results_save_path +'/Models', exist_ok=True)\n",
    "\n",
    "if load_path is not None:\n",
    "    if test:\n",
    "        if test_load_path is None:\n",
    "            print(\"WARNING : have you used load_path instead of test_load_path?\")\n",
    "    else:\n",
    "        checkpoint1 = torch.load(load_path , map_location=lambda storage, loc: storage)\n",
    "        fnet_dict = checkpoint1[0]\n",
    "        gnet_dict = checkpoint1[1]\n",
    "\n",
    "        polar.load_partial_nns(fnet_dict, gnet_dict)\n",
    "        print(\"Loaded nets from {}\".format(load_path))\n",
    "\n",
    "if 'KO' in decoder_type:\n",
    "    dec_params = []\n",
    "    for i in polar.fnet_dict.keys():\n",
    "        for j in polar.fnet_dict[i].keys():\n",
    "            if isinstance(polar.fnet_dict[i][j], dict):\n",
    "                for k in polar.fnet_dict[i][j].keys():\n",
    "                    dec_params += list(polar.fnet_dict[i][j][k].parameters())\n",
    "            else:\n",
    "                dec_params += list(polar.fnet_dict[i][j].parameters())\n",
    "elif decoder_type == 'RNN':\n",
    "    dec_params = polar.fnet_dict.parameters()\n",
    "else:\n",
    "    dec_train_iters = 0\n",
    "\n",
    "if 'KO' in encoder_type:\n",
    "    enc_params = []\n",
    "    if shared:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            enc_params += list(polar.gnet_dict[i].parameters())\n",
    "    else:\n",
    "        for i in polar.gnet_dict.keys():\n",
    "            for j in polar.gnet_dict[i].keys():\n",
    "                enc_params += list(polar.gnet_dict[i][j].parameters())\n",
    "elif encoder_type == 'scaled':\n",
    "    enc_params = [polar.a]\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)\n",
    "else:\n",
    "    enc_train_iters = 0\n",
    "\n",
    "if dec_train_iters > 0:\n",
    "    if optim_name == 'Adam':\n",
    "        dec_optimizer = optim.Adam(dec_params, lr = dec_lr, weight_decay = weight_decay)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    elif optim_name == 'SGD':\n",
    "        dec_optimizer = optim.SGD(dec_params, lr = dec_lr, weight_decay = weight_decay)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    elif optim_name == 'RMS':\n",
    "        dec_optimizer = optim.RMSprop(dec_params, lr = dec_lr, weight_decay = weight_decay)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    if scheduler == 'reduce':\n",
    "        dec_scheduler = optim.lr_scheduler.ReduceLROnPlateau(dec_optimizer, 'min', patience = scheduler_patience)  \n",
    "    elif scheduler == '1cycle':\n",
    "        dec_scheduler = optim.lr_scheduler.OneCycleLR(dec_optimizer, max_lr = dec_lr, total_steps=dec_train_iters*full_iters)  \n",
    "    if scheduler == 'cosine':\n",
    "        dec_scheduler = WarmUpCosineAnnealingLR(optimizer=dec_optimizer,\n",
    "                                            T_max=full_iters,\n",
    "                                            T_warmup=10,\n",
    "                                            eta_min=1e-6)\n",
    "    else:\n",
    "        dec_scheduler = None\n",
    "\n",
    "if enc_train_iters > 0:\n",
    "    enc_optimizer = optim.Adam(enc_params, lr = enc_lr)#, momentum=0.9, nesterov=True) #, amsgrad=True)\n",
    "    if scheduler == 'reduce':\n",
    "        enc_scheduler = optim.lr_scheduler.ReduceLROnPlateau(enc_optimizer, 'min', patience = scheduler_patience)  \n",
    "    elif scheduler == '1cycle':\n",
    "        enc_scheduler = optim.lr_scheduler.OneCycleLR(enc_optimizer, max_lr = enc_lr, total_steps=enc_train_iters*full_iters) \n",
    "    if scheduler == 'cosine':\n",
    "        enc_scheduler = WarmUpCosineAnnealingLR(optimizer=enc_optimizer,\n",
    "                                            T_max=full_iters,\n",
    "                                            T_warmup=10,\n",
    "                                            eta_min=1e-6)\n",
    "    else:\n",
    "        enc_scheduler = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'BCE' in loss_type:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'L1':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_type == 'huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss() \n",
    "\n",
    "info_positions = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fec064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen = polar.info_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad2abc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unfrozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "905d1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to save for: 100\n",
      "[1/50] At -2.0 dB, Train Loss: 8.284908294677734 Train BER 0.47940540313720703,                  \n",
      " [1/50] At 0.0 dB, Train Loss: 8.063368797302246 Train BER 0.47367027401924133\n",
      "Time for one full iteration is 7.3470 minutes\n",
      "encoder learning rate: 1.00e-04, decoder learning rate: 1.00e-04\n",
      "[2/50] At -2.0 dB, Train Loss: 5.7846903800964355 Train BER 0.43220001459121704,                  \n",
      " [2/50] At 0.0 dB, Train Loss: 5.69042444229126 Train BER 0.4182540476322174\n",
      "Time for one full iteration is 7.4573 minutes\n",
      "encoder learning rate: 2.00e-04, decoder learning rate: 2.00e-04\n",
      "[3/50] At -2.0 dB, Train Loss: 2.1544625759124756 Train BER 0.11124864965677261,                  \n",
      " [3/50] At 0.0 dB, Train Loss: 0.845924973487854 Train BER 0.03674054145812988\n",
      "Time for one full iteration is 7.5332 minutes\n",
      "encoder learning rate: 3.00e-04, decoder learning rate: 3.00e-04\n",
      "[4/50] At -2.0 dB, Train Loss: 0.8406299352645874 Train BER 0.04114594683051109,                  \n",
      " [4/50] At 0.0 dB, Train Loss: 0.25562039017677307 Train BER 0.013616216368973255\n",
      "Time for one full iteration is 7.3225 minutes\n",
      "encoder learning rate: 4.00e-04, decoder learning rate: 4.00e-04\n",
      "[5/50] At -2.0 dB, Train Loss: 0.29221653938293457 Train BER 0.011897297576069832,                  \n",
      " [5/50] At 0.0 dB, Train Loss: 0.02956935577094555 Train BER 0.0006756756920367479\n",
      "Time for one full iteration is 7.3689 minutes\n",
      "encoder learning rate: 5.00e-04, decoder learning rate: 5.00e-04\n",
      "[6/50] At -2.0 dB, Train Loss: 0.1936604231595993 Train BER 0.007702702656388283,                  \n",
      " [6/50] At 0.0 dB, Train Loss: 0.015606430359184742 Train BER 0.000351351365679875\n",
      "Time for one full iteration is 7.4249 minutes\n",
      "encoder learning rate: 6.00e-04, decoder learning rate: 6.00e-04\n",
      "[7/50] At -2.0 dB, Train Loss: 0.17301295697689056 Train BER 0.006983783561736345,                  \n",
      " [7/50] At 0.0 dB, Train Loss: 0.011193705722689629 Train BER 0.00032972972257994115\n",
      "Time for one full iteration is 7.4064 minutes\n",
      "encoder learning rate: 7.00e-04, decoder learning rate: 7.00e-04\n",
      "[8/50] At -2.0 dB, Train Loss: 0.15033431351184845 Train BER 0.0061837839893996716,                  \n",
      " [8/50] At 0.0 dB, Train Loss: 0.007949771359562874 Train BER 0.000156756752403453\n",
      "Time for one full iteration is 7.3485 minutes\n",
      "encoder learning rate: 8.00e-04, decoder learning rate: 8.00e-04\n",
      "[9/50] At -2.0 dB, Train Loss: 0.11897074431180954 Train BER 0.004999999888241291,                  \n",
      " [9/50] At 0.0 dB, Train Loss: 0.004874001257121563 Train BER 0.00011891892063431442\n",
      "Time for one full iteration is 7.3271 minutes\n",
      "encoder learning rate: 9.00e-04, decoder learning rate: 9.00e-04\n",
      "[10/50] At -2.0 dB, Train Loss: 0.12310201674699783 Train BER 0.0053027025423944,                  \n",
      " [10/50] At 0.0 dB, Train Loss: 0.004685057792812586 Train BER 0.00012432433140929788\n",
      "Time for one full iteration is 7.3781 minutes\n",
      "encoder learning rate: 1.00e-03, decoder learning rate: 1.00e-03\n",
      "[11/50] At -2.0 dB, Train Loss: 0.08280222862958908 Train BER 0.0033459458500146866,                  \n",
      " [11/50] At 0.0 dB, Train Loss: 0.002573983510956168 Train BER 7.027026731520891e-05\n",
      "Time for one full iteration is 7.2931 minutes\n",
      "encoder learning rate: 9.98e-04, decoder learning rate: 9.98e-04\n",
      "[12/50] At -2.0 dB, Train Loss: 0.10457438230514526 Train BER 0.004335135221481323,                  \n",
      " [12/50] At 0.0 dB, Train Loss: 0.0020585842430591583 Train BER 3.783783904509619e-05\n",
      "Time for one full iteration is 7.2718 minutes\n",
      "encoder learning rate: 9.94e-04, decoder learning rate: 9.94e-04\n",
      "[13/50] At -2.0 dB, Train Loss: 0.08485295623540878 Train BER 0.0036054053343832493,                  \n",
      " [13/50] At 0.0 dB, Train Loss: 0.002994607901200652 Train BER 0.0001081081063603051\n",
      "Time for one full iteration is 7.3078 minutes\n",
      "encoder learning rate: 9.86e-04, decoder learning rate: 9.86e-04\n",
      "[14/50] At -2.0 dB, Train Loss: 0.0856700986623764 Train BER 0.003718918887898326,                  \n",
      " [14/50] At 0.0 dB, Train Loss: 0.0016029465477913618 Train BER 4.324324254412204e-05\n",
      "Time for one full iteration is 7.2794 minutes\n",
      "encoder learning rate: 9.76e-04, decoder learning rate: 9.76e-04\n",
      "[15/50] At -2.0 dB, Train Loss: 0.07449667155742645 Train BER 0.0030918919946998358,                  \n",
      " [15/50] At 0.0 dB, Train Loss: 0.0010236847447231412 Train BER 1.6216215954045765e-05\n",
      "Time for one full iteration is 7.3517 minutes\n",
      "encoder learning rate: 9.62e-04, decoder learning rate: 9.62e-04\n",
      "[16/50] At -2.0 dB, Train Loss: 0.07379327714443207 Train BER 0.003189189126715064,                  \n",
      " [16/50] At 0.0 dB, Train Loss: 0.001383356866426766 Train BER 3.783783904509619e-05\n",
      "Time for one full iteration is 7.2584 minutes\n",
      "encoder learning rate: 9.46e-04, decoder learning rate: 9.46e-04\n",
      "[17/50] At -2.0 dB, Train Loss: 0.06547558307647705 Train BER 0.003070270176976919,                  \n",
      " [17/50] At 0.0 dB, Train Loss: 0.0016650859033688903 Train BER 4.86486496811267e-05\n",
      "Time for one full iteration is 7.2518 minutes\n",
      "encoder learning rate: 9.26e-04, decoder learning rate: 9.26e-04\n",
      "[18/50] At -2.0 dB, Train Loss: 0.07102982699871063 Train BER 0.0030270270071923733,                  \n",
      " [18/50] At 0.0 dB, Train Loss: 0.0007223536376841366 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2698 minutes\n",
      "encoder learning rate: 9.05e-04, decoder learning rate: 9.05e-04\n",
      "[19/50] At -2.0 dB, Train Loss: 0.06516829878091812 Train BER 0.0027243243530392647,                  \n",
      " [19/50] At 0.0 dB, Train Loss: 0.0007969310972839594 Train BER 1.081081063603051e-05\n",
      "Time for one full iteration is 7.2567 minutes\n",
      "encoder learning rate: 8.80e-04, decoder learning rate: 8.80e-04\n",
      "[20/50] At -2.0 dB, Train Loss: 0.05614759400486946 Train BER 0.002421621698886156,                  \n",
      " [20/50] At 0.0 dB, Train Loss: 0.0006902204477228224 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2110 minutes\n",
      "encoder learning rate: 8.54e-04, decoder learning rate: 8.54e-04\n",
      "[21/50] At -2.0 dB, Train Loss: 0.052779920399188995 Train BER 0.0022918919567018747,                  \n",
      " [21/50] At 0.0 dB, Train Loss: 0.00048708461690694094 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2556 minutes\n",
      "encoder learning rate: 8.25e-04, decoder learning rate: 8.25e-04\n",
      "[22/50] At -2.0 dB, Train Loss: 0.06459195166826248 Train BER 0.003000000026077032,                  \n",
      " [22/50] At 0.0 dB, Train Loss: 0.0007938995258882642 Train BER 2.162162127206102e-05\n",
      "Time for one full iteration is 7.2510 minutes\n",
      "encoder learning rate: 7.94e-04, decoder learning rate: 7.94e-04\n",
      "[23/50] At -2.0 dB, Train Loss: 0.05621839687228203 Train BER 0.002389189088717103,                  \n",
      " [23/50] At 0.0 dB, Train Loss: 0.00069723732303828 Train BER 2.162162127206102e-05\n",
      "Time for one full iteration is 7.3300 minutes\n",
      "encoder learning rate: 7.61e-04, decoder learning rate: 7.61e-04\n",
      "[24/50] At -2.0 dB, Train Loss: 0.04782414063811302 Train BER 0.001978378277271986,                  \n",
      " [24/50] At 0.0 dB, Train Loss: 0.0010032100835815072 Train BER 4.324324254412204e-05\n",
      "Time for one full iteration is 7.2747 minutes\n",
      "encoder learning rate: 7.27e-04, decoder learning rate: 7.27e-04\n",
      "[25/50] At -2.0 dB, Train Loss: 0.04974013566970825 Train BER 0.002135135233402252,                  \n",
      " [25/50] At 0.0 dB, Train Loss: 0.0006036990671418607 Train BER 1.081081063603051e-05\n",
      "Time for one full iteration is 7.3297 minutes\n",
      "encoder learning rate: 6.92e-04, decoder learning rate: 6.92e-04\n",
      "[26/50] At -2.0 dB, Train Loss: 0.04586533084511757 Train BER 0.0018756756326183677,                  \n",
      " [26/50] At 0.0 dB, Train Loss: 0.0006768123130314052 Train BER 2.7027026590076275e-05\n",
      "Time for one full iteration is 7.2507 minutes\n",
      "encoder learning rate: 6.55e-04, decoder learning rate: 6.55e-04\n",
      "[27/50] At -2.0 dB, Train Loss: 0.05400943011045456 Train BER 0.002324324334040284,                  \n",
      " [27/50] At 0.0 dB, Train Loss: 0.0007021035999059677 Train BER 2.7027026590076275e-05\n",
      "Time for one full iteration is 7.3236 minutes\n",
      "encoder learning rate: 6.17e-04, decoder learning rate: 6.17e-04\n",
      "[28/50] At -2.0 dB, Train Loss: 0.05183127522468567 Train BER 0.002248648554086685,                  \n",
      " [28/50] At 0.0 dB, Train Loss: 0.0006499907467514277 Train BER 1.6216215954045765e-05\n",
      "Time for one full iteration is 7.3274 minutes\n",
      "encoder learning rate: 5.79e-04, decoder learning rate: 5.79e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/50] At -2.0 dB, Train Loss: 0.047022268176078796 Train BER 0.0021081080194562674,                  \n",
      " [29/50] At 0.0 dB, Train Loss: 0.0006223446107469499 Train BER 1.6216215954045765e-05\n",
      "Time for one full iteration is 7.4467 minutes\n",
      "encoder learning rate: 5.40e-04, decoder learning rate: 5.40e-04\n",
      "[30/50] At -2.0 dB, Train Loss: 0.03980370610952377 Train BER 0.0016594594344496727,                  \n",
      " [30/50] At 0.0 dB, Train Loss: 0.00040340080158784986 Train BER 1.081081063603051e-05\n",
      "Time for one full iteration is 7.4522 minutes\n",
      "encoder learning rate: 5.01e-04, decoder learning rate: 5.01e-04\n",
      "[31/50] At -2.0 dB, Train Loss: 0.04789822921156883 Train BER 0.002135135233402252,                  \n",
      " [31/50] At 0.0 dB, Train Loss: 0.0004227725730743259 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.3258 minutes\n",
      "encoder learning rate: 4.61e-04, decoder learning rate: 4.61e-04\n",
      "[32/50] At -2.0 dB, Train Loss: 0.0449778251349926 Train BER 0.0020702702458947897,                  \n",
      " [32/50] At 0.0 dB, Train Loss: 0.0002928034809883684 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.1804 minutes\n",
      "encoder learning rate: 4.22e-04, decoder learning rate: 4.22e-04\n",
      "[33/50] At -2.0 dB, Train Loss: 0.04181383177638054 Train BER 0.0018270270666107535,                  \n",
      " [33/50] At 0.0 dB, Train Loss: 0.0005337834008969367 Train BER 1.081081063603051e-05\n",
      "Time for one full iteration is 7.2336 minutes\n",
      "encoder learning rate: 3.84e-04, decoder learning rate: 3.84e-04\n",
      "[34/50] At -2.0 dB, Train Loss: 0.044896550476551056 Train BER 0.0020486486610025167,                  \n",
      " [34/50] At 0.0 dB, Train Loss: 0.0004361826286185533 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2706 minutes\n",
      "encoder learning rate: 3.46e-04, decoder learning rate: 3.46e-04\n",
      "[35/50] At -2.0 dB, Train Loss: 0.046326491981744766 Train BER 0.0019189189188182354,                  \n",
      " [35/50] At 0.0 dB, Train Loss: 0.00023795876768417656 Train BER 0.0\n",
      "Time for one full iteration is 7.2810 minutes\n",
      "encoder learning rate: 3.09e-04, decoder learning rate: 3.09e-04\n",
      "[36/50] At -2.0 dB, Train Loss: 0.04851076379418373 Train BER 0.0018702702363952994,                  \n",
      " [36/50] At 0.0 dB, Train Loss: 0.000993116176687181 Train BER 1.6216215954045765e-05\n",
      "Time for one full iteration is 7.2343 minutes\n",
      "encoder learning rate: 2.74e-04, decoder learning rate: 2.74e-04\n",
      "[37/50] At -2.0 dB, Train Loss: 0.03690524026751518 Train BER 0.0016540540382266045,                  \n",
      " [37/50] At 0.0 dB, Train Loss: 0.00047462727525271475 Train BER 1.6216215954045765e-05\n",
      "Time for one full iteration is 7.1841 minutes\n",
      "encoder learning rate: 2.40e-04, decoder learning rate: 2.40e-04\n",
      "[38/50] At -2.0 dB, Train Loss: 0.034507714211940765 Train BER 0.0014216216513887048,                  \n",
      " [38/50] At 0.0 dB, Train Loss: 0.0007776857237331569 Train BER 2.162162127206102e-05\n",
      "Time for one full iteration is 7.1520 minutes\n",
      "encoder learning rate: 2.07e-04, decoder learning rate: 2.07e-04\n",
      "[39/50] At -2.0 dB, Train Loss: 0.04001186415553093 Train BER 0.0017297297017648816,                  \n",
      " [39/50] At 0.0 dB, Train Loss: 0.0002424777194391936 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.1600 minutes\n",
      "encoder learning rate: 1.76e-04, decoder learning rate: 1.76e-04\n",
      "[40/50] At -2.0 dB, Train Loss: 0.04837948456406593 Train BER 0.002318918937817216,                  \n",
      " [40/50] At 0.0 dB, Train Loss: 0.0002137527771992609 Train BER 0.0\n",
      "Time for one full iteration is 7.2761 minutes\n",
      "encoder learning rate: 1.47e-04, decoder learning rate: 1.47e-04\n",
      "[41/50] At -2.0 dB, Train Loss: 0.033828869462013245 Train BER 0.0014162162551656365,                  \n",
      " [41/50] At 0.0 dB, Train Loss: 0.0002797377237584442 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2807 minutes\n",
      "encoder learning rate: 1.21e-04, decoder learning rate: 1.21e-04\n",
      "[42/50] At -2.0 dB, Train Loss: 0.034570034593343735 Train BER 0.0014918919187039137,                  \n",
      " [42/50] At 0.0 dB, Train Loss: 0.00018340235692448914 Train BER 0.0\n",
      "Time for one full iteration is 7.3350 minutes\n",
      "encoder learning rate: 9.64e-05, decoder learning rate: 9.64e-05\n",
      "[43/50] At -2.0 dB, Train Loss: 0.042159151285886765 Train BER 0.0017621621955186129,                  \n",
      " [43/50] At 0.0 dB, Train Loss: 0.0003867232007905841 Train BER 1.081081063603051e-05\n",
      "Time for one full iteration is 7.2762 minutes\n",
      "encoder learning rate: 7.46e-05, decoder learning rate: 7.46e-05\n",
      "[44/50] At -2.0 dB, Train Loss: 0.031374379992485046 Train BER 0.0013675675727427006,                  \n",
      " [44/50] At 0.0 dB, Train Loss: 0.00019513217557687312 Train BER 0.0\n",
      "Time for one full iteration is 7.2287 minutes\n",
      "encoder learning rate: 5.54e-05, decoder learning rate: 5.54e-05\n",
      "[45/50] At -2.0 dB, Train Loss: 0.048744045197963715 Train BER 0.002199999988079071,                  \n",
      " [45/50] At 0.0 dB, Train Loss: 0.00027968152426183224 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2659 minutes\n",
      "encoder learning rate: 3.90e-05, decoder learning rate: 3.90e-05\n",
      "[46/50] At -2.0 dB, Train Loss: 0.03556685149669647 Train BER 0.0015351350884884596,                  \n",
      " [46/50] At 0.0 dB, Train Loss: 0.00046727765584364533 Train BER 1.081081063603051e-05\n",
      "Time for one full iteration is 7.2802 minutes\n",
      "encoder learning rate: 2.54e-05, decoder learning rate: 2.54e-05\n",
      "[47/50] At -2.0 dB, Train Loss: 0.03827003017067909 Train BER 0.0017837837804108858,                  \n",
      " [47/50] At 0.0 dB, Train Loss: 0.0001736796402838081 Train BER 0.0\n",
      "Time for one full iteration is 7.3065 minutes\n",
      "encoder learning rate: 1.48e-05, decoder learning rate: 1.48e-05\n",
      "[48/50] At -2.0 dB, Train Loss: 0.0356375053524971 Train BER 0.001427027047611773,                  \n",
      " [48/50] At 0.0 dB, Train Loss: 0.00021495029795914888 Train BER 5.405405318015255e-06\n",
      "Time for one full iteration is 7.2877 minutes\n",
      "encoder learning rate: 7.15e-06, decoder learning rate: 7.15e-06\n",
      "[49/50] At -2.0 dB, Train Loss: 0.02758801355957985 Train BER 0.001135135185904801,                  \n",
      " [49/50] At 0.0 dB, Train Loss: 0.0003032989043276757 Train BER 0.0\n",
      "Time for one full iteration is 7.3056 minutes\n",
      "encoder learning rate: 2.54e-06, decoder learning rate: 2.54e-06\n",
      "[50/50] At -2.0 dB, Train Loss: 0.031672243028879166 Train BER 0.0013081080978736281,                  \n",
      " [50/50] At 0.0 dB, Train Loss: 0.0001780739112291485 Train BER 0.0\n",
      "Time for one full iteration is 7.2576 minutes\n",
      "encoder learning rate: 1.00e-06, decoder learning rate: 1.00e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    " if not test:\n",
    "    bers_enc = []\n",
    "    losses_enc = []\n",
    "    bers_dec = []\n",
    "    losses_dec = []\n",
    "    train_ber_dec = 0.\n",
    "    train_ber_enc = 0.\n",
    "    loss_dec = 0.\n",
    "    loss_enc = 0.\n",
    "   \n",
    "    \n",
    "\n",
    "    # Create CSV at the beginning of training\n",
    "    #save_path_id = random.randint(100000, 999999)\n",
    "    with open(os.path.join(results_save_path, f'training_results.csv'), 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Step', 'Loss', 'BER'])\n",
    "\n",
    "        # save args in a json file\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Need to save for:\", model_save_per)\n",
    "    if not batch_schedule:\n",
    "        batch_size = batch_size \n",
    "    else:\n",
    "        batch_size = min_batch_size \n",
    "        best_batch_ber = 10.\n",
    "        best_batch_iter = 0\n",
    "    try:\n",
    "        best_ber = 10.\n",
    "        for iter in range(1, full_iters + 1):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if not batch_schedule:\n",
    "                batch_size = batch_size \n",
    "            elif batch_size != max_batch_size:\n",
    "                if iter - best_batch_iter > batch_patience:\n",
    "                    batch_size = min(batch_size * 2, max_batch_size)\n",
    "                    print(f\"Increased batch size to {batch_size}\")\n",
    "                    best_batch_ber = train_ber_enc\n",
    "                    best_batch_iter = iter                        \n",
    "            if 'KO' in decoder_type or decoder_type == 'RNN':\n",
    "                # Train decoder\n",
    "                loss_dec, train_ber_dec = train(polar, dec_optimizer, \n",
    "                                      dec_scheduler if scheduler in ['1cycle'] else None,\n",
    "                                      batch_size, dec_train_snr, dec_train_iters, \n",
    "                                      criterion, device, info_positions, \n",
    "                                      binary=binary, noise_type=noise_type)\n",
    "                # Update ReduceLROnPlateau scheduler if used\n",
    "                if scheduler == 'reduce':\n",
    "                    dec_scheduler.step(loss_dec)                 \n",
    "                bers_dec.append(train_ber_dec)\n",
    "                losses_dec.append(loss_dec)\n",
    "            if 'KO' in encoder_type:\n",
    "                # Train encoder\n",
    "                loss_enc, train_ber_enc = train(polar, enc_optimizer,\n",
    "                                      enc_scheduler if scheduler in ['1cycle'] else None,\n",
    "                                      batch_size, enc_train_snr, enc_train_iters,\n",
    "                                      criterion, device, info_positions,\n",
    "                                      binary=binary, noise_type=noise_type)\n",
    "                # Update ReduceLROnPlateau scheduler if used\n",
    "                if scheduler == 'reduce':\n",
    "                    enc_scheduler.step(loss_enc)                 \n",
    "                bers_enc.append(train_ber_enc)\n",
    "                losses_enc.append(loss_enc)  \n",
    "            if scheduler == 'cosine':\n",
    "                dec_scheduler.step() \n",
    "                enc_scheduler.step()\n",
    "\n",
    "\n",
    "            if batch_schedule and train_ber_enc < best_batch_ber:\n",
    "                best_batch_ber = train_ber_enc\n",
    "                best_batch_iter = iter\n",
    "                print(f'Best BER {best_batch_ber} at {best_batch_iter}')\n",
    "\n",
    "            # Save to CSV\n",
    "            with open(os.path.join(results_save_path, f'training_results.csv'), 'a', newline='') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile)\n",
    "                csvwriter.writerow([iter, loss_enc, train_ber_enc, loss_dec, train_ber_dec])\n",
    "            \n",
    "            print(f\"[{iter}/{full_iters}] At {dec_train_snr} dB, Train Loss: {loss_dec} Train BER {train_ber_dec}, \\\n",
    "                  \\n [{iter}/{full_iters}] At {enc_train_snr} dB, Train Loss: {loss_enc} Train BER {train_ber_enc}\")\n",
    "            print(\"Time for one full iteration is {0:.4f} minutes\".format((time.time() - start_time)/60))\n",
    "            print(f'encoder learning rate: {enc_optimizer.param_groups[0][\"lr\"]:.2e}, decoder learning rate: {dec_optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "            if iter % model_save_per == 0 or iter == 1:\n",
    "                if train_ber_enc < best_ber:\n",
    "                    best_ber = train_ber_enc\n",
    "                    best = True \n",
    "                else:\n",
    "                    best = False\n",
    "                save_model(polar, iter, results_save_path, best = best)\n",
    "                plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_path)\n",
    "        save_model(polar, iter, results_save_path)\n",
    "        plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_path)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        save_model(polar, iter, results_save_path)\n",
    "        plot_stuff(bers_enc, losses_enc, bers_dec, losses_dec, results_save_path)\n",
    "\n",
    "        print(\"Exited and saved\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053eafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepPolar_Results/attention_Polar_16(256,37)/Scheme_polar/KO_Encoder_KO_Decoder/epochs_50_batchsize_20000'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e6b672b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "NN weights loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "times = []\n",
    "results_load_path = results_save_path\n",
    "\n",
    "\n",
    "if model_iters is not None:\n",
    "    checkpoint1 = torch.load(results_save_path +'/Models/fnet_gnet_{}.pt'.format(model_iters), map_location=lambda storage, loc: storage)\n",
    "elif test_load_path is not None:\n",
    "    checkpoint1 = torch.load(test_load_path , map_location=lambda storage, loc: storage)\n",
    "else:\n",
    "    checkpoint1 = torch.load(results_load_path +'/Models/fnet_gnet_final.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "fnet_dict = checkpoint1[0]\n",
    "gnet_dict = checkpoint1[1]\n",
    "\n",
    "polar.load_nns(fnet_dict, gnet_dict, shared = shared)\n",
    "\n",
    "if snr_points == 1 and test_snr_start == test_snr_end:\n",
    "    snr_range = [test_snr_start]\n",
    "else:\n",
    "    snrs_interval = (test_snr_end - test_snr_start)* 1.0 /  (snr_points-1)\n",
    "    snr_range = [snrs_interval* item + test_snr_start for item in range(snr_points)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# For polar code testing.\n",
    "\n",
    "ell = 2\n",
    "Frozen = get_frozen(N, K, rate_profile)\n",
    "Frozen.sort()\n",
    "polar_l_2 = PolarCode(int(np.log2(N)), K, Fr=Frozen, infty = infty, hard_decision=hard_decision)\n",
    "\n",
    "\n",
    "if pairwise:\n",
    "    codebook_size = 1000\n",
    "    all_msg_bits = 2 * (torch.rand(codebook_size, K, device = device) < 0.5).float() - 1\n",
    "    deeppolar_codebook = polar.deeppolar_encode(all_msg_bits)\n",
    "    polar_codebook = polar_l_2.encode_plotkin(all_msg_bits)\n",
    "    gaussian_codebook = F.normalize(torch.randn(codebook_size, N), p=2, dim=1)*np.sqrt(N)\n",
    "\n",
    "    from scipy import stats\n",
    "    w_statistic_deeppolar, p_value_deeppolar = stats.shapiro(deeppolar_codebook.detach().cpu().numpy())\n",
    "    w_statistic_gaussian, p_value_gaussian = stats.shapiro(gaussian_codebook.detach().cpu().numpy())\n",
    "    w_statistic_polar, p_value_polar = stats.shapiro(polar_codebook.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Deeppolar Shapiro test W = {w_statistic_deeppolar}, p-value = {p_value_deeppolar}\")\n",
    "    print(f\"Gaussian Shapiro test W = {w_statistic_gaussian}, p-value = {p_value_gaussian}\")\n",
    "    print(f\"Polar Shapiro test W = {w_statistic_polar}, p-value = {p_value_polar}\")\n",
    "\n",
    "    dists_deeppolar, md_deeppolar = pairwise_distances(deeppolar_codebook)\n",
    "    dists_polar, md_polar = pairwise_distances(polar_codebook)\n",
    "    dists_gaussian, md_gaussian = pairwise_distances(gaussian_codebook)\n",
    "\n",
    "    # Function to calculate and plot PDF\n",
    "    def plot_pdf(data, label, bins=30, alpha=0.5):\n",
    "        counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, counts, label=label, alpha=alpha)\n",
    "\n",
    "    # Plotting PDF for each list\n",
    "    plt.figure()\n",
    "    plot_pdf(dists_deeppolar, 'Neural', 300)\n",
    "    # plot_pdf(dists_polar, 'Polar', 300)\n",
    "    plot_pdf(dists_gaussian, 'Gaussian', 300)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title(f'Pairwise Distances - N = {N}, K = {K}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(os.path.join(results_save_path, f\"hists_N{N}_K{K}_{id}_2.pdf\"))\n",
    "    plt.show()\n",
    "    print(f'dists_deeppolar: {dists_deeppolar}')\n",
    "    print(f'dists_gaussian: {dists_gaussian}')\n",
    "if epos:\n",
    "    from collections import OrderedDict, Counter\n",
    "\n",
    "    def get_epos(k1, k2):\n",
    "        # return counter for bit ocations of first-errors\n",
    "        bb = torch.ne(k1.cpu().sign(), k2.cpu().sign())\n",
    "        # inds = torch.nonzero(bb)[:, 1].numpy()\n",
    "        idx = []\n",
    "        for ii in range(bb.shape[0]):\n",
    "            try:\n",
    "                iii = list(bb.cpu().float().numpy()[ii]).index(1)\n",
    "                idx.append(iii)\n",
    "            except:\n",
    "                pass\n",
    "        counter = Counter(idx)\n",
    "        ordered_counter = OrderedDict(sorted(counter.items()))\n",
    "        return ordered_counter\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (k, msg_bits) in enumerate(Test_Data_Generator):\n",
    "            msg_bits = msg_bits.to(device)\n",
    "            polar_code = polar_l_2.encode_plotkin(msg_bits)\n",
    "            noisy_code = polar.channel(polar_code, dec_train_snr)\n",
    "            noise = noisy_code - polar_code\n",
    "            deeppolar_code = polar.deeppolar_encode(msg_bits)\n",
    "            noisy_deeppolar_code = deeppolar_code + noise\n",
    "            SC_llrs, decoded_SC_msg_bits = polar_l_2.sc_decode_new(noisy_code, dec_train_snr)\n",
    "            deeppolar_llrs, decoded_deeppolar_msg_bits = polar.deeppolar_decode(noisy_deeppolar_code)\n",
    "\n",
    "            if k == 0:\n",
    "                epos_deeppolar = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "            else:\n",
    "                epos_deeppolar1 = get_epos(msg_bits, decoded_deeppolar_msg_bits.sign())\n",
    "                epos_SC1 = get_epos(msg_bits, decoded_SC_msg_bits.sign())\n",
    "                epos_deeppolar = epos_deeppolar + epos_deeppolar1\n",
    "                epos_SC = epos_SC + epos_SC1\n",
    "\n",
    "        print(f\"epos_deeppolar: {epos_deeppolar}\")\n",
    "        print(f\"EPOS_SC: {epos_SC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ada1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeppolar_example_test(polar, KO, snr_range, device, info_positions, binary=False, num_examples=10**7, noise_type='awgn'):\n",
    "    bers_KO_test = [0. for _ in snr_range]\n",
    "    blers_KO_test = [0. for _ in snr_range]\n",
    "    bers_SC_test = [0. for _ in snr_range]\n",
    "    blers_SC_test = [0. for _ in snr_range]\n",
    "\n",
    "    kernel = N == KO.ell\n",
    "    num_batches = num_examples // test_batch_size\n",
    "\n",
    "    print(f\"TESTING for {num_examples} examples ({num_batches} batches)\")\n",
    "    for snr_ind, snr in enumerate(snr_range):\n",
    "        total_block_errors_SC = 0\n",
    "        total_block_errors_KO = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        sigma = snr_db2sigma(snr)\n",
    "\n",
    "        try:\n",
    "            for _ in range(num_batches):\n",
    "                msg_bits = 2 * (torch.rand(test_batch_size, K) < 0.5).float() - 1\n",
    "                msg_bits = msg_bits.to(device)\n",
    "                polar_code = polar.encode_plotkin(msg_bits)\n",
    "\n",
    "                if 'KO' in encoder_type:\n",
    "                    if kernel:\n",
    "                        KO_polar_code = KO.kernel_encode(kernel_size, KO.gnet_dict[1][0], msg_bits, info_positions, binary=binary)\n",
    "                    else:\n",
    "                        KO_polar_code = KO.deeppolar_encode(msg_bits, binary=binary)\n",
    "\n",
    "                noisy_code = polar.channel(polar_code, snr, noise_type)\n",
    "                noise = noisy_code - polar_code\n",
    "                noisy_KO_code = KO_polar_code + noise if 'KO' in encoder_type else noisy_code\n",
    "\n",
    "                SC_llrs, decoded_SC_msg_bits = polar.sc_decode_new(noisy_code, snr)\n",
    "                ber_SC = errors_ber(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                bler_SC = errors_bler(msg_bits, decoded_SC_msg_bits.sign()).item()\n",
    "                total_block_errors_SC += int(bler_SC*test_batch_size)\n",
    "\n",
    "                if 'KO' in decoder_type:\n",
    "                    if kernel:\n",
    "                        if decoder_type == 'KO_parallel':\n",
    "                            KO_llrs, decoded_KO_msg_bits = KO.kernel_parallel_decode(kernel_size, KO.fnet_dict[1][0], noisy_KO_code, info_positions)\n",
    "                        else:\n",
    "                            KO_llrs, decoded_KO_msg_bits = KO.kernel_decode(kernel_size, KO.fnet_dict[1][0], noisy_KO_code, info_positions)\n",
    "                    else:\n",
    "                        KO_llrs, decoded_KO_msg_bits = KO.deeppolar_decode(noisy_KO_code)\n",
    "                else:\n",
    "                    KO_llrs, decoded_KO_msg_bits = KO.sc_decode_new(noisy_KO_code, snr)\n",
    "\n",
    "                ber_KO = errors_ber(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                bler_KO = errors_bler(msg_bits, decoded_KO_msg_bits.sign()).item()\n",
    "                total_block_errors_KO += int(bler_KO*test_batch_size)\n",
    "\n",
    "                batches_processed += 1\n",
    "\n",
    "                # Update accumulative results\n",
    "                bers_KO_test[snr_ind] += ber_KO\n",
    "                bers_SC_test[snr_ind] += ber_SC\n",
    "                blers_KO_test[snr_ind] += bler_KO\n",
    "                blers_SC_test[snr_ind] += bler_SC\n",
    "\n",
    "                # Progress logging\n",
    "                if batches_processed % 10 == 0:  # Print every 10 batches\n",
    "                    print(f\"SNR: {snr} dB, Sigma: {sigma:.5f}, Progress: {batches_processed}/{num_batches} batches\", end='\\r')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        # Normalize by actual number of batches processed\n",
    "        bers_KO_test[snr_ind] /= batches_processed\n",
    "        bers_SC_test[snr_ind] /= batches_processed\n",
    "        blers_KO_test[snr_ind] /= batches_processed\n",
    "        blers_SC_test[snr_ind] /= batches_processed\n",
    "\n",
    "        print(f\"\\nSNR: {snr} dB, Sigma: {sigma:.5f}\")\n",
    "        print(f\"SC   - BER: {bers_SC_test[snr_ind]:.6f}, BLER: {blers_SC_test[snr_ind]:.6f}\")\n",
    "        print(f\"Deep - BER: {bers_KO_test[snr_ind]:.6f}, BLER: {blers_KO_test[snr_ind]:.6f}\")\n",
    "\n",
    "    return bers_SC_test, blers_SC_test, bers_KO_test, blers_KO_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "645cc944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING\n",
      "TESTING for 1000000 examples (1000 batches)\n",
      "SNR: -5.0 dB, Sigma: 1.77828, Progress: 1000/1000 batches\n",
      "SNR: -5.0 dB, Sigma: 1.77828\n",
      "SC   - BER: 0.166621, BLER: 0.434991\n",
      "Deep - BER: 0.128525, BLER: 0.545628\n",
      "SNR: -4.0 dB, Sigma: 1.58489, Progress: 1000/1000 batches\n",
      "SNR: -4.0 dB, Sigma: 1.58489\n",
      "SC   - BER: 0.072430, BLER: 0.196684\n",
      "Deep - BER: 0.048552, BLER: 0.265720\n",
      "SNR: -3.0 dB, Sigma: 1.41254, Progress: 1000/1000 batches\n",
      "SNR: -3.0 dB, Sigma: 1.41254\n",
      "SC   - BER: 0.020114, BLER: 0.056063\n",
      "Deep - BER: 0.011277, BLER: 0.084208\n",
      "SNR: -2.0 dB, Sigma: 1.25893, Progress: 1000/1000 batches\n",
      "SNR: -2.0 dB, Sigma: 1.25893\n",
      "SC   - BER: 0.003049, BLER: 0.008610\n",
      "Deep - BER: 0.001547, BLER: 0.017444\n",
      "SNR: -1.0 dB, Sigma: 1.12202, Progress: 1000/1000 batches\n",
      "SNR: -1.0 dB, Sigma: 1.12202\n",
      "SC   - BER: 0.000207, BLER: 0.000573\n",
      "Deep - BER: 0.000142, BLER: 0.002622\n",
      "Test SNRs : [-5.0, -4.0, -3.0, -2.0, -1.0]\n",
      "\n",
      "Test Sigmas : [1.7782794100389228, 1.5848931924611136, 1.4125375446227544, 1.2589254117941673, 1.1220184543019633]\n",
      "\n",
      "BERs of DeepPolar: [0.12852521613240242, 0.04855172968283296, 0.011277351349126547, 0.0015472972996940372, 0.00014189189199532849]\n",
      "BERs of SC decoding: [0.1666208649277687, 0.07242972968891263, 0.020114459443837406, 0.003049216217274079, 0.00020740540567567222]\n",
      "BLERs of DeepPolar: [0.5456279999999997, 0.2657199999999998, 0.08420799999999976, 0.017443999999999977, 0.002621999999999966]\n",
      "BLERs of SC decoding: [0.43499099999999963, 0.19668399999999975, 0.05606299999999989, 0.008609999999999946, 0.0005730000000000004]\n",
      "time = 332.2995735367139 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING\")\n",
    "\n",
    "start = time.time()\n",
    "bers_SC_test, blers_SC_test, bers_deeppolar_test, blers_deeppolar_test = deeppolar_example_test(polar_l_2, polar, snr_range, device, info_positions, binary = binary, num_examples=10**6, noise_type = noise_type)\n",
    "print(\"Test SNRs : {}\\n\".format(snr_range))\n",
    "print(f\"Test Sigmas : {[snr_db2sigma(s) for s in snr_range]}\\n\")\n",
    "print(\"BERs of DeepPolar: {0}\".format(bers_deeppolar_test))\n",
    "print(\"BERs of SC decoding: {0}\".format(bers_SC_test))\n",
    "print(\"BLERs of DeepPolar: {0}\".format(blers_deeppolar_test))\n",
    "print(\"BLERs of SC decoding: {0}\".format(blers_SC_test))\n",
    "print(f\"time = {(time.time() - start)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f42683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BER\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "ok = 0\n",
    "plt.semilogy(snr_range, bers_deeppolar_test, label=\"DeepPolar\", marker='*', linewidth=1.5)\n",
    "\n",
    "plt.semilogy(snr_range, bers_SC_test, label=\"SC decoder\", marker='^', linewidth=1.5)\n",
    "\n",
    "## BLER\n",
    "plt.semilogy(snr_range, blers_deeppolar_test, label=\"DeepPolar (BLER)\", marker='*', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.semilogy(snr_range, blers_SC_test, label=\"SC decoder (BLER)\", marker='^', linewidth=1.5, linestyle='dashed')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=16)\n",
    "plt.ylabel(\"Error Rate\", fontsize=16)\n",
    "if enc_train_iters > 0:\n",
    "    plt.title(\"PolarC({2}, {3}): DeepPolar trained at Dec_SNR = {0} dB, Enc_SNR = {1}dB\".format(dec_train_snr, enc_train_snr, K,N))\n",
    "else:\n",
    "    plt.title(\"Polar({1}, {2}): DeepPolar trained at Dec_SNR = {0} dB\".format(dec_train_snr, K,N))\n",
    "plt.legend(prop={'size': 15})\n",
    "if test_load_path is not None:\n",
    "    os.makedirs('Polar_Results/figures', exist_ok=True)\n",
    "    fig_save_path = 'Polar_Results/figures/new_plot_DeepPolar.pdf'\n",
    "else:\n",
    "    fig_save_path = results_load_path + f\"/Step_{model_iters if model_iters is not None else 'final'}{'_binary' if binary else ''}.pdf\"\n",
    "if not no_fig:\n",
    "    plt.savefig(fig_save_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
